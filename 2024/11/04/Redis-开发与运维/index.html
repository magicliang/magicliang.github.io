<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Redis 开发与运维 | 守株阁</title><meta name="author" content="magicliang"><meta name="copyright" content="magicliang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Redis 特性 Redis 高性能的原因 Redis 的读写性能达到 10w&#x2F;s，主要基于以下原因：  数据主要放在内存中。 Redis 使用距离 OS “层次更近”的 C 语言实现。 Redis 使用单线程架构，没有很高的 lock contention。 IO 多路复用技术 Redis 的代码实现得优雅而兼顾性能  Redis 的数据结构 Redis 本身是 Remote Dictionar">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis 开发与运维">
<meta property="og:url" content="https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/index.html">
<meta property="og:site_name" content="守株阁">
<meta property="og:description" content="Redis 特性 Redis 高性能的原因 Redis 的读写性能达到 10w&#x2F;s，主要基于以下原因：  数据主要放在内存中。 Redis 使用距离 OS “层次更近”的 C 语言实现。 Redis 使用单线程架构，没有很高的 lock contention。 IO 多路复用技术 Redis 的代码实现得优雅而兼顾性能  Redis 的数据结构 Redis 本身是 Remote Dictionar">
<meta property="og:locale">
<meta property="og:image" content="https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/cover.jpg">
<meta property="article:published_time" content="2024-11-04T12:10:16.000Z">
<meta property="article:modified_time" content="2025-10-22T08:01:33.029Z">
<meta property="article:author" content="magicliang">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/cover.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Redis 开发与运维",
  "url": "https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/",
  "image": "https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/cover.jpg",
  "datePublished": "2024-11-04T12:10:16.000Z",
  "dateModified": "2025-10-22T08:01:33.029Z",
  "author": [
    {
      "@type": "Person",
      "name": "magicliang",
      "url": "https://magicliang.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: magicliang","link":"Link: ","source":"Source: 守株阁","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Redis 开发与运维',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="守株阁" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/cover.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">守株阁</span></a><a class="nav-page-title" href="/"><span class="site-name">Redis 开发与运维</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Redis 开发与运维</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-11-04T12:10:16.000Z" title="Created 2024-11-04 20:10:16">2024-11-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-10-22T08:01:33.029Z" title="Updated 2025-10-22 16:01:33">2025-10-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">24.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>82mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>Redis 特性</h1>
<h2 id="redis-高性能的原因">Redis 高性能的原因</h2>
<p>Redis 的读写性能达到 10w/s，主要基于以下原因：</p>
<ul>
<li>数据主要放在内存中。</li>
<li>Redis 使用距离 OS “层次更近”的 C 语言实现。</li>
<li>Redis 使用单线程架构，没有很高的 lock contention。</li>
<li>IO 多路复用技术</li>
<li>Redis 的代码实现得优雅而兼顾性能</li>
</ul>
<h2 id="redis-的数据结构">Redis 的数据结构</h2>
<p>Redis 本身是 Remote Dictionary Server 的简称，其中，老的、常见的数据结构有：</p>
<ul>
<li>字符串</li>
<li>哈希</li>
<li>列表</li>
<li>set（集合）</li>
<li>zset（有序集合）</li>
</ul>
<p>但后来追加了几种新颖的数据机构，包括：bitmap、hyperloglog，更后来更添加了 GEO 地理信息相关的工具。</p>
<p>基于这些数据结构，我们可以实现一些常见的功能：</p>
<ul>
<li>键过期，<strong>可以用来实现缓存，进而实现分布式锁</strong>。</li>
<li><strong>发布订阅功能，进而实现消息系统</strong>（TODO）。</li>
<li>Lua 脚本功能，<strong>可以实现自定义的 Redis 命令</strong>（TODO）。</li>
<li><strong>实现简单的事务功能，能在一定程度上实现事务特性。</strong></li>
<li>提供流水线功能，能够让客户端一次性把一批命令一次性上传到 Redis 里，能够合并 IO 并减少网络开销。<strong>流水线不同于事务特性，倒像是 batch</strong>。</li>
</ul>
<p>redis 有一个很优秀的实现，不需要像 memcache 一样依赖于 libevent 之类的类库（TODO）。</p>
<h2 id="redis-应用场景">Redis 应用场景</h2>
<ul>
<li>
<p>缓存：搭配使用自带的缓存（1）超时时间（2）<strong>最大内存控制加内存溢出后的淘汰策略</strong>（TODO），可以制造一个稳定的缓存集群。</p>
</li>
<li>
<p>排行榜（社交网络数据存储）（todo）：有序数据集合（sorted set）可以制造<strong>各种维度</strong>的排行榜。</p>
</li>
<li>
<p>计数器应用（社交网络数据存储）：不要使用 mysql 来制造 counter</p>
</li>
<li>
<p>其他社交网络数据存储：用 8 种数据结构可以比较合理地实现、存储各种社交网络里的踩、赞、粉丝、好友数据：Redis 自带比较丰富的集合操作。</p>
</li>
<li>
<p>消息队列系统：消息队列可以拿来做业务解耦，非实时削峰。Redis 有新的 pub/subscribe 和 blocking  queue 功能。</p>
</li>
</ul>
<h2 id="redis-不适合的应用场景">Redis 不适合的应用场景</h2>
<p>Redis 本身是热存储为主，应该存热数据为主，<strong>应该尽量区分热数据和冷数据</strong>，把冷数据排出在热数据之外，这样才能合理地提高内存利用效率。</p>
<p>对于食品网站，视频信息是跨业务线的热数据，而每个电视剧的观众信息，则是偏冷的数据。</p>
<p>Redis 本身不支持传统关系型数据库<strong>复杂的 CRUD 复杂查询语句</strong>，更不适合 OLAP 场景。</p>
<h2 id="关于-redis-我们不知道的事情">关于 Redis 我们不知道的事情</h2>
<p><strong>不要只把 redis 当做 get、set、del 的黑盒，开发和运维同样重要。</strong></p>
<h2 id="redis-的性能黑洞">Redis 的性能黑洞</h2>
<ul>
<li>keys 是读操作负荷非常重的操作，不适合对成千上万个键进行操作。
<ul>
<li>KEYS 命令会遍历所有键，时间复杂度为 O(N)，N 为键的总数</li>
<li>Redis 是单线程模型，KEYS 命令执行期间会阻塞其他命令-大 key、长命令都有类似的问题</li>
<li>匹配到的结果会一次性返回，占用大量内存</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查找某一个模式的所有 key</span><br><span class="hljs-built_in">eval</span> <span class="hljs-string">&quot;return #redis.pcall(&#x27;keys&#x27;, &#x27;csrf:*&#x27;)&quot;</span> 0<br></code></pre></td></tr></table></figure>
<ul>
<li>rdb dump 本身对于写操作量很大的集群，是一个很容易让进程 hang 住的操作。</li>
</ul>
<h1>toolkit</h1>
<h2 id="redis-server">redis-server</h2>
<p>常用的配置文件内容：</p>
<ul>
<li>port 一般是 6379</li>
<li>logfile 日志文件（redis 的日志文件和 Kafka 不一样，和存储文件是分离的）</li>
<li>dir Redis 工作目录（存放持久化和日志文件）</li>
<li>daemonize 是否以守护进程的方式来启动 Redis</li>
</ul>
<p>redis 的 minor 版本号如果是奇数，则含有实验性 feature 的非稳定版本；如果是偶数，则是稳定版本。所以我们应该在生产环境使用偶数版本，而在实验性环境里使用奇数版本。</p>
<h2 id="redis-cli">redis-cli</h2>
<p>cli 有两种工作形式：interactive 和 non-interactive。</p>
<p>使用 redis-cli 关闭 redis 的时候，redis 会做优雅关闭的操作，优雅关闭主要包括：</p>
<ol>
<li>断开客户端连接。</li>
<li>存储数据到 rdb 文件。</li>
</ol>
<p>所以要尽量用 shutdown 命令，而不要直接 kill-大部分的devops场景下我们是不应该kill一个集群的，这会让线上服务降级。</p>
<h2 id="redis-benchmark">redis-benchmark</h2>
<p>基准测试工具</p>
<h2 id="redis-check-aof">redis-check-aof</h2>
<p>AOF 持久化文件校验和<strong>修复</strong>工具</p>
<h2 id="redis-check-rdb">redis-check-rdb</h2>
<p>redis RDB 持久化文件检测和<strong>修复</strong>工具</p>
<h2 id="redis-sentinel">redis-sentinel</h2>
<p>启动 redis 哨兵</p>
<h2 id="其他-redis-模块">其他 redis 模块</h2>
<p>neural-redis      Online trainable neural networks as Redis data types.  把可训练的神经网络作为 Redis 的数据类型。<br>
RediSearch     Full-Text search over Redis 在 Redis 之上的全文本搜索引擎<br>
RedisJSON      A JSON data type for Redis Redis 的 Json 数据类型</p>
<p>rediSQL     A redis module that provide full SQL capabilities embedding SQLite 通过嵌入 SQLite 提供全 SQL 支持能力<br>
redis-cell     A Redis module that provides rate limiting in Redis as a single command.   支持在 Redis 中一键限流。<br>
RedisGraph     A graph database with a Cypher-based querying language using sparse adjacency matrices 一个使用基于密码的 使用稀疏邻接矩阵查询语言的图数据库<br>
RedisML     Machine Learning Model Server 机器学习模型服务器<br>
RedisTimeSeries      Time-series data structure for redis  Redis 的时序数据库<br>
RedisBloom     Scalable Bloom filters  Redis 的可伸缩的布隆过滤器<br>
cthulhu     Extend Redis with JavaScript modules Redis 的 JavaScript 模块<br>
redis-cuckoofilter      Hashing-function agnostic Cuckoo filters.     哈希函数的不可知布谷过滤器（？）<br>
RedisAI     A Redis module for serving tensors and executing deep learning graphs   一个提供张量和执行深度图的 Redis 模块<br>
redis-roaring     Uses the CRoaring library to implement roaring bitmap commands for Redis.  使用 CRoaring 库实现 Redis 的 roaring 位图命令<br>
redis-tdigest     t-digest data structure wich can be used for accurate online accumulation of rank-based statistics such as quantiles and cumulative distribution at a point. 一个可以被用来精确累积基于排名的统计（诸如分位点或者某一个点的累积分布）的 t 摘要数据结构<br>
Session Gate      Session management with multiple payloads using cryptographically signed tokens.<br>
使用密码学签名的令牌的多重负载的会话管理</p>
<p>countminsketch    An apporximate frequency counter<br>
一个近似频率计数器</p>
<p>ReDe     Low Latancy timed queues (Dehydrators) as Redis data types. 低延迟的计时队列<br>
topk     An almost deterministic top k elements counter<br>
一个有确定性的 topk 元素计数器</p>
<p>commentDis     Add comment syntax to your redis-cli scripts.</p>
<p>redis 客户端的评论语法</p>
<h1>数据结构和内部编码</h1>
<p>如前文所述，Redis 自带数据类型包括：string、hash、list、set 和 zset，<strong>但它们实际上只是 redis 的外部数据类型</strong>。Redis 还自带一套内部的编码实现，可以通过以下命令查询键的实际内部编码类型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 组合命令</span><br>object encoding hello<br><span class="hljs-string">&quot;embstr&quot;</span><br></code></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_RAW 0        <span class="hljs-comment">// 简单动态字符串，用于保存键值对的键和配置文件中的参数。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_INT 1        <span class="hljs-comment">// 整型值，用于优化小整数的内存使用。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_HT 2         <span class="hljs-comment">// 哈希表，用于存储普通哈希对象的字段和值。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_ZIPMAP 3     <span class="hljs-comment">// 缩字典，这是一种特殊类型的哈希表，用于优化小哈希对象的内存使用。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_LINKEDLIST 4 <span class="hljs-comment">// 双端链表，用于存储列表键。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_ZIPLIST 5    <span class="hljs-comment">// 压缩列表，用于优化小列表或者小哈希对象的内存使用。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_INTSET 6     <span class="hljs-comment">// 整数集合，用于优化只包含整数元素的集合的内存使用。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_SKIPLIST 7   <span class="hljs-comment">// 跳跃表和字典，用于存储有序集合键。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_EMBSTR 8     <span class="hljs-comment">// 对于长度小于44字节的字符串，Redis选择使用此特殊的编码方式。</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> OBJ_ENCODING_QUICKLIST 9  <span class="hljs-comment">// 对于列表对象（list object）的一种编码方式。quicklist是ziplist和双向链表的混合体。</span></span><br></code></pre></td></tr></table></figure>
<p><img src="value.png" alt="type-and-encoding"><br>
<a href="redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E9%83%A8%E7%BC%96%E7%A0%81.xmind">redis的数据结构和内部编码.xmind</a><br>
<img src="redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="redis的数据结构"><br>
<a href="redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.xmind">redis的数据结构.xmind</a></p>
<p>Redis的列表和哈希表都是采用链表结构实现的。而有序集合则采用了跳跃表(Skip List)这种高效的数据结构。</p>
<p>这些数据结构都经过了精心设计和优化，以满足各种场景下的应用需求。例如，链表结构适合<strong>频繁地添加和删除元素</strong>，而<strong>跳跃表结构则适合排序和查找</strong>。</p>
<p>ziplist 对复杂数据结构几乎是万能的。<strong>他的特点是比较节省内存，但在数据元素较多的情况下性能比较容易下降。</strong></p>
<h1>常用命令</h1>
<p><img src="Redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.png" alt="Redis常用命令"><br>
<a href="Redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.xmind">Redis常用命令</a></p>
<h2 id="全局命令">全局命令</h2>
<h3 id="查看所有键">查看所有键</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看所有键，支持 glob 风格通配符</span><br>keys *<br></code></pre></td></tr></table></figure>
<p>这个命令会不加区别地，**做全局的键扫描，返回且只返回键。**它的时间复杂度是O（N），线上环境因为无法预测键的数量，应该禁用这个命令。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">keysCommand</span><span class="hljs-params">(client *c)</span> &#123;<br>    dictIterator *di; <br>    dictEntry *de;<br>    sds pattern = c-&gt;argv[<span class="hljs-number">1</span>]-&gt;ptr; <span class="hljs-comment">// 获取我们输入的pattern</span><br>    <span class="hljs-type">int</span> plen = sdslen(pattern), allkeys;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> numkeys = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">void</span> *replylen = addDeferredMultiBulkLength(c); <br><br>    di = dictGetSafeIterator(c-&gt;db-&gt;dict); <span class="hljs-comment">// 初始化一个安全迭代器</span><br>    allkeys = (pattern[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;*&#x27;</span> &amp;&amp; pattern[<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;\0&#x27;</span>); <span class="hljs-comment">// 判断是否返回全部keys的集合</span><br>    <span class="hljs-keyword">while</span>((de = dictNext(di)) != <span class="hljs-literal">NULL</span>) &#123; <span class="hljs-comment">// 遍历整个键空间字典</span><br>        sds key = dictGetKey(de); <span class="hljs-comment">// 获取key值</span><br>        robj *keyobj;<br><br>        <span class="hljs-comment">// 如果是返回全体键的集合，或者当前键与我们给定的pattern匹配，那么添加到返回列表</span><br>        <span class="hljs-keyword">if</span> (allkeys || stringmatchlen(pattern,plen,key,sdslen(key),<span class="hljs-number">0</span>)) &#123;<br>            keyobj = createStringObject(key,sdslen(key));<br>            <span class="hljs-keyword">if</span> (!keyIsExpired(c-&gt;db,keyobj)) &#123; <span class="hljs-comment">// 筛选出没有过期的键</span><br>                addReplyBulk(c,keyobj); <span class="hljs-comment">// 添加到返回列表</span><br>                numkeys++; <span class="hljs-comment">// 返回键的数量++</span><br>            &#125;<br>            decrRefCount(keyobj); <br>        &#125;<br>    &#125;<br>    dictReleaseIterator(di); <span class="hljs-comment">// 释放安全迭代器</span><br>    setDeferredMultiBulkLength(c,replylen,numkeys); <span class="hljs-comment">// 设置返回值的长度</span><br>&#125;<br></code></pre></td></tr></table></figure>
<ol>
<li><code>while((de = dictNext(di)) != NULL)</code>这个遍历操作的时间复杂度是最高的。</li>
<li>整个请求没有使用类似</li>
</ol>
<h3 id="键总数">键总数</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看所有键</span><br>dbsize<br></code></pre></td></tr></table></figure>
<p>这个操作的性能是 O(1)，也就意味着可以直接被线上使用。</p>
<p>它可以作为查询全部数据以前的预优化，至少全局的记录数量可以预先提取出来，以获得分页查询的依据。</p>
<h3 id="检查键是否存在">检查键是否存在</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 确认 java 作为一个键是否存在</span><br>exists java<br></code></pre></td></tr></table></figure>
<p>如果存在返回 1，不存在返回 0。</p>
<p><strong>Redis 的 API 倾向于返回数字而不是布尔值</strong>：在存在多个候选返回值的时候，redis会返回语义更加丰富的返回值。如返回成功或失败，可以直接返回true或false，但返回0既可以表示失败，也可以表示操作的操作数（operand）为0，而返回非0不仅可以告诉我们操作成功了，而且还会精确地告诉我们操作了多少个对象，可谓一举两得。这种设计思路遍布 Redis API 中。</p>
<p>问题：估计有个全局优化，能够不返回具体值的情况下确认是否存在某个 key。</p>
<h3 id="删除键">删除键</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 删除 java 键</span><br>del java<br></code></pre></td></tr></table></figure>
<p>如果删除成功则返回 1，否则返回 0</p>
<h3 id="键过期">键过期</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> hello world<br><br><span class="hljs-built_in">set</span> hello world EX 10 NX<br><br>expire hello 10<br></code></pre></td></tr></table></figure>
<p>set 是为比较少的返回“OK”的 command。</p>
<p>因为这个命令有复合的EX、PX、NX、XX等选项，所以其他相对的命令（如SETNX）可能会被设为过期，且被移除。</p>
<p>expire 命令的结果也是 0 和 1。在 redis 中，最早支持的时间单位为second，如果不特别指定单位，指定时间时数字都代表秒。这个策略可以推广到其他系统里。美团的 redis 系统里面的默认时间单位就是秒。如果值是负数，键会立即被删除。</p>
<p>如果使用了 expire 命令，还有一个可以拿来轮询的 ttl 命令，可以告诉我们键的剩余时间：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">ttl hello<br>(<span class="hljs-built_in">integer</span>) 7<br><br>......<br><span class="hljs-comment"># 如果返回-2，意味着键已被删除</span><br>ttl hello<br>(<span class="hljs-built_in">integer</span>) -2<br><br><span class="hljs-comment"># 这时候试着取健值，则得到 nil</span><br>get hello<br>(nil) <br></code></pre></td></tr></table></figure>
<h3 id="键的数据结构类型">键的数据结构类型</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> a b<br><span class="hljs-built_in">type</span> a <br>string<br><br><span class="hljs-comment"># rpush 会强制转化一个 key 到 list 类型</span><br>rpush mylist a b c<br><span class="hljs-comment"># 返回结果为 7</span><br>(<span class="hljs-built_in">integer</span>) 7<br><span class="hljs-built_in">type</span> mylist<br>list<br><br><span class="hljs-comment"># 不存在的键</span><br><span class="hljs-built_in">type</span> non_exist_key<br><span class="hljs-comment"># 返回 none</span><br></code></pre></td></tr></table></figure>
<h2 id="字符串命令">字符串命令</h2>
<h3 id="设-取值">设/取值</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> hello world<br>exsts hello<br>setnx hello wolrd<br><span class="hljs-comment"># 若存在才设值</span><br><span class="hljs-built_in">set</span> hello jedix xx<br><br>get hello<br></code></pre></td></tr></table></figure>
<h3 id="批量设-取值">批量设/取值</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">mset a 1 b 2 c 3<br>get a<br>get b<br>get c<br><br><span class="hljs-comment"># 取不到返回nil</span><br>mget a b c d<br></code></pre></td></tr></table></figure>
<p>如果使用平凡的取/设值命令，时间开销为：</p>
<p>总开销= n * (一次网络开销 + 一次操作开销)</p>
<p>如果使用批量取/设值命令，时间开销为：</p>
<p>总开销= 一次网络开销 + n * (一次操作开销)</p>
<p>redis每秒可以处理上万的读写操作，相当于每次读写操作的开销小于0.1毫秒，而网络开销很难低于1毫秒。根据阿姆达尔定律，网络开销的减少才是性能优化的大头。</p>
<h3 id="加-减值">加/减值</h3>
<p>因为 Redis 本身是单线程架构，所以本身不需要其他设计中的悲观锁或者 cas 操作保证操作正确性。<br>
返回的自增结果永远是正确的。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 值不是整数，返回错误</span><br><span class="hljs-comment"># 值是整数，返回自增后的结果</span><br><span class="hljs-comment"># 值不存在，按照结果为0自增，返回结果1</span><br>incr java<br><br>decr java<br><br>incrby java 10<br>decrby java 5<br><span class="hljs-comment"># 没有 decrbyfloat 命令</span><br>incrbyfloat java 4.3<br></code></pre></td></tr></table></figure>
<p><strong>注意，java里涉及数字的缺省值都是0，而且只是缺省值，并不是终值。</strong></p>
<h3 id="位操作命令">位操作命令</h3>
<p>背景见：<a target="_blank" rel="noopener" href="https://redis.io/topics/data-types-intro#bitmaps">https://redis.io/topics/data-types-intro#bitmaps</a></p>
<p>Redis 并不只是一个平凡的 kv 数据存储，而是一个拥有许多数据类型的服务器。其中有一种类型是用 String 来解释为位图-“Bitmaps are not an actual data type, but a set of bit-oriented operations defined on the String type”。字符串是safe blobs，最大长度是 512 MB，恰好等于一个2的32次方的位图。字符串的英文字符，都符合（comply to）ascii编码。</p>
<p>所谓的位图，可以用紧凑的方式来表示一个大的 true/false 值域，而且这个 true/false 的点还带有 position 信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 把键的 offset 的位取出来，如果offset无值，则取0</span><br>getbit hello 10<br><span class="hljs-comment"># 把键的 offset 的位设值，只能设值0或1，返回旧值</span><br>setbit hello 1000 1<br><span class="hljs-comment"># Number of set bits in the range</span><br>bitcount hello<br><br><span class="hljs-comment"># 1st position of 1 or 0 in the key in range. O(N)</span><br>BITPOS hello  0<br><br><span class="hljs-comment"># 与或非</span><br>SET key1 <span class="hljs-string">&quot;foobar&quot;</span><br>SET key2 <span class="hljs-string">&quot;abcdef&quot;</span><br><br><span class="hljs-comment"># and or not xor</span><br>BITOP AND dest key1 key2<br>GET dest<br></code></pre></td></tr></table></figure>
<h3 id="其他命令">其他命令</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 返回最后结果的长度</span><br>append hello 123<br><br><span class="hljs-comment"># 返回结果的长度</span><br>strlen hello<br><br><span class="hljs-comment"># 原子化地设值并返回旧值</span><br>getset hello world123<br><br><span class="hljs-comment"># 设值指定位置的字符，返回修改后的字符串长度</span><br>setrange hello 1 a<br><br><span class="hljs-comment"># 设定指定位置的值，并返回。start 和 end 都是闭区间</span><br>getrange hello 1 2<br></code></pre></td></tr></table></figure>
<h2 id="哈希命令">哈希命令</h2>
<h3 id="设-取值">设/取值</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 设值，在 key 和 value 之间加入了一个 field</span><br>hset user:1 name tom<br><br><span class="hljs-comment"># 取值，在 key 和 value 之间加入了一个 field</span><br>hget user:1 name<br><br><span class="hljs-comment"># 删除 field，而不删除key</span><br>hdel user:1 name<br><br><span class="hljs-comment"># 计算 key 数目</span><br>hlen user:1<br><br><span class="hljs-comment"># 若 field 不存在，则设值</span><br>hsetnx user:1 name jerry<br></code></pre></td></tr></table></figure>
<p>注意，len 往往是计数，而 strlen 往往是计值。</p>
<h3 id="批量设-取值">批量设/取值</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 批量设值</span><br>hmset user:1 name tom age 20 city beijing<br><br><span class="hljs-comment"># 批量获取</span><br>hmget user:1 name age city<br></code></pre></td></tr></table></figure>
<p>对于mset的升级，就是把数据结构写在最前头。set -&gt; mset -&gt; hmset。</p>
<h3 id="数值操作">数值操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 按照指定值加值，这里的命令没有缺省被加数1了，必须显式指定被加数</span><br>hincrby user:1 age 10<br><br><span class="hljs-comment"># 按照指定值加浮点值，这里的命令没有缺省被加数1了，必须显式指定被加数</span><br>hincrbyfloat user:1 age 5.1<br></code></pre></td></tr></table></figure>
<h3 id="其他操作">其他操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 判断一个 field 是否存在</span><br>hexists user:1 name<br><br><span class="hljs-comment"># 遍历一个 key 下面所有的 fields，实际上应该叫 hfields 比较恰当。时间复杂度为O(N)。一个key下面的N比较小的时候，可以直接在生产上使用。</span><br>hkeys user:1<br><br><span class="hljs-comment"># 遍历一个 key 下面所有的 fields 的值</span><br>hvals user:1<br><br><span class="hljs-comment"># 遍历一个 key 下面所有的 fields 和值</span><br>hgetall user:1<br><br><span class="hljs-comment"># 获取一个 key 下面指定 field 的字符串长度</span><br>hstrlen user:1 name<br></code></pre></td></tr></table></figure>
<h2 id="列表命令">列表命令</h2>
<h3 id="增删操作">增删操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 从右至左插入元素，这个命令天然就是多参数的</span><br>rpush listkey c b a<br><br><span class="hljs-comment"># 从左至右插入元素</span><br>lpush listkey c b a<br><br><span class="hljs-comment"># 按范围取元素。index从左至右为0至N-1，从右至左为-1至-N。</span><br>lrange listkey 0 -1<br><br><span class="hljs-comment"># 在枢轴前后插入元素，注意方向和前后的关系</span><br>linsert listkey before b  java<br><br><span class="hljs-comment"># 获取指定 index 的元素</span><br>LINDEX listkey -1<br><br><span class="hljs-comment"># 获取指定 key 的 size</span><br>llen listkey<br><br><span class="hljs-comment"># 列表类型总是没有删除操作，而使用弹出操作作为替代品</span><br>lpop listkey<br><br><span class="hljs-comment"># 从左至右删除元素，1表示从左至右删除1个元素，0表示删除全部元素，-1表示从右至左删除1个元素</span><br>lrem listkey 1 a<br><br><span class="hljs-comment"># 保留列表的1到最后一个元素-即去掉第一个元素</span><br>LTRIM listkey 1 -1<br><br><span class="hljs-comment"># 设置特定 index 的元素的 value，这里的 index 不能 out of bound。</span><br>LSET listkey 1 python<br></code></pre></td></tr></table></figure>
<p>redis里涉及区间的 end，都是闭区间的 end。</p>
<h3 id="阻塞操作">阻塞操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 从左至右阻塞操作，第一个返回值总是 listkey1，只要有一个元素可以弹出，blpop就会立即返回。如果时间参数为0，则无限阻塞。可以使用这个命令制造一个延时队列、阻塞队列。blpop 可以同时监听多个 key，类似 selector 方案。每个 value 只能在多个客户端中被 pop 一次。</span><br>blpop listkey1 listkey2 20<br></code></pre></td></tr></table></figure>
<h2 id="集合命令">集合命令</h2>
<h3 id="增删操作">增删操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 往集合里加元素，因为是无序的，所以也无所谓insert和左右</span><br>sadd myset a b c d<br><br><span class="hljs-comment"># 指名道姓直接删除集合里的元素</span><br>srem myset a b<br><br><span class="hljs-comment"># 计算集合的大小，注意这不是len。直接使用内置变量，所以其操作时间复杂度为 O(1)。</span><br>scard myset<br><br><span class="hljs-comment"># 确认 d 是不是 myset 的元素</span><br>sismember myset d<br><br><span class="hljs-comment"># 从集合中随机弹出1个元素。因为强调 set 是无序的，所以产生了这个操作。</span><br>srandmember myset 1<br><span class="hljs-comment"># 默认值为1</span><br>srandmember myset<br><br><span class="hljs-comment"># 从集合中弹出一个元素，元素会被删除</span><br>spop myset 1<br><br><span class="hljs-comment"># 获取集合中的所有元素</span><br>smembers myset<br></code></pre></td></tr></table></figure>
<h3 id="集合操作">集合操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 求交集</span><br>sinter myset1 myset2<br><br><span class="hljs-comment"># 求并集</span><br>sunion myset1 myset2<br><br><span class="hljs-comment"># 求差集</span><br>sdiff myset1 myset2<br><br><span class="hljs-comment"># 因为集合操作比较耗时（m*n的乘法二项式复杂度），求交集并存储到目标key里。</span><br>sinterstore interset myset1 myset2<br><br><span class="hljs-comment"># 因为集合操作比较耗时（m*n的乘法二项式复杂度），求并集并存储到目标key里。</span><br>sunionstore unionset myset1 myset2<br><br><span class="hljs-comment"># 因为集合操作比较耗时（m*n的乘法二项式复杂度），求差集并存储到目标key里。</span><br>sdiff myset1 myset2<br></code></pre></td></tr></table></figure>
<h2 id="有序集合命令">有序集合命令</h2>
<h3 id="增删操作">增删操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 给一个 zset 增加，成员，先写score再写元素。因为有这个排序操作，这个操作的时间复杂度是O(log(n))。也支持 nx、xx、ch、incr 几个 argument。</span><br>zadd user:ranking 250 tom 1 kris 91 mike 200 frank 220 tim 250 martin<br><br><span class="hljs-comment"># 获取集合大小。时间复杂度O(1)。</span><br>zcard user:ranking<br><br><span class="hljs-comment"># 获取集合中指定成员的分数。如果分数不同，由低到高输出。如果分数相同，按照成员名称的字典序（而不是lru）来输出成员</span><br>zscore user:ranking tom<br><br><span class="hljs-comment"># 获取集合中指定成员的从低到高排名</span><br>zrank user:ranking tom<br><br><span class="hljs-comment"># 获取集合中指定成员的从高到低排名</span><br>zrevrank user:ranking tom<br><br><span class="hljs-comment"># 删除集合中指定成员</span><br>zrem user:ranking tom<br><br><span class="hljs-comment"># 增加集合中指定成员的score</span><br>zincrby user:ranking 10 tom<br><br><span class="hljs-comment"># 返回集合中从低到高指定排名的成员，withscores 可以被去掉</span><br>zrange user:ranking 0 1 withscores<br><br><span class="hljs-comment"># 返回集合中从高到低指定排名的成员，withscores 可以被去掉</span><br>zrevrange user:ranking 0 1 withscores<br><br><span class="hljs-comment"># 返回集合中从低到高指定分数范围的成员，withscores 可以被去掉。此外也支持开、闭区间、正负无穷参数。</span><br>zrangebyscore user:ranking 200 250 withscores<br><br><span class="hljs-comment"># 返回集合中从高到低指定分数范围的成员（注意，参数是反的），withscores 可以被去掉。此外也支持开、闭区间、正负无穷参数。</span><br>zrevrangebyscore user:ranking 250 200 withscores<br><br><span class="hljs-comment"># 返回集合中指定分数段的成员的数量</span><br>zcount user:ranking 200 250<br><br><span class="hljs-comment"># 删除集合中指定排名的成员</span><br>zremrangebyrank user:ranking 0 2<br></code></pre></td></tr></table></figure>
<h3 id="集合操作">集合操作</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 交集聚合存储操作，2代表了要做交集的 keys 数目。如果不指定聚合类型，结果就是加权后相加sum。</span><br>zinterstore user:ranking:1_inter_0 2 user:ranking:1 user:ranking:2<br><br><span class="hljs-comment"># 交集聚合存储操作，2代表了要做交集的 keys 数目。1代表集合1的权重，0.5代表集合2的权重。</span><br>zinterstore user:ranking:1_inter_0 2 user:ranking:1 user:ranking:2 weights 1 0.5 aggregate max<br><br><span class="hljs-comment"># 并集聚合存储操作</span><br>zunionstore user:ranking:1_inter_0 2 user:ranking:1 user:ranking:2<br></code></pre></td></tr></table></figure>
<h2 id="键管理">键管理</h2>
<h3 id="单个键管理">单个键管理</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br><span class="hljs-comment"># 换 key 名称，rename会删除掉 java 的旧值，所以值比较大的时候可能会阻塞 redis 实例（类似关系型数据库的 alter）。python会直接返回nil。</span><br>rename python java<br><br><span class="hljs-comment"># 如果key不存在，则换 key 名称。这是为了防止误操作。</span><br>renamenx python java<br><br><span class="hljs-comment"># 随机返回一个key</span><br>randomkey<br><br><span class="hljs-comment"># 让一个键在一个特定的秒级时间戳过期</span><br>expireat hello 2000<br><br><span class="hljs-comment"># 让一个键在10毫秒后过期</span><br>pexpire hello 10<br><br><span class="hljs-comment"># 清除过期时间</span><br>persist hello<br></code></pre></td></tr></table></figure>
<p>注意，如果字符串的value为string类型，set 操作也会去除过期时间。</p>
<p>Redis不支持二级数据结构（例如列表或者哈希）里元素的过期时间。</p>
<h3 id="迁移键">迁移键</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在一个 redis 实例内的多个 db 迁移。</span><br>move key db<br><br><span class="hljs-comment"># 先导出一个键</span><br>dump hello<br><span class="hljs-comment"># 再另一个实例里面重建key。0代表没有ttl，非0代表ttl。</span><br>restore hello 0  <span class="hljs-string">&quot;\x00\x05world\t\x00\xc9#mH\x84/\x11s&quot;</span><br><br><span class="hljs-comment"># migrate 原子化地结合了 dump、restore和del的操作，可以支持多个键操作。批量地迁移键到目标主机和端口，超时时间为5000.</span><br>migrate 127.0.0.1 6380 <span class="hljs-string">&quot;&quot;</span> 0 5000 keys key1 key2 key3<br></code></pre></td></tr></table></figure>
<h3 id="遍历键">遍历键</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 遍历 videos 模式的键值对，删除键</span><br>redis-cli keys videos | xargs redis-cli del<br></code></pre></td></tr></table></figure>
<p>keys命令本身很容易阻塞redis节点，在以下情况下可以考虑使用：</p>
<ul>
<li>在不对外服务的从节点上使用。但会影响主从复制。</li>
<li>如果确认键值总数比较少，可以使用以下命令</li>
</ul>
<p>其他情况下，应该考虑使用 scan 命令，渐进式地遍历所有键。</p>
<p>scan的模式为： scan cursor [match pattern] [count number]</p>
<p>其中 cursor 是必须的，从0开始，到0又结束，周而复始。count 默认为10。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 返回若干个键，而不是值。scan并不是并发安全的。相当于隔离性非常差的事务。</span><br>scan 0<br><br><span class="hljs-comment"># 衍生命令</span><br>HSCAN hello 0<br>SSCAN hello 0<br>zscan hello 0<br></code></pre></td></tr></table></figure>
<h3 id="数据库管理">数据库管理</h3>
<p>关系型数据库用字符来区分不同的数据库名不同。Redis只是使用数字来区分不同的数据库。<br>
Redis 默认拥有16个数据库，默认选中的数据库的 dbindex 是0。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 切换到 db 0</span><br>SELECT 0<br></code></pre></td></tr></table></figure>
<p>未来的 redis-cluster 功能默认只使用 db 0。不同的db之间的数据（KV）是相互隔离的。但用不同的 redis instance 一样可以实现这个效果。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 清除当前db的所有数据！慎用</span><br>flushdb<br><span class="hljs-comment"># 清除所有db的所有数据！慎用</span><br>flushall<br></code></pre></td></tr></table></figure>
<h1>Redis小功能</h1>
<h2 id="慢查询">慢查询</h2>
<h3 id="命令执行的典型过程">命令执行的典型过程</h3>
<ol>
<li>发送命令</li>
<li>命令排队</li>
<li>命令执行</li>
<li>返回结果</li>
</ol>
<p>慢查询值统计 step3 的执行时间，<strong>即使没有慢查询，客户端也可能超时</strong>。</p>
<h3 id="阈值参数">阈值参数</h3>
<p>相关的阈值参数分别为：<code>slowlog-log-slower-than</code>和<code>slowlog-max-len</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 设置超时时间为10000微妙。设置为0则记录所有查询，设置为-1则不记录任何信息</span><br>config <span class="hljs-built_in">set</span> slowlog-log-slower-than 10000<br><br><span class="hljs-comment"># 设置记录慢查询的记录集大小。这个集采用先进先出的淘汰逻辑</span><br>config <span class="hljs-built_in">set</span> slowlog-max-len 1000<br><br><span class="hljs-comment"># 获取所有慢日志</span><br>SLOWLOG get<br><br><span class="hljs-comment"># 获取时间上最近的一条慢日志</span><br>SLOWLOG get 1<br><br><span class="hljs-comment"># 获取所有慢查询数量</span><br>SLOWLOG len<br><br><span class="hljs-comment"># 重置慢查询日志列表</span><br>SLOWLOG reset<br></code></pre></td></tr></table></figure>
<h3 id="查询结果">查询结果</h3>
<blockquote>
<ol>
<li>
<ol>
<li>(integer) 7</li>
</ol>
</li>
</ol>
</blockquote>
<ol start="2">
<li>(integer) 1570264725</li>
<li>(integer) 7</li>
<li>
<ol>
<li>“SLOWLOG”</li>
<li>“get”</li>
<li>“0”</li>
</ol>
</li>
<li>“127.0.0.1:49802”</li>
<li>“”</li>
</ol>
<p>慢日志的格式为：<br>
1 慢日志id<br>
2 日志发生的时间戳<br>
3 命令耗时<br>
4 命令详情<br>
5 客户端地址<br>
6 客户端的名称</p>
<p>参考：<a target="_blank" rel="noopener" href="https://redis.io/commands/slowlog">https://redis.io/commands/slowlog</a></p>
<h3 id="最佳实践">最佳实践</h3>
<p>1 调大 slowlog-log-slower-than 到1毫秒左右，可以保证 1000 的QPS（实际上在单台 mac pro上的 rps 可以达到接近10万）。<br>
2 调大 slowlog-max-len，并定期把其中的数据取出来存入其他存储层。<br>
3 如果发生客户端超时，注意对照相应的时间点，注意查看是不是存在慢查询导致级联失败。</p>
<h2 id="redis-shell">Redis Shell</h2>
<h3 id="redis-cli">redis-cli</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 重复执行命令3次</span><br>redis-cli -r 3 ping<br><br><span class="hljs-comment"># 重复每隔1秒执行命令5次</span><br>redis-cli -r 5 -i 1 ping<br><br><span class="hljs-comment"># 重复每隔10毫秒执行命令5次</span><br>redis-cli -r 5 -i 0.01 ping<br><br><span class="hljs-comment"># 定时输出内存使用状况</span><br>redis-cli -r 100 -i 1 info | grep used_memory_human<br><br><span class="hljs-comment"># 从 stdin 读取数据作为 redis-cli 的最后一个参数</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;world&quot;</span> | redis-cli -x <span class="hljs-built_in">set</span> hello<br><br><span class="hljs-comment"># -c 在 Redis Cluster节点中使用</span><br><br><span class="hljs-comment"># -a 使用auth，可以不用手动输入 auth 命令</span><br><br><span class="hljs-comment"># --scan --pattern 扫描指定模式的键，相当于使用 scan 命令</span><br><br><span class="hljs-comment"># --slave 把当前客户端模拟成当前Redis节点的从节点，可以用来获取当前 Redis节点的更新操作。基本相当于一个全量的事件监听消费者（又像 wireshark）。</span><br><br><span class="hljs-comment">#  --rdb 可以强制当前系统执行一次 dump 到 rdb 中的操作。</span><br>redis-cli --rdb dump1.rdb<br><br><span class="hljs-comment"># 性能调优的时候很有用，会输出现有节点里最大的 key 的统计数据</span><br>redis-cli --bigkeys<br><br><span class="hljs-comment"># --pipe 把命令封装成 Redis通信协议定义的数据格式。</span><br><span class="hljs-built_in">cat</span> pipeline.txt | redis-cli --pipe<br><br><span class="hljs-comment"># 对 lua 脚本求值，注意和 pipe 区别。它消费的内容是lua脚本，pipe消费的脚本是 redis 命令</span><br>redis-cli --<span class="hljs-built_in">eval</span><br><br><span class="hljs-comment"># 对网络延迟进行采样</span><br>redis-cli --latency<br>redis-cli --latency-history<br>redis-cli --latency-dist<br><br><span class="hljs-comment"># 输出实时统计数据，类似 info 命令</span><br>redis-cli --<span class="hljs-built_in">stat</span><br><br><span class="hljs-comment"># --no-raw 返回原始格式（可以看到编码、格式化以前的字符，不可见字符），--raw返回格式化后的格式（human readable，看不见不可见字符）</span><br>redis-cli --no-raw get hello<br>redis-cli --raw get hello<br></code></pre></td></tr></table></figure>
<h3 id="redis-server">redis-server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试当前系统是否能提供 1024 M 字节（1G）的内存</span><br>redis-server --test-memory 1024<br></code></pre></td></tr></table></figure>
<h3 id="redis-benchmark">redis-benchmark</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 100个客户端同时请求redis，一共请求20000次，随机插入10000个键，每个请求携带3个 pipeline，以 csv 格式输出测试结果</span><br>redis-benchmark -c 100 -n 20000 -r 10000 -P 3 --csv<br><br><span class="hljs-comment"># 只测试 get set 命令</span><br>redis-benchmark -t get <span class="hljs-built_in">set</span><br><br><span class="hljs-comment"># 只输出 requests per second 相关信息</span><br>redis-benchmark -q<br></code></pre></td></tr></table></figure>
<h2 id="pipeline">pipeline</h2>
<p>如上所述，Redis 命令执行流程是：</p>
<ol>
<li>发送命令</li>
<li>命令排队</li>
<li>命令执行</li>
<li>返回结果</li>
</ol>
<p>1+4 的耗时统称为RTT（Round Trip Time，往返时间）。</p>
<p>当我们把多个命令合并到一个 RTT 里的时候，可以使用 pipeline。</p>
<p>原生批量命令和 pipeline 的差异是：</p>
<ol>
<li>原生批量命令是原子的，pipeline 是非原子的。</li>
<li>原生批量命令是一种操作针对多个 key，而 pipeline 是更高层的组合，一个流水线组合多个批量命令。</li>
<li>原生批量命令只靠 Redis 服务端即可实现，pipeline 需要服务端和客户端共同实现。</li>
</ol>
<p>注意，pipeline 是一种<strong>批量发送命令的客户端工作模式</strong>，需要关注的是它只是对命令的组合：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> -en <span class="hljs-string">&#x27;redis 命令&#x27;</span> | redis-cli --pipe<br></code></pre></td></tr></table></figure>
<h2 id="事务">事务</h2>
<p>Redis 支持简单的事务（multi-exec）以及 lua 脚本。</p>
<h3 id="简单事务-multi-exec">简单事务（multi-exec）</h3>
<p>一个基本的例子</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">multi<br>sadd user:a:follow user:b<br>sadd user:b:fans user:a<br><span class="hljs-comment"># 在提交以前，所有的命令都会被 queued 住，提交以后会批量返回批量执行结果</span><br><span class="hljs-built_in">exec</span><br><br><span class="hljs-comment"># 在事务提交以后，其他 cli 才能读到最新的结果。被 queued 不算真的执行过</span><br>sismember user:b:fans user:a:follow<br></code></pre></td></tr></table></figure>
<p>放弃提交（而不是回滚）的例子：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">multi<br>incr num1<br>discard<br></code></pre></td></tr></table></figure>
<p>被 queue 的命令因为被抛弃所以没有被执行。</p>
<p>除此之外，**如果命令本身有语法错误，如把 set 写成了 sset，可以在 queue 的时候被检测出来，则事务整体都不会被执行。**我们只能得到 EXECABORT 错误。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">multi<br>incrs num1<br><span class="hljs-built_in">exec</span><br></code></pre></td></tr></table></figure>
<p>但是，<strong>如果命令本身有运行时错误，比如对错误类型的value 进行了错误的操作（对 list 执行了 zadd 操作），则已经执行成功的命令是不会被回滚的！</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">multi<br>del user:a:follow user:b:fans<br><span class="hljs-comment"># 这两条命令可以执行成功</span><br>sadd user:a:follow user:b<br>sadd user:b:fans user:a<br><span class="hljs-comment"># 这一条则不可以</span><br>zadd user:b:fans 1 user:a<br><span class="hljs-built_in">exec</span><br></code></pre></td></tr></table></figure>
<p>上面的操作本身会部分操作成功。可见 Redis 虽然声称这个特性是一个 transacion，但并不具备标准的数据库事务的原子性。</p>
<p><strong>不会回滚是这种工作模式的局限</strong>。</p>
<h3 id="乐观锁">乐观锁</h3>
<p>在 Redis 中使用 watch 命令可以决定事务是执行还是回滚。一般而言，可以在 multi 命令之前使用 watch 命令监控某些键值对，然后使用 multi 命令开启事务，执行各类对数据结构进行操作的命令，这个时候这些命令就会进入队列。</p>
<p>当 Redis 使用 exec 命令执行事务的时候，它首先会去比对被 watch 命令所监控的键值对，如果没有发生变化，那么它会执行事务队列中的命令，提交事务；如果发生变化，那么它不会执行任何事务中的命令，操作结果就是  nil。</p>
<p><img src="%E7%BB%8F%E5%85%B8%E4%B9%90%E8%A7%82%E9%94%81.png" alt="经典乐观锁.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> key java<br><span class="hljs-comment"># watch 在单一的操作流水里应该放在 multi 以前</span><br>watch key<br>multi<br>append key jedis<br><span class="hljs-built_in">exec</span><br>get key<br><br><span class="hljs-comment"># 另一个 redis-cli 如果同步操作这个 key，上面的 exec 就会返回 nil</span><br>append key python<br></code></pre></td></tr></table></figure>
<p>我们也可以使用事务来获取多重结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">multi<br>get hello<br>get hello<br><span class="hljs-built_in">exec</span><br><br>1<br>1<br></code></pre></td></tr></table></figure>
<h4 id="一点额外的结论">一点额外的结论</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">multi<br>命令 1<br>命令 2<br><span class="hljs-built_in">exec</span><br><br><span class="hljs-comment"># 批量返回结果，所以这种事务并不是返回最后一个执行结果，而是返回每个命令的执行结果，事务执行不是一个 func</span><br>1<br>1<br></code></pre></td></tr></table></figure>
<p>多个命令的写入在客户端就好像执行了一样，exec 才是把排队的命令结束。这也就意味着，这个事务的用法不是一个 func，而是一个类似普通事务的“起-止”边界模式。它的缺点是，它无法在执行出错的时候触发前面的执行结果的回滚。</p>
<h3 id="lua">Lua</h3>
<p>Redis 提供 eval 和 evalsha 两种方法来调用 Lua 脚本。</p>
<p>lua 脚本拥有以下优点：</p>
<ol>
<li>可以提供原子执行的能力，执行过程中不会插入其他命令。</li>
<li>可以提供自定义命令的能力。</li>
<li>可以提供命令复用的能力。</li>
</ol>
<p>我们可以自由建模，然后打包一个组合脚本进行组合之间的运算-所以可以组合使用各种原子 API 来实现复杂计算。</p>
<h4 id="eval">eval</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 脚本里的 1 指的是 keys 列表的长度，然后我们会跟上一个长度为 1 的 keys 列表（1 就是用来分割参数列表用的），接下来的参数都 arguments。</span><br><span class="hljs-built_in">eval</span> <span class="hljs-string">&#x27;return &quot;&quot;..KEYS[1]..ARGV[1]&#x27;</span> 1 redis world<br><br><span class="hljs-comment"># 分布式锁解锁的例子。注意单引号和双引号的区别。KEYS 和 ARGV 数组的区别。</span><br><span class="hljs-built_in">eval</span> <span class="hljs-string">&quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;</span> 1 hello world<br><br><br><span class="hljs-comment"># 调用 redis 内置命令</span><br><span class="hljs-built_in">eval</span> <span class="hljs-string">&#x27;redis.call(&quot;set&quot;, &quot;hello&quot;, &quot;java123&quot;)&#x27;</span> 0<br></code></pre></td></tr></table></figure>
<p>call 如果遇到错误，则脚本执行会返回错误。如果需要忽略错误执行，需要使用 pcall。</p>
<p>除了 redis.call 以外，还可以使用 redis.log 来把日志打印到 redis 的日志文件里，但要注意日志级别。</p>
<p>如果脚本比较长，可以考虑使用外部文件，配合 --eval 选项来执行。</p>
<p>Redis 的高版本里自带 <a target="_blank" rel="noopener" href="https://redis.io/topics/ldb">lua debuger</a>。</p>
<h4 id="evalsha">evalsha</h4>
<p>这个功能可以实现 lua script 的复用，其基本流程为：</p>
<ol>
<li>将 lua 脚本加载到服务器端，得到脚本的 sha1 指纹。</li>
<li>evalsha 可以使用 sha1 指纹来复用脚本，避免重复发送脚本到服务器端的开销。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">redis-cli script load <span class="hljs-string">&quot;<span class="hljs-subst">$(cat lua_get.lua)</span>&quot;</span><br>xcdfdfggsgf<br>evalsha xcdfdfggsgf 1 hello world<br></code></pre></td></tr></table></figure>
<h4 id="管理-lua-脚本">管理 lua 脚本</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br><span class="hljs-comment"># 加载脚本</span><br>script load <span class="hljs-string">&quot;<span class="hljs-subst">$(cat lua_get.lua)</span>&quot;</span><br><br><span class="hljs-comment"># 确认 sha1 是否存在</span><br>script exists xdfg<br><br><span class="hljs-comment"># 清理所有的脚本，一切加载过的脚本都不存在</span><br>script flush<br><br><span class="hljs-comment"># 无参数，直接杀掉当前正在阻塞 redis server instance 的脚本。但如果这个脚本正在执行 write commands，这个命令无法成功执行。这时候只能使用 shutdown 来关掉 redis 服务器。</span><br>script <span class="hljs-built_in">kill</span><br></code></pre></td></tr></table></figure>
<h2 id="位图">位图</h2>
<p>详细的用法见<a href="#%E4%BD%8D%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4">位操作命令</a>。</p>
<p>它的用例比较有意思，一个典型的用例是，统计一个大型社交网站的所有成员的具体登录信息。我们可以统计每天都产生了多少登录，最小的登录 id 是什么，最大的登录 id 是什么。但位图也不是万能的，如果位图很稀疏，则不如转为一个 list 或者 set 会更省内存-这需要做内存测试。</p>
<h2 id="hyperloglog">HyperLogLog</h2>
<p>HyperLogLog 并不是新的数据结构，而是字符串与基数算法（cardinality algorithm）的结合。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 往一个 key 里增加值，即 string 也可以当做复合值使用。这些值不能重复，特性上与 set 和 sorted set 一样。</span><br>pfadd 2016_03_06:unique:ids u1 u2 u3<br><br><span class="hljs-comment"># raw</span><br>object encoding 2016_03_06:unique:ids<br><br><span class="hljs-comment"># string</span><br><span class="hljs-built_in">type</span> 2016_03_06:unique:ids<br> <br><span class="hljs-comment"># HYLL\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x80\x80d\xb1\x84M\xbb\x88M\x8e</span><br>get 2016_03_06:unique:ids<br><br><span class="hljs-comment"># 计算集合总数</span><br>pfcount 2016_03_06:unique:ids<br></code></pre></td></tr></table></figure>
<p>HyperLogLog 本身极省内存，但数据量变大后，pfcount 会变得不准，最多有 0.81%的失误率。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">pfadd 2016_03_07:unique:ids u1 u2 u3 u4<br><br><span class="hljs-comment"># 合并集合</span><br>pfmerge 2016_03_06-07:unique:ids 2016_03_06:unique:ids 2016_03_07:unique:ids<br></code></pre></td></tr></table></figure>
<p>HyperLogLog 具有以下特点：</p>
<ol>
<li>不能取出存入数据。</li>
<li>计数不准，近似准确。</li>
<li>极省内存。</li>
</ol>
<p>在现实之中，bitmap、HyperLogLog和传统的 set 可以视场景交替使用或者配合使用。比如 bitmap 标识哪些用户活跃，hyperloglog计数。</p>
<h2 id="发布-publish-订阅-subscribe">发布（publish）/订阅（subscribe）</h2>
<p>在老版本的 Redis 里，开发者可以通过 list 这一数据结构来模拟消息队列中间件，但后来 Redis 提供了发布订阅功能。这一功能清晰地解耦了发布者和订阅者，两者不直接通信，发布者客户端）向指定的频道（channel）发布消息，订阅该频道的客户端都可以收到该消息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 发布端发送消息，返回值就是收到消息的客户端的数量。</span><br>publish channel:sports <span class="hljs-string">&quot;tom won the message&quot;</span><br><br><span class="hljs-comment"># 接收端接收消息。这个订阅是在不断 polling 的过程</span><br>subscribe channel:sports<br><br><span class="hljs-comment"># 取消订阅</span><br>unsubscribe channel:sports<br><br><span class="hljs-comment"># 按照 glob 风格进行订阅（只有订阅，不能发布）</span><br>psubscribe it*<br><br><span class="hljs-comment"># 按照 glob 风格取消订阅</span><br>punsubscribe it*<br><br><span class="hljs-comment"># 查看活跃的频道-至少有一个订阅者的频道</span><br>pubsub channels<br><br><span class="hljs-comment"># 查看特定频道的订阅者数量</span><br>pubsub numsub channel:economy<br><br><span class="hljs-comment"># 查看模式订阅数</span><br>pubsub numpat<br></code></pre></td></tr></table></figure>
<p>值得注意的亮点分别是：</p>
<ol>
<li>客户端在执行订阅命令后就进入订阅状态，只能接收 subscribe、psubscribe、unsubscribe 和 punscribe 四个命令。</li>
<li>新开启的客户端，无法收到该频道之前的消息，因为 <strong>Redis 不会对发布的消息进行持久化</strong>。–消息既无法堆积（accumulate），也无法回溯（backtrace）。</li>
</ol>
<h2 id="geo-地理信息定位">GEO（地理信息定位）</h2>
<p>Redis 的 GEO 可以用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 向地理信息列表里加入北京的经度（longtitude）、纬度（latitude）。这个命令除了添加信息，还能更新老地理信息</span><br>geoadd cities:locations 116.28 39.55 beijing<br>geoadd cities:locations 117.12 39.08 tianjin<br><br><span class="hljs-comment"># 求两个地理位置之间的距离，单位可切换</span><br>geodist cities:locations beijing tianjin km<br><br><span class="hljs-comment"># 获取以 beijing 为中心150km内的城市，包括北京</span><br>georadiusbymember cities:locations beijing 150 km<br><br><span class="hljs-comment"># 获取特定城市的地理信息</span><br>geopos cities:locations beijing<br><br><span class="hljs-comment"># zset 地理信息的实际存储类型是有序集合</span><br><span class="hljs-built_in">type</span> cities:locations<br><br><span class="hljs-comment"># 没有 geo 开头的命令，只能使用 zset 自带的原生删除命令</span><br>zrem cities:locations beijing<br></code></pre></td></tr></table></figure>
<p>此外还可以对 geo 集合的成员求geohash。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># wx48ypbe2q </span><br>geohash cities:locations beijing<br></code></pre></td></tr></table></figure>
<ul>
<li>geohash 的长度越长，精度越精确。</li>
<li>两个 geohash 越相似，距离越近。</li>
</ul>
<h1>客户端</h1>
<h2 id="redis-协议">Redis 协议</h2>
<p>Redis 的客户端和服务器端使用 TCP 直连，基本的协议都是一问一答（request and response） 形式的。但它发送的请求是遵循特定的应用层协议（Redis Serialization Protocal）的。</p>
<p>一个请求如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">*3\r\n<span class="hljs-variable">$3</span>\r\nSET\r\n<span class="hljs-variable">$5</span>\r\nhello\r\nworld\r\n <br></code></pre></td></tr></table></figure>
<p><code>*3</code>代表 3 个参数（SET KEY VALUE）。 $3 代表紧随其后的参数长度为 3 字节。 每一段可见字符都必须以一个CLRF(\r\n)结尾。</p>
<p>而返回值也有格式：</p>
<p>状态回复，在 RESP 中第一个字节为“+”。 错误回复，在 RESP 中第一个字节为“-”。 多条字符串回复，在 RESP 中第一个字节为“<em>”。 整数回复，在 RESP 中第一个字节为“:”。 字符串回复，在 RESP 中第一个字节为“$”。 多条字符串回复，在 RESP 中第一个字节为“</em>”。</p>
<h2 id="jedis-客户端">Jedis 客户端</h2>
<p>使用的时候要注意配上 try-finally 块，小心连接泄漏。 也可以使用连接池，也要注意规划，连接池一样可以造成连接泄漏。</p>
<h2 id="客户端管理">客户端管理</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 客户端列表，定位每个客户端的问题</span><br>client list<br><span class="hljs-comment"># 整体看待客户端信息 </span><br>info clients<br><br><span class="hljs-comment"># 获取内存信息 </span><br>info memory<br><br><span class="hljs-comment"># 杀死指定地址端口的客户端 </span><br>client <span class="hljs-built_in">kill</span> 127.0.0.1:3780<br><br><span class="hljs-comment"># 暂停客户端 1000 毫秒 </span><br>client pause 1000<br><br><span class="hljs-comment"># 另一种镜像监控所有流量的方式，注意需要庞大的输出缓冲区，很可能耗尽内存。禁止在生产上使用。 </span><br>monitor <br></code></pre></td></tr></table></figure>
<p>redis 服务端为每个客户端分配一个输入缓冲区（默认大小为 1G，而且不受 maxmemory 的限制）。输入缓冲区满了以后，客户端可能会被关闭。</p>
<p>与客户端相关的几个参数：</p>
<ul>
<li>tcp-keepalive 默认值为 0，即 Redis 不检查死连接。如果设置为 60，则 Redis 会定期清理死连接，防止僵尸连接占用资源。</li>
<li>tcp-backlog tcp 接受连接的总数的大小，默认值为 511。这个值也受 OS 的内核参数控制，可以修改/proc/sys/net/core/somaxconn。</li>
</ul>
<h2 id="监控内存过大的思路">监控内存过大的思路</h2>
<p>消耗的内存如果接近了 maxmemory，则可以按照以下步骤来排查问题：</p>
<ol>
<li>确认各个主从节点的 dbsize 是否一样。</li>
<li>使用<code>info clients</code>来输出内存消耗信息，确认输入输出缓冲区的大小。</li>
<li>使用<code>redis-cli client list | grep -v &quot;omem=0&quot;</code>查找消耗内存比较多的 client。</li>
<li>检查是否有慢查询-注意查询 slowlog，或者遇到 slowlog 的时候直接报警。</li>
</ol>
<h1>持久化</h1>
<p>持久化可以避免进程退出而数据丢失。</p>
<p>Redis 的持久化文件主要包括两种格式，RDB 格式和 AOF 格式，这两种格式的生成机制各有不同。</p>
<p><strong>Redis 在重启时优先加载 AOF 文件（因为 AOF 文件颗粒度更细），如果没有 AOF 文件可加载则加载 RDB 文件。</strong></p>
<p><img src="redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%87%E4%BB%B6%E5%8A%A0%E8%BD%BD%E6%B5%81%E7%A8%8B.png" alt="redis持久化文件加载流程"></p>
<h2 id="rdb">RDB</h2>
<p>RDB 持久化会把进程内的数据全量快照保存到硬盘上，其触发方式包括手动触发和自动触发。</p>
<h3 id="手动触发">手动触发</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 阻塞当前 Redis 服务器，直到 RDB dump 完成为止。内存里数据越大，阻塞时间越久。不建议在生产环境使用，未来会被废弃。</span><br>save<br><br><span class="hljs-comment"># fork 出一个子进程。子进程负责生成 RDB 文件后，通知父进程，主进程还可以继续响应其他命令。只有 fork 的一瞬间会阻塞 Redis 进程。</span><br>bgsave<br></code></pre></td></tr></table></figure>
<p>bgsave 的工作流程如下：</p>
<p><img src="bgsave%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="bgsave 的工作流程"></p>
<p>注意，RDB 文件本身永远只有一个。子进程产生的都是临时文件，会通过原子替换的方式来维持 RDB 文件的唯一性。</p>
<p>Redis 内部主动生成 RDB 文件的过程都是采用 bgsave 的方式。</p>
<h3 id="自动触发">自动触发</h3>
<ol>
<li>在 config 里配置<code>save m n</code>。表示 m 内数据集存在 n 次修改时，自动触发 bgsave。</li>
<li>如果从节点执行<strong>全量复制操作</strong>，主节点自动执行 bgsave生成 RDB 文件并发送给从节点。</li>
<li>执行 debug reload 命令重新加载 Redis 时，也<strong>自动触发 save 操作</strong>。</li>
<li>默认情况下执行 shutdown 命令时，如果没有开启 AOF 持久化功能，则自动执行 bgsave-<strong>Redis 自带的优雅关闭流程</strong>。</li>
</ol>
<h3 id="rdb-文件的存储">RDB 文件的存储</h3>
<p>默认会存在 <code>config set dir &#123;newDir&#125;</code>和<code>config set dbfilename &#123;newFileName&#125;</code>的文件里。也可以动态修改（）比如在硬盘出问题的时候动态修改）。</p>
<p>默认情况下会对 RDB 文件进行 LZF 压缩处理（可以关闭）。压缩会消耗 CPU 性能，但利于网络传输。</p>
<h3 id="rdb-的优缺点">RDB 的优缺点</h3>
<p>优点：</p>
<ul>
<li>紧凑存储，适于全量保存/恢复。</li>
<li>加载 RDB 的速度远快于 AOF 文件。</li>
</ul>
<p>缺点：</p>
<ul>
<li>没有办法强实时/秒级持久化。</li>
<li>版本不兼容</li>
</ul>
<h2 id="aof-append-only-file">AOF（append only file）</h2>
<p>以独立的日志（log）记录每次写命令，重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。<strong>AOF 具有持久化的强实时性，是 RDB 的补充。</strong></p>
<h3 id="配置方式">配置方式</h3>
<p>需要设置<code>appendonly yes</code>（默认不开启），开启后就会被自动触发（也就是说无需手动触发）。可以修改文件名和路径。</p>
<h3 id="工作流程">工作流程</h3>
<p>aof 的工作流程如下：</p>
<p><img src="aof%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="aof工作流程"></p>
<p>其中：</p>
<ol>
<li>append 其实是把写命令写入 aof_buf 中。</li>
<li>sync 是把写入命令从内存持久化到硬盘中。</li>
<li>rewrite 则会压缩重写 AOF 文件使其达到更紧凑的目的。</li>
<li>当 Redis 重启后，可以加载 AOF 文件进行数据恢复。</li>
</ol>
<p>其中被持久化的命令，是纯文本的格式，遵循 RESP 协议。</p>
<h3 id="文件同步">文件同步</h3>
<p>Redis 本身是个单线程架构，如果每次新的写命令都要写入硬盘，则硬盘的负载能力可能成为一个瓶颈。而如果先写入一个 aof_buf，则可以采取多种策略持久化数据到硬盘中。</p>
<p><strong>这提醒我们，对于零散的多次写 IO，我们都要想办法化零为整，通过 buffer-sync 的分段异步写形式充分协调内存和硬盘的写性能。</strong></p>
<p>我们可以采用的策略分别是：</p>
<ul>
<li>always 命令写入 aof_buf 后调用系统 fsync 操作同步到 AOF 文件，fsync 完成后系统返回。<strong>等于一个强实时的策略。在 sata 上只有几百的 tps。</strong></li>
<li>everysec 命令写入 aof_buf 后调用系统 write 操作，write 完成后线程返回。fsync 操作由专门线程每秒调用一次。<strong>等于一个中等实时的策略。默认策略，最多丢失 1s 的数据</strong></li>
<li>no 命令写入 aof_buf后调用系统 write 操作，而不对 AOF 做 fsync 同步操作， fsync 同步操作由操作系统负责，通常同步周期最长 30 秒。<strong>无法保障同步实时性。</strong></li>
</ul>
<p>write 其实是一种 delaywrite，写入操作系统的页缓冲区以后线程会立即返回（阻塞期很短），依赖于系统的调度（如时间阈值满或者空间阈值满，期间如果系统宕机则数据会丢失）或者 fsync才能真正持久化到硬盘中。<br>
fsync 就是强行同步到硬盘的syscall，阻塞时间会稍长，但持久化更彻底。</p>
<h3 id="重写机制">重写机制</h3>
<p>重写主要通过有效地去除无用命令、合并多条有效命令的方式使得 AOF 文件变得更小，更利于加载。</p>
<p>重写（只是重写这个过程）也同样包括手动触发和被动触发两种机制。</p>
<p>重写流程：</p>
<p><img src="aofrewrite%E6%B5%81%E7%A8%8B.png" alt="aofrewrite流程"></p>
<p>其中同时存在两个 aof 文件，新的 aof 文件也会进行一个原子替换。</p>
<h4 id="手动触发">手动触发</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bgrewrite<br></code></pre></td></tr></table></figure>
<h4 id="自动触发">自动触发</h4>
<p>if (aof_current_size &gt; auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size)/aof_base_size &gt;= auto-aof-rewrite-percentage)</p>
<p>auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 是配置文件的配置项。</p>
<h2 id="相关问题">相关问题</h2>
<h3 id="fork-问题">fork 问题</h3>
<p>fork 调用会让子进程调用父进程的内存页表，理论上一个进程占用内存越大，它的 fork 命令就越耗时，而且有些虚拟机（如 xen）里 fork 的性能还更差。</p>
<h3 id="性能优化点">性能优化点</h3>
<h4 id="cpu">cpu</h4>
<ol>
<li>不要和其他 cpu 密集型应用部署在一起。</li>
<li>如果部署多个 Redis 实例，保证每个时刻只有一个后台进程在工作。</li>
</ol>
<h4 id="内存">内存</h4>
<ol>
<li>如果部署多个 Redis 实例，保证每个时刻只有一个后台进程在工作。</li>
<li>不要增加 copy-on-write 的负担，尽可能让子进程少一些后台重写的负担（如何做到？）。</li>
<li>关掉大页（huge page）优化-和 JVM 的优化策略正好相反。</li>
</ol>
<h4 id="硬盘">硬盘</h4>
<p>AOF 对硬盘的写压力更大。</p>
<h4 id="aof-追加阻塞">AOF 追加阻塞</h4>
<p>此外，AOF 体系还存在一个追加阻塞的问题，其流程如下：<br>
<img src="aof%E8%BF%BD%E5%8A%A0%E9%98%BB%E5%A1%9E.webp" alt="aof追加阻塞"></p>
<p>可以看到，主线程如果在写入 AOF 缓冲区时如果上次 fsync 成功的时间（所谓的 checkpoint）还在两秒内，则会持续写入 AOF 缓冲区。这时候 AOF 缓冲区是不安全的。所以实际上 AOF 机制最多会丢两秒内的信息。而如果主线程阻塞，则 Redis 的性能会急剧下降。</p>
<p><strong>至此为止，我们至少以下潜在的性能瓶颈：save、fork、 AOF 的 append、AOF 的 fsync 造成的阻塞。</strong></p>
<h1>复制</h1>
<p>在分布式系统中为了解决单点问题，必须建立副本复制机制，以解决容灾和负载均衡问题。</p>
<p><a href="Redis%E5%90%8C%E6%AD%A5.xmind">Redis同步.xmind</a><br>
<img src="Redis%E5%90%8C%E6%AD%A5.png" alt="Redis同步"></p>
<h2 id="配置">配置</h2>
<h3 id="建立复制">建立复制</h3>
<p>建立复制共有三种方法：</p>
<ol>
<li>在配置文件中使用如下的配置：slaveof localhost 6379</li>
<li>在启动时使用如下命令：redis-server --slaveof localhost 6379</li>
<li>在 redis-cli 中对服务端使用 slaveof localhost 6379</li>
</ol>
<p>而在主节点里可以查看自己的主从信息：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">info</span> <span class="hljs-keyword">replication</span><br></code></pre></td></tr></table></figure>
<p>可以看到自己的角色：</p>
<blockquote>
<p>role:master</p>
</blockquote>
<p>而从节点则会看到：</p>
<blockquote>
<p>role:slave</p>
</blockquote>
<h3 id="断开复制">断开复制</h3>
<p>可以使用如下命令断掉与 master 的联系：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">slaveof no one<br></code></pre></td></tr></table></figure>
<ol>
<li>本节点断开和 master 的连接。</li>
<li>本节点自己上升为 master。</li>
</ol>
<p>也可以使用如下命令切换 master：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">slaveof localhost 6379<br></code></pre></td></tr></table></figure>
<p><strong>如果新 master 不同于老 master，老 master 的数据会被清理掉。</strong></p>
<h3 id="安全性">安全性</h3>
<p>主节点可以设置 requirepass 参数进行验证，这时所有的客户端访问必须使用 auth 命令进行校验。</p>
<h3 id="只读">只读</h3>
<p>从节点（默认）使用 slave-read-only = yes 来保证从节点是只读模式的。在生产上最好保持这种不能允许从节点写的模式，否则会导致数据不一致。</p>
<h3 id="传输延迟">传输延迟</h3>
<p>关闭 repl-disable-tcp-nodelay 可以降低延迟，但整体带宽使用比较大。</p>
<h2 id="拓扑">拓扑</h2>
<h3 id="一主一从">一主一从</h3>
<p><img src="%E4%B8%80%E4%B8%BB%E4%B8%80%E4%BB%8E.png" alt="一主一从"></p>
<p>这种思路是把 slave 当做 standby，只在从节点打开持久化（RDB 或 AOF）。这种场景如果主节点重启，则主节点会自动清空数据（因为没有打开持久化-实际上如果没有打开 AOF 持久化，Redis 的优雅关闭也会回退到 RDB 持久化），从节点也可能清空数据。为了预防这种情况出现，在主节点重启以前从节点要<code>slaveof no one</code>断开主从复制-但这种措施无法阻挡主节点宕机引起的数据丢失。</p>
<p><strong>这种一主一从的架构设计和 MySQL 的主从复制很相似，但只打开一端持久化的思路还是比较特别的，不那么安全。而且主节点 flush 数据会导致从节点也 flush 数据，本身也是一种很危险的行为</strong></p>
<h3 id="一主多从">一主多从</h3>
<p><img src="%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E.png" alt="一主多从"></p>
<p>这种拓扑又被叫做星形拓扑。这种拓扑比较像 MySQL 的读写分离设计，主节点承担写命令的操作，而从节点也分担读命令的操作，。其中还可以设计一些特殊的读节点，专门执行 keys，sort 操作。但这种操作会占用太多的网络带宽。</p>
<h3 id="树状结构">树状结构</h3>
<p><img src="%E6%A0%91%E7%8A%B6%E4%B8%BB%E4%BB%8E%E7%BB%93%E6%9E%84.png" alt="树状主从结构"></p>
<p>这种树形架构通过<strong>分层架构来分层放大流量</strong>，平衡了带宽和冗余复制的需要，但下层的节点的同步时延变大了。</p>
<h2 id="原理">原理</h2>
<p><img src="%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.jpg" alt="主从复制过程流程"><br>
<img src="%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B%E6%B5%81%E7%A8%8B.png" alt="主从复制过程流程"><br>
<a href="Redis%E5%86%85%E5%AD%98%E5%88%92%E5%88%86.xmind">Redis内存划分.xmind</a></p>
<h3 id="过程">过程</h3>
<p>1 如果使用配置文件配置主从关系，这一步几乎可以说是一闪而过。这一步只保存 master 的 ip 和 port 。如果这个时候从 master 节点去看 client 信息的话，会看到一个刚刚建立的 client（从主节点的角度来看，从节点实际上也是client，类似某些 kafka 的数据迁移方案迁移的端点把自己伪装成一个 consumer）。</p>
<p>2 从节点内部有个每秒运行的定时任务（大致上是一个定时线程）维护复制相关逻辑，当定时任务发现新的主节点后，会尝试与该节点建立网络连接。从节点会单独打开一个 port（而不是当前从节点的 server 的 port），尝试建立新的 socket。<strong>所以 Redis 的主从复制的连接建立是一个拉过程。</strong></p>
<blockquote>
<p>34020:S 06 Oct 2019 23:09:28.709 * Connecting to MASTER localhost:6379<br>
34020:S 06 Oct 2019 23:09:28.712 * MASTER &lt;-&gt; REPLICA sync started</p>
</blockquote>
<p>这个过程如果失败，可以在日志中看到以下错误：</p>
<blockquote>
<p>34020:S 06 Oct 2019 23:09:38.086 * MASTER &lt;-&gt; REPLICA sync started<br>
34020:S 06 Oct 2019 23:09:38.086 ## Error condition on socket for SYNC: Connection refused</p>
</blockquote>
<p>从节点会无限重试，直到成功或者主从关系被切断为止。</p>
<p>3 从节点会发送 ping，验证：</p>
<ul>
<li>连接的 socket 是否正常</li>
<li>主节点是否能正确响应命令</li>
</ul>
<p>如果验证成功，能收到：</p>
<blockquote>
<p>Master replied to PING, replication can continue…</p>
</blockquote>
<p>4 权限验证 如果 master 配置了 requirepass 参数的话，从节点要配置 masterauth 参数来保证密码一致。</p>
<p>5 同步数据集 分为全量同步和部分同步两种策略。<br>
6 命令持续复制 数据集同步完成后。主节点会把自己收到的写命令，持续发给从节点。</p>
<h3 id="同步数据集">同步数据集</h3>
<p>注意，全量复制和部分复制都属于同步数据集的一部分，<strong>后续的写命令持续发送不是部分复制</strong>。</p>
<h4 id="全量复制-full-resync">全量复制（Full resync）</h4>
<p>在初次复制的场景下，Redis 会使用全量复制策略（对应 Redis 旧版本唯一用于复制的 sync 命令）。主节点的数据会被一次性全部发送给从节点，造成主从节点和网络的很大开销。</p>
<p>一般从节点会打印如下的日志：</p>
<blockquote>
<p>34020:S 06 Oct 2019 23:09:39.128 * MASTER &lt;-&gt; REPLICA sync started<br>
34020:S 06 Oct 2019 23:09:39.128 * Non blocking connect for SYNC fired the event.<br>
34020:S 06 Oct 2019 23:09:39.128 * Master replied to PING, replication can continue…<br>
34020:S 06 Oct 2019 23:09:39.129 * Partial resynchronization not possible (no cached master)<br>
34020:S 06 Oct 2019 23:09:39.130 * Full resync from master: 3e6a48b3ce0d87851c0882f4120145a0d7611f0d:0<br>
34020:S 06 Oct 2019 23:09:39.181 * MASTER &lt;-&gt; REPLICA sync: receiving 175 bytes from master<br>
34020:S 06 Oct 2019 23:09:39.182 * MASTER &lt;-&gt; REPLICA sync: Flushing old data<br>
34020:S 06 Oct 2019 23:09:39.182 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory<br>
34020:S 06 Oct 2019 23:09:39.182 * MASTER &lt;-&gt; REPLICA sync: Finished with success</p>
</blockquote>
<p>证明了部分复制不可能，必须打开全量复制。注意PID 34020:S意味着当前 节点是个 Slave（M意味着 Master 而 C 意味着子进程）。</p>
<p>其全流程如下：</p>
<p><img src="%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6rsync.png" alt="全量复制全流程"></p>
<p>注意：</p>
<ul>
<li>主节点和从节点之间的复制超时时间一般为 60s，如果数据量很大要调高这个超时阈值，否则从节点会放弃全量复制。- 不要复制太大的数据量！否则就要调高超时</li>
<li>主节点在生成 rdb 的过程中，还在不断接受新的命令（因为 bgsave 是由子进程进行操作的），这些新的命令会被保存在一个单独的客户端复制缓冲区里面（<strong>注意，和部分复制的replication-backlog 不一样，这里的 buffer 属于未被发送的命令的 buffer</strong>）。在 send RDB 以后还要单独再 send buffer 一遍。</li>
<li>从节点得到了一个完整的 RDB 文件以后要先 flush old data，然后再进行 load，这个全过程都是阻塞的-这也是 MySQL 不具有，Redis 独有的。</li>
<li>如果从节点自己开启了 AOF 功能，为了保证同步完成以后 AOF 文件立刻可用，先启动一段 bgrewriteaof，子进程 rewrite 完成以后全量复制才算收尾-<strong>增加了阻塞点</strong>。</li>
<li>全量复制过程中，子节点的数据可以算是 stale 的。如果关闭了 slave-serve-stale-data，则全量复制过程中从节点是不接受读命令的（写命令更加不会被接受），<strong>属于完全阻塞状态</strong>。</li>
</ul>
<h4 id="部分复制-partial-replication">部分复制（partial replication）</h4>
<p>在出现网络闪断等情况时，主节点可以只发送一部分数据给从节点以弥补丢失，效率会很高。</p>
<p>普通的主从建立时，会出现若干次部分复制失败的日志，最终会直接通过全量复制成功-<strong>Redis 会优先考虑部分复制的策略</strong>。</p>
<p><code>psync</code>命令需要组件支持以下特性：</p>
<ul>
<li>主从节点各自复制、保存偏移量</li>
<li>主节点复制积压缓冲区</li>
<li>主节点运行 id</li>
</ul>
<h5 id="复制偏移量">复制偏移量</h5>
<p>主节点在自己完成写入后，会累加并保存自己的本地 offset。从节点每次完成复制后，也会上报自己的 offset 到主节点中。所以主节点保存了所有节点的偏移量。</p>
<p>而同步了写命令后，从节点也会累加并保存自己的 offset。</p>
<p>对比主从节点的 offset 的差值可以知道<strong>复制延迟多大，从而判定系统健康程度</strong>。</p>
<h5 id="复制写命令到复制积压缓冲区">复制写命令到复制积压缓冲区</h5>
<p>Redis 会针对每个 client 准备一个固定长度的队列- replication-backlog，默认大小为 1mb 作为复制积压缓冲区。所有写命令在被发送给从节点的同时，也会被发送到这个队列里。这个队列实际上记录了已被复制的命令，可以作为日后补偿部分丢失写命令的依据。</p>
<p><strong>注意，这个缓冲区是已被发送的命令数据的缓冲区，只是为了重放闪断数据用的，和全量复制里的 send buffer 用到的 buffer，也不保存复制完以后持续同步的后续命令。</strong></p>
<h5 id="主节点运行-id">主节点运行 id</h5>
<p>每个 Redis 节点都会有一个 40 位的 16 进制字符串来唯一识别节点。</p>
<p>如果主节点重启（必然？）替换了 RDB/AOF 文件（比如两种文件的重写？）的时候会导致节点 id 变化，从节点已经不适用老的 offset， 从节点会重新进行全量复制。-<strong>所以尽量不要随便重启主节点</strong></p>
<h5 id="psync-命令">psync 命令</h5>
<p>psync 命令要求 Redis 2.8 以上版本，<strong>它同时兼容全量复制和部分复制</strong>。</p>
<p>其格式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">psync runId offset<br></code></pre></td></tr></table></figure>
<p>runId 为待复制的主节点 id，offset 为已复制的数据偏移量（如果是全量复制，其值为-1）。</p>
<p>从节点发送 psync 命令给主节点，主节点回复不同内容的响应给从节点：</p>
<ul>
<li>FULLSYCN {runId} {offset} 从节点将开始全量复制</li>
<li>+CONTINUE 从节点触发部分复制</li>
<li>+ERR 主节点的版本低于 2.8，要从 sync 命令开始重新触发全量复制。</li>
</ul>
<h5 id="全流程">全流程</h5>
<p><img src="%E9%83%A8%E5%88%86%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.png" alt="部分复制流程"></p>
<p>普通的全量复制，一旦遇到网络闪断，肯定会触发超时复制失败，浪费大量的系统开销。但拥有部分复制的流程，在网络中断后，可以尝试用部分复制来修复小部分数据（默认 1MB）。</p>
<p><strong>部分复制只能发送 replication-backlog 里的数据，如果超出了这个缓冲区的范围，复制就会直接像普通的全量复制超时一样失败，然后重启一个新的全量复制。</strong></p>
<h3 id="心跳">心跳</h3>
<p>主从会相互维护心跳监测：</p>
<ol>
<li>主从会互相模拟成各自的客户端进行通信，也就是会出现在对方的 client list 里。只不过主节点的 flags=M，而从节点的 flags=S。</li>
<li>主节点定时发送 ping 命令到各个从节点。</li>
<li>从节点定时上报自己的复制偏移量（<strong>实际上主从节点都会保存很详细的彼此的进度信息，特别lastest、last 之类的信息，这点同 hdfs、 MySQL 一样，值得学习</strong>）。</li>
</ol>
<h3 id="后续-命令持续-异步-复制">（后续）命令持续（异步）复制</h3>
<p>主节点接下来响应写命令，直接返回客户端写结果，而不受从节点复制结果的影响-如何防止这一步数据丢失？应该还存在若干 offset 回溯的功能来预防这个问题。</p>
<h2 id="开发运维中的问题">开发运维中的问题</h2>
<h3 id="读写分离">读写分离</h3>
<h4 id="数据延迟">数据延迟</h4>
<p>这个问题是由架构和网络通信的特性决定的，不可避免。我们能够做的就是设立多种监控措施，不断用轮询的方式来发现超高的 lag 及时报警人工干预。</p>
<h4 id="读到过期数据">读到过期数据</h4>
<p>**低版本的从节点不会主动删除数据，除非它收到主节点的 del 命令。**高版本的从节点在读取数据的时候也会检查数据是否已经超时，如果没有超时则</p>
<p>主节点删除超时数据有两种策略。实际上现实中的系统必须混合使用两种策略才能安全删除。</p>
<h5 id="惰性删除-用时-读时删除">惰性删除（用时/读时删除）</h5>
<p>在收到读命令的时候检查超时阈值，如果已超时则主动删除，且返回 nil 给客户端，并同步 del 命令到从节点。</p>
<p><strong>实际上 Java 的 weakHashMap 也是采用这种策略来维护自己的数据集的。</strong></p>
<h5 id="定时删除">定时删除</h5>
<p>主节点内部有一个定时任务循环采样数据，发现采样的键过期执行 del 命令，之后再同步到从节点。</p>
<h5 id="从节点故障">从节点故障</h5>
<p>如果自己做水平扩展，则故障转移方案（特别是从节点失效的问题）要自己做。所以可以上 Redis-Cluster 这样的现成方案。</p>
<h3 id="主从配置不一致">主从配置不一致</h3>
<p>如果主从的配置不一致，从节点可能无法像主节点一样正常工作。特别是从节点的 maxmemory 不如主节点大的时候，从节点可能会发生内存淘汰而丢失部分数据。-<strong>主从节点最好有一样的容量</strong>。</p>
<h3 id="规避全量复制">规避全量复制</h3>
<p>全量复制非常耗费资源，应该注意几个问题：</p>
<ul>
<li>首次复制应该与业务高峰期错开。</li>
<li><strong>避免主节点重启</strong>导致从节点全量复制，这种情况可以考虑提升从节点为主节点。</li>
<li>合理规划配置，避免挤压缓冲区不足，部分复制失败回退回全量复制。</li>
</ul>
<h3 id="规避复制风暴">规避复制风暴</h3>
<p>Redis 针对主节点做过专门优化，使得多个从节点可以共用针对第一个从节点生成的 RDB 文件。但还存在其他问题，值得注意：</p>
<ul>
<li>应该尽量避免单一主节点复制多个从节点，使用树形架构来节约主节点的带宽。</li>
<li>打散多个主节点，避免多个节点一起容灾（同时重启开始复制会拖垮CPU、内存、硬盘和带宽）。</li>
</ul>
<h1>理解内存</h1>
<p><a href="Redis%E5%86%85%E5%AD%98%E5%88%92%E5%88%86.xmind">Redis内存划分.xmind</a><br>
<img src="Redis%E5%86%85%E5%AD%98%E5%88%92%E5%88%86.png" alt="Redis内存划分"></p>
<p>内存是昂贵的资源，要合理地使用内存，首先要做到：</p>
<ul>
<li>理解 Redis 的内存布局，以及它管理内存的方案</li>
<li>思考调优的方案</li>
</ul>
<p>理解内存而能优化内存。</p>
<h2 id="内存消耗">内存消耗</h2>
<h3 id="内存使用统计">内存使用统计</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">## 这个命令只有 redis-client 可用</span><br>info memory<br></code></pre></td></tr></table></figure>
<blockquote>
<p>used_memory:1050880<br>
used_memory_human:1.00M<br>
used_memory_rss:2162688<br>
used_memory_rss_human:2.06M<br>
used_memory_peak:1051776<br>
used_memory_peak_human:1.00M<br>
used_memory_peak_perc:99.91%<br>
used_memory_overhead:1037590<br>
used_memory_startup:987792<br>
used_memory_dataset:13290<br>
used_memory_dataset_perc:21.07%<br>
allocator_allocated:1005760<br>
allocator_active:2124800<br>
allocator_resident:2124800<br>
total_system_memory:17179869184<br>
total_system_memory_human:16.00G<br>
used_memory_lua:37888<br>
used_memory_lua_human:37.00K<br>
used_memory_scripts:0<br>
used_memory_scripts_human:0B<br>
number_of_cached_scripts:0<br>
maxmemory:0<br>
maxmemory_human:0B<br>
maxmemory_policy:noeviction<br>
allocator_frag_ratio:2.11<br>
allocator_frag_bytes:1119040<br>
allocator_rss_ratio:1.00<br>
allocator_rss_bytes:0<br>
rss_overhead_ratio:1.02<br>
rss_overhead_bytes:37888<br>
mem_fragmentation_ratio:2.15<br>
mem_fragmentation_bytes:1156928<br>
mem_not_counted_for_evict:0<br>
mem_replication_backlog:0<br>
mem_clients_slaves:0<br>
mem_clients_normal:49694<br>
mem_aof_buffer:0<br>
mem_allocator:libc<br>
active_defrag_running:0<br>
lazyfree_pending_objects:0</p>
</blockquote>
<p>其中值得关注的值分别是：</p>
<ul>
<li>used_memory Redis 分配器（allocator分配的内存总量，也就是内部存储的所有数据内存占用量-实际上等于被实际使用的不包含内存碎片的物理内存和物理内存）</li>
<li>used_memory_human 以可读的形式返回的 used_memory</li>
<li>used_memory_rss 以操作系统角度显示 Redis 进程占用的物理内存总量</li>
<li>used_memory_peak 内存使用的最大值</li>
<li>used_memory_peak_human 以可读的格式返回的 used_memory_peak</li>
<li>used_memory_lua lua 引擎锁消耗的内存大小</li>
<li>used_memory_lua_human 以可读的格式返回的 used_memory_lua</li>
<li>mem_fragmentation_ratio used_memory_rss/used_memory 的比值，这个值越高，物理内存碎片越高-有时候和内存页对齐有关。这个比值越小，证明有很多内存被调度到了 swap 空间里。</li>
</ul>
<p>实际上 Linux 系统的很多系统指标都有 human readable 版本，Redis 基本模仿了这个设计。</p>
<h3 id="主进程-内存消耗划分">（主进程）内存消耗划分</h3>
<h4 id="对象内存">对象内存</h4>
<p>对象内存是 Redis 内存中占用量最大的一块，实际上我们存储的所有数据都存在这个内存区域。</p>
<p>对象只分为 key 和 value。这一区域的大小大致上等于 sizeof(keys) + sizeof(values)。</p>
<p>keys 都是字符串。values 就是五种基本类型：字符串、列表、哈希、集合和有序集合（bitmap 和 hyperloglog 本质上是字符串，geo 数据是 zset）。</p>
<h4 id="缓冲内存">缓冲内存</h4>
<h5 id="客户端缓冲内存">客户端缓冲内存</h5>
<p>客户端缓冲包括输入缓冲和输出缓冲。</p>
<p>Redis 的输入缓冲是无法控制的，默认就是每个客户端只能使用最多 1G 内存-<strong>Redis 的自保比较严格</strong>。</p>
<p>而输出缓冲则通过 client-output-buffer-limit 控制。</p>
<h6 id="普通客户端">普通客户端</h6>
<p>除了复制和订阅客户端以外的所有客户端。</p>
<p>Redis 的缺省配置是 client-output-buffer-limit normal 0 0 0。注意，0 意味着限制被禁用了，这是因为 Redis 认为普通客户端大部分情况下没有很多的数据输出，所以 normal 客户端相当于会有无限大的输出空间。但实际上有些特殊场景下还是需要限制输出缓冲的大小。比如如果客户端使用 monitor 命令，会有大量的输出堆积在 Redis 里，导致 Redis 的内存飙升。解决这个问题有两种思路：调整 maxclients 或者调整 client-output-buffer-limit。</p>
<h6 id="从-replica-客户端">从（Replica）客户端</h6>
<p>Master 会单独为每个 slave 建立一条单连接。每个链接的默认配置是 client-output-buffer-limit replica 256mb 64mb 60。</p>
<p>其中 256mb 是硬限制，只要一到达连接就关闭。64mb是软限制，只要达到并持续 60s，则连接被关闭。</p>
<h6 id="订阅-pubsub-客户端">订阅（ pubsub）客户端</h6>
<p>尚不明确到底对于同一个 channel的多个 pubsub 客户端是不是共用一个缓冲区。因为 Redis 没有消费组的概念，所有 client 即使是争抢同一个缓冲区也是有可能的-其实这样设计比较自然，因为多个缓冲区可能导致消息的重复 subscribe。另外，<a target="_blank" rel="noopener" href="https://github.com/StackExchange/StackExchange.Redis/issues/872">如果一个 pubsub 客户端订阅了多个 channels，也是共用同一个连接</a>，这更增加了多个客户端共用一个缓冲区的可能性。其默认配置为：</p>
<p>client-output-buffer-limit pubsub 256mb 64mb 60</p>
<p>如上所述，订阅客户端的缓冲区大小会稍微大一些。</p>
<h5 id="复制积压缓冲区">复制积压缓冲区</h5>
<p>所有的从节点共用一个复制积压缓冲区，这个复制积压缓冲区还可以被重用，其大小默认只有 1mb，可以调整到 100mb。这样有了更大的应付网络闪断的内存余量。</p>
<h5 id="aof-缓冲区">AOF 缓冲区</h5>
<p>AOF 重写期间，Redis 接收写命令不会停，必须使用 buffer-<strong>non-blocking的方案 之一就是使用 buffer</strong>，这部分 buffer 不能被定制。</p>
<h4 id="内存碎片-memory-framentation">内存碎片（Memory Framentation）</h4>
<p>常见的内存分配器（allocator）有：glibc、tcmalloc和 jemalloc，Redis 使用 jemalloc。</p>
<p>allocator 为了更好地分配内存，一般总是 fixed-size 地分配对齐的内存块。在 64 位内存空间里，jemalloc 会把内存分为小、大、巨大三个范围。每个范围内有若干种大小不一的内存块。分配器会在分配内存的时候，选择尺寸最接近的大内存块分配内存（5kb 的内存通常会被分配在 8kb 的内存块里）。jemalloc 高度优化过内存碎片问题，通常情况下 mem_fragmentation_ratio 接近 1。</p>
<p>但当存储的 value 长短差异较大的时候，以下操作一样可以导致高内存碎片问题：</p>
<ul>
<li>频繁做更新操作，比如频繁地执行 append、setrange 等更新操作。</li>
<li>大量过期键操作，会在内存空间里留下大量空洞-实际上批量删除键也一样。</li>
</ul>
<p>为了解决这个问题，可以采取的潜在措施有：</p>
<ul>
<li>使用数据对齐的内存。</li>
<li>使用 Sentinel 或者 Redis Cluster 的机制进行定期的主从切换，安全重启。</li>
</ul>
<h3 id="子进程-内存消耗划分">（子进程）内存消耗划分</h3>
<p>在进行备份的时候，AOF/RDB 重写会 fork 子进程。因为 COW 机制，大部分情况下子进程和父进程共用一段物理内存，在子进程发生写的时候，子进程单独复制一页出来完成写操作。</p>
<p>THP（透明大页）的存在会导致内存拷贝时产生的页非常大，拷贝代价增多，这在写命令很多的时候会造成过度内存消耗。所以和 JVM 相反，应该关闭大页优化。</p>
<p>除此之外，应该设置 vm.overcommit_memory=1，允许内核充分使用物理内存。</p>
<h2 id="内存管理">内存管理</h2>
<h3 id="设置内存上限">设置内存上限</h3>
<p>内存管理的上限是 maxmemory，这个阈值是为了保护 memory exhausted，触发各种 policy 准备的 - 缓存场景下特别重要。</p>
<h3 id="动态调整-maxmemory">动态调整 maxmemory</h3>
<p>这个值可以被动态修改，方便扩容缩容-JVM 就不可以。<br>
如果不设置，Redis 默认 maxmemory 无限大。</p>
<h3 id="内存回收策略">内存回收策略</h3>
<h4 id="删除过期对象">删除过期对象</h4>
<p><strong>Redis 所有的 Key 都可以 expire</strong>，key 会被保存在过期字典中（Redis数据库主要是由两个字典构成的，一个字典保存键值对，另一个字典就是保存的过期键的过期时间，我们称这个字典叫过期字典）。</p>
<p>Redis 为了节省 CPU，并不会精准删除 Redis 中的每个 Key，主要采用两个方案：</p>
<h5 id="惰性删除">惰性删除</h5>
<p><strong>所谓的惰性删除，其实是只有发生特定的事件（读/写）的时候</strong>，才进行删除数据，并返回空值（nil）的一种策略。</p>
<p>这样做实际上避免了维护 ttl 链表（类似 Java 中的 LinkedHashMap），节省了 CPU。</p>
<p>**惰性删除的缺点是，事件并不一定发生，或者过了很长的时间才发生，内存容易发生泄漏。**这可能是所有事件驱动悬垂事件的缺点。</p>
<h5 id="定时任务删除">定时任务删除</h5>
<p>Redis虽然是个单线程架构，但内部维护一个定时任务，默认每秒运行 10 次（可配置，不知道是不是 event loop 实现的）。</p>
<p>其基本流程为：</p>
<p><img src="%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%88%A0%E9%99%A4.png" alt="定时任务删除"></p>
<ul>
<li>以慢模式启动。</li>
<li>每次执行时针对每个 db 空间随机采样 20 个 key，进行超时检验并删除 key，并采样统计。</li>
<li>如果没有 25% 的 key 过期，任务退出。</li>
<li>否则循环执行删除 key 的操作。</li>
<li>如果最终执行超过 25 ms 或者统计数据低于 25%以后，直接退出。</li>
<li>否则每次 Redis 事件发生以前用快模式删除 Key。</li>
</ul>
<p>快模式和慢模式的流程一样（也就是和上面一样），但超时时间短很多，只有 1ms，且 2 s 内只能运行一次。</p>
<h4 id="内存溢出控制策略">内存溢出控制策略</h4>
<p>内存使用量(实际上应当是去掉缓冲区内存后的对象内存)一旦到达 maxmemory，Redis 就要开始 evict 操作。基于 maxmemory-policy，Redis 一共有 6 种策略：</p>
<ul>
<li>noeviction：默认策略。拒绝写入任何数据而报错。</li>
<li>volatile-lru：根据 LRU 算法删除设置了 expire 的键，直到腾出空间为止。如果没有可删除的对象（了），回退到 noeviction。</li>
<li>allkeys-lru：对全 key 进行 lru 删除，直到腾出空间为止-<strong>这也就意味着不设置 expire 也能区分出 lru 的键来</strong>，这也意味着 Redis 可以当做准成的 lru cache 用。</li>
<li>volatile-random：随机删除过期键，直到腾出空间为止。</li>
<li>volatile-ttl：根据键值对的 ttl 属性，删除最近将过期的数据。如果（要有 expire 才有 ttl）没有，回退到 noeviction。</li>
</ul>
<p>每次执行命令时，Redis 都会检查 maxmemory，尝试进行内存回收工作。内存回收造成的 delete 还会被同步到从节点，造成写放大-凡是主从模式都要考虑写放大问题。</p>
<p>因为这个值可以动态调整，所以可以动态触发 Redis 缩容，这是 JVM 做不到的。</p>
<h2 id="内存优化">内存优化</h2>
<h3 id="redisobject-对象">redisObject 对象</h3>
<p>Redis 中的<strong>值对象</strong>在内部定义为 redisObject 结构体。</p>
<p><img src="redisObject.png" alt="redisObject"></p>
<p>其内容为：</p>
<ul>
<li>type：type 会返回value（not key）的数据类型。</li>
<li>encoding：同一种类型的 value，使用不同的 encoding 差别也会非常大。</li>
<li>lru：记录对象被最后一次访问的时间。这对allkeys-lru 和 volatile-lru 场景下特别有用。</li>
<li>refcount 记录当前对象被引用的次数。refcount=0 意味着对象可以被安全回收。</li>
<li><code>*ptr</code>如果是整数则储存整数，否则指向数据内存段。</li>
</ul>
<h3 id="缩减键值对象">缩减键值对象</h3>
<p>应该尽量减少 key 和 value 的长度。</p>
<ul>
<li>在完整描述业务的情况，key 越短越好。</li>
<li>value 应该被序列化前尽量精简对象，使用最好的序列化算法+压缩算法（考虑 snappy）。</li>
</ul>
<h3 id="共享对象池">共享对象池</h3>
<p>共享对象池就是整数对象池，不像 JVM，不存在其他类型的对象池。</p>
<p>类似 Java 中的字符串 intern 池和 wrapper cache，Redis 会自动复用[0-9999]的整数对象池。5 种类型的 value 一旦涉及整数，也会引用整数对象池。</p>
<p>使用</p>
<blockquote>
<p>127.0.0.1:6379&gt; set foo 2<br>
OK<br>
127.0.0.1:6379&gt; object refcount foo<br>
(integer) 2147483647</p>
</blockquote>
<p>这个对象池的大小可以通过 REDIS_SHARED_INTEGERS 来定义，不能<code>config set</code>。类似 JVM。</p>
<p>如果 maxmemory-policy 为 volatile-lru 或者 allkeys-lru，整数对象池会无效化，否则这两种策略无法好好工作。</p>
<h3 id="字符串优化">字符串优化</h3>
<p>字符串没有使用 c 语言的字符串类型，而使用了 sds（simple dynamic string：</p>
<ul>
<li>大量操作时间复杂度O（1）。</li>
<li>可保存字节数组</li>
<li>有预分配机制-会在 append 场景下造成内存损耗。</li>
<li>有惰性删除机制。</li>
</ul>
<p>某些场景下，使用 hash 来重构字符串类型的数据结构更节省内存。</p>
<h3 id="编码优化">编码优化</h3>
<p>Redis 的特点就是“all in memory”。</p>
<p>可以使用<code>config set</code>来调整某些类型的内部编码的阈值，使数据编码从压缩编码（小编码）向非压缩编码转换（大编码）。其中 ziplist 是一种特别优秀、紧凑的数据结构，会使用线性连续的内存。</p>
<p>重点值得用是 ：</p>
<ul>
<li>ziplist（list，hashtable，zset 都可以用），节省内存但规模大了以后消耗 cpu</li>
<li>intset 节省内存</li>
</ul>
<h1>哨兵 Sentinel</h1>
<p>Redis 有若干套高可用实现方案。2.8 开始提供哨兵功能（不要使用更低版本的哨兵，可能有 bug）。</p>
<h2 id="基本概念">基本概念</h2>
<p><img src="%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.png" alt="基本概念"></p>
<h3 id="主从复制模式的问题">主从复制模式的问题</h3>
<p>Redis 天然就带有主从复制的功能，但主从复制有若干缺点：</p>
<ul>
<li>需要手工干预，缺乏自动 FO 机制-分布式高可用问题。</li>
<li>单机的写能力有限-分布式容量问题。</li>
<li>单机的存储能力有限-分布式容量问题。</li>
</ul>
<h3 id="一个经典的高可用场景">一个经典的高可用场景</h3>
<p>当一个主从集群的 主节点 失效的时候，经典的恢复步骤如下：</p>
<ol>
<li>主节点失效。</li>
<li>选出新的从节点，<code>slaveof no one</code>。</li>
<li>先更新应用方的连接。</li>
<li>再让其他从节点换主。</li>
<li>再把恢复好的主节点作为新的从节点复制新的主节点。</li>
</ol>
<p>3 和 4 的步骤可以互换。这种需要手工介入的运行机制不能被当作高可用的。而 sentinel 的作用是把这些经典步骤从<strong>手工实现为自动</strong>。</p>
<h3 id="sentinel-的高可用性">Sentinel 的高可用性</h3>
<p>Sentinel 方案是在原生的 Master-Slave 集群之外加上一个 Sentinel 集群。</p>
<p>每个 Sentinel 节点会监控其他 Sentinel 节点和所有 Redis 节点。任何一个不可达的节点，它都会将其做下线标识。</p>
<p>如果标识的是主节点，它还会：</p>
<ol>
<li>与其他 Sentinel 节点进行“协商”（negotiate），当大多数 Sentinel节点认为主节点都认为主节点不可达时。。</li>
<li>会先选举出一个 leader Sentinel 节点来完成自动的 FO 工作。。</li>
<li>把集群变化通知 Redis 应用方。</li>
</ol>
<p><img src="%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%9C%A8%E4%B8%BB%E5%8A%A8%E7%9B%91%E6%8E%A7%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4.png" alt="哨兵集群在主动监控主从集群"></p>
<ol>
<li>monitor</li>
<li>negotiate、vote、self-election</li>
<li>slaveof no one、slave of new master</li>
<li>notify client</li>
</ol>
<h2 id="sentinel-的部署和启动">sentinel 的部署和启动</h2>
<h3 id="单个-sentinel-节点的配置文件">单个 sentinel 节点的配置文件</h3>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-comment"># 常见参数有 4 个。这四个参数可以配置多套，每套 my_redis_master 可以监控不同的主从</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># my_redis_master 是主节点的别名，redis1 是主节点的域名，当前 sentinel 起始就要监控一个 redis 节点，意味着 sentinel 的拓扑结构受 redis 集群的拓扑结构影响。3 意味着 quorum 是 3 ，3个节点认为 master 不可达才形成决议。</span><br><span class="hljs-comment"># Redis 集群应该和其他集群一样，尽量设置为大于等于 3 的奇数，兼顾高可用和选举领导的需要</span><br><span class="hljs-comment"># 只有集群里的节点达到 max(quorum, num(sentinel)/2 + 1) ，选举才成立。在大多数情况下 quorum = num(sentinel)/2 + 1</span><br><span class="hljs-attr">sentinel</span> <span class="hljs-string">monitor my_redis_master redis1 6379 3</span><br><span class="hljs-comment"># sentinel 会定期发送 ping 到 master（其实也包括所有其他节点），3000 毫秒不回应就意味着不可达</span><br><span class="hljs-attr">sentinel</span> <span class="hljs-string">down-after-milliseconds my_redis_master 3000</span><br><span class="hljs-comment"># redis 同时对从节点进行故障转移的复制的并发度。并发度高会消耗新 master 的系统带宽-网络和磁盘。</span><br><span class="hljs-attr">sentinel</span> <span class="hljs-string">parallel-syncs my_redis_master 1</span><br><span class="hljs-comment"># 集群故障转移四个阶段的任何一个步骤的失败时延，如果超过这个时间则会重新发起新故障转移</span><br><span class="hljs-attr">sentinel</span> <span class="hljs-string">failover-timeout my_redis_master 10000</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># 辅助参数</span><br><span class="hljs-attr">port</span> <span class="hljs-string">26379</span><br><span class="hljs-comment"># 写了这个文件就会导致 stdout 不再输出</span><br><span class="hljs-attr">logfile</span> <span class="hljs-string">&quot;sentinel.log&quot;</span><br><span class="hljs-comment"># 不要乱用镜像中不存在的路径</span><br><span class="hljs-comment">#dir /opt/soft/redis/data</span><br></code></pre></td></tr></table></figure>
<p>实际上每个 sentinel 节点的配置文件都可以写成这样，但每个文件必须单独存在，<strong>因为 sentinel 文件会在启动时重写各自的配置文件</strong>，写入 config-epoch/leader-epoch。</p>
<p>通过域名/容器名，来标定唯一 ip + port 标识的 redis 进程，是容易被忽略的管理集群的方法。这里的配置只配了 master name，通过与 master 协商，可以很快地理解整个 M/S 的拓扑结构。</p>
<p>quorum 是最小结合，而不是陪审团总大小的意思。quorum 达到一半加 1 即客观。要选出 leader sentinel 需要 max(quorum, num(sentinels)/2 + 1)个节点举行选举。</p>
<p>这个文件里有不少的配置都是调大变严格， 调小变宽松，严格的成本比较高。</p>
<p>此外，还有如下有意思的命令：</p>
<ol>
<li>sentinel notification-script <master-name> <script-path>：这个命令要求能用 msg=$* 来解析消息格式，如 +sdown master mymaster 127.0.0.1 6379</li>
<li>sentinel client-reconfig-script <master-name> <script-path>：这个脚本可以接收故障转移结果</li>
</ol>
<p>这些命令对脚本化运维是很有帮助的。sentinel 本身是角色的，我们可以看到 leader observer sentinel。</p>
<h3 id="启动命令">启动命令</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 这两种启动方法本质上是一样的</span><br>redis-server /etc/redis-conf/sentinel.conf --sentinel<br>redis-sentinel /etc/redis-conf/sentinel.conf<br></code></pre></td></tr></table></figure>
<p>sentinel 本质上只是一种特殊的 Redis 节点。因此可以使用如下的命令查看哨兵的已知信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">redis-cli -p 26379 info sentinel<br></code></pre></td></tr></table></figure>
<p>sentinel （使用 info 子命令）可以清楚地知道当前监控了多少个集群，集群里有多少个主从节点，一共有几个哨兵节点。</p>
<p><img src="info-sentinel.png" alt="info sentinel 试图向我们描述的东西"></p>
<h3 id="监控多个集群">监控多个集群</h3>
<p>一套 Sentinel 可以监控多个 Redis 集群，只要准备多套<code>sentinel monitor my_redis_master redis1 6379 3</code>里的 master name my_redis_master 即可。</p>
<h3 id="配置调整">配置调整</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sentinel <span class="hljs-built_in">set</span> xxx xxx<br></code></pre></td></tr></table></figure>
<p>需要注意：</p>
<ol>
<li>sentinel set 只对当前节点有效。</li>
<li>sentinel set 命令执行完成以后会立即刷新配置文件，这点和普通节点需要使用<code>config rewrite</code>。</li>
<li>所有节点的配置应该一致。注意 1。</li>
<li>sentinel 对外不支持 config 命令</li>
</ol>
<h3 id="部署技巧">部署技巧</h3>
<ol>
<li>sentinel 节点应该在物理机层面做隔离，这样才客观，能实现真正的高可用。</li>
<li>sentinel 集群应该有超过 3 个的奇数节点。</li>
<li>奇数节点对选举的效果是最优的。</li>
<li>可以一套 sentinel 监控多套集群，也可以多套 sentinel 监控多套集群。取舍的时候需要考虑的是：是否 sentinel 节点自身的失败需要被隔离。最佳的方案是：一个业务一套 sentinel。但实践中似乎有些大厂采用多套业务一套 sentinel，在成本和高可用之间，倾向于成本。</li>
</ol>
<h3 id="api">API</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在 cli 内</span><br>sentinel masters<br>sentinel master master-name<br>sentinel slaves slave-name<br><br><span class="hljs-comment"># 强制失效转移</span><br>sentinel failover master-name<br><br><span class="hljs-comment"># 校验 quorum 是否稳定</span><br>sentinel ckquorum master-name<br><br><span class="hljs-comment"># 配置刷盘</span><br>sentinel flushconfig<br><br><span class="hljs-comment"># 取消 sentinel 对集群的监控</span><br>sentinel remove master-name<br><br><span class="hljs-comment"># 增加 sentinel 对集群的监控</span><br>sentinel monitor &lt;master-name&gt; &lt;host&gt; &lt;port&gt; &lt;quorum&gt;<br></code></pre></td></tr></table></figure>
<h3 id="如何实现一个好的客户端">如何实现一个好的客户端</h3>
<p>服务端拥有管理元数据的功能，也有通知的功能，也有自动介入的功能。而 client 要同 sentinel 集群保持密切联系，才能保持对 Redis  master 的联系。但 sentinel 方案本身并不像 Zookeeper，没有主动广播的机会。</p>
<p>jedis-client 本身是使用 common-pool + 遍历 sentinel 集群各个节点的方式来维持一个 resource 池的。而遍历 sentinel 集群是通过发布-订阅 sentinel 的特有频道来实现的。</p>
<h2 id="实现原理">实现原理</h2>
<p><img src="Sentinel%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E7%9A%84%E5%8E%9F%E7%90%86.png" alt="Sentinel故障转移的原理.png"><br>
<a href="Sentinel%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E7%9A%84%E5%8E%9F%E7%90%86.xmind">Sentinel故障转移的原理.xmind</a></p>
<h3 id="三个定时任务">三个定时任务</h3>
<ul>
<li>每隔 10s，sentinel 往所有 M/S 发 info 获取最新的拓扑结构</li>
<li>从主节点可以实时获知从节点的信息</li>
</ul>
<p><img src="info%E4%BB%BB%E5%8A%A1.png" alt="info任务"></p>
<ul>
<li>每隔 2s，sentinel 节点会向 Redis 数据节点的 <em>sentinel</em>:hello 频道上发送改 Sentinel 节点对主节点的判断，以及当前 Sentinel 节点的信息。同时每隔 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及它们对主节点的判断。</li>
<li>sentinel 可以通过这个频道获取 sentinel 之间的信息</li>
<li>交换主节点的状态，可以作为后续<strong>客观下线</strong>和领导者选举操作的依据：</li>
</ul>
<p><img src="%E5%8F%91%E5%B8%83%E6%84%8F%E8%A7%81%E4%BB%BB%E5%8A%A1.png" alt="发布意见任务.png"></p>
<ul>
<li>每隔 1s，sentinel 会向M/S和其他 Sentinel 发送一条 ping 命令做一次心跳检测，来确认节点是否可达。</li>
</ul>
<p><img src="ping%E4%BB%BB%E5%8A%A1.png" alt="ping任务"></p>
<h3 id="主观下线和客观下线">主观下线和客观下线</h3>
<h4 id="主观下线-odown">主观下线（odown）</h4>
<p>任意sentinel ping master 超时（sentinel down-after-milliseconds my_redis_master 3000），就可以单节点认为该节点已失败。</p>
<p>任何一个节点进入主观下线状态时，都会使用<code>new_epoch</code>让当前纪元加一。</p>
<h4 id="客观下线-sdown">客观下线（sdown）</h4>
<p>sentinel 一进入主观下线状态，就会发送<code>SENTINEL is-master-down-by-addr &lt;masterip&gt; &lt;masterport&gt; &lt;sentinel.current_epoch&gt; *</code> 命令<strong>直接询问</strong>其他哨兵节点对主节点的判断，<strong>当主观下线的 哨兵数量超过<quorum>的个数（不一定要超过半数）</strong>，Sentinel 节点认为主节点确实有问题，这时候 Sentinel 就可以客观下线的决定。第一个进入主观下线状态的节点，往往成为进入客观下线的节点-这点特别像 Raft。</p>
<p><img src="%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%92%8C%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF.jpg" alt="主观下线和客观下线"></p>
<p>runId等于<code>*</code>时，sentinel 交换的是主节点下线的判定；runId 等于哨兵的runId时，哨兵请求的是其他节点同意它成为领导者。</p>
<h4 id="客观下线必须举行-sentinel-节点选举">客观下线必须举行 Sentinel 节点选举</h4>
<p><strong>主观下线和客观下线本质上只是对 Redis 主节点的一个状态标记，并不会天然将自己标记为领导者，更不会自动故障转移。</strong></p>
<ol>
<li>确定进入客观状态的 Sentinel 节点会成为一个 candidate，立刻发送一个<code>SENTINEL is-master-down-by-addr &lt;masterip&gt; &lt;masterport&gt; &lt;sentinel.current_epoch&gt; 自己的 runid</code></li>
<li>每个 sentinel 节点在收到该命令的后，如果没有同意过其他 Sentinel 节点的 sentinel is-master-down-by-addr 命令，将同意该请求，否则拒绝（<strong>raft 里每个节点每轮选举只能有一票</strong>）。</li>
<li>发起选举的 Sentinel 要么成为领导者，<strong>要么进入下一轮选举（或者恢复到主观下线以前的状态？）</strong>。</li>
</ol>
<h3 id="故障转移">故障转移</h3>
<p>所有的故障转移其实只是执行命令，把手动步骤编程为自动步骤而已。</p>
<p>具体步骤为：</p>
<ul>
<li>在从节点列表中选择一个节点作为新的主节点。因为从节点本身是有状态的，所以实际上是使用<strong>综合考虑权重、优先级和一致性的类负载均衡选择算</strong>法：</li>
<li>过滤不健康节点：主观下线、断线、5s 内没有回复过 Sentinel 的 ping 命令、与主节点失联超过 down-after-miliseconds。</li>
<li>选择 slave-priority 最高的节点（如何配置？）。</li>
<li>选择偏移量最大的从节点-复制最完整。</li>
<li>选择 runid 最小的从节点。</li>
<li>对选出的节点发出 slave of no one 命令，从节点升为主节点。</li>
<li>对剩下的从节点发出命令，让它们成为主节点的从节点，复制规则和 parallel-sync 参数有关。</li>
<li>（<strong>最后</strong>）Sentinel 节点集合会将原来主节点更新为从节点，（这样线上先止血成功），然后持续对其关注，待其恢复后命令其去复制新的主节点。</li>
</ul>
<h3 id="全流程">全流程</h3>
<p><img src="redis%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF%E6%B5%81%E7%A8%8B.png" alt="redis客观下线流程"></p>
<h2 id="节点运维">节点运维</h2>
<h3 id="节点下线">节点下线</h3>
<ul>
<li>临时下线：暂时将节点关掉，之后还会重新启动，继续提供服务。</li>
<li>永久下线：将节点关掉不再使用，需要做一些清理工作，如删除配置文件，持久化文件、日志文件。</li>
</ul>
<h4 id="主节点下线">主节点下线</h4>
<ol>
<li>
<p>将一个合适的从节点（如高性能）的 priority 设置为 0。可参考 <a target="_blank" rel="noopener" href="https://redis.io/topics/sentinel">sentinel</a> 中的 Replicas priority section。</p>
</li>
<li>
<p>在任意一个 sentinel 上，执行<code>sentinel failover master-name</code>。</p>
</li>
</ol>
<h4 id="从节点或-sentinel-节点下线">从节点或 sentinel 节点下线</h4>
<p>如果使用了读写分离，要确保读写分离机制能够自动感知拓扑结构的变化。<br>
如果只是临时下线（命令下线、kill），sentinel 会对下线节点念念不忘，也就是会不断地对这些节点进行 monitor，浪费硬盘和网络资源，这种时候可以考虑永久下线。</p>
<h3 id="节点上线">节点上线</h3>
<h4 id="从节点上线">从节点上线</h4>
<p>配置节点 slave of [masterIp] [masterPort] 让节点上线。master 收到链接后，主从就会自动相互注册发现，而 sentinel 也会自动发现新的从节点。</p>
<h4 id="sentinel-节点上线">Sentinel 节点上线</h4>
<p>sentinel 只要配了 sentinel monitor，它就会连上 master，进而被 sentinel 网络互相理解发现。</p>
<h1>集群 Cluster</h1>
<h2 id="背景">背景</h2>
<p>在 Redis Cluster 方案诞生以前，在 Redis 集群遇到单机资源和流量瓶颈时，有两种常见分布式解决方案：</p>
<ul>
<li>客户端方案：需要自己处理分区逻辑、路由、故障转移（有时候 Routing、LB 和 Failover是同一个问题，都需要通过 routing 技术来切换流量的 endpoint）。</li>
<li>代理方案：减轻了客户端的职责和压力，架构上的负担过重。</li>
</ul>
<p>Redis Cluster 的出现，极大地降低了架构师的负担，解放了生产力。</p>
<h2 id="数据分布">数据分布</h2>
<h3 id="数据分布理论">数据分布理论</h3>
<p>|分区方式|特点|代表产品|取舍逻辑|<br>
|:–:|:–:|:–:|<br>
|哈希分区| 离散度好 数据分布业务无关 无法顺序访问| <strong>KV型</strong> Redis Cluster Cassandra Dynamo <strong>Elastic Search</strong>|如果需要平衡地存储大量数据而只有随机访问其中的若干条，则可以使用简单的哈希分区|<br>
|顺序分区|离散度易倾斜 数据分布业务相关 可顺序访问| <strong>表型 Bigtable</strong> HBase Hypertable|如果需要存储大量数据且需要支持区间查找，则也需要使用简单的顺序分区，如果要解决负载均衡的问题可能需要不均匀分片以及分裂和压缩算法的支持|</p>
<p>我们在常规的实践里，随机查找和区间查找的场景同时存在，所以主存储都是按照某个索引顺序存储（MySQL、HBase），再想着怎样使用顺序分区来解决负载均衡（不均衡就会产生倾斜）的问题。而 Dynamo、Cassandra（一个希腊女神的名字）和 Redis用于存储大批量的点状数据为宜。</p>
<p>Redis Cluster 采取<strong>哈希分区规则</strong>，常见的哈希分区规则有</p>
<h4 id="节点取余">节点取余</h4>
<p>根据固定的数量（区间数）而不只是总数取余是简单的。</p>
<p>使用特定的数据，如 Redis 的键或用户 Id，再根据节点数量 N 使用公式：<code>hash(key) % N</code>（经典的双层 hash），用来决定数据映射到哪一个桶里。这种方案存在一个问题，当节点数量变化时，整个映射关系都要重新计算。</p>
<p>如果使用这种哈希方式，一开始就要规划好分区，保证可以支撑<strong>未来一段时间的数据量</strong>，扩容时可以天然采用翻倍扩容。</p>
<p>在实践中，如果使用超量部署的方法，一开始就配好 8 个分片或者16个分片，则可能很长时间都不需要扩容-如果扩容也可以使用新建集群的方法，也不需要考虑数据迁移（然后要依赖于 rehash）的问题。预分区的规划很重要。</p>
<p>如果涉及到数据迁移，则需要考虑：</p>
<ol>
<li>新旧分区的资源申请</li>
<li>新旧分区的目标分布</li>
<li>双写</li>
<li>双读</li>
<li>停写校验</li>
<li>切换读</li>
</ol>
<h4 id="一致性哈希">一致性哈希</h4>
<p>一致性哈希（Distributed Hash Table）的实现思路是为系统中每个节点分配一个 token，范围一般在<code>0~2&lt;sup&gt;32&lt;/sup&gt;</code>，这些 token 构成一个 hash 环。数据读写执行查找时，先 hash，然后顺时针（向大数方向）选最近一个 bucket(第一个&gt;= hash value 的token)。</p>
<p><img src="%E4%B8%80%E8%87%B4%E6%80%A7%E6%95%A3%E5%88%97.jpg" alt="一致性散列.jpg"></p>
<p>一致性散列的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。但一致性哈希分区存在几个问题：</p>
<ul>
<li>加减节点会造成哈希环中部分数据无法命中（取余分区一样存在这个问题），需要手动处理或者忽略这部分数据，因此一致性哈希常用于缓存场景。</li>
<li>当使用少量节点时，节点变化将大范围影响哈希环中数据映射，因此这种方式不适合少量数据节点的分布式方案。</li>
<li>普通的一致性哈希分区在增减节点时需要增加一倍或减去一般节点才能保证数据和负载的均衡。</li>
</ul>
<h4 id="虚拟槽分区">虚拟槽分区</h4>
<p>虚拟槽分区兼顾了取余分区和一致性哈希的优点，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个数一般远大于节点数，比如 Redis Cluster 的槽范围是 0 -16383。槽是集群内数据管理和迁移的基本单位。采用大范围的槽的目的是为了方便数据拆分和集群扩展，每个节点负责一定数量的槽。</p>
<h3 id="redis-数据分区">Redis 数据分区</h3>
<p>slot = crc16(key) * 16383</p>
<p>注意：</p>
<ul>
<li>crc16 是一种哈希函数</li>
<li>用 * 取余的方法</li>
</ul>
<p>每个节点负责维护一部分槽以及槽锁映射的键值数据。</p>
<p><img src="RedisCluster%E7%9A%84%E6%A7%BD%E4%BD%8D%E6%98%A0%E5%B0%84.jpg" alt="RedisCluster的槽位映射"></p>
<p>Redis 虚拟槽分区的特点：</p>
<ul>
<li>解耦数据和几点之间的关系，简化了节点扩容和收缩难度。如果增加一个节点 6，就需要从节点 1 ~ 5 获得部分 槽 分配到节点 6 上。如果想移除节点 1，需要将节点 1 中的槽移到节点 2 ~ 5 上，然后将没有任何槽的节点 1 从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。</li>
<li>节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。</li>
<li>支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。</li>
</ul>
<h3 id="redis-数据分区限制">Redis 数据分区限制</h3>
<ol>
<li>只允许对映射到同一个 slot 的 key 进行批量操作，如 mget、mset。</li>
<li>只支持对映射到同一个 node 的 key 进行事务操作。</li>
<li>大数据结构（hash/list）必须映射到同一节点（key 在最小的可分割单位）。</li>
<li>不支持多数据空间，只能使用 db0。有了 Redis Cluster，会推动多数据空间消亡。</li>
<li>复制结构只支持一层，从节点只能复制主节点。</li>
</ol>
<h2 id="搭建集群">搭建集群</h2>
<h3 id="准备节点">准备节点</h3>
<p>Redis Cluster 至少需要 6 个节点。<br>
开启配置<code>redis-enabled yes</code>。</p>
<p>准备配置文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 开启后台运行，在 docker 中不能使用这个属性，否则 redis 会直接退出，具体原因见：https://stackoverflow.com/questions/50790197/why-redis-in-docker-need-set-daemonize-to-no/50790274</span><br><span class="hljs-comment"># 实际上 docker 容器的启动命令都不能使用守护态执行，否则会直接导致 Docker 的 exec（实际上就是 init 的第一个子进程，执行命令的 shell）走到尽头直接退出。</span><br><span class="hljs-comment"># daemonize yes</span><br><span class="hljs-comment"># 指定工作目录，rdb,aof持久化文件将会放在该目录下，不同实例一定要配置不同的工作目录</span><br><span class="hljs-built_in">dir</span> <span class="hljs-string">&quot;/etc/redis-conf/dir&quot;</span><br>logfile <span class="hljs-string">&quot;/etc/redis-conf/log/redis.log&quot;</span><br><br><span class="hljs-comment"># 启用集群模式</span><br>cluster-enabled <span class="hljs-built_in">yes</span><br><span class="hljs-comment"># 生成的集群配置文件名称，集群搭建成功后会自动生成，在工作目录下</span><br>cluster-config-file <span class="hljs-string">&quot;redis-cluster.conf&quot;</span><br><span class="hljs-comment"># 节点宕机发现时间，可以理解为主节点宕机后从节点升级为主节点时间</span><br>cluster-node-timeout 5000<br><span class="hljs-comment"># 开启AOF模式</span><br>appendonly <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure>
<p>要特别注意：</p>
<ul>
<li>dir、log 等目录一定要可写。</li>
<li>cluster-config-file 是会被自动生成的，类似 sentinel 会覆写 sentinel 节点的配置文件。</li>
</ul>
<p><img src="%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%96%87%E4%BB%B6.png" alt="集群启动文件.png"></p>
<h3 id="节点握手">节点握手</h3>
<p><strong>注意，配置文件里并没有指明当前任何节点属于什么集群，这些节点可以手动加入任何集群</strong>。</p>
<p>节点握手是指一批运行在集群模式下的节点通过 Gossip 协议彼此通信，达到感知对方的过程。节点握手是集群彼此通信的第一步，由客户端发起命令：<code>cluster meet &#123;ip&#125; &#123;port&#125;</code>。</p>
<p>cluster meet 是一个<strong>异步命令</strong>，执行后立即返回。内部发起与目标节点进行握手通信：</p>
<ol>
<li>节点1创建节点2的节点信息对象，并发送 meet 消息。</li>
<li>节点2接收到 meet 消息后，保存 6379 节点信息并回复 pong 消息。</li>
<li>之后节点 6379 和 6380 彼此定期通过 ping/pong 消息进行正常的节点通信。</li>
</ol>
<p><img src="cluster-meet.png" alt="cluster-meet"></p>
<p>meet、ping、pong 消息是 Gossip 协议通信的载体。它的主要作用是使节点彼此交换状态数据信息。</p>
<p>使用<code>cluster nodes</code>可以获知当前集群的全貌：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">7979ba1902bc0e282e714a67dd74ec089348f5c6</span> <span class="hljs-number">172.22.1.20:6379</span>@<span class="hljs-number">16379</span> master - <span class="hljs-number">0</span> <span class="hljs-number">1573396221415</span> <span class="hljs-number">3</span> connected<br><span class="hljs-attribute">169a1f9a2e43783af421d8d6fd1f12681cc9c1b5</span> <span class="hljs-number">172.22.1.30:6379</span>@<span class="hljs-number">16379</span> master - <span class="hljs-number">0</span> <span class="hljs-number">1573396222427</span> <span class="hljs-number">2</span> connected<br><span class="hljs-attribute">2a7a24e0b3269eaa2bfd787a04a704fa3a04e952</span> <span class="hljs-number">172.22.1.50:6379</span>@<span class="hljs-number">16379</span> master - <span class="hljs-number">0</span> <span class="hljs-number">1573396220409</span> <span class="hljs-number">4</span> connected<br><span class="hljs-attribute">847473ff9b35d4579f829626d97e24d102ce8f4c</span> <span class="hljs-number">172.22.1.40:6379</span>@<span class="hljs-number">16379</span> master - <span class="hljs-number">0</span> <span class="hljs-number">1573396221000</span> <span class="hljs-number">5</span> connected<br><span class="hljs-attribute">985a94be2fc9950bfb5d7e47fab214c42d232a05</span> <span class="hljs-number">172.22.1.60:6379</span>@<span class="hljs-number">16379</span> master - <span class="hljs-number">0</span> <span class="hljs-number">1573396221000</span> <span class="hljs-number">0</span> connected<br><span class="hljs-attribute">3e5bdb0972b892c170960b678185b034e5506d0a</span> <span class="hljs-number">172.22.1.10:6379</span>@<span class="hljs-number">16379</span> myself,master - <span class="hljs-number">0</span> <span class="hljs-number">1573396220000</span> <span class="hljs-number">1</span> connected<br></code></pre></td></tr></table></figure>
<p>其中开头的 40 位 16 进制数是当前集群的节点 id，<strong>在节点生成的时候就唯一初始化好了，每次重启都不会变-不同于 runId，runId 每次重启都会变</strong>。我们只要在集群内的任意节点上执行 <code>cluster meet</code>命令，握手状态就会通过消息在集群内传播，这样其他节点会自动发现新节点并发起握手流程。</p>
<h3 id="分配槽位">分配槽位</h3>
<p>这时候集群只是建立起来，还处于下线状态。直接往任意节点写会出现<code>(error) CLUSTERDOWN Hash slot not served</code>错误。</p>
<p>这时候执行<code>cluster info</code>命令，可以看到</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash">cluster_state:fail<br>cluster_slots_assigned:0<br>cluster_slots_ok:0<br>cluster_slots_pfail:0<br>cluster_slots_fail:0<br>cluster_known_nodes:6<br>cluster_size:0<br>cluster_current_epoch:5<br>cluster_my_epoch:1<br>cluster_stats_messages_ping_sent:1947<br>cluster_stats_messages_pong_sent:1979<br>cluster_stats_messages_meet_sent:5<br>cluster_stats_messages_publish_sent:7899<br>cluster_stats_messages_sent:11830<br>cluster_stats_messages_ping_received:1979<br>cluster_stats_messages_pong_received:1952<br>cluster_stats_messages_received:3931<br></code></pre></td></tr></table></figure>
<p><code>cluster_slots_assigned:0</code>意味着当前的集群的槽位没有做过映射，<strong>只有节点被分配了槽位，才能响应和这些槽关联的键命令</strong>。</p>
<p>首先把所有槽位分配给 3 个节点。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 要在 bash 环境下使用，否则 &#123;0..5461&#125; 不会被 redis-cli 的上下文识别</span><br>redis-cli -h 127.0.0.1 -p 6379 cluster addslots &#123;0..5461&#125;<br>redis-cli -h 127.0.0.1 -p 6380 cluster addslots &#123;5462..10922&#125;<br>redis-cli -h 127.0.0.1 -p 6381 cluster addslots &#123;10923..16383&#125;<br></code></pre></td></tr></table></figure>
<p>这个时候再执行<code>cluster info</code>，则会看到：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">cluster_state:ok<br>cluster_slots_assigned:16384<br>cluster_slots_ok:16384<br>cluster_slots_pfail:0<br>cluster_slots_fail:0<br>cluster_known_nodes:6<br>cluster_size:3<br>cluster_current_epoch:5<br>cluster_my_epoch:1<br>cluster_stats_messages_ping_sent:574<br>cluster_stats_messages_pong_sent:456<br>cluster_stats_messages_publish_sent:2190<br>cluster_stats_messages_sent:3220<br>cluster_stats_messages_ping_received:456<br>cluster_stats_messages_pong_received:571<br>cluster_stats_messages_received:1027<br></code></pre></td></tr></table></figure>
<h3 id="制造主从结构">制造主从结构</h3>
<p>这时候把剩下三个节点作为从节点：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 3e5bdb0972b892c170960b678185b034e5506d0a 是要复制的主节点 node id</span><br>redis-cli -h 127.0.0.1 -p 6382 cluster replicate 3e5bdb0972b892c170960b678185b034e5506d0a<br></code></pre></td></tr></table></figure>
<p>这时候集群就已经开始各司其职了。</p>
<p><img src="cluster-nodes.png" alt="cluster-nodes"></p>
<p><img src="%E9%9B%86%E7%BE%A4%E5%AE%8C%E6%95%B4%E7%BB%93%E6%9E%84.png" alt="集群完整结构.png"></p>
<h3 id="简便方案">简便方案</h3>
<p>下面的命令可以一键生成集群，如果 Redis 版本不够高，就必须使用<code>redis-trib.rb</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># --cluster-replicas 1 告诉 Redis 每个主节点应该使用多少个从节点。</span><br>redis-cli --cluster  create --cluster-replicas 1  127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384<br></code></pre></td></tr></table></figure>
<p>如果当前节点都位于同一个 host 上，就会报<code>[WARNING] Some slaves are in the same host as their master</code>信息。实际上这些节点都处于一个 docker 集群里，但因为共用了<code>127.0.0.1</code>的地址，触发了反亲和性报错。</p>
<p>广播协议。<br>
共识协议。<br>
发布订阅。<br>
流言协议。</p>
<h2 id="搭建一个集群管理平台要回答好几个问题">搭建一个集群管理平台要回答好几个问题</h2>
<ol>
<li>业务归属地<br>
2.事业群、业务线：这里主要供运维参考，方便集群的运维管理。</li>
<li>集群部署位置（几个地域、几个中心）</li>
<li>服务等级</li>
<li>是否涉及现金交易：如果涉及到支付场景，请与SRE/DBA联系。</li>
<li>容量预估：需求容量应该事先评估好，减少后续的扩容次数（扩容过程会不会有数据丢失要看存储方案）。</li>
<li>峰值QPS(次/秒)预估</li>
<li>读写分布</li>
<li>客户端类型：根据实际使用情况进行选择，通常是 Redisson。</li>
<li>集群名：应该能准确简介地描述业务的功能或用途。使用“-”分隔（不要出现超过三次），不要出现环境结尾（环境后缀通常会自动被拼进去），不要出现数字。</li>
<li>集群描述：详细描述具体使用场景</li>
<li>是否持久化：redis集群主要提供的是存储功能。如果仅仅是作为缓存来用，持久化功能可以关闭，关闭了持久化功能的集群可以提供更好的性能。</li>
<li>是否可淘汰</li>
<li>可运维周期（星期几、是否工作日）。</li>
<li>可运维时间（通常是业务低峰期）。</li>
</ol>
<h2 id="怎样隔离-kv？">怎样隔离 kv？</h2>
<p>制造名字空间。</p>
<p>一种思路是<code>key</code>等于<code>$&#123;表名&#125;.$&#123;列名&#125;_$&#123;version&#125;</code>。每一个 key 要指定类型为好。</p>
<ul>
<li>category 表名</li>
<li>template 列名</li>
<li>version 是 redis 内部管理的一个数字，如果这个 category 清一次缓存，那么 version 会加1，这样最后的 key 字符串会变成全新的字符串，应用使用新的 key 之后需要重新从数据源加载数据到缓存-这又要引入事件驱动机制。</li>
</ul>
<h2 id="集群与集群组">集群与集群组</h2>
<p>在 Set/单元化架构中，一个 cluster group 包含多个 ldc 里的多个 cluster，每个 cluster 服从每个 unit/region/set 的配置。</p>
<p>在 cluster group 里对 category 进行操作最终会同步到各个 cluster 上。</p>
<h2 id="集群的辅助服务">集群的辅助服务</h2>
<ul>
<li>
<p>Redis-Keeper 集群间数据同步，美团也有自己的 Squirrel-Keeper</p>
</li>
<li>
<p>Redis-Migrate 扩容/迁移</p>
</li>
<li>
<p>Redis-Web 管理</p>
</li>
<li>
<p>Redis-Monitor 监控告警</p>
</li>
<li>
<p>Redis-Schedule 调度/运营</p>
</li>
<li>
<p>Redis-HA 集群高可用</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://magicliang.github.io">magicliang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/">https://magicliang.github.io/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Redis/">Redis</a></div><div class="post-share"><div class="social-share" data-image="/2024/11/04/Redis-%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4/cover.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2019/10/30/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%8D%81-%E5%93%A8%E5%85%B5-Sentinel/" title="Redis 笔记之十-哨兵 Sentinel"><img class="cover" src="/img/wall-paper-20.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-10-30</div><div class="info-item-2">Redis 笔记之十-哨兵 Sentinel</div></div><div class="info-2"><div class="info-item-1">Redis 有若干套高可用实现方案。2.8 开始提供哨兵功能（不要使用更低版本的哨兵，可能有 bug）。 基本概念  主从复制模式的问题 Redis 天然就带有主从复制的功能，但主从复制有若干缺点：  需要手工干预，缺乏自动 FO 机制-分布式高可用问题。 单机的写能力有限-分布式容量问题。 单机的存储能力有限-分布式容量问题。  一个经典的高可用场景 当一个主从集群的 主节点 失效的时候，经典的恢复步骤如下：  主节点失效。 选出新的从节点，slaveof no one。 先更新应用方的连接。 再让其他从节点换主。 再把恢复好的主节点作为新的从节点复制新的主节点。  3 和 4 的步骤可以互换。这种需要手工介入的运行机制不能被当作高可用的。而 sentinel 的作用是把这些经典步骤从手工实现为自动。 Sentinel 的高可用性 Sentinel 方案是在原生的 Master-Slave 集群之外加上一个 Sentinel 集群。 每个 Sentinel 节点会监控其他 Sentinel 节点和所有 Redis 节点。任何一个不可达的节点，它都会将其做下线标识。 如果标识的是...</div></div></div></a><a class="pagination-related" href="/2019/11/09/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%8D%81%E4%B8%80-%E9%9B%86%E7%BE%A4-Cluster/" title="Redis 笔记之十一-集群 Cluster"><img class="cover" src="/img/wall-paper-108.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-09</div><div class="info-item-2">Redis 笔记之十一-集群 Cluster</div></div><div class="info-2"><div class="info-item-1">背景 在 Redis Cluster 方案诞生以前，在 Redis 集群遇到单机资源和流量瓶颈时，有两种常见分布式解决方案：  客户端方案：需要自己处理分区逻辑、路由、故障转移（有时候 Routing、LB 和 Failover是同一个问题，都需要通过 routing 技术来切换流量的 endpoint）。 代理方案：减轻了客户端的职责和压力，架构上的负担过重。  Redis Cluster 的出现，极大地降低了架构师的负担，解放了生产力。 数据分布 数据分布理论 |分区方式|特点|代表产品|取舍逻辑| |:–:|:–:|:–:| |哈希分区| 离散度好 数据分布业务无关 无法顺序访问| KV型 Redis Cluster Cassandra Dynamo Elastic Search|如果需要平衡地存储大量数据而只有随机访问其中的若干条，则可以使用简单的哈希分区| |顺序分区|离散度易倾斜 数据分布业务相关 可顺序访问| 表型 Bigtable HBase Hypertable|如果需要存储大量数据且需要支持区间查找，则也需要使用简单的顺序分区，如果要解决负载均衡的问题可能需要...</div></div></div></a><a class="pagination-related" href="/2022/01/13/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%EF%BC%9A%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98/" title="Redis 笔记之：内存调优"><img class="cover" src="/img/wall-paper-139.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-13</div><div class="info-item-2">Redis 笔记之：内存调优</div></div><div class="info-2"><div class="info-item-1">Redis 的 memory info Redis 的内存使用状况可以使用info memory来获取。 需要重点关注的值是 used_memory_rss（用于存储消耗的物理内存），used_memory（用于存储消耗的内存= 物理内存 + 硬盘），以及他们的比值mem_fragmentation_ratio（used_memory_rss/used_memory）。 used_memory_rss或者used_memory很高时，意味着当前的 Redis 实例正在蚕食系统中的内存/硬盘资源。 当这个mem_fragmentation_ratio大于 1 的时候，意味着用于存储消耗的物理内存超过了 Redis 自己掌控的内存值，也就意味着当前有些未能回收的内存泄漏或者碎片。 当这个mem_fragmentation_ratio小于 1 的时候，这意味着有一部分用于存储的内存，实际上是在使用虚拟内存中的 swap 空间，此时 Redis 的性能会非常差。 Redis 的内存轮廓 memory_used = 进程自身消耗的内存 + 存储对象的内存（大头） + buffer 内存 m...</div></div></div></a><a class="pagination-related" href="/2025/07/28/Redis-%E7%9A%84%E7%A5%9E%E5%A5%87%E7%94%A8%E4%BE%8B/" title="Redis 的神奇用例"><img class="cover" src="/img/wall-paper-128.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-28</div><div class="info-item-2">Redis 的神奇用例</div></div><div class="info-2"><div class="info-item-1">二级评论区 在现代 Web 应用中，评论系统是用户互动的核心功能之一。一个设计良好的评论系统不仅要能处理大量的读写请求，还需要支持诸如“回复评论”这样的嵌套结构（通常称为二级评论或评论回复）。Redis，作为一个高性能的内存数据库，凭借其丰富的数据结构，非常适合用来构建这样的系统。 本文将探讨如何利用 Redis 的 Hashes(哈希) 和 Sorted Sets(有序集合) 来设计和实现一个高效、可扩展的二级评论系统。 核心设计理念 我们设计的核心思想可以概括为两点：  实体存储: 使用 Redis Hash 来存储每条评论（包括一级评论和二级回复）的具体内容-不存博客的具体内容。 关系与排序: 使用 Redis Sorted Set 来维护评论之间的父子关系，并利用其天然的排序能力（基于 Score）来管理评论和回复的顺序（例如按时间倒序）。  数据结构详解 存储评论/回复内容 (Hash) 我们将每条评论或回复的实际数据存储在一个 Hash 中。   Key: comment:&#123;unique_comment_id&#125; (例如 comment:1001, ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Redis 特性</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-number">1.1.</span> <span class="toc-text">Redis 高性能的原因</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">Redis 的数据结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.3.</span> <span class="toc-text">Redis 应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E4%B8%8D%E9%80%82%E5%90%88%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.4.</span> <span class="toc-text">Redis 不适合的应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E-redis-%E6%88%91%E4%BB%AC%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B%E6%83%85"><span class="toc-number">1.5.</span> <span class="toc-text">关于 Redis 我们不知道的事情</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E7%9A%84%E6%80%A7%E8%83%BD%E9%BB%91%E6%B4%9E"><span class="toc-number">1.6.</span> <span class="toc-text">Redis 的性能黑洞</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">toolkit</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-server"><span class="toc-number">2.1.</span> <span class="toc-text">redis-server</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-cli"><span class="toc-number">2.2.</span> <span class="toc-text">redis-cli</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-benchmark"><span class="toc-number">2.3.</span> <span class="toc-text">redis-benchmark</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-check-aof"><span class="toc-number">2.4.</span> <span class="toc-text">redis-check-aof</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-check-rdb"><span class="toc-number">2.5.</span> <span class="toc-text">redis-check-rdb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-sentinel"><span class="toc-number">2.6.</span> <span class="toc-text">redis-sentinel</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96-redis-%E6%A8%A1%E5%9D%97"><span class="toc-number">2.7.</span> <span class="toc-text">其他 redis 模块</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">数据结构和内部编码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">常用命令</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%91%BD%E4%BB%A4"><span class="toc-number">4.1.</span> <span class="toc-text">全局命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E9%94%AE"><span class="toc-number">4.1.1.</span> <span class="toc-text">查看所有键</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%AE%E6%80%BB%E6%95%B0"><span class="toc-number">4.1.2.</span> <span class="toc-text">键总数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E9%94%AE%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8"><span class="toc-number">4.1.3.</span> <span class="toc-text">检查键是否存在</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E9%94%AE"><span class="toc-number">4.1.4.</span> <span class="toc-text">删除键</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%AE%E8%BF%87%E6%9C%9F"><span class="toc-number">4.1.5.</span> <span class="toc-text">键过期</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.1.6.</span> <span class="toc-text">键的数据结构类型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%91%BD%E4%BB%A4"><span class="toc-number">4.2.</span> <span class="toc-text">字符串命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE-%E5%8F%96%E5%80%BC"><span class="toc-number">4.2.1.</span> <span class="toc-text">设&#x2F;取值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E8%AE%BE-%E5%8F%96%E5%80%BC"><span class="toc-number">4.2.2.</span> <span class="toc-text">批量设&#x2F;取值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0-%E5%87%8F%E5%80%BC"><span class="toc-number">4.2.3.</span> <span class="toc-text">加&#x2F;减值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8D%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4"><span class="toc-number">4.2.4.</span> <span class="toc-text">位操作命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4"><span class="toc-number">4.2.5.</span> <span class="toc-text">其他命令</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E5%91%BD%E4%BB%A4"><span class="toc-number">4.3.</span> <span class="toc-text">哈希命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE-%E5%8F%96%E5%80%BC"><span class="toc-number">4.3.1.</span> <span class="toc-text">设&#x2F;取值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E8%AE%BE-%E5%8F%96%E5%80%BC"><span class="toc-number">4.3.2.</span> <span class="toc-text">批量设&#x2F;取值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E6%93%8D%E4%BD%9C"><span class="toc-number">4.3.3.</span> <span class="toc-text">数值操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%93%8D%E4%BD%9C"><span class="toc-number">4.3.4.</span> <span class="toc-text">其他操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%97%E8%A1%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">4.4.</span> <span class="toc-text">列表命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%88%A0%E6%93%8D%E4%BD%9C"><span class="toc-number">4.4.1.</span> <span class="toc-text">增删操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%BB%E5%A1%9E%E6%93%8D%E4%BD%9C"><span class="toc-number">4.4.2.</span> <span class="toc-text">阻塞操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E5%91%BD%E4%BB%A4"><span class="toc-number">4.5.</span> <span class="toc-text">集合命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%88%A0%E6%93%8D%E4%BD%9C"><span class="toc-number">4.5.1.</span> <span class="toc-text">增删操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C"><span class="toc-number">4.5.2.</span> <span class="toc-text">集合操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E5%91%BD%E4%BB%A4"><span class="toc-number">4.6.</span> <span class="toc-text">有序集合命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%88%A0%E6%93%8D%E4%BD%9C"><span class="toc-number">4.6.1.</span> <span class="toc-text">增删操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C"><span class="toc-number">4.6.2.</span> <span class="toc-text">集合操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%94%AE%E7%AE%A1%E7%90%86"><span class="toc-number">4.7.</span> <span class="toc-text">键管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA%E9%94%AE%E7%AE%A1%E7%90%86"><span class="toc-number">4.7.1.</span> <span class="toc-text">单个键管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%81%E7%A7%BB%E9%94%AE"><span class="toc-number">4.7.2.</span> <span class="toc-text">迁移键</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%81%8D%E5%8E%86%E9%94%AE"><span class="toc-number">4.7.3.</span> <span class="toc-text">遍历键</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86"><span class="toc-number">4.7.4.</span> <span class="toc-text">数据库管理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">Redis小功能</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%85%A2%E6%9F%A5%E8%AF%A2"><span class="toc-number">5.1.</span> <span class="toc-text">慢查询</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E7%9A%84%E5%85%B8%E5%9E%8B%E8%BF%87%E7%A8%8B"><span class="toc-number">5.1.1.</span> <span class="toc-text">命令执行的典型过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%88%E5%80%BC%E5%8F%82%E6%95%B0"><span class="toc-number">5.1.2.</span> <span class="toc-text">阈值参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C"><span class="toc-number">5.1.3.</span> <span class="toc-text">查询结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="toc-number">5.1.4.</span> <span class="toc-text">最佳实践</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-shell"><span class="toc-number">5.2.</span> <span class="toc-text">Redis Shell</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-cli"><span class="toc-number">5.2.1.</span> <span class="toc-text">redis-cli</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-server"><span class="toc-number">5.2.2.</span> <span class="toc-text">redis-server</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-benchmark"><span class="toc-number">5.2.3.</span> <span class="toc-text">redis-benchmark</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pipeline"><span class="toc-number">5.3.</span> <span class="toc-text">pipeline</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1"><span class="toc-number">5.4.</span> <span class="toc-text">事务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E4%BA%8B%E5%8A%A1-multi-exec"><span class="toc-number">5.4.1.</span> <span class="toc-text">简单事务（multi-exec）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B9%90%E8%A7%82%E9%94%81"><span class="toc-number">5.4.2.</span> <span class="toc-text">乐观锁</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E7%82%B9%E9%A2%9D%E5%A4%96%E7%9A%84%E7%BB%93%E8%AE%BA"><span class="toc-number">5.4.2.1.</span> <span class="toc-text">一点额外的结论</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lua"><span class="toc-number">5.4.3.</span> <span class="toc-text">Lua</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#eval"><span class="toc-number">5.4.3.1.</span> <span class="toc-text">eval</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#evalsha"><span class="toc-number">5.4.3.2.</span> <span class="toc-text">evalsha</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%A1%E7%90%86-lua-%E8%84%9A%E6%9C%AC"><span class="toc-number">5.4.3.3.</span> <span class="toc-text">管理 lua 脚本</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8D%E5%9B%BE"><span class="toc-number">5.5.</span> <span class="toc-text">位图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hyperloglog"><span class="toc-number">5.6.</span> <span class="toc-text">HyperLogLog</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E5%B8%83-publish-%E8%AE%A2%E9%98%85-subscribe"><span class="toc-number">5.7.</span> <span class="toc-text">发布（publish）&#x2F;订阅（subscribe）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#geo-%E5%9C%B0%E7%90%86%E4%BF%A1%E6%81%AF%E5%AE%9A%E4%BD%8D"><span class="toc-number">5.8.</span> <span class="toc-text">GEO（地理信息定位）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">客户端</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis-%E5%8D%8F%E8%AE%AE"><span class="toc-number">6.1.</span> <span class="toc-text">Redis 协议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jedis-%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">6.2.</span> <span class="toc-text">Jedis 客户端</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%AE%A1%E7%90%86"><span class="toc-number">6.3.</span> <span class="toc-text">客户端管理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7%E5%86%85%E5%AD%98%E8%BF%87%E5%A4%A7%E7%9A%84%E6%80%9D%E8%B7%AF"><span class="toc-number">6.4.</span> <span class="toc-text">监控内存过大的思路</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#rdb"><span class="toc-number">7.1.</span> <span class="toc-text">RDB</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="toc-number">7.1.1.</span> <span class="toc-text">手动触发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="toc-number">7.1.2.</span> <span class="toc-text">自动触发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8"><span class="toc-number">7.1.3.</span> <span class="toc-text">RDB 文件的存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdb-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">7.1.4.</span> <span class="toc-text">RDB 的优缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#aof-append-only-file"><span class="toc-number">7.2.</span> <span class="toc-text">AOF（append only file）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F"><span class="toc-number">7.2.1.</span> <span class="toc-text">配置方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">7.2.2.</span> <span class="toc-text">工作流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5"><span class="toc-number">7.2.3.</span> <span class="toc-text">文件同步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6"><span class="toc-number">7.2.4.</span> <span class="toc-text">重写机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="toc-number">7.2.4.1.</span> <span class="toc-text">手动触发</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="toc-number">7.2.4.2.</span> <span class="toc-text">自动触发</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98"><span class="toc-number">7.3.</span> <span class="toc-text">相关问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fork-%E9%97%AE%E9%A2%98"><span class="toc-number">7.3.1.</span> <span class="toc-text">fork 问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%82%B9"><span class="toc-number">7.3.2.</span> <span class="toc-text">性能优化点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cpu"><span class="toc-number">7.3.2.1.</span> <span class="toc-text">cpu</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98"><span class="toc-number">7.3.2.2.</span> <span class="toc-text">内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A1%AC%E7%9B%98"><span class="toc-number">7.3.2.3.</span> <span class="toc-text">硬盘</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#aof-%E8%BF%BD%E5%8A%A0%E9%98%BB%E5%A1%9E"><span class="toc-number">7.3.2.4.</span> <span class="toc-text">AOF 追加阻塞</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text">复制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE"><span class="toc-number">8.1.</span> <span class="toc-text">配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E5%A4%8D%E5%88%B6"><span class="toc-number">8.1.1.</span> <span class="toc-text">建立复制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%AD%E5%BC%80%E5%A4%8D%E5%88%B6"><span class="toc-number">8.1.2.</span> <span class="toc-text">断开复制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E6%80%A7"><span class="toc-number">8.1.3.</span> <span class="toc-text">安全性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AA%E8%AF%BB"><span class="toc-number">8.1.4.</span> <span class="toc-text">只读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E8%BE%93%E5%BB%B6%E8%BF%9F"><span class="toc-number">8.1.5.</span> <span class="toc-text">传输延迟</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8B%93%E6%89%91"><span class="toc-number">8.2.</span> <span class="toc-text">拓扑</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%BB%E4%B8%80%E4%BB%8E"><span class="toc-number">8.2.1.</span> <span class="toc-text">一主一从</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E"><span class="toc-number">8.2.2.</span> <span class="toc-text">一主多从</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%91%E7%8A%B6%E7%BB%93%E6%9E%84"><span class="toc-number">8.2.3.</span> <span class="toc-text">树状结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">8.3.</span> <span class="toc-text">原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E7%A8%8B"><span class="toc-number">8.3.1.</span> <span class="toc-text">过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">8.3.2.</span> <span class="toc-text">同步数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6-full-resync"><span class="toc-number">8.3.2.1.</span> <span class="toc-text">全量复制（Full resync）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%83%A8%E5%88%86%E5%A4%8D%E5%88%B6-partial-replication"><span class="toc-number">8.3.2.2.</span> <span class="toc-text">部分复制（partial replication）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E5%81%8F%E7%A7%BB%E9%87%8F"><span class="toc-number">8.3.2.2.1.</span> <span class="toc-text">复制偏移量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E5%86%99%E5%91%BD%E4%BB%A4%E5%88%B0%E5%A4%8D%E5%88%B6%E7%A7%AF%E5%8E%8B%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-number">8.3.2.2.2.</span> <span class="toc-text">复制写命令到复制积压缓冲区</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E8%8A%82%E7%82%B9%E8%BF%90%E8%A1%8C-id"><span class="toc-number">8.3.2.2.3.</span> <span class="toc-text">主节点运行 id</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#psync-%E5%91%BD%E4%BB%A4"><span class="toc-number">8.3.2.2.4.</span> <span class="toc-text">psync 命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">8.3.2.2.5.</span> <span class="toc-text">全流程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BF%83%E8%B7%B3"><span class="toc-number">8.3.3.</span> <span class="toc-text">心跳</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%E7%BB%AD-%E5%91%BD%E4%BB%A4%E6%8C%81%E7%BB%AD-%E5%BC%82%E6%AD%A5-%E5%A4%8D%E5%88%B6"><span class="toc-number">8.3.4.</span> <span class="toc-text">（后续）命令持续（异步）复制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">8.4.</span> <span class="toc-text">开发运维中的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB"><span class="toc-number">8.4.1.</span> <span class="toc-text">读写分离</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BB%B6%E8%BF%9F"><span class="toc-number">8.4.1.1.</span> <span class="toc-text">数据延迟</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%88%B0%E8%BF%87%E6%9C%9F%E6%95%B0%E6%8D%AE"><span class="toc-number">8.4.1.2.</span> <span class="toc-text">读到过期数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4-%E7%94%A8%E6%97%B6-%E8%AF%BB%E6%97%B6%E5%88%A0%E9%99%A4"><span class="toc-number">8.4.1.2.1.</span> <span class="toc-text">惰性删除（用时&#x2F;读时删除）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E6%97%B6%E5%88%A0%E9%99%A4"><span class="toc-number">8.4.1.2.2.</span> <span class="toc-text">定时删除</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%E6%95%85%E9%9A%9C"><span class="toc-number">8.4.1.2.3.</span> <span class="toc-text">从节点故障</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4"><span class="toc-number">8.4.2.</span> <span class="toc-text">主从配置不一致</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%84%E9%81%BF%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6"><span class="toc-number">8.4.3.</span> <span class="toc-text">规避全量复制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%84%E9%81%BF%E5%A4%8D%E5%88%B6%E9%A3%8E%E6%9A%B4"><span class="toc-number">8.4.4.</span> <span class="toc-text">规避复制风暴</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">9.</span> <span class="toc-text">理解内存</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97"><span class="toc-number">9.1.</span> <span class="toc-text">内存消耗</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%BB%9F%E8%AE%A1"><span class="toc-number">9.1.1.</span> <span class="toc-text">内存使用统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%BF%9B%E7%A8%8B-%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E5%88%92%E5%88%86"><span class="toc-number">9.1.2.</span> <span class="toc-text">（主进程）内存消耗划分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98"><span class="toc-number">9.1.2.1.</span> <span class="toc-text">对象内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%86%B2%E5%86%85%E5%AD%98"><span class="toc-number">9.1.2.2.</span> <span class="toc-text">缓冲内存</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BC%93%E5%86%B2%E5%86%85%E5%AD%98"><span class="toc-number">9.1.2.2.1.</span> <span class="toc-text">客户端缓冲内存</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">9.1.2.2.1.1.</span> <span class="toc-text">普通客户端</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%BB%8E-replica-%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">9.1.2.2.1.2.</span> <span class="toc-text">从（Replica）客户端</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%AE%A2%E9%98%85-pubsub-%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">9.1.2.2.1.3.</span> <span class="toc-text">订阅（ pubsub）客户端</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E7%A7%AF%E5%8E%8B%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-number">9.1.2.2.2.</span> <span class="toc-text">复制积压缓冲区</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#aof-%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-number">9.1.2.2.3.</span> <span class="toc-text">AOF 缓冲区</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87-memory-framentation"><span class="toc-number">9.1.2.3.</span> <span class="toc-text">内存碎片（Memory Framentation）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%90%E8%BF%9B%E7%A8%8B-%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E5%88%92%E5%88%86"><span class="toc-number">9.1.3.</span> <span class="toc-text">（子进程）内存消耗划分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">9.2.</span> <span class="toc-text">内存管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E5%86%85%E5%AD%98%E4%B8%8A%E9%99%90"><span class="toc-number">9.2.1.</span> <span class="toc-text">设置内存上限</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4-maxmemory"><span class="toc-number">9.2.2.</span> <span class="toc-text">动态调整 maxmemory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5"><span class="toc-number">9.2.3.</span> <span class="toc-text">内存回收策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E8%BF%87%E6%9C%9F%E5%AF%B9%E8%B1%A1"><span class="toc-number">9.2.3.1.</span> <span class="toc-text">删除过期对象</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4"><span class="toc-number">9.2.3.1.1.</span> <span class="toc-text">惰性删除</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%88%A0%E9%99%A4"><span class="toc-number">9.2.3.1.2.</span> <span class="toc-text">定时任务删除</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5"><span class="toc-number">9.2.3.2.</span> <span class="toc-text">内存溢出控制策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96"><span class="toc-number">9.3.</span> <span class="toc-text">内存优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#redisobject-%E5%AF%B9%E8%B1%A1"><span class="toc-number">9.3.1.</span> <span class="toc-text">redisObject 对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%A9%E5%87%8F%E9%94%AE%E5%80%BC%E5%AF%B9%E8%B1%A1"><span class="toc-number">9.3.2.</span> <span class="toc-text">缩减键值对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1%E6%B1%A0"><span class="toc-number">9.3.3.</span> <span class="toc-text">共享对象池</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%BC%98%E5%8C%96"><span class="toc-number">9.3.4.</span> <span class="toc-text">字符串优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E4%BC%98%E5%8C%96"><span class="toc-number">9.3.5.</span> <span class="toc-text">编码优化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">10.</span> <span class="toc-text">哨兵 Sentinel</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">10.1.</span> <span class="toc-text">基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%BC%8F%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">10.1.1.</span> <span class="toc-text">主从复制模式的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E7%BB%8F%E5%85%B8%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">10.1.2.</span> <span class="toc-text">一个经典的高可用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sentinel-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">10.1.3.</span> <span class="toc-text">Sentinel 的高可用性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sentinel-%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E5%90%AF%E5%8A%A8"><span class="toc-number">10.2.</span> <span class="toc-text">sentinel 的部署和启动</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA-sentinel-%E8%8A%82%E7%82%B9%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">10.2.1.</span> <span class="toc-text">单个 sentinel 节点的配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">10.2.2.</span> <span class="toc-text">启动命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7%E5%A4%9A%E4%B8%AA%E9%9B%86%E7%BE%A4"><span class="toc-number">10.2.3.</span> <span class="toc-text">监控多个集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E8%B0%83%E6%95%B4"><span class="toc-number">10.2.4.</span> <span class="toc-text">配置调整</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2%E6%8A%80%E5%B7%A7"><span class="toc-number">10.2.5.</span> <span class="toc-text">部署技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#api"><span class="toc-number">10.2.6.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%A5%BD%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">10.2.7.</span> <span class="toc-text">如何实现一个好的客户端</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">10.3.</span> <span class="toc-text">实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E4%B8%AA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1"><span class="toc-number">10.3.1.</span> <span class="toc-text">三个定时任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%92%8C%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF"><span class="toc-number">10.3.2.</span> <span class="toc-text">主观下线和客观下线</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF-odown"><span class="toc-number">10.3.2.1.</span> <span class="toc-text">主观下线（odown）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF-sdown"><span class="toc-number">10.3.2.2.</span> <span class="toc-text">客观下线（sdown）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%BF%85%E9%A1%BB%E4%B8%BE%E8%A1%8C-sentinel-%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE"><span class="toc-number">10.3.2.3.</span> <span class="toc-text">客观下线必须举行 Sentinel 节点选举</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-number">10.3.3.</span> <span class="toc-text">故障转移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">10.3.4.</span> <span class="toc-text">全流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E8%BF%90%E7%BB%B4"><span class="toc-number">10.4.</span> <span class="toc-text">节点运维</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E4%B8%8B%E7%BA%BF"><span class="toc-number">10.4.1.</span> <span class="toc-text">节点下线</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%8A%82%E7%82%B9%E4%B8%8B%E7%BA%BF"><span class="toc-number">10.4.1.1.</span> <span class="toc-text">主节点下线</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%E6%88%96-sentinel-%E8%8A%82%E7%82%B9%E4%B8%8B%E7%BA%BF"><span class="toc-number">10.4.1.2.</span> <span class="toc-text">从节点或 sentinel 节点下线</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">10.4.2.</span> <span class="toc-text">节点上线</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">10.4.2.1.</span> <span class="toc-text">从节点上线</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sentinel-%E8%8A%82%E7%82%B9%E4%B8%8A%E7%BA%BF"><span class="toc-number">10.4.2.2.</span> <span class="toc-text">Sentinel 节点上线</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">11.</span> <span class="toc-text">集群 Cluster</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">11.1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83"><span class="toc-number">11.2.</span> <span class="toc-text">数据分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%90%86%E8%AE%BA"><span class="toc-number">11.2.1.</span> <span class="toc-text">数据分布理论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%8F%96%E4%BD%99"><span class="toc-number">11.2.1.1.</span> <span class="toc-text">节点取余</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C"><span class="toc-number">11.2.1.2.</span> <span class="toc-text">一致性哈希</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%A7%BD%E5%88%86%E5%8C%BA"><span class="toc-number">11.2.1.3.</span> <span class="toc-text">虚拟槽分区</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA"><span class="toc-number">11.2.2.</span> <span class="toc-text">Redis 数据分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E9%99%90%E5%88%B6"><span class="toc-number">11.2.3.</span> <span class="toc-text">Redis 数据分区限制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4"><span class="toc-number">11.3.</span> <span class="toc-text">搭建集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E8%8A%82%E7%82%B9"><span class="toc-number">11.3.1.</span> <span class="toc-text">准备节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E6%8F%A1%E6%89%8B"><span class="toc-number">11.3.2.</span> <span class="toc-text">节点握手</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E6%A7%BD%E4%BD%8D"><span class="toc-number">11.3.3.</span> <span class="toc-text">分配槽位</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%B6%E9%80%A0%E4%B8%BB%E4%BB%8E%E7%BB%93%E6%9E%84"><span class="toc-number">11.3.4.</span> <span class="toc-text">制造主从结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BE%BF%E6%96%B9%E6%A1%88"><span class="toc-number">11.3.5.</span> <span class="toc-text">简便方案</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E8%A6%81%E5%9B%9E%E7%AD%94%E5%A5%BD%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98"><span class="toc-number">11.4.</span> <span class="toc-text">搭建一个集群管理平台要回答好几个问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E6%A0%B7%E9%9A%94%E7%A6%BB-kv%EF%BC%9F"><span class="toc-number">11.5.</span> <span class="toc-text">怎样隔离 kv？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%9B%86%E7%BE%A4%E7%BB%84"><span class="toc-number">11.6.</span> <span class="toc-text">集群与集群组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E7%9A%84%E8%BE%85%E5%8A%A9%E6%9C%8D%E5%8A%A1"><span class="toc-number">11.7.</span> <span class="toc-text">集群的辅助服务</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2017 - 2025 By magicliang</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">簡</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>