[{"title":"英文汇总","date":"2022-01-30T06:09:18.000Z","url":"/2022/01/30/%E8%8B%B1%E6%96%87%E6%B1%87%E6%80%BB/","tags":["语言","英语"],"content":"词汇表表头的头两行是一定要有的，不然不是 markdown 语法。 中文 符号 英文 大括号 {} brace 中括号 [] bracket 算数操作符 +, -, *, /, %, ^, div, mod Arithmetic 关系操作符 &lt;, &gt;, ==, !=, &lt;=, &gt;=, lt, gt, eq, ne, le, ge Relational 逻辑操作符 and, or, not, &amp;&amp;, 条件操作符 ?: Conditbnmional 正则匹配 matches Regex 小括号 () parentheses [pə’renθəsi:z] 冒号 : colon 分号 ; semicolon 逗号 , comma 句号 . period 与音乐有关 斜杠 / slash 反斜杠 \\| back slash 连字符 - hyphen 连字符 - dash 引号 ‘’ quotation marks 反引号 ` back-ticks reverse quote grave accent 星号 * asterisk [ˈæstərɪsk] 英文 音标 含义 refund [ˈri:fʌnd] 退费 algebra /ˈældʒəbrə/ 代数 mathematics [ˌmæθəˈmætɪks] 数学 arithmetic [əˈrɪθmɪtɪk] 算数 interoperability [‘ɪntərɒpərə’bɪlətɪ] 互操作性 quadratic [kwɑ:ˈdrætɪk] 平方的，二次的 collective intelligence [kəˈlektɪv][ɪnˈtelɪdʒəns] 集体智慧 de-facto [ˌdeɪ ˈfæktəʊ] 事实上 e.g. [ˌi: ˈdʒi:] 例如 .etc [‘ɪt’setərə, et-] 等等 Miscellaneous [ˌmɪsəˈleɪniəs] 杂项 rationale [ˌræʃəˈnɑ:l] 理性 rational [ˈræʃnəl] 合理的 congestion [kənˈdʒestʃən] 拥堵 cryptographic [‘krɪptəʊ’græfɪk] 加密的，密码学的 censorship [ˈsensəʃɪp] 审查 malleability [ˌmælɪə’bɪlətɪ] 可延展性 cryptography [krɪpˈtɒgrəfi] 密码学 elliptic [ɪ’lɪptɪk] 椭圆的 notary [ˈnəʊtəri] 公证人 derivatives [dɪ’rɪvətɪvz] 衍生品 sybil [‘sɪbɪl] 女巫 Revocation [ˌrevəˈkeɪʃn] 吊销 requisite [ˈrekwɪzɪt] 必需品 self-explanatory [self ɪk’splænətrɪ] 不言自明的 ECDSA Epllitic Curve Digital Sinature Algorthmn 椭圆曲线数字签名算法 Mnemonic Codes [nɪˈmɒnɪk] 助记词 Redeem [rɪˈdi:m] 赎回 overwhelm [ˌəʊvəˈwelm] 压垮 compel [kəmˈpel] 强迫 paradox [ˈpærədɒks] 佯谬 parliament [ˈpɑ:ləmənt] 国会 council [ˈkaʊnsl] (市、郡等的)政务委员会，地方议会; 市政(或地方管理)服务机构; (顾问、立法、研究、基金等)委员会; Sybil [‘sɪbɪl] 女巫 incentive [ɪn’sentɪv] 激励 craftsmanship [ˈkrɑ:ftsmənʃɪp] 工艺 pseudonymous [sju:’dɒnɪməs] 匿名的 confidentiality [ˌkɒnfɪˌdenʃiˈæləti] 机密性 work like a charm 非常有效 comprise [kəmˈpraɪz] 由…组成 affiliation [əˌfɪliˈeɪʃn] 附属 full-duplex [‘fʊldj’u:pleks] 全双工 pseudo [‘sju:dəʊ] 伪的 compliant [kəmˈplaɪənt] 遵循的 orientation [ˌɔ:riənˈteɪʃn] 方向，定位 alphabetically [ˌælfə’betɪklɪ] 照字母顺序排列地 actuator [‘æktʃʊeɪtə] 激励者 miscellaneous [ˌmɪsəˈleɪniəs] 混杂的，五花八门的 premium [ˈpri:miəm] 保险费 collation [kə’leɪʃn] 核对，校对。在 MySQL 中经常和语言体系一起用。比如 latin collation 应该指的是拉丁语系 disclosure [dɪsˈkləʊʒə(r)] 披露 designator [ˌdezɪg’neɪtə] 指示者 vault [vɔ:lt] 保险库 foundry [ˈfaʊndri] 铸造厂 nevertheless [ˌnevəðəˈles] 然而 trailing [‘treɪlɪŋ] 尾随的 trail 轨迹 fractional [ˈfrækʃənl] 分数的，小数的 integer [ˈɪntɪdʒə(r)] 整数 decimal point 小数点 epoch [ˈi:pɒk] 纪元 duration [djuˈreɪʃn] 持续时间，在监控中指的是耗时 chronology [krəˈnɒlədʒi] 年代学 ambiguity [ˌæmbɪˈgju:əti] 二义性。handling ambiguity temporal [ˈtempərəl] 1 时间的 2 临时的 punctuation [ˌpʌŋktʃuˈeɪʃn] 标点。punctuation character 应该就是我们中文讲的标点符号 Spatial [ˈspeɪʃl] 空间的 contention [kənˈtenʃn] 争论，我们常说锁竞争应该是 lock contention fraction [ˈfrækʃn] 分数 To some extent [tu: sʌm iksˈtent] 某种程度上 swarm [swɔ:m] 蜂群 ingress [ˈɪngres] 进入权 tutorial [tju:ˈtɔ:riəl] 教程 guideline [ˈgaɪdlaɪn] 指导方针 criteria [kraɪ’tɪərɪə] (查询/校验用的)标准 heuristically [hju’rɪstɪk] 启发式地 avatar [ˈævətɑ:(r)] 化身（gitlab上使用的） actuator [‘æktʃʊeɪtə] 激励者 trunk [trʌŋk] 1 （代码）主干2 （汽车）行李箱 facet [ˈfæsɪt] (事物的)面,方面在eclipses中的facets可以理解为 JavaSE、Dynamic Web Module 等框架或者类库的特性支持 knowledge base 知识库。一般是一个公司沉淀自己业务文档，交流传播知识的场所 inquiry [ɪn’kwaɪərɪ] [保险]定价，打听 occupancy [ˈɒkjəpənsi] [物] 占有率。CMS 的内存回收阈值就是这样定义的 refinement [rɪˈfaɪnmənt] 改良 rational [ˈræʃnəl] 理性的; 合理的;软件工程里一般是统一设计流程里需要 rational unified process dividend [ˈdɪvɪdend] 红利，股息，利息，（破产时清算的）分配金; surplus [ˈsɜ:pləs] 盈余; 顺差; 剩余额; 公积金; vague [veɪg] 模糊的 reimburse [ˌri:ɪmˈbɜ:s] 偿还、（差旅报销）退款 clash [klæʃ] （名字）冲突 validate [ˈvælɪdeɪt] 校验 verify [ˈverɪfaɪ] 验证 valid [ˈvælɪd] 有效的 episode [ˈepɪsəʊd] 集，期 preceding [prɪ’si:dɪŋ] 前置修饰。在前的 prior to [ˈpraiə tu:] 后置修饰。在…之前 net [net] 净 wherein [weərˈɪn] 在其中，相当于 in which surefire [‘ʃʊəˌfaɪə] 完全，一定成功的 failsafe [‘feɪlˌseɪf] 破损安全 synonym [ˈsɪnənɪm] 同义词; precision [prɪˈsɪʒn] 精度 interpolation [ɪnˌtɜ:pə’leɪʃn] 窜改。我们经常说的字符串内插、变量展开，实际上指的是 string interpolation (or variable interpolation, variable substitution, or variable expansion) Syntactic [sɪnˈtæktɪk] 语法糖的“语法” directive [dɪˈrektɪv, daɪ-] 指示。在网页模板（如果 angular）里，是一些内置命令标签的意思 honor [‘ɒnə(r)] 尊敬。和 respect 差不多，是honor user input as xxx 是常用用法 pseudocode [‘sju:dəʊˌkəʊd] 伪代码 dynamic programming 动态规划 greedy algorithm 贪心算法 amortized analysis [‘əmɔ:taɪzd əˈnæləsɪs] 摊还分析，平摊分析 opimiztion problem 最优化问题 optimal solutions 最优解 arrangement 排列 time-memory trade-off 时空权衡 top-down 自顶向下 bottom-up 自底向上 memoized 带备忘录的 exponential [ˌekspəˈnenʃl] 指数的。Exponential time complexity 指数时间复杂度 polynomial [ˌpɒlɪ’nəʊmɪəl] 多项式的。Polynomial time complexity Logarithmic [ˌlɒɡə’rɪðmɪk] 对数的。Logarithmic time complexity linear [ˈlɪniə(r)] 线性的。linear time complexity; frontier [ˈfrʌntɪə(r)] 边疆；开拓的 intersection [ˌɪntəˈsekʃn] 横断，交集 – 差集 difference union [ˈju:niən] 并集 intrusive [ɪnˈtru:sɪv] 侵入的 feature [ˈfi:tʃə(r)] 特性 predator [ˈpredətə(r)] 掠夺者 rival [ˈraɪvl] 对手 linguist [ˈlɪŋgwɪst] [ˈlɪŋgwɪst] Defensive programming 防御性编程 breeze [bri:z] 一阵风 quadratic [kwɒˈdrætɪk] 二次方的 cubical [‘kju:bɪkəl] 立方的，三次方的 base [beɪs] （生物学上的）碱基 permutation [ˌpɜ:mjuˈteɪʃn] 排列，组合 committee [kəˈmɪti] 委员会，不是 committer，虽然通常 committee 都是 commiter。Committee 相对而言是一种被委托人的横向组织，旨在共同努力，做出决策。（项目指导 Committee、监督 Committee、议会特殊 Committee、村民公平奖 Committee、罢工 Committee）。Committee 更强调“我们如何做这件事？”。Committee 按规范化的程序规则运作。如果您不确定是使用 committee 还是使用 commission，使用 committee。 commission [kəˈmɪʃn] 委员会。Commission 的权力来自其上层，并被分配了一项需要执行的任务（例如 采购 Commission、美国证券交易 Commission）。这些 Commission 的职责范围（terms of refernce）相对而言是具体清楚的，虽然有时候职责范围很广（例如 欧洲 Commission），有时候很小（一家公司的 IT 采购 Commission）。代表性并不是一个与 Commission 相关联的标准。 oss Object Storage Service atlassian jira 的软件公司 systematic [ˌsɪstəˈmætɪk] 有系统的，有规则的; 有条不紊的; 有步骤的; 一贯的，惯常的; polymorphism [ˌpɒlɪ’mɔ:fɪzəm] 多态 paradigm [ˈpærədaɪm] 多态 itinerary [aɪˈtɪnərəri] 旅程 interval [ˈɪntəvl] （数学）区间，不应该使用range greedy-choice property 贪心选择性质，通常也都具有最优子结构性质 Optimal Substructure Property 最优子结构性质 archetype [ˈɑ:kitaɪp] （人）典范；（maven）原型 conservative [kənˈsɜ:vətɪv] 保守的; conversion [kənˈvɜ:ʃn] 变换 additivity [ædɪ’tɪvɪtɪ] 可加性 compliance [kəmˈplaɪəns] 服从 compliance with the agreement 遵循了协议 coalesce [ˌkəʊəˈles] 联合，合并; SQL 中的查询函数中的一种，返回参数中的第一个非空值；如果所有值都为NULL，那么返回NULL。 SELECT COALESCE(NULL,NULL,3,4,5) FROM dual 其返回结果为：3 reception [rɪˈsepʃn] 接待处; 欢迎 assure [əˈʃʊə(r)] 向…保证; 使…确信; &lt;英&gt;给…保险; He hastened to assure me that there was nothing traumatic to report。在保险领域 insurred 和 assured 都指被保人 wildcard [‘waɪldkɑ:d] 通配符; orthogonal [ɔ:’θɒgənl] 正交的 resilience [rɪˈzɪliəns] 弹性 Agnostic [æɡˈnɒstɪk] 不可知的，如：Provider Agnostic（供应商无关） plane 平面，如控制平面，数据平面 inference [ˈɪnfərəns] 推断，type inference disburse [dɪsˈbɜːs] 支付，支出，类似于 pay mercurial [mɜːˈkjʊəriəl] 多变的 cylinder [ˈsɪlɪndə(r)] 圆柱体 intrinsic [ɪnˈtrɪnzɪk] 内在的，固有的，instrinsic state 内生状态 extrinsic [eksˈtrɪnzɪk] 非固有的; 非本质的; 外在的; 外来的; collate [kəˈleɪt] 核对。MySQL 中的核对规则，同一个字符集下使用不同的校对规则，也可能导致字典排序的结果不一样。 druid [ˈdruːɪd] 德鲁伊特(古代凯尔特人的祭司); Fast-evolving [fɑːst iˈvɒlvɪŋ] 快速进化; journal [ˈdʒɜːnl] 报刊、杂志 oceanus 海洋之神，如mazu boundary [ˈbaʊndri] 边界 locale [ləʊˈkɑːl] 发生地点; 现场; hassle [ˈhæsl] 困难 vanilla [vəˈnɪlə] 寻常的; 毫无特色的 – 其实就是原生的意思，比如vanilla js，vanilla java antique [ænˈtiːk] 古董 bump [bʌmp] 碰、撞 bump version caretaker [ˈkeəteɪkə(r)] (建筑物的) 管理员 opaque [əʊˈpeɪk] 不透明的，意为不可修改的，类似于immutable memento [məˈmentəʊ] 备忘录（memo的另一种写法） reuters [‘rɔitəz] 路透社，世界三大通信社之一，英国通信社 manipulation [məˌnɪpjʊˈleɪʃən] 操作；操作法；管理措施；操作处理；处理; 操纵证券市场；操纵证券交易; 变换; cardinality [kɑ:dɪ’nælɪtɪ] 基数；集的势; cask [kɑːsk] 小酒桶 radius [ˈreɪdiəs] 半径(长度); 半径范围; 周围; 桡骨; ganglia [ˈgæŋglɪə] 神经中枢。一个开源的集群监控系统 invoice [ˈɪnvɔɪs] 开发票(或清单); 发出发票(或清单); beacon [ˈbiːkən] 灯塔 gadget [ˈɡædʒɪt] 小装置 arena [əˈriːnə] 圆形运动场; 圆形剧场; 斗争场所; 竞争舞台; 活动场所; glibc 的内存 chunk 的一种 evict [ɪˈvɪkt] 驱逐 empowers [ɪmˈpaʊəz] 授权; 给(某人)…的权力; 增加(某人的)自主权; 使控制局势; sentinel [ˈsentɪnl] 哨兵; quorum [ˈkwɔːrəm] (会议的) 法定人数、法定票数、仲裁 longing [ˈlɒŋɪŋ] (对…的) 渴望，热望; falcon [ˈfɔːlkən] 隼 raptor [ˈræptə(r)] 猛禽。cat 和 falcon 技术融合产生 raptor utilization [ˌju:təlaɪ’zeɪʃn] 利用率。cpu utilization average [ˈævərɪdʒ] 不只是形容词，如 load average。平均水平，平均值。 delimiter [dɪ’lɪmɪtə] 定界符 cognitive [ˈkɒɡnətɪv] 认知的; 感知的; 认识的; tweakable 可调整的 reconciliation [ˌrekənsɪliˈeɪʃn] 对账 liquidity [lɪˈkwɪdəti] 资产流动性 netting [ˈnetɪŋ] 轧差（[gá chà]）是指交易伙伴或者系统的参与者之间一致同意的余额或债务对冲。轧差把大量逐笔交易额或债务减少到较小数目的交易额或债务。轧差可以采用不同的方式进行，这些方式在一方丧失清偿能力的情况下，其法律强制轧差的程度不尽相同。参见双边和多边轧差，状态轧差，债务更新，更替。 analogy [əˈnælədʒi] 类比 Reversal [rɪˈvɜːsl] 金融系统：冲正；反转; 倒置; 倒退; 逆转; 退步; 转胜为败; Acquirer [əˈkwaɪərə] 金融系统：受理⽅；收购者; 兼并者; verbose [vɜːˈbəʊs] 冗长的; 啰唆的; 唠叨的; trival [t’raɪvəl] 琐碎的 acronym [ˈækrənɪm] 首字母缩略词，如 SE seminar [ˈsemɪnɑː(r)] (大学教师带领学生作专题讨论的)研讨课;研讨会;培训会 debitor [‘debitə] 债务人 Debit [ˈdebɪt] n. 借记，借方；借项v. 记入借（账户）借方，借记；（从银行账户中）取款 liability [ˌlaɪəˈbɪləti] 负债 equity [ˈekwəti] 所有者权益； (公司的) 股本; 资产净值; (公司的) 普通股; 公平; 公正; fusion [ˈfjuːʒn] 融合; 熔接; 结合; 核聚变; 热核反应; 合成音乐，混合音乐(尤指爵士乐和摇滚乐); anti-affinity 反亲和性 mole [məʊl] 鼹鼠(体小，视力极差，居住在挖掘的地道); 色素痣; 间谍; 内奸; talos 塔罗斯; 塔洛斯; 黄铜骑士; 洛斯; 护岛神; suboptimal 次优的 concise [kənˈsaɪs] 简明的; 简练的; 简洁的; 简略的; 简缩的; concise xml 配置，允许大小写混用。与 strict xml 正相反 cumbersome [ˈkʌmbəsəm] 大而笨重的; 难以携带的; 缓慢复杂的; 冗长的; 累赘的; 复杂的; cargo [ˈkɑːɡəʊ] 货物 cantor [ˈkæntɔː(r)] 康托， (犹太教会堂和教堂唱诗班的) 领唱; indispensable [ˌɪndɪˈspensəbl] 不可或缺 tabular [ˈtæbjələ(r)] 表格式的; 列成表的; 制成表的; resemble [rɪˈzembl] 看起来像; 显得像; 像; production enviroment resembles staging environment rollout [ˈroʊˌlaʊt] 首次展示; 在软件开发中等同于 deployment rigor [‘rɪɡə] 僵硬 calibration [ˌkælɪˈbreɪʃn] （绩效）校准 repurpose [ˌriːˈpɜːpəs] (为适合新用途) 对…稍加修改，略微改动; ramp up 上升; 增加; 提高; 提升、升高 defect [ˈdiːfekt , dɪˈfekt] 缺点;缺陷;毛病 crane [kreɪn] 鹤 rationale [ˌræʃəˈnɑːl] 基本原理，基本原因 conceptual [kənˈseptʃuəl] 概念上的，观念上的 derivation [ˌderɪˈveɪʃn] 起源 datastore 数据存储; 数据存储区; 数据存储对象; 数据存储定义; 数据存储槽; collapsing [kəˈlæpsɪŋ] 倒塌 dante [ˈdɑnteɪ] 但丁; 丹特; 丹蒂; assess [əˈses] 评估、评价 overhauled [ˌəʊvəˈhɔːld] 彻底检修; 赶上，超过(赛跑对手); revenue [ˈrevənjuː] 营收 contour [ˈkɒntʊə(r)] 外形; 轮廓; (地图上表示相同海拔各点的) 等高线; 在领域驱动设计中，conceptual contour 是指为了所有的类和操作具有相似的规模而寻找一种一致的粒度的设计模式。 manufacture ˌmænjuˈfæktʃə 制造 timeliness [ˈtaɪmlɪnɪs] 合时，时; commission [kəˈmɪʃn] (通常为政府管控或调查某事的) 委员会; 佣金; 回扣; (银行等的) 手续费; identifiable [aɪˌdentɪˈfaɪəbl] 可识别的; 可辨认的; forecast [ˈfɔːkɑːst] 预测; 预报; acquisition [ˌækwɪˈzɪʃn] (知识、技能等的) 获得，得到; (多指贵重的) 购得物; 购置物; 收购的公司; 购置的产业; 购置; 收购; rendezvous [ˈrɒndɪvuː] 约会; 约会地点; (酒吧等) 热门聚会场所，聚会处; picky [ˈpɪki] 挑剔的; 难伺候的; beautifier 美化器; 美化者; lite [laɪt] 低热量的，清淡的(light的一种拼写方法); 类似…的劣质品; vulnerability [ˌvʌlnərə’bɪlətɪ] 弱点 stipulate [ˈstɪpjuleɪt] 规定; 明确要求; synthetic [sɪnˈθetɪk] 人造的; (人工) 合成的; 综合(型)的; configure [kənˈfɪɡə(r)] (按特定方式) 安置; (尤指对计算机设备进行) 配置; 对(设备或软件进行)设定; onerous [ˈəʊnərəs] 费力的、艰巨的 grapple [ˈɡræpl] 努力设法解决 ingenious [ɪnˈdʒiːniəs] 精巧的 appeal [əˈpiːl] 吸引 inferno [ɪnˈfɜːnəʊ] 无法控制的大火; simultaneously [ˌsɪməlˈteɪniəsli] 同时; 联立; 急切地; substitute [ˈsʌbstɪtjuːt] 替换 remedy [ˈremədi] 处理方法; 改进措施; 补偿; 疗法; 治疗; 药品; (通过法律程序的) 解决方法，救济; cryptic [ˈkrɪptɪk] 含义隐晦的; 晦涩难懂的; [əˌprɒksɪˈmeɪʃn] [əˌprɒksɪˈmeɪʃn] 近似物 bloat [bləʊt] 膨胀 teplate code bloat synthesize [ˈsɪnθəsaɪz] (通过化学手段或生物过程) 合成; (音响) 合成; 综合; pearson [ˈpɪəsən] 皮尔逊; clashes [ˈklæʃɪz] (两群人之间的) 打斗，打架，冲突; 争论; 辩论; 争执; 差别; 差异; 分歧; 在 Java 中发生 clash 意味着编译器会 complain with errors astray [əˈstreɪ] 歧途，intuition leads us astray reify 使具体化 intuitively [ɪnˈtjuːɪtɪvli] 直觉地，直观地；由直觉而得地; warframe 太空战甲 with all due respect 恕我直言; 恕我冒昧; 无意冒犯; chronology [krəˈnɒlədʒi] 按事件发生的年代排列的顺序; 年表; uninitiated [ˌʌnɪˈnɪʃieɪtɪd] 无专门知识(或经验)的人; 门外汉; 外行; intimidating [ɪnˈtɪmɪdeɪtɪŋ] 吓人的; 令人胆怯的; denote [dɪˈnəʊt] 标志; 预示; 象征; 表示; 意指; gloss over [ɡlɒs ˈəʊvə(r)] 粉饰; 掩盖; 掩饰; to all intents 指实际上，几乎在一切方面 dormant [ˈdɔːmənt] 休眠，线程被 park api停在一边不再调度，就变成 dormant了 definite [ˈdefɪnət] 肯定的; 确定的; 不会改变的; 清楚的; 明显的; 肯定; 有把握; nevertheless [ˌnevəðəˈles] 然而（毫无影响的 but、however） thus [ðʌs] 以此方式; 如此; 这样; 因此; 从而; 所以; retain [rɪˈteɪn] 保持; 持有; 保留; 继续拥有; 继续容纳; 聘请(律师等); faint [feɪnt] (光、声、味) 微弱的，不清楚的; 微小的; 可能性不大的; 不热情的; 不积极的; faint memory 微弱记忆 configure [kənˈfɪɡə(r)] (按特定方式) 安置; (尤指对计算机设备进行) 配置; 对(设备或软件进行)设定; weld 焊接; 熔接; 锻接; 使紧密结合; 使连成整体; 焊接点; 焊接处; pose a problem 造成一个问题 bogus [ˈbəʊɡəs] 伪造的 veteran [ˈvetərən] 经验丰富的人; 老手; 退伍军人; 老兵; 老战士; 老水兵; scale [skeɪl] (尤指与其他事物相比较时的) 规模，范围，程度; 等级; 级别; 等级体系; 在 bigdecimal 中指的是小数点后 digit 的数量，也就是我们经常讲的小数位数 prudent [ˈpruːdnt] 谨慎 suboptimal 次优的; 次优; 次优化; 次佳; jumbo [ˈdʒʌmbəʊ] 大型客机(尤指波音747); viable [ˈvaɪəbl] 可实施的; 切实可行的; 能独立发展的; 能独立生存的; 可生长发育的; premature [ˈpremətʃə(r)] 未成熟的; 过早的; 提前的; 早产的; 草率的; 仓促的; abstract [ˈæbstrækt , æbˈstrækt] 抽象出（动词） hype [haɪp] (电视、广播等中言过其实的) 促销广告，促销讨论; flack [flæk] 高射炮，广告 splash [splæʃ] 落水声; 溅泼声; 溅上的液体; 溅洒后留下的污渍; 色块; 光斑; neutral [ˈnjuːtrəl] 中立的; 持平的; 无倾向性的; 中立国的; 中性的; 不含褒贬义的; excerpt [ˈeksɜːpt] 摘录; 节选; (音乐、电影的) 片段; buzzword [ˈbʌzwɜːd] (报刊等的) 时髦术语，流行行话; commentary [ˈkɒməntri] (尤指电台或电视台所作的) 实况报道，现场解说; 注释; 解释; 评注; 评论; 批评; 议论; esoteric [ˌesəˈterɪk] 只有内行才懂的; 难领略的; grief [ɡriːf] (尤指因某人去世引起的) 悲伤，悲痛，伤心; 伤心事; 悲痛事; 担心; 忧虑; clumsy [ˈklʌmzi] 笨拙的; 不灵巧的; 无技巧的; 冒犯人的; 不得体的; 难以移动的; 难用的; 设计欠佳的; proportion [prəˈpɔːʃn] 份额 tamper [ˈtæmpə(r)] 夯; 夯具; 捣乱者; 填塞者; 反射器; tamper-free 注意和 spam 的区别 extensive [ɪkˈstensɪv] 广阔的; 广大的; 大量的; 广泛的; 广博的; extensive library 大量的库， ease [iːz] 容易; 轻易; 不费劲; 舒适; 安逸; 自在; 无忧无虑; undertaking [ˌʌndəˈteɪkɪŋ] (重大或艰巨的) 任务 error-prone [ˈerə(r) prəʊn] 容易出错; 错误倾向; 易错; 易于出错的; 易错配; situation that are error-prone memory-corruption 内存损坏 overdone [ˌəʊvəˈdʌn] (食物) 煮得过久的; 过分的;广告 夸张的; overrunning [ˌəʊvəˈrʌnɪŋ] 泛滥; 横行; 肆虐; 多用(时间、钱财等); 超时; subtle [ˈsʌtl] 不易察觉的; 不明显的; 微妙的; 机智的; 机巧的; 狡猾的; 巧妙的; subtile bug，不易察觉的 bug flaw [flɔː] 错误; 缺点; 裂痕; 裂隙; 瑕疵; (性格上的) 弱点; hindsight [ˈhaɪndsaɪt] 事后聪明; 事后的领悟; presence [ˈprezns] 在场; 出席; 存在; 出现; (派遣的) 一个队; (尤指执行任务的) 部队; primitive [ˈprɪmətɪv] 原始的; 远古的; 人类或动物发展早期的; 发展水平低的; 落后的; java 的原始类型不同于 cpp，不止是 short &lt; int &lt; long stretch [stretʃ] 一片; 一泓; 一段; (连续的) 一段时间; 服刑期; exotic [ɪɡˈzɒtɪk] 来自异国(尤指热带国家)的; 奇异的; 异国情调的; 异国风味的; traction [ˈtrækʃn] 牵引 hostile [ˈhɒstaɪl] 敌意的; 敌对的; 坚决否定; 强烈反对; 有阻碍的; 不利的; malicious [məˈlɪʃəs] 怀有恶意的; 恶毒的; dogged dɒɡd 折磨 presumably [prɪˈzjuːməbli] 很可能; 大概; 想必是; amusingly 好笑地; 可笑地; dissolved [dɪˈzɒlvd] 溶; 使(固体)溶解; 解除(婚姻关系); 终止(商业协议); 解散(议会); undergraduate [ˌʌndəˈɡrædʒuət] 本科生; post-graduate [pəʊst ˈɡrædʒuət] 研究生 prime [praɪm] 主要的; 首要的; 基本的; 优质的; 上乘的; 优异的; 典型的; 有代表性的; ever-growing [ˈevə(r) ˈɡrəʊɪŋ] 日益增大的; abated [əˈbeɪtɪd] (使) 减弱，减退，减轻，减少; appliance [əˈplaɪəns] (家用) 电器，器具; unary [ˈjuːnəri] 一元的; fussing [ˈfʌsɪŋ] 瞎忙一气 coined in 创造的 theorem [ˈθɪərəm] (尤指数学) 定理; web scale 不仅在规模上超越了常规，也在速度与敏捷性上打破了常规 surge [sɜːdʒ] (强烈感情的) 突发; (数量的) 急剧上升，激增; 大量; 一大批; 奔涌向前; 突然的向上运动; Electrical Pulse Surge 电涌 obligated [ˈɒblɪɡeɪtɪd] (道义或法律上) 有义务的，有责任的，必须的; sabotage [ˈsæbətɑːʒ] (为防止敌人利用或表示抗议而对设备、交通等进行的) 蓄意毁坏; 故意妨碍; 捣乱; 刻意阻碍; aviator [ˈeɪvieɪtə(r)] 飞行员 provisions [prəˈvɪʒnz] 提供; 供给; 给养; 供应品; (为将来做的) 准备; 饮食供应; (尤指旅途中的) 粮食; 备付金 lancet [ˈlɑːnsɪt] (医生用的) 柳叶刀，小刀; flume [fluːm] (工业用) 引水槽，放水沟; (游乐园或游泳池的) 水滑道; ergonomics [ˌɜːɡəˈnɒmɪks] 工效学，人类工程学(研究如何改善工作条件，提高工作效率); mandates [ˈmændeɪts] 强制执行; 委托办理; 授权; analogue [ˈænəlɒɡ] 相似物; 类似事情; analogous to mutually [ˈmjuːtʃuəli] 相互地; 彼此; 共同地; threshold [ˈθreʃhəʊld] 阈值 designate [ˈdezɪɡneɪt] 命名; 指定; 选定，指派，委任(某人任某职); 标明; 标示; 指明; designates error level contiguous [kənˈtɪɡjuəs] 相接的; 相邻的; gauge [ɡeɪdʒ] 测量仪器(或仪表); 计量器; 宽度; 厚度; (枪管的) 口径; burglar [ˈbɜːɡlə(r)] 破门盗贼; 入室窃贼; strangle [ˈstræŋɡl] 扼死; 勒死; 掐死; 抑制; 压制; 扼杀; mafia [ˈmæfiə] 秘密犯罪集团,秘密施加巨大影响的一伙人，黑手党; Configurer 配置者 Spring 的 configurer 一般都配备流利 api backwards compatibility 向前兼容-逆向兼容 CyclomaticComplexity 圈复杂度。 可理解为覆盖所有的可能情况最少使用的测试用例数。 quarantine [ˈkwɒrəntiːn] (为防传染的) 隔离期; 检疫; sanitizer [‘sænɪtaɪzə] （食物加工设备所用的）消毒杀菌剂； hand sanitizer 洗手液 mission-critical [ˌmɪʃn ˈkrɪtɪkl] (对于机构的成功运作) 关键的，至关重要的; flux [flʌks] 不断的变动; 不停的变化; 通量; 流动; APM application performance monitor 应用性能管理 plague [pleɪɡ] 瘟疫 collective [kəˈlektɪv] 集体的; 共有的; 共同的; 全体成员的; 总体的; collective memory pirated 盗版 reorganization [ˌriːˌɔːgənaɪˈzeɪʃən] 改组 fundamentals [ˌfʌndəˈmɛntlz] 基础; 基本原则(或原理); retrieve [rɪˈtriːv] 取回; 索回; 检索数据; 扭转颓势; 挽回; 找回; Removal [rɪˈmuːvl] 移动; 调动; 去除; 除去; 消除; 清除; 免职; 解职; directive [dəˈrektɪv] 指示; 命令; resolve [rɪˈzɒlv] 解决(问题或困难); 决心; 决定; 作出决定; 作出决议; 表决; 解析 xxxResolver VUCA 也即volatility（易变性）、uncertainty（不确定性）、complexity（复杂性）、ambiguity（模糊性）。VUCA的概念90年代诞生于军事领域 parallel with 并行于 Provides support parallel with Spring XML’s context:component-scan element. IVR 互动语音呼叫 epidemic [ˌepɪˈdemɪk] 流行病; (迅速的) 泛滥，蔓延; cartesian [kɑːˈtiːziən] 笛卡尔坐标系; 笛卡尔; 直角; 笛卡尔的; 笛卡儿积; cartesian product 笛卡尔积 kata &lt;日&gt;（空手道的）形（即套路，练习时必须按形进行），（柔道）招数的类型; triage [ˈtriːɑːʒ] 患者鉴别分类; 伤员鉴别分类; 治疗类选法; bug 分类 mental flow 心流 bootstrapp 自举、启动。bootstrapping AnnotatedApplication principal [ˈprɪnsəpl] 大学校长; 学院院长; 本金; 资本; 主要演员; 主角; Security principal 安全主角，见《Tomcat 容器的安全认证和鉴权》 precedence [ˈpresɪdəns] 优先; 优先权; Ordered.HIGHEST_PRECEDENCE registrar [ˌredʒɪˈstrɑː(r)] 登记员; 户籍管理员; (大学的) 教务长，教务主任，注册主任; (英国医院的) 专科住院医生; bidirectional [ˌbaɪdəˈrekʃənl] 双向的; unidirectional 单向的；单方面的；单自由度的; spool [spuːl] 把…绕到线轴上(或从线轴上绕下来); 假脱机(尤指打印前出现的操作情况); velocity [vəˈlɒsəti] (沿某一方向的) 速度; 高速; 快速; chainsaw [ˈtʃeɪnsɔː] 链锯; demarcation [ˌdiːmɑːˈkeɪʃn] (工种、人、土地等的) 划分，区分，界线; in place 原地，就地 declared in place 原地声明 designators 指示符; 指示者; contextual [kənˈtekstʃuəl] 上下文的; 与上下文有关的; 与语境相关的; idiom [ˈɪdiəm] 习语; 成语; 惯用语; (某时期或某地区的人的) 语言和语法; (写作、音乐、艺术等的) 典型风格;编程格言 blueprint [ˈbluːprɪnt] (建筑、机器等的) 蓝图; 行动方案; 计划蓝图; (生物细胞的) 模型，型板; focal [ˈfəʊkl] 中心的; 很重要的; 焦点的; 有焦点的; focal review lexical [ˈleksɪkl] 词汇的; abruptly [əˈbrʌptli] 突然地；忽然间；猝然；出其不意地；兀地一下; 立刻，立即; 粗暴地；不客气地; formulae [ˈfɔːmjʊliː] 公式; 方程式; 计算式; 分子式; 方案; 方法; in essence [ɪn ˈesns] 实质上; gradients [ˈgreɪdiənts] (尤指公路或铁路的) 坡度，斜率，倾斜度; (温度、压力等的) 变化率，梯度变化曲线; saturn [ˈsætɜːn] 土星; layout [ˈleɪaʊt] 布局 fundermental [ˌfʌndəˈmentl] 基本规律; 根本法则; 基本原理; 基础; devise [dɪˈvaɪz] 发明; 设计; 想出; devise a design strategy empathy [ˈempəθi] 换位思考，同理心 carousel [ˌkærəˈsel] (机场的) 行李传送带;轮播图 engagement 参与度 dremel 尼美; 德雷梅尔; 达美; 达美电磨; 点墨;谷歌的大数据框架 radix [‘rædɪks; ‘reɪ-] 进制; 基数; 鼻根; introspection [ˌɪntrəˈspekʃn] 内省; 反省; adopt [əˈdɒpt] 采用 objenesis 另一种初始化对象的方式 memory leak 不是 memory leakage Design Philosophy 设计哲学 under the hood 底层机制 due process [djuː ˈprəʊses] 正当程序，正当法律程序; Italic [ɪˈtælɪk] 斜体 critique [krɪˈtiːk] 评论; 评论文章; logistics [ləˈdʒɪstɪks] 后勤; 物流; 组织工作; alphabetical order [ˌælfəˈbetɪkl ˈɔːdə(r)] 字母顺序; 按字母顺序; 字母排序; 字母順序; 按字母顺序排列; gadget [ˈɡædʒɪt] 小器具; 小装置; magnitude [ˈmæɡnɪtjuːd] 巨大; 重大; 重要性; 星等; 星的亮度; 震级; retrospective [ˌretrəˈspektɪv] (艺术家作品) 回顾展; oceania [ˌəʊsiˈɑːniə] 大洋洲; scavenge [ˈskævɪndʒ] 拾荒者 Jaguar [ˈdʒæɡjuə(r)] 美洲豹;美洲虎 cheetah [ˈtʃiːtə] 猎豹 originality [əˌrɪdʒəˈnæləti] 创意 artisan [ˌɑːtɪˈzæn] 工匠; 手艺人; sanction [ˈsæŋkʃn] 制裁 interfere [ˌɪntəˈfɪə(r)] 干涉; 干预; 介入; concatenation [kənˌkætəˈneɪʃn] 一系列相关联的事物(或事件); canonical [kəˈnɒnɪkl] 被收入真经篇目的; 经典的; 按照基督教会教规的; (数学表达式)最简洁的; snappy [ˈsnæpi] 精练的; 简洁的; 漂亮入时的; 烦躁的; 没好气的; syphilization 感染梅毒; 梅毒接种; drastically 彻底地；激烈地; unattended-upgrades 无人值守升级 Take Rate 佣金率 Net Revenue 净收入 standing book 台账 percentile [pəˈsentaɪl] 百分位数; résumé [rezjʊmeɪ] （法）简历 SPU Standard Product Unit （标准产品单位） SKU Stock Keeping Unit（库存量单位） state of the art [ˌsteɪt əv ði ˈɑːt] 应用最先进技术(或方法)的; 最先进的; voucher [ˈvaʊtʃə(r)] 代币券; 票券; pandemic [pænˈdemɪk] (全国或全球性)流行病; 大流行病;（一波）疫情 coordinates [kəʊˈɔːdɪneɪts] 坐标; (颜色协调的)配套服装，套装; cognitive [ˈkɒɡnətɪv] 不同于 recognize 和 concept boutique [buːˈtiːk] 精品 ephemeral [ɪˈfemərəl] 短暂的; 瞬息的; heterogeneous [ˌhetərəˈdʒiːniəs] 异构的 cognition [kɒɡˈnɪʃn] 认知; 感知; 认识; syndrome [ˈsɪndrəʊm] 综合征; 综合症状; 典型意见; 典型表现; caliper [ˈkæləpər] 卡尺；卡钳; 谷歌的 JVM 测量工具 cargo [ˈkɑːɡəʊ] (船或飞机装载的)货物; leverage [ˈliːvərɪdʒ] 影响力; 杠杆作用; 杠杆效力; citadel [ˈsɪtədəl] 城堡; (旧时的)堡垒; scorpio [ˈskɔːpiəʊ] 天蝎(星)座; 天蝎宫; 黄道第八宫; 属天蝎座的人(约出生于10月23日至11月21日); courier [ˈkʊriə(r)] 信使; (递送包裹或重要文件的)通讯员; 专递公司; (旅游公司的)导游;世界上最流行的字体就是 courier 字体 autonomous [ɔːˈtɒnəməs] 自治的 sketch [sketʃ] 素描; 速写; 草图 category [ˈkætəɡəri] 类别; (人或事物的)种类; blackout [ˈblækaʊt] 断电; 停电; 新闻封锁; 灯火管制(期); detonate [ˈdetəneɪt] (使)爆炸; 引爆; 起爆; counsellor [ˈkaʊnsələ(r)] 律师 robotics [rəʊˈbɒtɪks] 机器人科学(或技术); dysfunction [dɪsˈfʌŋkʃn] (关系、行为等的)不正常，异常; 机能障碍; douchebag （美国俚语）人渣、变态、傻X; existing 存在中的 codecs 解码器; 编解码器; 编码解码器; 译码器; 编译码器; quality attributes 质量属性 analysis paralysis 分析瘫痪 protocol suite 协议簇 further reading 延伸阅读 operator 操作符、操作员 multi-disciplinary learning 跨学科学习 settle down 安顿下来 steno notes 速记本 return circuit 回路 exif Exchangeable image file format Independent Adjustor 独立理算师 Adjustment Bureau 理算所 New Year resolution 新年愿望清单 blend [blend] (不同类型东西的)混合品; 混合物; (不同事物的)和谐结合; 融合; 常见同义词去 codelf 找命名 subject -&gt; topic listener -&gt; observer attribute -&gt; property evict（大多数缓存依赖于 evict 操作） -&gt; purge（大多数的软删除依赖于 puge 线程） -&gt; prune -&gt; expunged journal -&gt; log reclaim -&gt; collect verbose -&gt; trival branch -&gt; franchise center -&gt; platform launch -&gt; deploy -&gt; release proxy -&gt; delegate -&gt; agent db -&gt; meta(hive) flaw -&gt; shortcoming ad-hoc -&gt; on-the-fly 即席查询。普通查询是定制开发的（可以使用索引优化）查询，即席查询则无法做相应优化，因此可能拖垮系统 poll -&gt; take conents -&gt; inventory 目录 field 成员变量、字段 -&gt; properties 带有 getter 方法的 field 以及相应的方法 -&gt; attribute seperator -&gt; 序列的中断点，分隔符，one,two,three。我们分解字符串应该多用 seperator。 delimiter -&gt; 序列的休止符，定界符，,one,two,three, runner -&gt; launcher circuit break -&gt; meltdown 熔断 locate -&gt; search -&gt; find -&gt; query -&gt; list -&gt; extract -&gt; fetch to be blunt -&gt; to be frankly 直言不讳地 retrieve（用于缓存） -&gt; get -&gt; fetch directive -&gt; instruct monitor -&gt; watch marker superinterface -&gt; tagging interface stage 阶段、步骤、环节 -&gt; phase 阶段 -&gt; step -&gt; process -&gt; pass execute —&gt; proceed substitution -&gt; replacement -&gt; resolve（log4j 的 Property Substitution） characteristic Spring 喜欢用 -&gt; feature advised 可以用在对象上，也可以用在方法 -&gt; enhanced 可以用在对象上，也可以用在方法 -&gt; proxy 只可以用在对象上 amend -&gt; revise -&gt; modify -&gt; alter hence -&gt; thus -&gt; therefore wire -&gt; assemble permit -&gt; allow -&gt; token -&gt; credential -&gt; principal source -&gt; origin handler -&gt; processor model -&gt; object -&gt; entity container -&gt; box -&gt; server portal -&gt; gateway 近义词mutator -&gt; setter getter -&gt; extractor authentication -&gt; authorization -&gt; certification master -&gt; slave leader -&gt; follower primary -&gt; secondary/backup procedure/process/routine，专业的流程选 procedure，如 rpc concatenation / format sonar 建议，字符串应该优先 format 而不是 concatenation emit -&gt; fire -&gt; publish element -&gt; component graph -&gt; diagram -&gt; picture -&gt; chart 在监控领域 chart 和 graph用得多，diagram 在 UML 里用得多 bootstratp -&gt; launch 引导 启动 * 对前面字符匹配0次或者无限次 + 对前面字符匹配1次或者无限次 ? 对前面字符匹配0次或者1次 service -&gt; application block -&gt; segment -&gt; paragraph -&gt; sector word -&gt; chunk -&gt; packet -&gt; segment how come -&gt; why subsystem -&gt; module check -&gt; validate -&gt; verify transaction -&gt; trade column store -&gt; column database stream -&gt; pipeline master/slave -&gt; leader/follower backlog -&gt; todo mode -&gt; pattern item -&gt; entry -&gt; node -&gt; element link -&gt; associate scenario -&gt; context replicate -&gt; backup repository -&gt; store nest -&gt; contain -&gt; consist -&gt; composite council -&gt; committee -&gt; Parliament change -&gt; modification stop -&gt; halt -&gt; pause barrier -&gt; fence replica -&gt; copy offer -&gt; advice -&gt; proposal -&gt; suggest ephemeral -&gt; temporal epoch -&gt; term -&gt; age half -&gt; semi discovery -&gt; lookup -&gt; detect pipeline -&gt; streamline additional -&gt; extra group -&gt; merge -&gt; batch backup -&gt; standby -&gt; follower -&gt; slave skeleton -&gt; template extension -&gt; plugin correlated -&gt; dependent predicate -&gt; filter condition -&gt; criteria -&gt; query clause partition -&gt; bucket -&gt; shard merge -&gt; compact flush -&gt; refresh occupancy -&gt; utilization grade -&gt; level -&gt; rank TLB 操作系统快表 -&gt; TLAB 线程分配缓冲 -&gt; SATB snapshot at the begining template -&gt; schema -&gt; definition fuzzy -&gt; fulltext exact value -&gt; precise value tag -&gt; badge -&gt; label state（Java rt 里面的源码通常使用这个概念） -&gt; status pending -&gt; todo -&gt; on the way appkey -&gt; appName Zone -&gt; Domain -&gt; Scope -&gt; context scale out -&gt; Scaling Horizontally scale up -&gt; Scaling Vertically target -&gt; object -&gt; goal divide -&gt; split archive -&gt; file trace -&gt; flow -&gt; trade -&gt; bill interaction 交互 -&gt; Collaboration 协同 lb 给算法命名 Round Robin -&gt; poll 给函数命名 glow -&gt; light alarm -&gt; alert add -&gt; save-&gt; insert s -&gt; collection -&gt; list instrumentation -&gt; inspection -&gt; monitor info -&gt; data（避免使用这种含义模糊不清，没有信息量的后缀） extension point -&gt; hook 通常是一个意思 在 Java 并发领域：computation -&gt; tasks 在 RPC 领域proxy -&gt; delegate -&gt; skeleton -&gt; client bolt -&gt; latch Rel -&gt; Association -&gt; use -&gt; dependency -&gt; Aggregation -&gt; Composite（这个概念比较强） orchestration[ˌɔːkɪˈstreɪʃn]（编配） -&gt; choreography[ˌkɒriˈɒɡrəfi]（编排）-&gt; schedule 反义词prefix 前缀 -&gt; suffix 后缀 utilization 利用率 -&gt; capacity 容量 top-down -&gt; bottom up up-to-date -&gt; out-to-&gt;date 常见缩写biz -&gt; business res -&gt; resource qty -&gt; quantity msg -&gt; message pk -&gt; primary key pct -&gt; percent cb -&gt; control block lsn -&gt; log sequence number PBC -&gt; People’s Bank of China 中国人民银行 HIDS -&gt; 主机入侵检测系统 (Host-based intrusion detection system) npc -&gt; network latency、process pause、clock drift ERR_CONNECTION_TIMED_OUT 网络连接超时 pdl product line owt Organization, Work &amp; Technology srv server MVP -&gt; minimal viable product config -&gt; configure 互联网黑话 User Group 用户组 Work Group 工作组 Mailing List 邮件列表 Usenet/NewsGroup 一般指新闻组 IRC USENIX 高等计算机系统协会; UNIX用户协会; 计算机系统协会; 高档计较机系统协会; 商业用语 Working Backwards 逆向工作法 Flywheel 飞轮 OP（Operating Plan）运营计划 OP1/OP2 运营计划1，运营计划2 Team Goals 团队目标 Controllable Input Metrics 可控输入指标 WBR/MBR/QBR（Weekly/Monthly/Quarterly Business Review） Offsite Meeting LRP（Long Range Plan） 长程计划 PR/FAQ（Press Release/Frequently Asked Questions） Narratives/Six-pager Leadership Principle 领导力原则 Tenets 信条 Bar Raiser 升杆者 Talent Discussion 人才盘点 Overall Value 总体价值 Forte 特长; 专长; Role Guideline STL（Separable single-threaded Leadership）第一个 S stands Separable Two-pizza Team SOA（Service Oriented Architecture） Connection Correction of Error Voice of the Customer The Andon Cord Empty Chair C2（Customer Connection） PXT（People eXperience &amp; Technology） TPA（Technical Promotion Assessment） IC（Individual Contributior） SDE（Software Development Engineer） TPM（Technical Program Manager） SpringACCEPTING_TRAFFIC 接受流量 心理学Couple Counseling 婚姻咨询"},{"title":"Spring 数据库的若干种小技巧","date":"2022-01-25T15:17:20.000Z","url":"/2022/01/25/Spring-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%8B%A5%E5%B9%B2%E7%A7%8D%E5%B0%8F%E6%8A%80%E5%B7%A7/","tags":["Java","MySQL","Spring","H2"],"content":"常用命令 LiquibaseUse Liquibase to Safely Evolve Your Database Schema 数据库的演化，可以是 evolve，也可以是 refactor。 FlywayDatabase Migrations with Flyway 这里使用的术语是 remodel。 MariaDB4jUsing MariaDB4j for a Spring Boot Embedded Database 注意它对 datasource 的抽象。 H2 和 JPA 的速成搭配"},{"title":"团队协作的五大障碍","date":"2022-01-23T04:23:16.000Z","url":"/2022/01/23/%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E7%9A%84%E4%BA%94%E5%A4%A7%E9%9A%9C%E7%A2%8D/","tags":["管理"],"content":"引言企业最根本的竞争优势既不是来自资本实力、发展战略，也不是来自技术，而是来自团队协作，因为团队协作能力是非常强大而且弥足珍贵的。 很多领导者认为，让团队所有成员齐心协力实际上是不可能做到的。 由于团队是由具有各种缺点的人所组成的，这样团队就不可避免地带有其先天缺陷。但这绝不是说团队协作注定要失败，恰恰相反，建立一支强大的团队既切实可行又相当简单，但是却需要克服困难才能做到。 第一部分 寓言故事背景硅谷的概念更取决于公司的文化特征。 两年对于一家科技创业公司来说，可能就是其从诞生到灭亡的全过程。 团队出问题的迹象：管理层相互倾轧，团队毫无团结友爱可言，大家对这种情况心照不宣。每项工作似乎都要花费很长时间才能完成。 在硅谷工作是不流行穿西服。 凯瑟琳在团队建设方面有惊人的天赋。 凯瑟琳几乎什么都没做，只是旁听团队会议，进行记录。凯瑟琳有如下几段经历：在军队打滚过，后来嫁给一位篮球教练，然后入读了三年夜校，后来在一家日美合资企业任职，迅速成为首席运营官。 大多数程序员都被他们的知识弄得麻木不仁，好像认为只有编程和产品设计才能使公司腾飞。 管理者不需要成为业务的专家，也可以管理一项业务。 不团结的管理团队开会永远得不到真正的共识，计划讨论既缓慢又缺乏生气。他们之间几乎没有真正的交流，每次会议大家都盼着快点结束。 杰夫在主持会议的时候通常是照本宣科，就像一个学生干部那样，每次会议之前他都会发布会议议程，会后分发详细的会议纪要。和其他高科技公司不一样的是，他主持的会议总是按计划开始，按计划结束。而这些会议实际上没有解决任何问题，但杰夫对此却毫不介意。 市场推广是决策科技有限公司的重要工作，董事会曾经费尽心思才找到米歇尔·比比。她喜欢别人叫她米琪。她是硅谷公认的树立品牌的天才，所以人们绝对不会想到她的性格中会存在基本的社交障碍。 在会议上她说得最多，有时她能够提出一些好的想法，但大多数时候她总是在抱怨，说自己待过的其他公司在所有事情上都比决策科技有限公司做得好。她在这家新公司里看起来就像个观察员，或者更确切地说，像个受害者。 因此，尽管米琪颇有才华和成就，她却成了公司里最不受欢迎的人，而凯瑟琳对此一点儿也不觉得奇怪。如果说还有人比她更不受欢迎的话，可能就是马丁了。 点燃团队希望之火“首先，不要认为我在随意制造矛盾来显示我的权力。前两周我一直在仔细地观察他们，我所做的一切以及我将要做的一切，都是有特别 用意的。我没让马丁下不了台，是因为我当时不想那样做。” “如果你现在能够做我要做的事，你就不需要我了，我说得对吗?” 放任问题不管，意味着好意带来的伤害更大。 有着更富经验和能力的管理团队以及更多资金，在盈利和用户增长方面这家公司却落后于竞争对手，是因为“我们的管理团队没有起到作用，事实上我们这支团队陷入了困境。” 开会虽然指出问题，但不忙指责其他人。不过，如果为了公司和团队的利益，有些情况下需要请某些人离开公司。 所有一切管理动作，只是为了让公司成功，而不是展开敌我斗争。 “当然，我们也不是要手拉手地相互恭维以示友好。” 一般团队都会有五大障碍，这会阻止团队取得成功-连业绩都达不成。 第一个障碍，建立信任“信任是真正意义上的 团队协作的基础，所以第一个问题就在于团队成员不能相互理解、以诚相待。如果这一条听起来太多愁善感的话，让我告诉你们，这不是一件小事，而是建立高效团队至关重要的条件，可能也是最难做到的一条。” “优秀团队的成员绝不会互相防备，他们不会掩饰自己的缺点，他们勇于承认错误和不足，敢于发表意见，不必担心遭到打击报复。” “但有一点比别人告诉我的那些信息更能说明问题：这支团队在会议上或其他交流中缺乏必要的争论，这就说明大家缺乏信任。不过，缺乏争论是 另一大障碍，我留到后面分析。” “不过据我观察，每一支高效团队中都存在着深层次的辩论，即使是最团结的团队也存在很多争论。” 不喜欢辩论不代表没有争论，而是因为不喜欢彼此反驳，而且人们很难说清为什么会如此。 开会不认真是个人行为问题，而不是行业问题。 谈童年和成长经历很重要。 凯瑟琳高兴地发现马丁也参与到讨论中来了。不过她再次提醒自己，每个人都喜欢了解和谈论自己，一旦他们面临批评就不是这样了，而批评总是会有的。 缺乏信任的结果是相互戒备要“揭短”。有时候弱点和长处是一样的东西，很多时候事情就是这样的。即使已然做到高管，也未必知道自己的优缺点。 最顶层的障碍是无视结果，因为它关乎地位和自我“我们现在看图形的最上面，讨论最后一大障碍:团队成员在工作中过分追求对个人的认同和注意，而忽视了集体的利益或者集体的工作成绩，即整个团队的工作目标。” “但我不是说在团队中不允许自我的存在，关键是要让集体的‘自我’高于个人的‘自我’。” “是这样的，当每个人都以集体的工作成绩为中心，以共同的工作成果作为成功的定义时，个人主义就会被严格控制住。不论团队中的个体自我感觉多良好，只要整个团队失败了，那他就失败了。” “好的，大多数体育运动最后都有一个明确的得分来评判你到底是赢还是输，几乎没有折中，就是说不能……”他停了一下，想选择恰当的用词，“……不能主观地、自以为是地认为自己成功。” 屋里的人都点头表示明白了。 “等一等，”JR说，“你是在告诉我们运动员没有个人主义吗?” 马丁看起来不太确定，于是凯瑟琳插话说：“他们有很明显的个人主义，但是优秀运动员会把他的个人主义同一个明确的目标联系在一起：赢得比赛。他们最想要的是赢，而不是进入全明星队，或者在报纸上露个脸，而且也不是赚钱。” “当然利润是很重要的标准，但我指的主要是季度末成绩。如果你把利润当作唯一的目标去追求，除非到了一个季度快要结束的时候，否则就没办法了解团队的进展情况，因为不到那时候，我们是无法计算利润率的。” “我们的任务是使整个团队取得成绩，这一点在座的都明白。谁也不能以提高他自己的个人地位或个人利益为目标，因为那样的话就会削弱我们实现整体目标的能力，我们就会全盘皆输。” 讨论的话题转向公事，大家的活力似乎随之消退，取而代之的是和从前一样的互相批评。 在这种场合，只要一开始谈公事，大家就都恢复从前的言行，而正是那些言行使他们陷入困境。 凯瑟琳看出他们不会轻易放弃各自的观点，于是决定改为采用一种带有质问性质的说服方法:“在一个季度内，当工作目标看起来难以实现时，部门之间的工作需要重新协调才能改善这种情况，那你们多长时间讨论一次?” 他们的表情说明了他们从来没有这样做过。 “你们在开会的时候，是否能很有条理地从细节上回顾这些工作目标?比如说深度探讨为什么这些目标能够实现，或者为什么实现不了?”其实她已经知道答案了。 “设想一名篮球教练在上半场比赛结束时，在休息室逐个叫队员进 来讨论上半场的表现，他们每个人都不知道其他人和教练谈些什么。这 样的话他们就不是一支团队，而是一群独立的运动员。” 凯瑟琳脸上浮现出难以置信的表情，好像在说:我简直不能相信我还需要告诉你们这些。她耐心地说道:“你们所有人，每一个人都有责任了解销售的事，而不只是JR;所有人都有责任了解市场的事，而不只是米琪;所有人都有责任了解产品开发、客户服务、财务等这些工作的 进展情况，明白了吗?” 凯瑟琳的解释简单明了，他们的团队协作显然不合格。这样一天半讨论过后，大家仅存的团结似乎所剩无几了。 “然后呢?是什么阻碍你们建立一支真正的团队，或者阻碍你们像他们那样调整商业计划呢?” 应当自称“我们”。 “是的，开会的时候我们似乎没有共同的目标，我们都在为自己的部门争取更多资源和投入，或者说尽量避免参与自己领域以外的事情。” 因为大家都守护着自己的边界和领地，所以如果有人出现“摆烂”的行为，最终所有人都会摆烂，进而形成官僚主义。 “我们公司内部的官僚主义简直到了令人震惊的地步，这是因为大家对于共同目标认识不清，从而把精力放在个人得失上。” “企业中的官僚主义是指，一个人所说的话和所做的事，是为了让其他人按其期望的那样作出反应，而不是出于他们自己真实的想法。” 第四个障碍“信任非常重要，你们知道为什么吗?如果在一个团队里大家彼此不信任，会产生什么样的实际问题呢?” 第四个障碍是“惧怕冲突”-“一团和气”。 “不是的，你们的关系是紧张，但是几乎没有积极、有益的争论。被动、讽刺的言语不在我所说的范围之内。” “问题在于缺乏必要的、有益的冲突。我认为如果融洽来源于不断解决问题和矛盾的话，那么融洽本身就是好事;但是如果是因为隐瞒自己的意见和真实的想法，那么所谓的融洽就是坏事。我需要的不是那种虚假的融洽(表面上一团和气)，我想要的是一支团队能够有效地对事情进行争论，然后毫发无伤地结束。” 凯瑟琳继续争取他们的支持:“在观察了你们的几次会议之后，我敢说你们并不太同意彼此的观点。有时候你们的不满用微妙的语言表达了出来，但在大多数情况下，你们还是听之任之了，我说得对吗?” 第三个障碍欠缺投入-模棱两可 凯瑟琳回到记录板前：“团队协作的下一种障碍是，在作出决策的时候欠缺投入和不能达成共识。”她在前一个问题上面的区域写下了“欠缺投入”这一条，并指出：产生这个问题的结果是作出模棱两可的决策。随后，她把“模棱两可”写在了记录板上。 凯瑟琳解释道:“简单地说，如果大家没有讲出自己的观点，觉得没人听自己的意见，他们就不会进入角色。” “你可以迫使他们进入角色。”尼克有反对意见，“我猜你的丈夫不会让他的队员们举手表决，是不是应该在训练的时候做迂回跑。” 凯瑟琳很高兴有这种挑战:“他不会，但是他会让他们说出不想那样做的原因。如果他不同意他们的看法，他同样会告诉他们原因，然后让他们开始跑，这种情况经常发生。” “那么说这不是一致同意的了。”简的话更像是一个提问。 “当然不是一致同意了，”凯瑟琳坚持说，这时她看起来又像个教师了，“一致同意很可贵。我是说如果每个人确实同意一件事，那么很快、很自然地就达成了一致，那样很棒。但是事实通常不是这样的，于是往往所谓的一致同意变成了谁也不得罪的权宜之计。” “通常也变成得罪所有人的事。”杰夫苦着脸说，他似乎在回顾一段痛苦的经历。 “一点儿都没错。关键在于大多数理智的人不一定急于发表意见，他们需要确信别人愿意听他们的想法，以及确信他们的说法可以得到关注和回应才肯开口。” “是这样的，在我待过的前一家公司，我们称这种情况为‘不同意但是投入’。大家可以争论，可以有不同意见，但最终要同意一起去做这件事。” 这为杰夫点燃了一盏明灯:“哦，我知道冲突的作用了。没有冲突，就不能真正说服别人，这样即使大家表面上表示同意，也不会真的去做，因为……” 卡洛斯打断他:“……因为他们在达成共识之前需要权衡利弊。” 大家看起来都明白这一点。 第二种障碍逃避责任 - 低标准 “一旦我们弄清楚要做的事情，而且准备去做，我们就需要对自己所做的事负责，并要有良好的表现。虽然这听起来很简单，但是大多数主管人员不乐意这么做，尤其是对于同事所做的事情更不愿意负责，因为他们想避免人际关系上的摩擦。” “你说的这些到底是指什么?”杰夫问道。 “我是说当人们觉得有必要提醒同事注意一些事情的时候，还是决定不说了，因为他们不喜欢那种感觉，比如说……”她停了一下，马丁帮她补充完后半句，“……比如说有必要告诉某个人在开会的时候关闭电子邮件。” “一点儿没错。”凯瑟琳感激地确认道。 卡洛斯补充说:“我就不喜欢这样做。我特别不爱告诉别人他们缺乏基本素质。我宁愿选择忍受他们的行为，来避免……”他试图找到合适的词汇表达自己。 简替他找到了准确的用词:“……人际关系上的摩擦。” 卡洛斯点点头:“是的，我想就是这个。”他想了一会儿，然后继续说道:“真有点奇怪，我即使对直接下属都不能完全说出自己的真实想法。我好像总让他们按自己的想法去处理问题，甚至有时候遇到关键的问题也是如此。” 凯瑟琳进一步解释说:“平级对平级的关系，当然是造成团队成员不愿对彼此负责的原因之一，不过还有其他原因。” 大家看起来都想不出其他原因是什么，于是凯瑟琳准备回答。这时米琪的表情舒展开来，好像猜出了一个谜语:“没有连带责任。” 为什么人们讨厌开会而喜欢看电影？开会是免费的，而看电影是要花钱的。因为开会很枯燥。 我们为什么喜欢看电影，因为电影有冲突，无巧不成书。开会之所以枯燥，是因为没有吸引人的冲突。 “好的，我们的讨论结果是赢得新的客户。谁能告诉我这为什么是我们共同的、长期的目标?” 这次用不着凯瑟琳点名了，卡洛斯自告奋勇。 “因为赢得新客户可以让媒体有材料可写，让我们的员工信心百倍，给马丁和他手下的工程师们带来更多反馈，还有助于我们在下一年出去寻找更多的客户。” 凯瑟琳想利用这个机会为接下来的事做铺垫。她先对JR和尼克说:“我很感谢你们愿意用尽可能多的时间做成生意。”她说这话的时候有点儿心不在焉，尽量避免显得过早地否定他们。“不过，我想提醒大家昨天会议开始的时候我说过的话。我们拥有比竞争对手更多的资金、更好的技术、更富经验和才华的管理人员，但我们落在竞争对手后面。我们所缺少的是团队精神，我向你们保证，我作为CEO最大的优势，就是使你们，不对，是使我们，成为一支更有效率的团队。” 米琪、马丁和尼克的态度看起来缓和了，凯瑟琳继续说道:“我现在要说的比我们昨天到这里以来所说过的都更重要。”她停下来看看他们的反应，“在今后的两个星期，我对那些缺乏信任、过度自我的行为绝不会姑息。我要鼓励适当的矛盾冲突，追求对工作的全情投入，并且让你们互相监督。看到不合适的地方我就会适时提出来，我希望你们也是如此，我们不能再浪费时间了。” 重磅出击布兰登技术很好，但缺乏社会交往的技巧，他想都没想就说:“大家即使花钱都想看看米琪怎样回答关于她的态度问题。” 凯瑟琳继续说道:“但是如果公司的经理们不能真正成为一支团队，这就会使他们自己和公司陷入进退两难的局面。你们看，麻烦来了，到底哪支团队是自己的第一团队呢?” 杰夫疑惑地问道:“第一团队?” “是的，更重要的团队。而且这与团队的最后一种障碍紧密相关，在你们的第一团队中，大家必须把团队的利益摆在个人利益之上。”她环视在场的人，让他们知道这话是很重要的。 “即使我们对自己的下属很有感情，他们也很感激这一点，但是你们不能丢掉对我们这支团队的忠诚和责任。” 凯瑟琳平静地解释说:“米琪，你不太尊重你的同事，不愿意向他们敞开心扉。在会议上，你给其他所有人包括我，造成了消极影响。”虽然凯瑟琳知道自己所说的一点儿没错，但还是觉得对于一个没有思想准备的人来说，这种指责似乎太直接了。 “你认为我不尊重同事?问题是他们不尊重我。”米琪话一出口，就意识到这话其实出卖了自己。她略显疲惫，试图解释说:“他们无视我的才干和经验，而且他们根本不知道怎样宣传软件产品。” 凯瑟琳真诚而温和地告诉她:“你也许会找到更欣赏你的才干和风格的公司。”下边的话凯瑟琳本不想说，但她觉得米琪应该听听这话，于是继续说道:“但如果你不反省自己的话，恐怕一切没那么容易。” 凯瑟琳于是开门见山:“我认为米琪不愿意改变自己的言行，而她的行为对团队造成了伤害，所以我请她离开公司。” 凯瑟琳失败的地方：给弗雷德升职导致其他人离职，最后公司解雇了她。 所以她后来开始规训自己团队的言行。 收获当原则和人际关系出现冲突的时候，马丁选择了原则而不是人际关系。 第二部分 模式要建立信任，需要先剖析自己的性格。"},{"title":"亚马逊发展研究","date":"2022-01-21T15:41:49.000Z","url":"/2022/01/21/%E4%BA%9A%E9%A9%AC%E9%80%8A%E5%8F%91%E5%B1%95%E7%A0%94%E7%A9%B6/","tags":["亚马逊"],"content":"亚马逊成长战略研究FROM：《【案例】亚马逊成长战略研究》 对于亚马逊来说，考虑到其电子商务的特质（零售+互联网），业务拓展、投融资、物流基建和技术研发对其持续增长起到最强的内在推动。由于电子商务的高固定成本与规模经济本质，持续发展的唯一方式就是不断的扩张业务，以达到成本下降，摊薄固定成本，实现规模收益的目标。当企业达到一定规模时，自建业务所需的成本往往将超过收购业务的成本，这时收购成为企业在对应时间点上继续发展的重要选项。而电子商务的本质是零售供应链的进化，这种进化依托于更快、更好、更精准针对的客户体验，物流体系是否完备，是电子商务企业是否能够决定性持续满足客户需求的基础所在。同时，技术能力决定了企业运营的效率，减少内部损耗和浪费，同时为向更积极、享受高估值溢价的产业延伸乃至最终转型提供依托。 边际效应低意味着马太效应高。做电商强依赖于物流能力。 亚马逊的业务扩张从两个维度分别延伸，即地域扩张和品类扩张，两者同时对其营收与利润的绝对值和结构造成影响。在地域扩张方面，亚马逊不单推广国际化，将成熟的模式拓展到海外市场，扩大营收规模，摊低运营成本，获取新的市场份额和客户群体，也同时在不同国家，依托当地经济发展、文化、消费习惯、受众喜好等设置不同的运营模式与方向，推进业务的本地化，这就使得公司不会因扩大了量而忽略了质。在品类上，亚马逊注重用户体验，以满足客户体验为导向的品类运营方式，在重点品类（如图书音像、消费电子）上打造独特风格。在配合以自营品类扩张+第三方平台扩充，增加细分品类与SKU，注重长尾与需求延伸的闭环方式增强用户粘性，从而达到营收与利润的增长。 亚马逊董事会主席杰夫•贝佐斯对亚马逊从一开始的定义就不仅仅是一家”商店“，而是希望通过零售作为切入点，吸引消费者，并最终掌控消费者。其品类扩充大方向上遵循”内容-载体-重定义载体-重定义内容“的发展逻辑。 增长飞轮总是从一项业务（品类）做小切入，切入的结果就是得到增长/发展路径。 在整体上，亚马逊自营和第三方并重，长期将更多的倚靠第三方平台。随着企业营收的规模不断扩大，亚马逊逐渐形成了以自营为基础，第三方平台销售为持续增长动力的业务驱动模式。同时，其品类也在进行多样化布局，传统零售增长趋缓，业务模式转型中。亚马逊的最大品类从发展初期的图书音像逐步变成EGM（消费电子和日百），目前这一变化趋势又在向具有较高毛利的新业务（数字内容、云计算、广告等）的方向演进。对于毛利率，亚马逊借助快速发展新业务的高毛利，不断压低零售毛利，施压竞争对手。近些年亚马逊报表毛利开始提升，其中一部分来自平台佣金，一部分是云计算等新业务。综合毛利提升使得亚马逊有能力始终保持低价，以达到稳健增长。而受到毛利提升的影响，亚马逊的新业务不断展开，享受“科技溢价”。云计算、数字内容及广告是Amazon近几年来快速成长的几项业务，这几项业务普遍有着远高零售的毛利（90%、43%、60%）和享受“科技溢价”的特质。 低毛利可能是打击竞对的一种策略。 在亚马逊历年投资收购的企业中，主要分为三大类，技术公司、垂直电商和互联网企业。对于与拥有亚马逊主营业务相关的各项技术，如CRM、订单履约、用户管理等的技术公司，亚马逊常采用直接合并的方式进行投融资，吸收团队与技术居多，用以支撑公司架构。亚马逊投资收购的垂直电商仍让其保持独立运营，主要用来拓展业务。让其在现有的基础上拓展业务，从而获取更多的销售与购买力资源，形成闭环与协同效应。而对于拥有移动应用开发团队、以及其他与亚马逊新业务（云计算、数字内容、物流自动化）相关的互联网企业，亚马逊在投资之后与其携手合作，齐头并进，努力寻求模式创新。 亚马逊用了非常久的时间来收购或者自建自己本来没有的硬件技术。这和苹果或者微软成为另一类业务的公司的逻辑是相似的。今日头条或者腾讯的悄然转型故事里也隐藏有类似的经营思路。这是贝索斯在写给股东的信里提到的“我们乐于见到种子变大树”的逻辑。 近几年亚马逊在全球范围内开展了新一轮的物流建设，仓储面积大幅度增加，近五年来，亚马逊仓储面积从13634000平方英尺上升至66383000平方英尺。 亚马逊在全球攻城略地，第一件事就是建仓储。当初它进入中国收购卓越网的逻辑即与此类似。 此外，亚马逊的物流体系发展不单纯的为降低费率而做形式策略，而是主要通过修整物流体系布局和技术提升来降低成本、提高效率。从建设伊始，亚马逊的物流建设标准就是以订单聚合自动化、后端负责制为基础同现代物流企业分工合作，在持续的投资自动化系统之后，物流费率得到了迅速的控制，为后来的整体盈利打下基础。在北美及欧洲、日本等发达国家市场，更多的选择长期租赁而非购买。在发达国家，亚马逊很少持有地产或仓库，而是在长期租赁的基础之上对设施进行改进。随着业务的发展，亚马逊的物流中心不断由成本主导的远离城市选址向客户体验主导的贴近城市选址演进。更贴近城市的物流中心不断的加强订单履约的效率及和客户体验。 Fulfillment by Amazon 亚马逊的后端履约体系非常强大，强大得足以输出、赋能行业。 2000年，亚马逊推出Marketplace，允许第三方卖家开店。卖家支付费用后，就可以利用亚马逊的流量与用户优势进行销售；初期第三方平台的作用除了丰富品类之外，更多的还是为扭亏考量；2007年，Amazon正式向第三方卖家开放FulfillmentbyAmazon（简称FBA）业务，为第三方中小卖家（特别是不具备仓配条件的，产品体积小，附加值较高的卖家）进入Amazon提供了更规范化的仓储运营体系；自推出以来，亚马逊第三方平台的业务始终以快过自营业务的速度增长，自2009年以来，增长速度更是快速提升，预计在未来的几年内，其营收额会达到亚马逊整体GMV的60%以上；目前，亚马逊第三方平台业务已经涵盖图书、音乐、手机通讯、数码、数码配件、大家电、小家电、电脑、办公用品、家居、食品、酒类、个护健康、美容化妆、玩具、母婴、运动户外休闲、服装鞋靴、箱包配饰、钟表、珠宝首饰、宠物用品、乐器等23个大类，GMV占总体接近50%。 在FBA业务中，物流的主要特性有四点，闲置资源利用、运营经验积累、吸引平台卖家以及无法从根本上使物流体系独立盈利。由于销售的不断增长，物流体系在发展过程中始终存在闲置资源，主动仓储服务使得对这种资源的利用成为可能。同时，针对第三方卖家和外部客户的物流服务，使得亚马逊除了在订单生产之外，还能积累其他的物流经验（如代运营）。FBA业务为第三方中小卖家提供了更低的准入门槛，更好的处理日常运营，同时与Prime和第三方平台深度整合，使得卖家、亚马逊和客户之间形成良性的循环。但是，从仓储运营数据中可知，FBA收入的增长无法带来物流费率的整体下降，主动仓储业务很难在可预期的未来独立盈利，其价值更多的体现在对客户体验的协同效应上。 亚马逊的冷链业务发展历程可以归纳为三个词，试点谨慎、积累深厚以及前景良好。2007年亚马逊正式向西雅图地区提供生鲜电商服务AmazonFresh。最初仅覆盖两个西雅图居民区，在之后的5年里缓慢扩展至其他西雅图社区。2012年，AmazonFresh业务扩展到洛杉矶与旧金山。亚马逊在将冷链业务扩展到新城市之前，都会“物流先行”的建设足够完备的冷链体系。2014年，AmazonFresh将业务扩展到纽约。预计在2015年，亚马逊的冷链业务将拓展到全美50个大型城市及德国。 冷链相关的零售业务都带有高耗损和低客单价的特点，所以这个行业注定低毛利，非常考验企业的运营能力。如果搞前置仓模式，则消费者将质量问题完全交给企业解决，企业作为平台，需要把品控控得非常非常好才行。 亚马逊进入云计算是具有优势与益处的。首先是亚马逊自身的特质，由于自身业务结构决定的，亚马逊的营收规模较大，运营费率高，净利率较低；而云计算业务本身也符合这样的“两高一低”特质。其次，是亚马逊业务本身极强的会计优势，云计算业务将使亚马逊的整体毛利上涨，同时，高额的固定投入表现为报表技术费率升高，提升投资者及公众对亚马逊的预期并强烈影响其估值溢价。最后，快速的云计算建设将使得其他高附加值互联网企业的报表稳定性受到威胁，而亚马逊则不会。由于固定成本较高，初期投入较大，净利润较高的企业（如Google/微软等），承担快速的云计算建设将使得其报表稳定性受到威胁，并在长期影响其业务及收益结构。 亚马逊技术的发展分为六个阶段，从支撑基础业务到引领转型变革，技术先行的理念被亚马逊始终贯彻。1995-1997年，打造底层架构雏形；1998-2000年，拓展流量与维系客户关系；2001年-2003年，整顿订单履约体系；2004-2006年，主动寻找新方向（偶得EC2）；2007-2009年，Kindle与系统生态闭环；2010年至今，AWS与智能硬件相关。 经过多样化尝试之后，亚马逊确定了自主研发为主，收购为辅的业务技术发展理念。这样的优势在于自身业务的发展更小的受制于技术的阻碍，也能更快速的针对运营中出现的问题进行反应。在新业务的拓展上，亚马逊遵循收购团队为主的策略。这样的优势在于以更低的成本获取新业务/行业的准入资格，同时获取合格的技术团队，增强开发能力。 整体而言，亚马逊拥有相对先进的基础架构、能力卓越的技术团队和不局限于业务支持的发展理念。从建立底层架构开始，亚马逊的技术体系雏形就具备了自动订货系统、订单履约系统、客户推荐系统等超前理念的技术雏形。在完备雏形的基础上，亚马逊达到成本领先的战略目标一直以不断的技术发展作为主要手段。亚马逊以Bezos为首的核心管理团队绝大多数为技术背景出身。Bezos偏爱绝顶聪明且有良好教育背景和目的导向性的成员。这使得亚马逊的管理团队与技术团队有良好的开发能力。互联网崩盘期间及之后一段时间里，亚马逊重新架构了技术团队，更换了一些核心技术成员，并对研发体系整体的绩效激励、业务气氛进行了整顿。亚马逊始终有技术团队在做“看起来与目前业务毫无关系”的研发工作——不局限于业务研发，使得亚马逊得以引领电商行业发展。 做好市值管理，维护增速与报表稳定性，将极大的助益企业估值的提升和企业形象的建设。从“一键下单”到“两高一低”的云计算，再到宣称“无人机送货”，亚马逊永远在“表明”自己的高科技含量。亚马逊始终宣称“坚持技术驱动”，非常善于用超前的理念提升自己的形象即使多年亏损、盈利也净利率极低，仍然得到大多数投资者的追捧。业界始终将其当做一家具有互联网特质的高成长企业，因此享受极高的估值溢价。企业应积极向“高科技”靠拢，不要“埋头”做零售，特别是未来IPO之后，这种战略方针的重要性更加凸显。 “零售+科技”意味着能够占领广大市场得到大量营收，也意味着市场会给予高估值。 对于技术发展，应提升投入、“运营效率”“客户体验”与“卖家营商便利度”三管齐下；在做好业务支持的同时，也关注“业务以外”的成长。亚马逊对技术研发的投入费率常年稳定在5%以上，近几年更是达到8%的历史最高点，而国内电商普遍只有2%-4%，技术研发投入的差距在长期将影响企业的持续发展。2009年亚马逊完成了全世界范围内的后台系统整合，使得其内部运营效率大幅提升。随着企业收入规模和组织结构的不断扩大，相互嵌套的架构与系统所产生的低效和损耗将牵制企业的发展。提升客户体验和卖家营商便利度，能够更好的协助第三方平台“标准化”，提升平台的质量与价值。打造完备的客户维护及供应商开放体系，提升用户粘性和卖家营商便利度，可以为长期发展提供有力支撑。在2002-2006年间，亚马逊有一部分技术团队长期在研发当时看来与其主营业务毫无关联的“分布式架构”技术，最终EC2弹性云的诞生成就了今天的AWS云计算业务。 优秀的基础架构是技术深耕的结果，是值得我们学习的东西。 观察家 | 亚马逊平台进化简史FROM：亚马逊平台进化简史 很多学者认为，亚马逊只是一个电商企业，其盈利模式是依靠管道式的买进卖出赚差价。这显然是一种严重的误解。事实上，尽管亚马逊在创业之初确实是一个管道式企业，但现在它早已发展成了一个大型的“嵌套平台”（NestedPlat－form。注：这个观点是我在和《平台革命》的作者埃尔斯泰恩在一次对话中听他说的。我没有在其他的著作或文章中看到类似的说法，我想这应该是他的原创），或者说是平台的平台。在这个平台上，存在着电商、云计算、物流、广告等多个子平台。正是一步步从管道式企业走向平台企业，再走向嵌套平台，才让亚马逊铸就了今日的强大。 国内称得上“平台的平台”的，只有阿里。但现在看起来阿里的人员能力不足和政治斗争问题可能会导致阿里衰落-因为阿里的底层员工普遍抱怨，不幸福。 在美国，图书市场的总规模相当可观：据估计，1994年时美国图书市场的规模约为190亿美元，平均每个美国人每年在图书上的支出有79美元。与此同时，这样一个规模巨大的市场并没有被垄断巨头把持。尽管当时美国有巴诺和博德斯这两大连锁书店，但它们的市场份额总共也不过25%，其余的市场份额则分散在各个独立的小书店手中。因此如果选择进入这一市场，不会遇到太多在位者的阻拦。考虑到这些，贝佐斯就将亚马逊最初的业务主要聚焦在了图书上。 贝索斯有非常敏锐的眼光，能够在 90 年代的报表里察觉互联网 2300% 的年增速。 用今天的眼光看，亚马逊在起家时的销售方式非常原始：它主要通过邮件接收订单，根据订单向图书批发商进货，然后再通过邮政系统将书寄给读者。从价值链角度看，这和传统书店并无二致，都是管道式的销售。不过，由于网络打破了地域市场的边界，因此亚马逊获得了比任何传统书店都要大的需求，而这些需求也成功地支撑了其最初的成长。 网络无边界的效应在网速很慢的时代就显现出来了，那么如果网络基础设施进一步进化，人类的社会结构会发生怎样的进一步变化呢？很值得畅想。 亚马逊的成功让一些老牌书店看到了网络的价值，并逐步开始试水电子商务。1996年，博德斯也推出了自己的网站，开始在线售书。作为传统连锁书店的两巨头之一，博德斯在品牌、渠道、资金等方面都比亚马逊更有优势，对于这样一个挑战者，亚马逊应该如何应付呢？贝佐斯团队给出了一个颇具平台思维的对策：建立评论板块，鼓励读者对所购图书进行评价，并建立各种渠道，让作者与读者、读者与读者进行广泛交流。这样，亚马逊的网站就不只是一个单纯的购书网站，而成了一个聚集了书友、作家的互动社区。我们知道，社区是具有强烈的网络外部性的，一旦形成了规模，就会产生强大的吸引力。通过对这个“社区”的建设，亚马逊成功黏住了读者，挡住了博德斯的进攻。 引发用户行为，也是一种设计业务的思路。 为了摆脱这一困境，亚马逊开始拓展业务，进行图书之外的商品销售。起初，亚马逊仍然选择了自营模式，自己进货、自己销售。为了配合销售，亚马逊还开始建立了自己的仓储和物流系统。不过，这种模式的问题很快就显露出来：由于当时的亚马逊财力有限，因此很难为消费者提供足够品类的商品，这就限制了其吸引力。购入更多的商品当然是一种可行的方案，但其带来的仓储、物流成本显然是亚马逊难以承受的。 拓宽品类其实非常非常难！自建仓储和销售系统似乎是亚马逊的经营惯性。但扩张品类带来的对履约体系的压力却是一个很难解决的技术问题。 那么，如何才能打破这一僵局呢？一个思路就是，将商业模式从管道式改成平台式，让商家进入亚马逊销售商品。1999年，亚马逊将这一设想变成了现实。它将自己的网站开放给了商户和个体经营者，允许它们在上面出售商品。对于那些交易比较频繁的商户，亚马逊要对其收取月费和交易抽成，而对那些交易频率较低的商户和个人，则只收取交易抽成。商家在亚马逊上达成交易后，自行把货物寄给客户，而亚马逊则会帮他们向买家收费，并把扣除抽成后的余额汇到他们的账户。 亚马逊的这一举措受到了小型商户的欢迎，这使得它们可以依托亚马逊的口碑和渠道，让更多的消费者看到自己的商品。于是，大批的商户集中到了亚马逊平台。而对于亚马逊而言，它的收获要比这些小型商户更大：这意味着它成功解决了商品品类少的问题，足以让整个亚马逊更有吸引力，更能吸引消费者，更能促进其自营业务的增长。更为重要的是，这个发展消费者的策略不仅只用投入很少的成本，还能获得可观的月费和抽成收入。 也就是说，C2C 总是容易做的，因为可以利用卖家自己的履约管道，B2C 需要长线布局才能建成。借助 C2C 的佣金收入投入对基础设施的建设之中，这需要经营者奉行长期主义。早期借助 C2C 的模式，蜂拥而至的卖家也能解决选品的问题。最终形成“多快好省”的局面。 从另一个视角看，时代也在进步。在亚马逊和阿里巴巴都很穷的时候，只能依靠本国的公有物流设施。但信息技术和中美两国的基建进一步发展以后，亚马逊和阿里巴巴突然之间就有钱了，于是一切水到渠成。 需要指出的是，2000年互联网泡沫破灭，包括亚马逊在内的电子商务企业都遭到了巨大的冲击，融资变得十分困难。在这种情况下，1999年推行的平台化改革方案保证了亚马逊的收入和盈利，使得它在巨大的冲击面前免于资金链断裂的困境。从这个意义上讲，平台化改革在某种意义上是在危亡之际拯救了亚马逊。 借助平台化的策略，亚马逊不仅挺过了互联网经济的寒冬，还迅速成长为了真正的“万有商店”。 亚马逊把云时代的几个基本的技术问题解决得很好： 大致上，云服务可以分为三类：基础设施服务（InfrastructureasaSer－vice，简称IaaS）、平台服务（PlatformasaService，简称PaaS）和软件服务（SoftwareasaService，简称SaaS）。其中，IaaS服务类似于硬件外包，即在服务提供商的机器上进行存储、硬件使用；PaaS主要是在网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统；而SaaS则是主要在网上提供软件的应用。软件的提供商在硬件提供商的机器上为客户提供服务，在这个过程中，硬件提供商就扮演了一个平台的角色。在这个平台之上，软件提供商和客户进行交互，而硬件提供者则可以从两者的交易中获取收益。 不过，云服务的固定投入要求非常高，不仅需要进行大量的硬件建设，为了启动平台的“网络外部性”，还需要联系一批技术合作伙伴。资金从何而来？在这个过程中，电商业务就扮演了一个输血者的角色。通过将电商业务获取的利润投入到云服务建设，AWS云服务业务很快发展起来，并成为了新的利润流来源。亚马逊的主要竞争对手微软的CEO萨提亚·纳德拉曾“吐槽”说“亚马逊能在云服务领域领先微软，原因就在于它有一个双边市场，可以用其他业务来对此进行补贴”。纳德拉的这番话，也恰恰佐证了亚马逊在发展云业务时对平台思维的应用。 多边市场是平台型公司的终极壁垒，没有形成平台的企业是没有这种竞争力的。 如果说亚马逊发展AWS云服务、物流等业务时，主要利用了电商平台在资金方面的优势，那么它在发展广告业务时，利用的就主要是其积累的数据优势。 对于互联网企业来说，广告一直是一块重要的收入来源。包括谷歌、Facebook在内的很多知名企业，其收益和利润的相当一部分都来自于广告。作为一家互联网企业，亚马逊当然不会放弃广告这块巨大的业务。问题在于，作为一家电商起家的企业，其广告的受关注程度又怎么可能和谷歌这样的搜索引擎、Facebook这样的社交平台相比呢？ 亚马逊有自己的优势！诚然，它并不能像谷歌那样知道消费者对什么感兴趣，也不像Facebook那样可以知道消费者到底是怎样的人，但是它却可以知道消费者想买什么——对于营销而言，这个信息要远比其他的信息更为重要。通过电商平台上巨大的交易量，亚马逊可以对每一位消费者的偏好状况进行精准的画像，依靠这些信息和数据，它就可以对消费者进行精准的广告投放。 事实证明，基于电商平台获取的数据可以帮助商家大幅提升广告的转化率。尽管亚马逊投放的广告可能不如谷歌、Facebook所投放的广告那样被更多的人看到，但一旦它们被看到，转化为实际购买的概率就要大得多。这意味着，商家通过亚马逊投放广告的效率会更高、经济利润会更大，因为这个原因，它们愿意付给亚马逊的广告费当然也就更高。 依托这种更为精准的广告，亚马逊很快在强敌环伺的广告业中杀出一条血路。根据最新的数据统计，2017年亚马逊的广告收入高达46.53亿美元，已在美国的在线广告商中排名第五。而从增长趋势上看，亚马逊很有可能在2020年之前超过微软，跻身在线广告三强。 只有消费者的行为能够为用户画像，使用用户画像可以帮助广告业务投放。 对于平台企业而言，最可怕的是熊彼特式的技术创新。目前，大多数在线平台都是建立在个人电脑，或者手机之上的。对于这些平台而言，即使现在拥有较强的市场力量，但如果技术革命导致交互终端发生了变化，那么所有的优势都将不复存在。 亚马逊当然注意到了这个问题，因此在继续深耕电商、云计算、广告等传统业务的同时，它也将不少精力投入到了新的交互终端的开发上。 2014年，亚马逊推出了一款新产品——智能音箱Echo。本质上，Echo是一个内置智能家居连接标准的音箱，同时搭载基于AI的语音助手Alexa。它可以用来听歌、可以实现语音命令，包括购物、智能家居控制等等。在刚刚上市时，几乎没有人看好Echo，不少评论家甚至认为它只不过是亚马逊搞的一个噱头而已。随着时间的推移，人们才慢慢觉出了亚马逊的高明：它做的哪里是一个小玩具，它要做的是一个新的交互终端！ 随着物联网、人工智能技术的发展，人们正在进入一个“万物互联”的新时代。在这个时代，一个沟通人与物，实现人对物的便捷控制的终端必不可少。而随着语音识别技术的发展，智能音箱似乎是一个十分可行的选项。正是看准了这一机会，亚马逊才率先投入了智能音箱的研发和生产。同时，亚马逊还以智能音箱为平台，积极培养围绕它的生态，鼓励第三方技术团队为智能音箱提供应用软件，说服设备制造商让智能音箱实现接入。这样，一个建筑在智能音箱之上的全新的平台生态系统就发展了起来。 尽管微软、谷歌等企业也很快进入了智能音箱市场，但此时亚马逊已经占尽了先手。数据显示，到2017年，亚马逊的智能音箱设备已经售出3000余万套。据此推算，它已经覆盖了全美国40%的家庭。 亚马逊的 Kindle、Kindle Fire 和 Echo 里，目前只有 Kindle 作为一款产品活了下来。这三款产品一直都被认为代表了特定场景的消费品，亚马逊虽然看到了这个机会，但未必抓住了这个机会。 通过对亚马逊发展史的回顾，我们可以看到在二十多年的发展历程中，平台化一直是助力亚马逊成长的重要力量：最初依赖平台化的社区积累用户，保证在线图书销售业务实现了稳步成长。随后又对业务进行平台化改造，允许第三方商家接入，从而迅速实现了商品品类的丰富，实现了“万有商店”的理想。在电商领域确立地位之后，又通过在电商领域获得的资金、数据等优势进入新的领域，将单一的平台逐步改造成了嵌套平台。面对技术变革可能带来的颠覆，还主动寻找新的平台终端、在新终端上营建新的平台生态系统……这一系列操作，可谓环环相扣，在每一环中都借力打力，充分利用了现有优势、彰显了平台思维。 在宣传上，亚马逊表示自己的业务是没有边界的。但“没有边界”并不等于“没有章法”。事实上，在整个亚马逊的成长过程中，一直体现着两个重要的原则：第一，重要的业务一定是从原有的业务中拆分、独立出去的；第二，新旧业务之间一定具有很好的互补性，可以实现良性的互动循环，形成良好的闭环。由于秉承了这两条原则，亚马逊的扩张一直都要比其他的企业来得更稳，各项业务之间的协调也表现得更好。 从业务互补的角度来讲，腾讯比阿里巴巴更有优势。 要理解这一点，我们不妨将亚马逊和阿里巴巴进行一下比较。作为优秀的电商企业，阿里巴巴一直被视为亚马逊的有力竞争者和重要参照对象。相比于亚马逊，阿里巴巴在很多维度上其实都要显得更加优秀，例如，阿里巴巴拥有更多的活跃用户、更稳定的利润流，在业务开拓上也比亚马逊走得更远。事实上，这也成为人们看好阿里巴巴的原因，在去年的这个时候阿里巴巴的市值还曾一度超越了亚马逊。 阿里巴巴的市场垄断地位更强。 但是如果我们比较一下亚马逊和阿里巴巴在各个业务之间的协同状况，就会发现亚马逊的优势。尽管亚马逊是以电商起家，但是现在已经较好地完成了从单一平台向嵌套平台的转化，各个业务之间的板块发展比较均衡，相互的协同、反馈效应都比较好。而反观阿里巴巴，其业务拓展的步伐相对来说比较激进，很多新业务和原有业务之间的跨越比较大，和原有业务之间的协同相对较弱，从整个公司层面看，电商业务依然是整个阿里巴巴业务的最重要核心。在这种情况下，尽管阿里巴巴能在利润上跑赢亚马逊，但却很难在人们的预期上赢过亚马逊，因此估值上和它存在不小的差距也就并不奇怪了。 方正证券研报-复盘亚马逊从优秀到卓越的24年复盘亚马逊从优秀到卓越的24年"},{"title":"常见架构推导法","date":"2022-01-19T16:42:48.000Z","url":"/2022/01/20/%E5%B8%B8%E8%A7%81%E6%9E%B6%E6%9E%84%E6%8E%A8%E5%AF%BC%E6%B3%95/","tags":["系统架构"],"content":"架构演进之路，路漫漫其修远兮架构关乎不变的顶层设计抽象。架构关乎组件（元素）、交互（连接器）、功能（function or feature）、约束（constraint 面向当前、未来-下一场景、下一个规模、下一个地域或国家） 洋葱架构的另一种解读系统是洋葱，看似有边界，但是每次改动总是端到端，过程让⼈人泪流满⾯面。 系统的本质功能与质量量的结合体：功能是核心价值 + 质量实现增值或保值。 系统的复杂性过程与过程数据过程与过程数据.drawio 易变性系统复杂度.drawio 系统复杂度 = 功能的数量 * 功能的过程《人月神话》：本质复杂度(Essential Complexity)和偶然复杂度(Accident Complexity)。 解法分离业务复杂度和系统复杂度。 回归面向对象的本质，重拾抽象思维的价值维护效率曲线.drawio三种编程范型.drawio 领域驱动设计战略设计领域驱动设计-战略设计-一般过程.drawio 需求分析需求分析.xmind 词汇提取知识提取.drawio 领域语⾔定义-合理的上下⽂和领域划分顺序-时间-追溯需求建模.drawio合理的上下文和领域划分.drawio 战术设计战术设计.drawio 分层结构与三模型分离分层结构与三模型分离.drawio 突破技术复杂度突破技术复杂度.drawio 技术能⼒分离与建设EDA[EDA 架构.drawio](EDA 架构.drawio)![EDA 架构](EDA 架构.png) OEF(Orchestration Execution Framework)服务编配框架参考《编配和编排的定义之争》 EOF.drawio [EOF 实战.drawio](EOF 实战.drawio)![EOF 实战](EOF 实战.png) RESILIENCE – 弹性⼯程平台弹性工程平台.drawio"},{"title":"演进式架构","date":"2022-01-19T11:21:21.000Z","url":"/2022/01/19/%E6%BC%94%E8%BF%9B%E5%BC%8F%E6%9E%B6%E6%9E%84/","tags":["系统架构"],"content":"本书是一本讲战略的书。 Notes： 大部分人都不愿意构建适应度函数。 因为大部分人不愿意承担复杂测试的成本。 "},{"title":"Gergely Orosz 文章翻译-成为一个更好的技术写作者","date":"2022-01-19T05:51:44.000Z","url":"/2022/01/19/Gergely-Orosz-%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91-%E6%88%90%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A5%BD%E7%9A%84%E6%8A%80%E6%9C%AF%E5%86%99%E4%BD%9C%E8%80%85/","tags":["翻译","技术人生"],"content":"原文链接：《Becoming a Better Writer in Tech》"},{"title":"Gergely Orosz 文章翻译-软件架构被高估，简明设计被低估","date":"2022-01-19T05:25:53.000Z","url":"/2022/01/19/Gergely-Orosz-%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91-%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%A2%AB%E9%AB%98%E4%BC%B0%EF%BC%8C%E7%AE%80%E6%98%8E%E8%AE%BE%E8%AE%A1%E8%A2%AB%E4%BD%8E%E4%BC%B0/","tags":["系统架构","翻译"],"content":"原文链接：《Software Architecture is Overrated, Clear and Simple Design is Underrated》"},{"title":"面向职场编程","date":"2022-01-18T12:36:10.000Z","url":"/2022/01/18/%E9%9D%A2%E5%90%91%E8%81%8C%E5%9C%BA%E7%BC%96%E7%A8%8B/","tags":["职场"],"content":"学习的衰减和回归 读了 100 分的书籍。 只能学会 80 分的知识。 做出 60 分的软件。 参加多人协同的项目，最后只能拿到 40 分的产出。 去参加晋升评审的时候，因为讲得不够好，只能得到 20 分的输出效果 提升自己的职场收获的法门有：在 1 上加大努力，让 5 也跟随 1 增长；练习 soft skill，让 4 和 5 的衰减变少。 不闻不若闻之,闻之不若见之,见之不若知之,知之不若行之。没有输入，谈不上学习；没有复制，谈不上学习；没有创造与运用，谈不上学习。学习就好像爬喜马拉雅山，你从北坡上山，要从南坡下山，你体会的山才完整，没有体会过知识的接受者视角和使用者视角的经历的是不完整的。 上士闻道，勤而行之；中士闻道，若存若亡；下士闻道，大笑之。 不笑不足以为道。 故建言有之：明道若昧；进道若退；夷道若颣；上德若谷，大白若辱，广德若不足，建德若偷，质真若渝；大方无隅；大器晚成；大音希声；大象无形。 道隐无名。 夫唯道，善始且善成。 职位的 max 和 min不要让评委进入 min 模式，那样评委很容易成为你的挑战者。不要让评委进入攻击者模式。 引导评委作为个体贡献者（individual contributor）， 会做是一种低阶能力，会定义是一种高阶能力。对组织有高价值的员工，通常有发现问题、解决问题的能力。ppt 里面只体现了拿结果，是经不住深度追问的。发现问题、定目标、排计划、拿结果、适度复盘、总结方法论等种种能力，构成了复合型人才的能力闭环。好的人才，能够在答辩的过程中把评委的思考带入闭环中。 平台的加成效应单量规模、web scale 本身都会给评委加上潜移默化的印象分。然而，在小团队中做技术方案，如果横向看过兄弟团队的技术方案，能够做出适配自身场景的选择，也能得到评委的认可。 IC 的一个主要晋升关卡因为业务发展迅速，L7、P6 这一级别容易成为被重点培养的人才，一般会成为核心系统的主要负责人， 主要关注的是高性能、大容量的可用性、稳定性和资金安全问题。 评委怎么看待 ROI对某些业务进行指标优化，有时候不能盲目追求最优解，roi 最好的解是经验解。你有什么指标能够让评委和你可以产生相同的决策-普适性的逻辑很重要。 ppt 与长短板 面试的呈现效果不完全由 ppt 决定。有的候选人的技术底蕴非常深厚。做技术尝试，看到可能性和把可能性落地，需要创新、担当和勇气。如果真的是做技术做得脚踏实地，不要怕被评委问，也不会被评委问倒。而有些候选人的 ppt 堆砌痕迹明显，临时抱佛脚是经不住评委问的。举一反三、倒背如流的候选人可以折服评委，反之则会给评委留下露怯的印象。所以写在晋升材料上的技术问题，一定要看得准一点。晋升面试可能把长板问出来，也可能把短板问出来。 后台通道讲系统通道的东西ppt 里面涉及大量领域知识、业务流程和横向工作领域，对于大部分候选人而言是个容易减分的选项。后台通道的晋升面试里，高性能、高并发的问题永远都是鲜明的问题，而后台通道的候选人试图讲系统通道的复杂性，很难讲好，不容易引起评委的认同，容易得到“希望加强技术深度”或者“专注某个领域的评语”。回答这类问题的时候，如果候选人不能斩钉截铁地让评委相信，自己能够把控业务的复杂发展，可以尽量淡化评委对这些问题的关注。 业务团队与中间件公司的技术组件的产品化非常好，在关键技术方案里借助公司的技术组件是漂亮和聪明的做法。但有的评委，随便问了几个技术组件的基本使用方法和原理问题，候选人就茫然无语，就造成了大大减分。 从上方入手看问题的认知方法 L8/P7的评委使用的话语体系普遍比候选人要抽象，L6/P6 级别优秀的候选人能够对答如流是因为他们已经有了高阶的能力-体系化思考、结构化表达。这类候选人晋升成功是水到渠成的，他们能够到达 L7/P6，是因为他们接近了 L8/P7 。所以练沟通基本功，是弥补自己思考、做事闭环短板的一种方式。 晋升只是副奖评委的俯视视角很容易看出候选人看不到的问题，这是一种信息差。但评委也不一定就真的能够总是躬身入局，体验到做事的真正价值和能力提升。无论如何，能够为组织拿到结果就是难能可贵的。相比起个人能力的全面发展，晋升结果只是副奖。晋升的流程，对大家而言只是一个“引导大家总结和思考”的大过滤器。因为种种阴差阳错的偏差，过不去这个过滤器也是正常的。大家平时还是要努力，功夫在诗外。我们作为业务团队的工程师，要坚持做顶天（持续向上突破技术难题）立地（扎根业务创造价值）的工程师。 后发优势与与时俱进部分候选人的技术观念非常与时俱进，超出了评委（主要是我）当初处于同一阶段时的水平，可见技术上后发优势效应在人才发展上的体现。这批人才应该好好培养。 晋升的逻辑 晋升 ppt 的结构个人介绍 原工作公司和时间 你所从事的岗位或职责 你所主导的项目 如果可能，呈现一下价值（可选） 组织架构与工作职责 说清楚所属的组织架构 说清楚自己在整个架构中的位置 说清楚自己的上下游和横向关系 说清楚工作职责 业绩贡献 最多只能描述3个项目 每个项目用STAR解读，案例化 描述三个关健问题 我们的业务是什么？ 我们的客户是谁？ 我们为客户提供的价值是什么？ 抽象出方法论 专业贡献方法论沉淀工作心得、方法论或案例沉淀等总结 知识传播分享过的课程：如主题、背景、参与对象及人数、分享次数 人才培养导师制辅导的人数、频次、结果 未来规划自我总结 对自身能力的长短板进行总结 建议针对专业能力模型，进行我能力评价，说明优势以及不足 未来规划 工作方向 个人成长方向 提升能力的计划（待发展项、发展方式等） 注意不要写流水账"},{"title":"贝索斯在普林斯顿大学毕业典礼上的演讲-We are What We Choose","date":"2022-01-18T07:00:16.000Z","url":"/2022/01/18/%E8%B4%9D%E7%B4%A2%E6%96%AF%E5%9C%A8%E6%99%AE%E6%9E%97%E6%96%AF%E9%A1%BF%E5%A4%A7%E5%AD%A6%E6%AF%95%E4%B8%9A%E5%85%B8%E7%A4%BC%E4%B8%8A%E7%9A%84%E6%BC%94%E8%AE%B2-We-are-What-We-Choose/","tags":["人生"],"content":"原文链接：《2010 Baccalaureate Remarks》 小时候，我经常到外公外婆家的德州牧场过暑假，帮忙修理风车、帮牛打疫苗、做些杂活。每天下午，我们还会在一起看电视连续剧。 外公和外婆是我挚爱、崇拜的两位老人。他们都是露营拖车俱乐部的会员，这是一群由Airstream露营车车主组成的车队，车队成员定期结伴在美国、加拿大到处旅游。我们每隔几年参加一趟，直接把路用车挂在外公的车子后面，就上路了。三百多辆拖车连成一线，非常壮观。 其中一次，大约在我10岁时。一路上，我都在车子的后座上随意打滚。外公在开车，外婆坐在他旁边，不停地抽着烟。而我很讨厌香烟的味道。 那个年纪的我，只有有机会就喜欢算来算去，做些简单的加减乘除练习。比如，估算汽油的行驶里程数，或者计算买东西花了多少钱。 抽一口烟，短命两分钟 当年，有个警告抽烟的广告，我已经忘了细节，只记得大意是说，你只要抽一口烟，就会减少几分钟的寿命，好像是两分钟吧。那天，我决定帮外婆算算看：她每天抽多少根烟、每根烟要抽几口等等。 最后，我很满意地算出来一个差不多的数字，把头伸到车子前座，拍了拍外婆的肩膀，很得意地说：“如果抽一口烟会缩短两分钟的寿命，你已经使自己的寿命减少了整整九年。” 直到今天，我都清楚的记得，当年说完这句话，接下来发生的事情，完全都出乎我的意料。我原本以为，自己的聪明会受到称赞：“杰夫，你好聪明，竟然会做这么复杂的计算，算出一年总共有多少分钟，还会用除法的出最终的结果……”，但我的期待并没有发生。 结果是，外婆听到我的话后，马上哭了出来。我呆坐在后座，看着外婆哭泣，不知道怎么办。这时，原本一直安静开车的外公，把车子停在公路旁边。他下了车，走到另一头开车门，等我出来。 我惹上麻烦了吗？外公是个非常有智慧、却不多话的人。他从来没有骂过我，但这次，他会不会开口责备我？会不会叫我回到车上，去跟外婆说对不起？我跟他们之间，从来没有遇到过这种情况，无法判断可能的后果。 就这样，我们站在露营车旁，外公看着我，一段沉默后，他温和地、平心静气地对我说：“杰夫，总有一天你会明白，做一个善良的人，要比做一个聪明的人更加困难。” 善良比聪明更难做到。 今天我要告诉你们的，就是“天赋”和“选择”之间的差别。聪明是一种天赋，而善良是一种选择（Cleverness is a gift, kindness is a choice.）。天赋得来容易，但选择往往很困难。你们如果不够谨慎，就可能被自己的天赋所误导，一旦误导，就可能危害到你所选择的价值观。 你们是一群拥有许多天赋、能力的人。 未来，你们的聪明才智必然会派上用场，因为你们即将迈向一个充满惊奇的世界。 将来，我们会发明出大量制造干净能源的方法；我们会组装出超级迷你的机器，用来穿透细胞，进行修复。就在这个月，科学界传出了了不起的突破：我们创造出了第一个人工合成生命。我也相信，人类终会完全解开脑部的秘密。 凡尔纳（Jules Verne，法国冒险小说家）、马克吐温、伽利略、牛顿……，这些勇于探索和开创的历史人物，一定都渴望，重新诞生在这个人类天赋愈来愈多的时代。 然而，你们将如何运用自己的天赋才智？有朝一日，你们将以什么自豪，你的才智，还是你的选择？ 16年前，我想出了创办亚马逊的主意。那时，我看到互联网的使用量，每年成长2300％，从来没见过任何趋势可以成长得这么快。既然这样，何不成立一家拥有几百万种书籍、在实体世界根本不可能存在的在线书店？这念头深深吸引了我 当年，我刚满三十岁，结婚才一年。我跟太太麦肯西说，想辞掉工作，去搞这个很可能会失败的疯狂创业计划。但万一真的失败，以后要做什么，我还没想到。麦肯西也是普林斯顿毕业的，今天就坐在台下第二排，她给我的回答是，放手去做吧。 从小，我就是个业余发明家，发明过一种用废轮胎做成的自动关门器；一种用雨伞和锡箔拼凑、但是很难用的太阳能锅子；还有一种用来唬弄弟弟妹妹的烤盘警报器。我一直想要当个发明家，麦肯西也鼓励我，追随自己的热情。 当时，我在纽约一家金融公司上班，与一群非常聪明的人共事，还有个非常厉害、让我非常佩服的老板。 当我去跟他说，想要自行创业，成立一家专门在网络卖书的公司时，他把我带到中央公园散步，仔细地听我说明，最后告诉我，“听起来是很好的想法，但是，它会更适合一个还没有找到好工作的人去尝试。”他说服我，多考虑两天再做决定。 人生意义，就在于你的选择。 对我来说，这真是个困难的选择，最终，我决定放手一搏。因为，万一试了以后失败，我并不会后悔；但如果不去试试看，我可能永远都会耿耿于怀。考虑了很久，我最后选择了一条比较不安全的路，去追随我的热情。今天，对于这个选择，我感到非常自豪。 明天，由你们自己主宰的人生，即将开始。你会如何善用自己的天赋？做出哪些选择？ 你会放任自己怠惰，还是追随热情？你会服从教条，还是坚持创新？你会选择安逸人生，还是服务与开创的人生？你会在批评之下屈服，还是坚持信念？你会在犯错的时候蒙混唬骗，还是认错道歉？你会在遇到逆境时放弃，还是坚毅不屈？你会是个嘲讽者，还是个建造者？你会用伤害他人的方法展现聪明，还是宁愿选择善良？ 我要斗胆做个预测。当你们活到八十岁，在某个安静的沉思时刻，回到内心深处，想起自己的人生故事时，最有意义的部份，将会是你所做过的那些选择。人生到头来，我们的选择，决定了我们是什么样的人（We are our choices.）。替你们自己写一篇精彩的人生故事吧。 "},{"title":"如何成为一名优秀的架构师","date":"2022-01-17T07:33:14.000Z","url":"/2022/01/17/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E4%B8%80%E5%90%8D%E4%BC%98%E7%A7%80%E7%9A%84%E6%9E%B6%E6%9E%84%E5%B8%88/","tags":["系统架构"],"content":"成为一个架构师：为了这一刻，你准备了多久？ 架构师的关注点：顶层设计、长期视角。 寿命：数据 &gt; 代码（特指业务逻辑）&gt; 技术（特指业务逻辑的载体） 不是传道受业，而是观点分享。 架构师的几种 profile：有架构能力、以架构为生也是一种架构师。 长期战略：对于任何一家公司，架构设计一定是必要的，而且需要自行解决。架构师的职责是保证组织拥有正确的设计，控制复杂度。 架构师的关键特质： 目标正确：限制条件和目标价值产生理解偏差。是架构师最常见的问题。 能力满足：为组织带来更好的外部适应性。 持续减熵：好架构等于发现、规划和演化。 思考深度和实战经验最重要：这是任何的书本都不能带给我们的。包容、求真、良知、勇气。 有没有德？考虑组织长期利益（基于良知做判断）。有没有勇气？承担责任，决定命运。有没有眼光？是否擅于思考？ 独立、理性、有深度的思考。长期感召力，来自于良知、成功、经验和勇气。 从复盘中学习。 郭东白.pdf"},{"title":"项目管理","date":"2022-01-17T07:14:16.000Z","url":"/2022/01/17/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/","tags":["项目管理"],"content":"比起重要紧急排序法，MoSCow优先级排序法更适用FORM： Must have：必须有。如果不包含，则产品不可行。Must Have的功能，通常就是最小可行产品（MVP）的功能。比如微信的聊天信息、通讯录、朋友圈。 Should have: 应该有。这些功能很重要，但不是必需的。虽然’应该有’的要求与’必须有’一样重要，但它们通常可以用另一种方式来代替，去满足客户要求。 Could have： 可以有。 这些要求是客户期望的，但不是必需的。可以提高用户体验，或提高客户满意度。如果时间充足，资源允许，通常会包括这些功能。但如果交货时间紧张，通常现阶段不会做，会挪到下一阶段做。 Won’t have（nice to have）： 这次不会有。 最不重要，最低回报项目，或在当下是不适合的要求。不会被计划到当前交货计划中。 “不会有”会被要求删除，或重新考虑。 总的来说，”这次不会有”在项目讨论阶段，就会被去除。所有要求看上去都很重要，但是如果交货时间紧，“”可以有”将第一批被删除，”应该有”紧随其后。 在《Why Companies Need to do a Better Job of Prioritizing Features》这篇文章中，作者介绍了三种方法： 按知识价值排序：知道得越多，排序越靠前。 按增收排序：量化潜在的收入增加（百分比，或者用美元）、对比增加收入（超过一年）和创建该功能的成本、对于所有增加收入相关的功能，按照递减的增收排序 按成本节省排序：任何间接节省时间的功能，都会降低成本；砍掉一些功能有时可以节省成本；创建开放的API，允许开发人员创建功能可以节省成本。 如果一切任务都是高优先级,那么就意味着没有优先级。"},{"title":"职场求生攻略","date":"2022-01-13T09:08:50.000Z","url":"/2022/01/13/%E8%81%8C%E5%9C%BA%E6%B1%82%E7%94%9F%E6%94%BB%E7%95%A5/","tags":["职场"],"content":"职场求生攻略.xmind"},{"title":"账务与结算","date":"2022-01-13T08:13:22.000Z","url":"/2022/01/13/%E8%B4%A6%E5%8A%A1%E4%B8%8E%E7%BB%93%E7%AE%97/","tags":["金融"],"content":"对账相关名词汇总.xmind如何设计一个对账平台.xmind"},{"title":"Redis 笔记之：内存调优","date":"2022-01-13T06:24:12.000Z","url":"/2022/01/13/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%EF%BC%9A%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98/","tags":["Redis"],"content":"Redis 的 memory infoRedis 的内存使用状况可以使用info memory来获取。 需要重点关注的值是 used_memory_rss（用于存储消耗的物理内存），used_memory（用于存储消耗的内存= 物理内存 + 硬盘），以及他们的比值mem_fragmentation_ratio（used_memory_rss/used_memory）。 used_memory_rss或者used_memory很高时，意味着当前的 Redis 实例正在蚕食系统中的内存/硬盘资源。 当这个mem_fragmentation_ratio大于 1 的时候，意味着用于存储消耗的物理内存超过了 Redis 自己掌控的内存值，也就意味着当前有些未能回收的内存泄漏或者碎片。 当这个mem_fragmentation_ratio小于 1 的时候，这意味着有一部分用于存储的内存，实际上是在使用虚拟内存中的 swap 空间，此时 Redis 的性能会非常差。 Redis 的内存轮廓memory_used = 进程自身消耗的内存 + 存储对象的内存（大头） + buffer 内存 memory_used_rss - memory_used = 内存碎片 每次 Redis 构造 k-v 的时候，总好创建 key 对象和 value 对象，内存消耗 = sizeof(key) + sizeof(value)。特别地，bitmap 和 hyperloglog 是由字符串实现的，GEO 是由 zset 实现的。"},{"title":"保险资料归集","date":"2022-01-13T05:59:50.000Z","url":"/2022/01/13/%E4%BF%9D%E9%99%A9%E8%B5%84%E6%96%99%E5%BD%92%E9%9B%86/","tags":["金融","保险"],"content":"保险类目保险类目.xmind 保司业务直保公司.xmind 基础数据模型搭售类基础数据模型 互助类保险相关互助保险流程.xmind"},{"title":"Java中的条件编译","date":"2022-01-12T10:10:55.000Z","url":"/2022/01/12/Java%E4%B8%AD%E7%9A%84%E6%9D%A1%E4%BB%B6%E7%BC%96%E8%AF%91/","tags":["Java"],"content":"Java中的条件编译"},{"title":"《战争论》","date":"2022-01-12T09:44:40.000Z","url":"/2022/01/12/%E3%80%8A%E6%88%98%E4%BA%89%E8%AE%BA%E3%80%8B/","tags":["历史"],"content":"“数量上的优势不论在战术上还是战略上都是最普遍的致胜因素。 战略上最重要而又最简单的准则是集中兵力。 人们必须承认，数量上的优势是决定一次战斗结果的最重要的因素，只不过这种优势必须足以抵消其他同时起作用的条件。从这里得出一个直接的结论:必须在决定性的地点把尽可能多的军队投入战斗。 在一般条件下进行的大小战斗中，不论其他方面的条件如何不利，只要有显著的数量上的优势，而且无需超过一倍，就足以取得胜利了。 如果我们不抱偏见地研究现代战史，那就必须承认，数量上的优势越来越起着决定性的作用。因此，在决定性的战斗中尽可能多地集中兵力这个原则，在现在必须提到过去更高的地位。 数量上的优势应该看作是基本原则，不论在什么地方都是应该首先和尽量争取的。 一切用于某一战略目的的现有兵力应该同时使用，而且越是把一切兵力集中用于一切行动和一个时刻就越好。” 《孙子-谋攻篇》：故用兵之法，十则围之，五则攻之，倍则分之，敌则能战之，少则能逃之，不若则能避之。"},{"title":"清分知识汇总","date":"2022-01-12T08:11:37.000Z","url":"/2022/01/12/%E6%B8%85%E5%88%86%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/","tags":["金融"],"content":"结算账务基础知识.xmind 本文来自于： 《中国央行支付清算系统概述（上）》 《清分、结算、清算、对账》 《银联清算业务基础知识介绍 VIP》 我国清结算架构 我国银行的（倒置）清结算架构图： 清结算属于底层架构，清算是发生在银行之间的。 在整个体系里，第三方支付公司扮演的角色是收单机构，银行提供资金服务能力。 两个例子从以上示意图中可知，参与支付清结算的市场主体有消费者、商户、商业银行、中国人民银行、收单机构（第三方支付公司）。上面介绍的内容相对比较抽象，我们先用现实生活中一个消费场景来分析下支付活动到底发生了什么。 比如，消费者A在沃尔玛买了300元的东西，A持招商银行借记卡在建设银行铺设的线下POS机上进行付款，则整个过程分为支付、清算、结算三步骤。 A在建行POS机上刷卡时，建行POS会判断下发卡行（为招行），并询问招行A所持卡内余额是否大于300元，如果大于，则招行会告诉建行可以消费，此时A需要输入支付pw，建行将支付信息传送至招行，招行会实时借记A300元，并告知建行POS扣款成功，此时支付完成，消费者得到商品，债权债务关系变更为招行与建行之间的债权债务关系。 此时招行欠建行300元，建行会向招行索要300元，一般此过程通过中国现代化支付系统完成。这个过程叫清算，其中招行与建行债权债务关系清偿完毕，变更为建行与商户之间的债券债务关系 最后，建行扣除相关手续费并将款项结算给沃尔玛。这个过程叫做结算，建行与商户间债权债务关系清偿完毕。 我们会发现，其实该交易过程商品和资金转移并不是同步完成的，也即并不是“一手交钱、一手交货”，且资金的转移也并不是立即完成的，中间首先经由支付信息传递、招行与建行之间、建行与沃尔玛之间债务记账及清分，然后才有资金的清算和结算。其中支付信息传递、记账清分即为信息流，资金清算和结算是现金流，信息流解决了各银行支付通讯、记账清分的问题，现金流才是最终的资金转移。 为了更加直观的分析其中的问题，我们先回忆下中国古代钱庄、票号的工作机制，以清道光年间晋商创立的“日升昌”票号为例，其支持异地汇款业务。比如客户A在北京日升昌进行汇款，客户交银子（存款）后，日升昌会给客户等面额的汇票，客户凭此汇票在上海日升昌分号兑换一部分银子，分号会在内部账本记录此笔交易（此时仅仅是记账），日后按照约定周期与北京日升昌进行结算（北京日升昌委托镖局将等额的银子押送至上海日升昌分号）并最终清偿相互间债权债务关系。这个只是某一个票号内部跨地业务。 如果全国有很多票号，则社会希望进行票号间通存通兑（即不同票号的客户可以在其他票号办理存、兑相关业务），比如票号A的客户凭票号A提供的汇票在票号B兑换银子，此时票号B需要先在其账簿的票号A会计账户（需要前期和票号A达成一致并开户，甚至为了预防票号A清算时拒付，票号B希望票号A先在此账户上预存一定量银子）上记录此笔账目（信息流）并截留客户汇票，并将银子给到客户，日后票号A需委托镖局将等额的银子押送至票号B（资金流）并将汇票给到票号A，最终完成债务清偿。 银行间清结算方案以上过程其实与现代社会面临的支付问题大体相同。假设现在社会上有300个银行，如果要实现银行间通存通兑，按照以上过程，各银行需要在其他银行都开户（开户主要为了记账，为避免在清算过程中银行拒付，一般都要求其他银行在该账户预存一定量的资金，这也即存款备付金，该账户也叫清算同业头寸户），采用这种方式，相当于每个银行都承担着对其他银行的清分、清算职责，各银行即一个小的清算机构，如果社会交易量较大，会造成银行间清分、对账、资金清算效率极低。而中国刚开始采用的便是以上清结算方式来满足社会支付需求，可能是因为当时中国是计划经济时代，市场活动并不频繁。 清算中心方案如果各银行能在某个银行统一开户并缴纳备付金，并由该银行完成其他各银行间由于支付产生的记账清分过程（信息流），最后对各银行备付金账户进行借&amp;贷记操作，并承诺各银行随时可凭借相关凭证（比如该（清算）银行发行的存款凭证）兑换为货币（黄金，后演变为信用货币），则效率会大大提升，此时该银行变为所有银行和全社会的清算中心。 总行手工联行 + 央行混合清算方案1984年，中国人民银行开始专门行使中央银行职能（之前中国人民银行只是国家层面的银行，并不是典型意义上的中央银行），为社会支付清结算活动负责，并确立了法定存款准备金制度。此时中国“清算-结算”体系尚未形成，央行只是在行使监管相关业务，因为当时中国各银行内部仍然处于数据分散、手工记账的阶段，在这样的条件下比较难建立央行清算中心体系。 为了满足跨行清算需求，当时央行提出商业银行要“自成联行系统，跨行直接通汇，相互发报移卡，及时清算资金”，也即同一家银行总行及各分支机构建立“联行系统”，同一联行内资金结算由联行总行完成。跨行业务可由央行清算，也可由商业银行间自行解决，由于由央行清算效率并没太大提升，故大部分还是由商业银行间自行解决，于是每家银行均办理跨行汇款业务，银行每天自行轧差清分，并将交易信息写成一张张特定公文，加印签后由邮电局在银行间送来送去，这种公文叫做联行信件。我们称这个时代为“全国手工联行”时代，可想而知，当时社会支付体验会非常差，资金在途时间很长，往往在一周以上，非常不利于资金在全社会的流通。 电子联行方案于是，1989年12月6日，央行发布了《关于改革联行清算制度的通知》，并在1990年建成中国人民银行清算中心，专门为社会提供支付清算服务，该清算中心包括NPC（国家清算总中心）和CPC（城市清算处理中心），1991年4月1日，基于金融微信通讯网的应用系统–全国电子联行系统（EIS）开始试运行，EIS是人民银行专门用于处理异地（跨行和行内）资金清算和资金划拨的系统，它连接了商业银行、央行、NPC、CPC，是支撑EIS运行的通讯网络。 假设此时有客户通过上海招行汇款给北京建行，此时跨行汇款业务的流程变更为： 这个时候人民银行成了一个报文的发送网络+资金支付通道。 商业银行（招行）接受客户汇款请求后，向人民银行当地分行（发报行）提交支付指令（转汇清单），支付指令目前可以是纸质凭证、磁介质信息、联机电子报文（此时电子通讯尚未大面积普及）。（信息流） 上海人行（发报行）借记汇出行账户后（可见此时商业银行各地分行仍分散接入央行清算系统），按手报行将支付信息分类、打包，通过CPC经卫星地面小站即时发送至NPC。如果汇出行在上海人行账户余额不足，则该支付指令需排队等待汇出行余额充足再发往NPC。（信息流&amp;资金流） NPC收到转汇电文后，经记账并按人民银行收报支行将支付指令清分后，通过卫星即时发送至北京人行（收报行）。（信息流） 收报行对汇入行账户贷记后，以生成的纸质凭证或电子报文方式通知汇入行。（资金流&amp;信息流） 汇入行做财务处理后（汇入行做结算处理），以来账反方向，向汇出行发送确认的答复信息，此时汇款过程完结。（资金流&amp;信息流） NPC和CPC每日核对无误后，扎平当日电子联行财务，并以存、借反应资金关系。 支付指令很早就出现了。在银行业里支付指令属于信息流。 早期的系统里的“借记汇出行账户”可能是本地资源锁定行为。 中国现代化支付系统方案中国国家金融通讯网（CNFN）是把中国中央银行、各商业银行和其他金融机构有机连接在一起的全国性与专业性的金融计算机网络系统，CNFN的目标是向金融系统用户提供专用的共用数据通信网络，通过文件和报文传输向应用系统提供服务，成为中国现代化支付系统（CNAPS）的可靠网络支撑。 1、CFNF的网络结构 CNFN分为两极网络和三层节点。一级节点为国家处理中心（NPC），二级为城市处理中心（CPC），三级是中国人民银行县支行处理节点（CLB）。CNFN在北京和无锡分设两个国家处理中心（NPC），这两个NPC互为备份，由SCPC（单路单载波）高速卫星线路和地面高速E1线路相连，正常情况下，由主用NPC（北京主站）控制、管理全网，一旦发生灾难，备用NPC（无锡主站）就接管瘫痪的主用NPC的所有业务。 由NPC与600个CPC构成国家级主干网，CPC与CLB构成区域网，国家级主干网以中国人民银行的卫星通信网为主体，以中国金融数据地面通信骨干网和邮电部门的公用数据通信网DDN为辅助信道，各商业银行总行要采用DDN线路与NPC连接。 2、物理通信线路 （1）卫星通信线路 CNFN采用卫星通信网为国家级主干网络。用于两个主站之间、主站和小站之间的数据通信。 卫星网络将利用卫星的Ku波段信道，采用单路单载波技术，以提供高质量、高效率和高速率的通信线路。卫星网络采用集中控制、集中管理的星型结构。 （2）CNFN的地面通信线路 它主要由中国金融数据地面通信骨干网和邮电部门的公用数据通信网(X．25和DDN)组成。CNFN的地面通信线路，一方面作为卫星通信线路备用信道，另一方面主要是构成CNFN的区域网。区域网的物理线路，根据当地通信状况可选用中国金融数据地面通信骨干网、DDN、X．25或PSTN。邮电部门的数字数据网China DDN，正向光纤网发展，可为广大用户提供高质量的数据通道。 CNFN建成后，我国的金融通信体系结构如下： 中国现代化支付系统(China National Advanced Payment System，CNAPS ) ：由中国人民银行建设并运营，是世界银行技术援助贷款项目，主要提供商业银行之间跨行的支付清算服务，是为商业银行之间和商业银行与中国人民银行之间的支付业务提供最终资金清算的系统，是各商业银行电子汇兑系统资金清算的枢纽系统，是连接国内外银行重要的桥梁，也是金融市场的核心支持系统。 并利用现代计算机技术和通信网络自主开发建设的，能够高效、安全处理各银行办理的异地、同城各种支付业务及其资金清算和货币市场交易的资金清算的应用系统。 支付系统（也叫清算系统）：是支付清算服务组织为实现支付指令传送及资金清算结算的一个系统，它由设施、技术和手段共同构成，以实现经济活动中债权债务清偿及资金转移的业务安排。是支撑各种支付工具应用、实现资金清算和完成资金转移的通道。是由于社会在经济活动过程中对债务清偿和资金转移的市场需求而出现、产生、发展而不断完善的。是由一系列计算机、网络通讯、电子设备等硬、软件构成的设施基础，并与制度安排和人员管理配套整合成的一个复杂集合体，来实现和完成整个支付的业务和过程。 以上概念指出支付系统由支付清算服务组织、支付工具、债权债务、资金转移、网络通信及电子设备、软件、制度和人员等关键要素组成。而支付系统本身定位便是支撑各种支付工具应用而产生的，而不同的支付清算服务组织和支撑的支付工具又一起形成了支付清算体系。故为了便于下文的具体展开，我们再对支付工具、支付清算体系做一个定义。 支付工具：是用于资金清算和结算过程中的一种载体，可以是授权传递支付指令并能进入金融机构（银行等）账户执行资金划转的证件，也可以是支付发起者合法签署的可用于清算和结算的金融机构认可的资金凭证。它是加快社会经济活动中资金周转、提高资金使用效率（具体为何需要提高资金使用效率大家可以了解下市场经济和金融运作的机制）的保障。其应具有方便、快捷和安全的特点，并且随着经济的发展，为提高资金使用效率和支付体验，新的支付工具也会不断出现、发展和演变（比如现在第三方支付机构的钱包、预付卡等，便是随着经济发展而演变出来的）。 目前中国主要支付工具清单如下： 而为支撑以上支付工具的使用，也会产生不同的支付系统，不同支付系统间则会逐渐组成支付清算体系。 支付清算体系：是实现和完成社会支付活动，由系列法规制度安排和相应的技术设施支持及相关组织监督管理保障的、并实现社会经济活动所需要的债权债务清偿、资金转移的一个有机整体，支付体系构成如下图所示： 中国现代化支付系统及中国支付体系（第一代）框架图如下： 大额支付系统（HVPS）：是现代化支付系统的重要组成部分，于2005年底在全国建成。系统在国家法定工作日运行，系统运行时间是每日的8：30到17：00，主要用于处理单笔金额在5万元以上跨行普通汇兑或5万元以下的跨行紧急汇兑业务，同时还负责处理国库资金汇划，资金拆借市场、证券买卖、外汇交易等业务的资金清算，现金存取、缴存款、再贷款等中央银行业务的资金清算以及同城票据交换净额清算等等，是大额资金汇划清算的主渠道。大额系统实行对支付指令逐笔发起、全额清算的方式，加快了大额资金汇划到账的速度及社会资金的周转。 小额支付系统（BEPS）：是现代化支付系统的主要组成部分，于2006年6月底在全国建成。系统实行7×24小时不间断运行的模式，主要用于处理单笔5万元以下的普通贷记业务和定期扣划业务。与大额支付系统相比，小额支付系统采取了批量发送业务、定时清算轧差的业务处理方式，故其资金划拨的实时性没有大额支付系统高。小额系统的主要优势在于其支持的支付业务种类繁多，可以处理以下几类与单位和个人相关的业务，且划款费用低廉： 普通贷记业务：如普通汇兑、委托收款（划回）、托收承付等。 定期贷记业务：如代付工资、代付保险金、养老金、定期缴纳社保、信用卡还款等。 定期借记业务：如代收水、电、煤气、电话等公用事业收费和国库批量扣税等。 小额系统的上线运行使得“一卡在手、收付无忧、足不出户、享受服务”的目标得以实现，任何个人只要在银行开立一个银行账户（银行卡或存折），与有关银行签订相关协议后，即可实现所有收款行为，如收取工资、保险金及养老金等，及所有的付款业务，如支付水、电、煤气、电话等公共事业收费而无需在多家银行开设不同账户。 支票影像交换系统（CIS）：是央行开发运行的、运营影像技术将实物支票转换为支票影像信息，通过计算机及网络将接收到的同城及异地支票影像传递至出票人开户银行提示付款的业务处理系统。支票影像交换系统的上线运行突破了支票只能同城使用的界限，实现了支票在全国范围内的通用。CIS于2007年6月底在全国范围内建成运行。 境内外币支付系统（CFXPS）：境内外币支付系统是中国人民银行建设运行的支持多币种运行的全国性银行间外币实时全额结算系统，为我国境内的银行业金融机构和外币清算机构提供外币支付服务，可以支持美元、港币、日元、欧元、澳大利亚元、加元、英镑和瑞士法郎 8个币种的支付与结算，资金结算通过代理结算银行处理。代理结算银行由指定或授权的商业银行担任，资格实行期限管理，3年一届。该系统于2008年4月28日投产，已成为境内商业银行间外币支付的主要渠道。 电子商业汇票系统（ECDS）：是人民银行建设运行的、依托网络和计算机技术，接收、登机、转发电子商业汇票数据电文，提供与电子商业汇票货币给付、资金清算行为相关服务并提供纸质商业汇票登机、查询和商业汇票公开报价服务的综合性业务处理平台。该系统2009你那11月试点运行，2010你那全国推广运行。电子商业汇票系统可以办理商业汇票的出票、承兑、背书、贴现、质押、付款及追索，同时电子商业汇票系统与大小额支付系统连接，可实现电子商业汇票系统贴现等融资交易和提示付款的即时转账结算，同步完成票据融资交易的交割。 与纸质汇票相比，电子商业汇票从出票到追索的各项票据行为均通过电子商业汇票系统以数据电文的形式处理，电子商业汇票在系统中集中登记处理，一张票只会存在一份，且当事人的签章为其电子签名，杜绝了直指商业汇票存在的伪造、变造、克隆、遗失、被盗等风险，具有更高的安全性。同时电子商业汇票的付款期限延长至一年，大大提高了电子商业汇票的流通性。 为满足社会经济活动中电子商业汇票当事人进行票据业务处理的需要，电子商业汇票系统按照7×12小时模式运行，每周运行7天，每天8：00至20：00位系统运行时间。 同城票据交换系统：由中国人民银行分支行组织运行，主要处理以支票为主的支付工具的交换、清分和轧差清算，同城清算系统主要处理同城贷记支付业务和定期借记支付业务的清分和轧差。全国县以上城市建立了同城票据交换所，许多城市还建立了同城清算系统。 银行业金融机构行内业务系统：是其办理内部资金汇划的渠道，是其拓展支付服务市场、直接面向广大企事业单位及个人提供服务、增强市场竞争力的重要设施，也是我国支付清算体系的重要基础。中国银联银行卡跨行支付系统（CUPS）：是专门处理银行卡跨行交易信息转接和交易清算业务，具有借记卡和信用卡、密码方式和签名方式共享系统资源等特点，为境内外人民币银联卡跨行业务的集中、高效处理提供了技术保障，其资金结算通过大额支付系统处理。2005年11月8日中国银联完成了各分公司交换系统的过渡切换工作，实现 了全国银行卡跨行交易的集中处理。 中央债券登记结算公司中央债券综合业务系统（CBGS）：其为全国银行间债券市场提供国债、金融债券、企业债券和其他固定收益证券的登记、托管、交易结算等服务，通过与大额支付系统连接，实现债券交易的 DVP 结算。 中央政权登记结算公司业务系统（CSDC）：其负责交易所（上交和深交）证券市场各类证券交易的证券结算，证券交易对应的资金结算则通过银行业金融机构行内业务系统完成。 城市商业银行银行汇票业务处理系统：处理城市商业银行等中小金融机构的银行汇票资金清算业务，依托大额支付系统实现银行汇票业务的实时清算，面向城市商业银行和农村信用社提供专业化的支付清算服务。农信银资金清算中心业务系统：面向全国农村金融机构，办理实时电子汇兑业务、银行汇票业务的异地资金清算和个人存款账户通存通兑业务的资金清算等业务。 集中代收付中心业务系统：集中代收付中心业务系统是集中办理代收水电煤气费、代发工资、代付养老金、保险等代收代付业务信息的收集、转发等信息处理的业务系统， 集中代收付中心以特许参与者的身份接入小额支付系统，各收付款单位可以通过与代收付中心连接，将其发生的代收付业务经小额支付系统转发给商业银行办理跨行代收代付业务。 第一家集中代收付中心于 2006 年 12 月在西安成立，目前全国已有 15个省（市）依托当地电子结算中心或票据交换所开展集中代收付业务。我们平时工作时企业缴纳五险一金及工资代发等即通过该系统完成相关业务流程。 互联网支付服务组织业务系统：是以互联网为依托袁采用第三方支付方式，实现从消费者、金融机构到商家的在线货币支付、现金流转、资金清算、查询统计等功能的业务系统。从图中可看出，在第一代支付系统的时候，互联网支付服务组织采用的是银行直连的方式实现资金跨行清结算的业务。 而CNAPS（特指大、小额，支票影像交换系统）本身的功能定位包括支持跨行支付清算、支持央行货币政策实时、货币市场资金清算、适度集中管理清算账户、商业银行流动性管理、支付风险防范和控制等，由于篇幅有限，有兴趣的朋友可以详细研究下以上几个功能定位的具体内容和运作机制。 CNAPS的参与者主要分为直接参与者和间接参与者。 直接参与者：中国人民银行的各级机构、在中国人民银行开设资金清算账户的商业银行与非银行金融机构（如银联即以特约身份参与CNAPS）的各级分支机构。 间接参与者：未在人民银行开设资金清算账户，而委托直接参与者代理其进行支付清算业务的单位和个人，简介参与者可以是银行、非银行金融机构、在商业银行或非银行金融机构开设账户的广发银行客户，包括工商企业、政府机关、公共事业单位和个人。 也即在整个支付清算体系内，CNAPS扮演着全国各支付活动参与者资金最终清算的核心、底层系统，其他支付系统通过CNAPS完成跨行的资金清算业务，然后再交由银行行内系统或其他支付系统内部完成相关结算或记账账户的资金结算。可以说CNAPS是支付清算体系的心脏，其他支付清算系统则为毛细血管，最终一起互联形成一个有机整体。 中国现代化支付系统（CNAPS）及支付清算体系（第二代）随着中国现代化支付系统（第一代）的运行以及中国社会、经济的发展，金融改革的继续深入、金融市场日益完善、支付方式不断创新，对中央银行的现代化支付系统提出了许多新的、更高的要求，从当前情况来看，CNAPS一代已经不能完全满足社会支付活动发展的需求，原因如下： 1、不能较好满足银行业金融机构灵活接入的需求 为实现集约化经营和扁平化管理，众多银行业金融机构加快了行内系统数据“大集中”的步伐，提出了多种接入支付系统的新需求。例如有的银行希望通过法人机构一点接入，并通过一个账户进行资金清算；有的银行希望一点接入支付系统，但仍保留多个清算账户进行资金清算，而CNAPS第一代是基于分散接入方式进行设计建设的，故以上需求不能较好满足。 2、流动性风险管理尚待进一步完善 目前CNAPS直接参与者分别在人民银行当地分支行开立清算账户，由于目前ABS（中央银行会计核算系统）尚未实现数据集中，同一银行机构的多个账户数据分散在人民银行341个ABS系统中，这就造成商业银行和央行不能实时监控其自身及商业银行的流动性情况，对商业银行来说，其难以统一安排所有清算账户的流动性，资金使用效率不高，以上情况急需改善。 3、业务功能及服务对象需进一步拓展 CNAPS第一代设计时是基于传统支付业务的处理流程。随着中国互联网及电子商务的发展，网上银行、电话银行等新型电子支付业务在支付活动中占比越来越大。同时非金融支付服务组织已逐步成为支付服务市场的重要参与者，这些组织在业务发展过程中迫切需要央行支付系统的支持，故后续需拓展服务范围以适应社会支付活动的发展。 4、应对突发事件能力需要加强 CNAPS第一代在NPC和CCPC采用了双机热备份和设备冗余的备份策略，但应急备案系统级别较低，系统恢复能力有限，为维护CNAPS这个经济金融活动基础系统的稳定性，急需切实提高系统应对突发事件的处理能力。 2009年底，央行要求清算总中心启动第二代CNAPS的建设工作。 第二代CNAPS的建设总体目标是：立足第一代支付系统的成功经验，引入先进的支付清算管理理念和技术，进一步丰富系统功能，提高清算效率，拓宽服务范围，加强运行监控，完善灾备系统，建设适应新兴电子支付发展的、面向参与者管理需要的、功能更完善、架构更合理、技术更先进、管理更简便，以上海中心建设为起点，以北京中心投产为建成的新一代支付系统。 网上支付跨行清算系统作为第二代CNAPS首先投产的业务系统，于2010年8月上线运行，大额支付系统、小额支付系统于2013年10月升级为第二代。银行以法人为单位以“一点接入、一点清算”模式接入第二代CNAPS，商业银行的各个分支机构均可使用本行统一的清算账户实现资金结算，支付清算效率和银行资金使用效率得以大幅提高，银行流动性状况普遍得到大幅改善，风险控制更加有效。 中国现代化支付系统（第二代）框架图如下： 相较于第一代而言，增加了网上支付跨行清算系统（俗称“超级网银”），以下同时将前面未提到的SAPS、PMIS、CCMS做说明。 清算账户管理系统（SAPS）：是支付系统的核心系统，集中管理清算账户，处理大额支付系统、小额支付系统和网上支付跨行清算系统提交的全额或净额清算业务，并支持中央银行会计核算数据集中系统（ACS）提交的单边业务的资金清算。 网上支付跨行清算系统（IBPS）：支持规定金额起点以下的网上支付、移动支付等新兴电子支付业务的跨行（同行）处理，业务逐笔发送、实时轧差、定时清算，采用实时应答机制，客户进行支付操作时，可实时获知业务最终处理结果。网上支付跨行清算系统支持符合条件的非金融支付服务组织接入，为其业务发展和创新提供公共清算平台。 支付管理信息系统（PMIS）：是支付系统重要的辅助支持系统，是一个多功能模块、统一平台的管理信息系统，主要功能包括行名行号管理、支付业务统计分析、业务监控、业务计费和数据存储等。通过建立面向客户和管理决策层的应用数据仓库及公共信息平台，实现支付业务数据共享，并充分运用数据仓库、数据分析和报表工具，对系统中蕴藏的大量支付清算交易信息进行深度挖掘和加工，为货币政策、反洗钱、金融稳定等提供可靠的信息支持。 公共控制系统（CCMS）：旨在对大额支付系统、小额支付系统、支票影像交换系统、网上支付跨行清算系统以及清算账户管理系统等提供统一服务，提高系统整体业务处理效率。 此时，中国现代化支付系统及体系（第二代）框架图变更为如下： ![中国支付清算体系（第二代）框架图](中国支付清算体系（第二代）框架图 .jpeg) 上图是笔者基于第二代支付系统的变化，并在第一代支付体系框架图的基础上进行了相关系统的细化和合并，并希望尽力用一张图向读者展示清楚其他各支付系统与CNAPS（第二代）内部各系统是如何连接的，其中CNAPS（第二代）省略了PMIS和CCMS系统非业务部分。 其中最大的变化如下： “超级网银”成为CNAPS新的组成部分。 电子商业汇票系统和境内外币支付系统与CNAPS（第二代）的大额支付系统相连，实现外汇市场人民币与外币交易的PVP结算以及电子商业汇票系统参与者之间汇票业务资金清算。 中央银行会计核算数据集中系统（ACS）和中央银行国库核算数据集中系统（TCBS）建成并与CNAPS（第二代）相连，实现央行会计核算数据集中需求以及国库集中支付业务。 中央债券综合业务系统与CNAPS（第二代）一点接入，处理央行公开市场操作业务，债券市场交易、发行、兑付资金清算业务，债券质押融资业务，为央行行使货币政策提供有力支撑。 增加了非银行支付机构网络支付清算平台与CNAPS（第二代）的连接，也即俗称的“网联平台”对于CNAPS的接入，此后，互联网第三方支付公司由网联平台统一与银行实现连接，并通过CNAPS大额支付系统完成跨行清算业务。大家可以看到从CNAPS角度来看，银联和网联平台属性和功能基本一致，只是按照目前的情况，网联平台负责线上支付收单业务，银联则负责线下支付收单业务。 下图是笔者在中国人民银行相关资料中找到的关于以上支付系统2013年支付交易笔数和交易额相关数据，帮助读者有个大致的业务数据认知。 而从接入方式来看，第二代支付系统上线后，其他支付系统即可选择单点接入集中清算，也可选择分散接入集中清算，也可继续维持第一代时的多点接入分散清算的模式，故中国支付清算体系对应的系统接入关系变为如下图所示： 其中黑底的为CNAPS网络，棕色部分为第二代CNAPS新的接入模式。 另外，第二代CNAPS比较大的改进是提出了“报文传输与业务处理分离”的理念，通过构建一个高可用的支付报文传输平台（PMTS）实现参与者与支付系统之间安全可靠的支付业务报文传递，报文设计时参照国际标准，大大提升了其自身的接入可拓展性。而第一代CNAPS设计建设时并没有考虑报文和业务分离的需求，当时大小额支付系统等每一个业务系统都建设了一套相对独立的从参与者到CCPC再到NPC的应用逻辑，相对来说系统耦合较强，且重复建设高，不具有较好的可拓展性。 有了PMTS之后，其他各支付系统均统一通过PMTS前置机及PMTS与CNAPS（第二代）相连，不仅大大降低了参与者对接CNAPS的难度及后续维护成本，同时使得CNAPS满足未来其他需求有更好的适应性。此时，CNAPS（第二代）和其他支付系统通过PMTS互联互通示意图如下： 图中有些眼尖的同学会看到有个人民币跨境支付系统（CIPS），如上图所示，CIPS与CNAPS之间未来会是平行&amp;互联的关系，并且两者分工明确，CNAPS负责境内人民币支付业务，CIPS则负责跨境人民币支付。 在此对CIPS做简单介绍，笔者对跨境业务及SWIFT不太熟悉，如有读者对相关业务熟悉，欢迎留言讨论。 人民币跨境支付系统（CIPS）2012年4月12日，中国人民银行有关负责人表示，央行决定组织开发独立的人民币跨境支付系统（(Cross-border Interbank PaymentSystem)），进一步整合现有人民币跨境支付结算渠道和资源，提高跨境清算效率，满足各主要时区的人民币业务发展需要，提高交易的安全性，构建公平的市场竞争环境。2015年10月8日CIPS第一期正式启用，2018年5月2日，CIPS二期全面投产。 该系统的建立主要是随着中国国际贸易规模的增大以及跨境人民币业务不断增长，人民币已成为中国第二大跨境支付货币和全球第四大支付货币，人民币跨境支付结算需求迅速增长，为满足市场相关支付需求，同时配合中国丝绸之路战略，并实践人民币国际化而提出并建立的，至于网上有些朋友说CIPS是中国金融基础设施国之重器，后面可以直接与SWIFT对抗，不亚于中国在导航领域的北斗、航空航天领域的发动机等说辞，如有同学感兴趣，可浏览相关知识做拓展了解，笔者在此不展开说明。 到此，通过两篇文章共两万多字，框架性的梳理和讲解了支付活动、支付清结算概念、中国支付系统和体系演变过程（全国手工联行、全国电子联行、CNAPS第一代、CNAPS第二代、CIPS等），并将17年出的网联平台纳入中国支付体系整体给读者较为直观和系统性的认识。 后续笔者会着重开始讲解大家在日常生活中接触比较多的银联（CUPS）及其衍生的收单行业相关知识，希望能帮助读者基本搞清楚银联支付收单业务和市场的支付资金清结算流程以及收单产业构造。 "},{"title":"财务知识","date":"2022-01-12T05:52:54.000Z","url":"/2022/01/12/%E8%B4%A2%E5%8A%A1%E7%9F%A5%E8%AF%86/","tags":["金融"],"content":"会计科目会计科目.xmind 财务报表三大财务报表.xmind"},{"title":"《架构师修炼之道》","date":"2022-01-12T03:47:20.000Z","url":"/2022/01/12/%E3%80%8A%E6%9E%B6%E6%9E%84%E5%B8%88%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93%E3%80%8B/","tags":["系统架构"],"content":"刻戒于碑，铸法于鼎 软件特性、质量属性。 将两个元素以某种方式连接在一起，就形成了结构。 module component-connector 就是我们经常讲的系统交叉点 allocation 就涉及到我们的部署设计 每一本书都会讲到利益相关者，也就是 stakeholder。 主动撰写设计决策，承担设计职责。 软件之所以叫软件，是因为它灵活而易于变动。架构是软件里硬的部分，为变动提供了章法，也制造了约束-否则我们不用经常“对架构产生冲击”，而需要打破架构。 设计原则： 以人为本（能落地能产生价值的架构才是真的好架构） 推迟决策 善于借鉴 化虚为实。 推迟决策不是推迟大的设计决策，要推迟的是细枝末节的决策。不要陷入舍本逐末的优化中，导致项目无法受控。 忽视前人的设计，是最低效的设计方法之一。所以寻找架构风格是很重要的。 设计思维模式： 理解：换位思考 探索：尝试各种结构组合，找到最能提升目标质量属性的那种组合。-大多数情况下，是我们手头最简单最现成的解决方案。 展示：用图、表、模型、原型来展示，探讨。原型应该尽量具有交互性，可以直接和客户评审。 评估：评估到底我们要做什么东西 软件只有发布状态，没有完成状态。 如何关注用户价值，先理清用户的关系。 加上约束，可以简化问题。过多的约束，会增加设计难度。 一定要区分好，外部约束和自己做的决策。外部的约束不可变动，不能讨价还价。自己的设计决策有时候反而会让自己束手束脚。识别出潜在的软、硬的约束，是一个很重要的软能力。 所有的架构都是设计，所以设计的下限是要保住的；不是所有的设计都是架构，所以不要盲目地随时随地地进行高成本的设计。"},{"title":"《计算机简史》","date":"2022-01-12T03:34:02.000Z","url":"/2022/01/12/%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%AE%80%E5%8F%B2%E3%80%8B/","tags":["历史"],"content":"解决问题的过程，是探索的过程。 19 世纪 30 年代，英国工程师巴贝奇发明了差分机，用来计算数学用表。巴贝奇还构思了分析机，意图使用一般性方法，用来解决通用计算问题。巴贝奇自己还是英国科学学会会员，以及一位经济学家。巴贝奇使用齿轮和条杆来制造分析机，受到时代所限，始终无法落地，没有得到英国政府资助，没有继续下去。后来有长达一百年的时间里，人们转而使用模拟的方式解决问题。 图灵对计算机的贡献是制造了通用机。 冯诺依曼的贡献是制造了“一般性方法”，即编程。 实时计算的发展历程是：美军飞行员的训练需求诞生了旋风计算机，而后又产生了 SAGE 系统。这两个项目为美国的商用计算机行业，培养了大量程序员。而且使 IBM 认识到商用计算机的商业潜力，斥巨资开发了 SABRE 系统。 IBM 是靠生产办公机器起家的。 computer 最早是指计算员。计算机的发展序列为：哈佛马克一号，ENIAC 和 EDVAC、EDSAC（威尔克斯）、UNIVAC。个人计算机首先是阿塔利的“牵牛星 8800”，然后是苹果，苹果 2，丽萨（太贵而卖不出去），麦金塔（平价版 lisa）。 第一个革命性的通用操作系统是 System/360。因为 IBM 的行业优势，所以戏称为 IBM 和七个小矮人。 阿兰凯发明了笔记本电脑（dynabook），萨瑟兰主持了帕洛阿尔托的 gui 设计工作。乔布斯通过餐馆帕洛阿尔托的 gui，领悟到 gui 是电子消费品的杀手级特性，于是开始努力开发图形界面操作系统。微软最早通过购买 CP/M 的系统获得了 IBM 的合同，借助 IBM 的行业优势奠定了在兼容机市场的行业地位，又借助承保苹果的操作系统的合同，获得了开发 gui 操作系统的技术，最后于 80 年代发布了自己的 windows 操作系统。"},{"title":"《重新定义团队-谷歌如何工作》","date":"2022-01-12T03:25:57.000Z","url":"/2022/01/12/%E3%80%8A%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E5%9B%A2%E9%98%9F-%E8%B0%B7%E6%AD%8C%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E3%80%8B/","tags":["管理"],"content":"自序领导者总是嘴上以人为本，但对待员工却弃之如敝履。 人的一生用在工作的时间是最多的。工作的经历-甚至为最好的一些雇主工作-令人动力尽失、丢掉本性，这样是不对的。 杰克韦尔奇和人力资源主管比尔康纳迪共同建立了广受赞誉的员工管理体系，严格按照绩效表现对员工进行排名，每 12 个月至 18 个月重新调配拔尖人才的工作岗位，同时还在纽约的克罗顿维尔建立了全球培训中心。 20-70-10 的绩效排名体系。最开头的人才会得到赞扬，最末位的人才要遭到解雇。 韦尔奇最著名的是他的六西格玛（six-sigma）。 谷歌的企业文化不提倡穿西装工作。 前言 为什么谷歌的原则也对你适用“10 亿小时之前，现代智人出现。 10 亿分钟之前，基督教诞生。 10 亿秒之前，IBM 个人电脑发布。 10 亿次谷歌搜索之前……是今天早上” “用心才能让企业成功，心怀这种愿景，不让客户离开时不开心，我们也依此做决定，善待员工，不计成本。” 命令导向型、低自由度的管理方式非常普遍，因为这种管理方式下容易产生效益，需要耗费的精力较少，而且绝大多数经理都畏惧其他的管理方式。管理一个按指令办事的团队很容易。但是要想他们解释做某件事的原因呢？然后讨论做这件事是否正确？如果他们不同意我的观点呢？如果我的团队不想做我安排他们做的事情呢？ 打造一个让人自由工作的场所可以吸引最优秀的人才。但打造这样一个场所非常难，因为从管理的核心角度来讲，权力的动态方向恰与自由背道而驰。员工要依靠管理者，希望取悦他们。然而注重取悦管理者意味着与其进行开诚布公的探讨是有风险的。如果你不取悦他，内心就可能惶恐不安或焦躁愤恨。同时他还要保证你实现某些工作成果。身陷这种戈尔迪之结般纷杂的杂事和情绪中，没有人能够表现出最好的工作状态。 谷歌的做法是割开这个结： 雇用谁 解雇谁 如何评估一个人的表现 给某个人加薪多少，给多少分红或配多少股权 选谁来拿最佳管理奖 给谁升职 代码何时才算合格，可以纳入到公司的软件代码库中 一种产品的最终设计以及何时投放 要在组织里实行公平最大化，要让管理者放弃权力，要让群体核定工作成果。 “管理者服务团队”。让团队成为更好的团队。 给员工冲分授权，让员工的产出最大化，可以提升团队的业绩。 “自由是免费的。我们每个人都应该做到。”机器会完成工作；主人翁会竭尽所能帮助企业和团队获得成功。 第一章 成为一名创始人每一段传奇，都有一个起源故事。 原型：收到召唤去冒险，经历了各种试炼，变得更明智，最后云淡风轻、心平气和。 “在工作中竭尽所能的工人是最难得的。无法从日间工作中得到一定满足感的人，就失去了薪酬中最好的一部分。” 好时建立“公司镇”。 不受信任的领导者，会被质疑判断力。 建立杰出的团队或机构的起点是有一位创始人。任何人都有能力成为一名创始人，也可以成为所在的团队的文化创造者。阅读本书的人，都站在创始人的角度看待自己。 把自己当做创始人。 像创始人一样行动。 第二章 文化可以把战略当早餐一样吃掉使命不是一种商业目标，而是一种道德目标。 我们永远也无法达成的使命，可以激励我们不断向前，创新和探索。 地球上最有才华的人才需要能够激励人心的抱负。领导者锁面临的挑战就是要创造出这样一个目标。 目标可以提高幸福感，也可以提高生产效率。 我们都希望自己的工作有意义。 应该假设所有的信息都可以和团队分享，而不能假设任何信息都不能分享。 dogfooding。 抛开自我认知的阻碍，理解真相。 我们人人都想掌控自身的命运。 让员工毫无保留地表达观点，对于决策的水平、团队的表现、组织的表现都有积极的影响。 经受考验的时候，文化最重要。 己所欲，施于人。 给人以稍多于你舒适区的信任、自由和自主权。如果你没有感到紧张，那是因为你给的还不够。 第三章 只聘用比你优秀的人多数人并不擅长面试。 面试官会倾向于招聘和自己相像的人，多数面试技巧是没有任何意义的。 不要自认为是出众的面试官，不要认为所选的候选人是在平均水平之上的。招聘的员工基本都是平均水平。 大部分的培训无法给员工的表现和行为带来持续性的改变。 很难把平均水平的员工培养成明星员工。 “麦肯锡的全面衰败及其追随者安然的崩塌在于，他们认为组织的智慧仅仅是员工智力的简单表现。他们相信明新员工，因为他们不相信体系。” 资源有限的情况下，将人力资源费用首先投入到招聘上。 慢慢来，聘用最优秀的人才，只聘用在某些特定方面更优秀的人，不要让经理肚子做团队人员聘用决策。 第四章 搜寻最优人才 要详细说明寻找人才的标准，依此找到最优秀的被推荐人 使招聘成为美国人的工作 不要害怕尝试风控的事情，以此引起最优秀人才的注意 第五章 不要相信你的直觉“你不会有第二次机会给人留下第一印象”。 面试官的头五分钟会对候选人产生印象，后续的面试流程只是给面试官以时间证明他们的第一印象。 问题在于，根据头 10 秒钟的印象做出的预测是没有任何意义的。这 10 秒钟的预测会使我们在面试的流程里证实我们的印象，而不是真正地去评估他们。这种现象称作证实偏见（Confirmation Bias）。 不能太自信。 预测某人在工作中表现最好的方法是样例测试 + 结构化测试。结构化测试可以分为行为测试和情境测试。 谷歌的面试流程实际上非常复杂，细节日后再补充（如果还有机会的话）。实际上要使用这样的流程，需要能够支撑这样的流程的人才才可以。 设定高质量标准 寻找自己的应聘者 客观评估应聘者 给应聘者一个加入的理由 第六章 打造最幸福的公司警惕权力滥用带来的危害。 我们的文化经常创造出等级制度，促使我们关注局部利益。 经理都倾向于累积和运用权力。 员工都倾向于服从命令。 人们对工作场所是有所期待的，可以自由地创造、建造和成长。 提倡不受头衔权威影响的领导艺术：激发领导力，激励追随者，促成同事之间做出决定。 个人责任，亲身践行。 经理需要有判断力。现代的经理要从负责提供直觉的人转变为搜寻真相的引导者，每个决定都依据最有用的事实做出。 消除地位象征 依靠数据（或者其他客观事实）而不是根据经理的想法做决定 探寻方法，让员工塑造自己的工作和公司 高期待 第七章 为什么每个人都讨厌绩效管理今天的绩效管理体系最大的问题在于它们替代了切实管理员工的关键行动。大多数组织的绩效管理都成为墨守成规的官僚流程，不是为了改善绩效，而是为了管理而管理。 关注过程而不是目的，会让人能够玩弄体系。 设定一个疯狂的目标，最后没有完成，你也至少能够实现一些了不起的成就。 每个人的 OKR 都应该是公开的。 一个包含校准的考评流程能够有效地消除坏的行为和偏见。 有几件事情做得好，有几件事情做得不好。 正确地设定目标 收集同事的反馈意见 通过校准流程确定考评结果 把奖励分配谈话与员工发展谈话分开 第八章 管理团队的两端-最优员工和最差员工正态分布又名高斯分布。任何符合高斯分布的事项都有一个平均数和标准偏差。 68% 的数据分布在均值的两侧，距离为一个标准差，95% 的人在平均值的两个标准差的范围内。组织上大多数人的表现符合幂律分布，少数精英员工做出主要贡献。 氧气项目，得到好的经理的特征： 职业决策更加公证。 个人的职业目标能够达成。 工作高效，决策迅速。 团队成员之间没有等级制度。 适当地参与到决策制定过程中。 自由地平衡工作和私人生活。 助力有难处的员工 将最优秀的人放在显微镜下观察 利用调查和检查清单寻找真相，推动员工学习 与人分享员工对你的反馈意见，以身作则采取行动解决问题，身先示范。 第九章打造学习型组织10 年学校生活学习的知识比 10 年公司培训项目学习的知识要多。 刻意练习：有意重复类似的小任务，即时反馈、修正和实验。 从内部选出培训授课人员。组织内的成员就是局部最大值。 向正在执行某项工作的人学习是最简单的。 很多东西都能自动化，但人际关系不行。 将技能分成小的部分，提供即时的、具有针对性的反馈意见，刻意提高你所在的组织或团队的学习效率。 进行刻意练习 请最优秀的员工教学 只在一家证明能够改变员工行为的课程上投入 第十章 不公平薪酬努力工作，但不炫耀。 你最优秀的员工比你想象中更有优秀，值得你付出更高的薪酬。 优秀的员工的理智做法有时候是辞职。 薪酬与贡献相匹配才算得上公平。 个人表现符合幂律分布。 低级别的员工如果创造出大量的价值，报酬会比高级别的员工高。 控制情感，做到不公平薪酬。 薪酬差异化要明显，应符合绩效表现的幂律分布。 以成就为荣，不以报酬为荣。 创造易于传播爱的环境。 精心筹划却遭受失败的要奖励。 第十一章 世界上最好的东西是免费的没有公司，人类仍会存在。 提高职业和个人生活的效率。 使员工的生活容易一些 想办法说可以 生命中的不幸罕有发生……一旦员工遭遇不幸，要伸出援手 第十二章 助推阿波罗神谕：认识你自己。 人类有两套思维系统，其中一套慢、有深度、有思索、以数据为导向，而另一套快、依靠本能、属于直觉思维系统。 “应然-实然”，休谟的断头台。 区分“实是”和“应是”。 进行许多小的实验。 助推，不要硬推。 第十三章 谷歌的教训《麦肯锡之我见》：如果有问题，应该大声说出来。 诊视怪人，有的放矢。 承认错误 坦诚面对错误 不管什么坏掉了，修好 找出错误中的寓意，加以传播。 第十四章 从明天起你可以做些什么如果你相信人性本善，那么你可以得到自由。 世界合并，可以消除分歧。 管理是改变人性，还是改变工作的性质。 赋予工作意义 相信员工 只聘用比你更优秀的人 不要将职业发展和管理绩效混为一谈（要有两个谈话） 关注团队的两端-最优员工和最差员工 既要节俭又要慷慨 不公平薪酬 助推 管理日益提升的期望 享受！然后回到第一条，再来一遍。 "},{"title":"面向失败编程","date":"2022-01-10T12:00:48.000Z","url":"/2022/01/10/%E9%9D%A2%E5%90%91%E5%A4%B1%E8%B4%A5%E7%BC%96%E7%A8%8B/","tags":["系统架构"],"content":"本文是《面向不确定性编程》的续篇，探讨与失败有关的编程问题。 前言我们的系统是一个乱动的螃蟹不可避免的乱动我们的分布式金融系统随时随地可能发生失败（此处的失败专指系统进入了异常状态，因为内外 bug 导致的 failure。我们不专门辨析 error、fault 等其他词汇）： 中间件崩溃 宿主机异常 黑客入侵 单据定价计算错误 营销活动配置错误导致黑产大规模薅羊毛 网络抖动 失败的原因有很多种： 网络并不是可靠的，存在不可预知的闪断、重试和并发引起的竞态条件 同节点之间的通信是存在延迟的 带宽是有上限的 数据由一份冗余成多份后如何保持一致 整个系统的不同部分可能是异构的 我们无法阻止程序员在快速迭代中出错，积累隐藏的错误 黑客总能入侵进入我们的系统中，制造某种程度的破坏 从客观上讲，自从分布式系统诞生以来，网络的基本约束条件自始至终没有发生过本质的变化。逻辑解决方案无法根本改变物理层的局限；从主观上讲，我们也没有一种可以在分析-设计-编码阶段完全消除 bug 的方法。所以我们无法从根本上阻止我们的系统“乱动”，就好像我们无法阻止从菜市场上买回来的螃蟹乱动一样。乱动是螃蟹的天性，也是分布式系统的天性。在分布式系统中，怀疑者、悲观者和偏执狂才能生存。 更多的例子，可以参考别忽视分布式系统这六大“暗流”和分布式系统的事务处理。 何谓质量属性我们的系统是由业务需求驱动而设计出来的。在堆砌业务功能的时候，我们会在系统里面下非常大的功夫，思考如何让功能性需求实现得准确。但我们很少思考： 我们的系统的非功能性需求（即我们的系统中隐含的质量属性（Quality Attribute））有哪些？ 如果我们理解了问题 1，我们应当如何交付质量属性很高的软件？ 对于分布式金融系统而言，质量属性至少应该包括： 如何让我们的系统实现高可用？这个问题基本上等价于 CAP 问题中的 A 问题。 如何让我们的系统实现资金安全？这个问题近似于于 CAP 问题中的 C 问题，实现资金安全离不开对 C 问题的理解，但不等于只需要理解 C。 众所周知，CAP 中的 P 是不可选择、必然存在的，我们可以选择性地调整我们对 P 的分布，在某些场景下寻求 A，在某些场景下寻找 C-我们常见的无状态服务搭配存储的设计，就是在一套 CP 的服务上搭建 AP 的服务。 为何我们要考虑体系化的方案设计复杂的业务系统是一项复杂的工程，因此我们需要运用大量的分析和设计技术（比如 DDD）。这些技术只能帮助我们管理功能性需求的复杂度，我们其实并不十分清楚，如何按部就班地剖析非功能性需求，进而提升我们的质量属性。 因为没有通行的理论指导，进行这种设计的知识，通常来源于资深工程师对某一个领域常年的坎坷摸索。每个工程师都有各自的踩坑经历，这导致这类知识的积累、传递和运用非常地碎片化。在现实的工程世界里，真正有意识和能力进行非功能性需求设计的，往往是高级工程师甚至架构师。除非他们有意识地对领域新手进行指导，否则新手独自产出的系统设计必然充满问题。然而，即使我们有意识地这样做，如果我们不使用按部就班的方法，而使用头脑风暴的方法，结果也往往事倍功半。所以做这种事情是吃力不讨好的事情，在现实中工作中的 ROI 不高，所以在设计技术方案的时候，我们总是有意无意地忽略这些东西。久而久之，程序员经常很乐观，不愿意给自己设置“假设自己会犯错”的约束。 事实上，阻止系统乱动也是个复杂的工程。问题是自一个体系中产生的，也应该被一个体系（有时候是另一个体系）解决。考虑到非功能性需求解决的问题更抽象、更复杂，解决系统失败的解决方案，应该是一个“包容系统的系统”或者“设计之上的设计”。它只会比原来的解决方案更大。当我们构建起一整套解决方案了以后，就好像给一只永远无法控制自己乱动的“大螃蟹”套上了绳子，在架构层面对系统质量施加影响。我们姑且把这套东西称作“风险防控体系”，它与业务系统一起工作的时候就好像“三斤螃蟹两斤绳”-我们在市场上买到的螃蟹总是带有绳子的，奸商卖的螃蟹上绑的绳子还非常重。如果我们最终交付的系统里面，螃蟹（功能性设计）每重一斤，都会配上两斤重的绳子（非功能性设计），我们通常可以保证我们的系统的稳定性。-从反方向上看，我们经常给我们的系统加的绳子不够多，就是我们的系统线上问题频出的根本原因。 本文的主要内容是探讨如何找到每个领域的螃蟹，以及如何绑上属于它的绳子。 按部就班是一种 divide and conquer，利于协同，不易出错。 推导绳子我们需要“全周期、多维度”的风险防控体系全周期：大家在现实之中听资深工程师开堂布道，讲系统稳定性，都听过“事前事中事后”这句话。这句话的意思很复杂，事前事中和事后有很多事情可以做。很多人把事前事中事后当作“事前仔细评估”、“事中认真应对”、“事后注意复盘”，这套 sop 下来，最后做出来的效果大差不差。无论怎么理解这句话，当我们谈到“事前事中事后”的时候，我们其实已经意识到了，风险防控是一个“全生命周期，反复迭代”的体系。我们经常发现我们风险防控做得不够好，就是因为我们对生命周期的认知不够全面。 多维度：现实中，系统的风险来自多个维度。我们有无数的 case study 告诉我们，我们自己构建的系统其实比我们想象的复杂，我们并不真正了解我们的系统的运行时状态。系统的真正运行状态对我们这些建造者而言，是混沌的，我们只能理解我们心中的那个静态系统。即使只是推导我们心中的静态系统，我们对系统的理解的维度也不够全面，我们经常遇到的系统故障，来自于我们想象不到的一个环节、维度，让我们难以置信。 所以我们要构造一个能够绑住我们的螃蟹的系统，我们就要尽力把我们的设计按照“全周期”、“多维度”的方向推导。 理解全周期的好处是：每个周期的输入和输出是有界的，它涉及的模型和行为也是有限的，我们只需要理解这个收敛问题的异常情况。 理解多维度的好处是：我们很难做到一次衡量多个混合维度，但经过多个维度的拆解，我们可以多次衡量单个单一维度。 领域驱动设计下的架构基线与风险大图领域驱动设计告诉我们，要做战略设计。 做战略设计的结果，通常是以下几样东西： 被划分好的领域。 领域里有相互依赖关系的领域模型。 领域模型自己的状态机。 由领域模型支撑的领域能力。 由领域能力编排成的系统用例。 绝大部分的失败，都隐藏在这些战略设计里。如果我们通过认真的设计消除了我们的风险，这些设计就是成功的设计。这样成功的设计，至少具有以下两个特点： 分解得当：我们能不能恰如其分地说明每一笔交易的所有细节，不漏不重。 可追溯：所有的细节都是可联系的-只靠单据可以还原出全流程（这通常意味着，我们不能删除数据）。 （下文会反反复复地出现这两个特点） 我们应当如何理解我们的服务架构？ 在古典架构师的思考工具里面，经常提到 “4+1 视图”（这在他们的架构师群体里面叫作 Architectural Blueprints）： ![传统的 4+1 视图能够帮我们在团队里沟通架构](4+1 view of software architecture.png) 我们的系统是复杂的、混沌的，由多种要素组成，而且在静态视角、动态视角、功能视角和运行视角来看，侧重点并不一样。单一视图很难表达清楚所有的要素，我们要有所侧重地理解架构，也就要“横看成岭侧成峰”，建立对系统的完整认知。 我们有了基础的战略设计，我们就可以建立我们的架构基线文档。架构基线一定程度上是 4+1 架构的选择性落地实现，它应该包含： 系统用例图（即 4+1 视图中的 scenarios，所以逻辑视图需要配合对用例的下钻） 用例图的例子 系统领域类图（logical view 是一部分）： 类图的例子 领域模型的状态图（logical view 是一部分）： 状态图的例子 系统流程图（process view 的一部分）： 流程图的例子 系统每个用例的时序图（process view 的另一部分）： 时序图的例子 基于这些领域基线，我们事实上已经穷举了我们领域里零散的“原子化元素”，这些元素不可再分，而且排列组合里隐藏了失败。我们可以建立对我们的领域有百科全书式的理解，进而回答这些问题： 到底有多少种模型？ 在每个用例中，到底模型之间存在怎样的平衡关系？ 在每个用例中，运行中的原子能力有什么样的彼此依赖，会产生什么样的故障？ 只要我们“分解得当”，我们一定有办法得到我们的系统的一种风险静态视图-《风险大图》（这个东西 4+1 视图没有，但总体上来讲是从用例拆解到领域能力，再拆解到领域能力能够遇到的问题的一种描述方式）： 风险大图.xmind 上图标红的子主题被称作风险分母，如果右边有相应的感知和应对手段，则可以称作我们找到了相应的风险分子，如果没有，则风险分子小于风险分母，存在风险敞口。从这个图我们可以看出，对于一个功能设计，应对风险的非功能性设计非常多，这就“三斤螃蟹两斤绳”的现实写照。风险分母和风险分子之间应该可以相互界定，风险分子和风险分子之间也应该可以相互界定。 关于风险大图还有几点需要注意： 即使我们拆解到单一的功能模块（比如一个接口），一个功能模块里也可能隐含有多个风险分母。衡量一个好的风险分母的标准通常是：你能否用一个中学数学难度的等式或者不等式来表达这一种异常。为什么要这么做？因为我们的事中监控手段的表达能力往往是有限的，只适合表达一些简单的数学关系，我们必须适配这种有局限性的工具来表达我们的系统。 一个模块往往蕴含有多种异常而不是一种异常，所以它必然拥有多个风险分母，我们应该警惕对单一模块只提取出一个风险分母的思路。 当我们得到了一个风险分母，要建立相应的风险分子的时候，风险分子必须针对这个简单不等式做出响应，但这种响应可以是多种多样的，它可以是多种多样的： 系统模块内的果断熔断措施。 系统模块内的果断异常措施 + 相应的监控模块的精确告警策略。 基于离在线服务的信息流核对体系。 针对告警必须采取的 SOP。 sop 应当具有这样的特征： 通常是问题的最优解。 通常采取的步骤简洁明了，一看就会。 通常能够覆盖所有隐藏的陷阱。 风险大图是按照领域流程逐步分解，一直分解到领域能力不可再分为止。得到了风险分母后，我们需要仔细思考金融系统在这个能力遇到失败时，会产生什么样的错、漏、重的风险。 风险大图体现了架构师对系统运行时场景的理解，提供了一种从静态视角看待动态风险的工具。我们如何说明一个系统是安全的呢？一个简单的思路是使用数学归纳法，只要我们的系统的每个环节都是安全的，那么整体就是安全的。严谨的分解会产生有简单的说服力的系统，一个分解到这个地步的系统“过于简单，以至于明显没有 bug”，任何入门者都可以维护得很好，这就体现了架构师的功力。 每个季度架构滚动规划的时候，我们总能看到我们对领域做了什么事： 我们新增了多少种领域模型？ 我们新增了多少种领域能力？ 我们新增了多少种系统用例？ 既然我们的系统变复杂了那么多，那么我们新增了多少种风险呢？我们如何说明我们理解了风险，我们化解了风险呢？我们在做架构滚动规划的时候，应该冷静地数清楚： 我们的风险分母涨了多少？ 我们的风险分子涨了多少？ 我们的风险敞口现在有多大？ 只有把我们的架构分解到这个地步，我们才算对我们的系统的风险有了如指掌的认识，证明我们的螃蟹在长大的同时，我们没有忘记给它们绑上绳子。这也是架构师述职和晋升时必备的东西-能够向完全不理解我们领域的其他技术专家讲清楚我们领域内的风险，证明了我们建立了我们的风险大局观，是货真价实的领域专家。 （这是这张图在这个系列里第二次出现。这张图出现在此处的意思是：我们在往桶里装水的时候，要时刻评估我们的短板的高度，我们的风险防控体系，既要适应我们的系统，也要具有 scale-out 的延展性，我们的系统永远要适应业务和组织的生长）。 （这是这张图在这个系列里第二次出现。这张图出现在此处的意思是：我们在往桶里装水的时候，要时刻评估我们的短板的高度，我们的风险防控体系，既要适应我们的系统，也要具有 scale-out 的延展性，我们的系统永远要适应业务和组织的生长）。 事实上，到这里我们已经开始建立了一个多维度风险防控体系的雏形。这个风险大图能够指导我们理解，我们的风险来自于如此多的维度。只要我们记得按时滚动更新它（特别是在出现事故以后），我们就在不断地认知迭代，进行更高层次的“事前事中事后”设计。 基于架构的风险防控体系，是源于架构基线又不仅仅关于架构基线的，算是超越架构基线的设计；同理，对于风险的管控，源于我们对生命周期的认识，又超越了我们对生命周期的认识。 当我们有了风险大图，我们可以按图索骥，开始构筑我们的风险防控体系。 如何做高可用的风险防控体系高可用的问题到底从何而来？我们的服务在孤立运作的时候，保持稳定总是很容易的，为什么进入分布式/云原生环境以后就变得如此脆弱？ 我们的系统服务在这些环境下变得脆弱的原因通常有： 不能处理的负载使得系统进入不正常的状态。 环境不稳定导致服务节点失效。 这些问题一旦发生，在复杂的环境里就很有可能引发连锁反应，没有做过高可用设计的服务，往往不会直接变成“低可用”，甚至有可能会变成“零可用”。 为了保持稳定，我们寻找保持孤立的方法，化整为零，并小心翼翼地建立联系；为了提高效率，我们寻找规模化的方法，化零为整，并小心翼翼地维护每个节点。我们要在这两种策略里保持平衡。 勾勒核心架构拓扑我们的系统通常很复杂，但我们在一个用例里通常不会用到一个系统的全部部分。每个用例的全流程在全局中的依赖是不一样的。有些系统中的依赖会一直被各种用例使用，有些系统中的依赖只会被部分用例使用到。可以想象我们的服务就好像一系列被有意摆放在一起的灯泡，每个业务流程只会点亮其中若干盏灯泡，有的灯泡无法点亮是可以接受的，它可能只会影响若干流程，或者流程里不重要的部分，有些灯泡无法点亮是不可接受的，它会导致我们的业务无法正常工作，进而对公司造成损失。 因为系统的不同部分对整体的影响是不一样的，我们一定有办法把核心区域勾勒出来，而把其他区域区别出来，这在很多团队叫作梳理核心链路。 核心区域通常具有以下特点： 系统的某一项核心价值产生某一个核心流程。 核心流程包含若干个生命周期，每个生命周期由系统基线的若干个部分维护。 根据业务的特点（work load 是写还是读，需不需要引入事务模型？），系统的每个部分要满足某些 sla，保证业务事务的完整性（integrity）。我们经常说的“强依赖”，指的就是完成这样一个事务的必要组成部分；我们常说的“弱依赖”，指的就是完成这样一个事务的可选组成部分。 所以核心区域是架构基线的一个子集。这个子集比整个架构里的其他部分更加重要，不容有失。 相应的保障措施需要考虑如下问题： 如果我们无法理解我们的全部系统，我们一定要能够理解架构的核心区域。 如果我们要建立风险分母和风险分子，我们应当找到所有核心用例、核心模型和核心生命周期，进而找到所有的风险分母，然后建立风险分子。 核心链路里的风险分子，要恰如其分地应对风险，对齐最高标准。 理解系统的方法理解系统即理解指标，理解指标才能理解系统。 那么应该理解多少种指标呢？ 异常指标。 基础性能指标。 基础业务指标。 异常指标收集与告警首先应该关注异常指标。异常指标总是优先级最高的问题。 异常指标的收集要注意系统内组件的层次关系，也要注意系统自己的中间件的异常指标。 针对风险分母的不等式的理解一定能够产生多个异常指标。 性能指标的收集与告警性能指标至少要对照 SLA 来设计，不同系统的要求是不一样的。有些人也会考虑使用 SLO 和 SLI。 一个被优化得很好的服务，需要长期关注这些指标： QPS。 RT（注意，通常很多人会看 AVG 和 MAX，但其实性能优化需要关注的是长尾部分，即 tp50、tp99、tp999、tp9999等指标）。要懂得使用 sampling（metric）、profiling（本地或者线上的全方法 profiling）、tracing（基于 transaction 的 tracing 和链路 trace 的 tracing）和 thread dump。 JVM 相关的指标：gc count、gc max time 和 gc mean time。 host 相关的指标：cpu busy、load（和 busy 不一样）、disk io utilization、network io utilization。 异常错误数。 中间件吞吐量。 节点数。 如果我们的服务还有有状态的存储部分，我们还需要关注： 存储分片数。 存储副本数。 存储水位。 负载均衡指标。 io 数。 qps 数、tps 数。 响应 rt。 主从延迟。 如果我们的服务涉及中间件，也需要思考： 中间件堆积。 中间件存储水位。 中间件 cpu、mem 水位。 中间件 sla：rt、吞吐。 中间件 io 水位。 对于性能指标的收集和监控一定要引入运营的思路，懂得区分正常指标，和异常指标。 基础业务指标的收集与告警要想办法把点状指标打磨得很敏锐，也要想办法把网状指标组装成线、面、网，然后监控才能形成体系。要善用聚合指标和智能告警等新技术方案。 懂得设计业务指标的基础，是了解业务，更具体地说，是要了解业务的预期。 懂得设计业务指标要知道业务的哪些运营指标是必须观测的，指标的波峰波谷分别是什么，波动的箱体是什么情况的，我们应该防止业务出现什么波动。 举个例子： 保单： 请求数 最终投保成功数 退保数 净保单量 净保费 理赔： 理赔保险金 赔付比 理赔各个阶段的案件比 理赔各阶段时效 几种风险分子的设计思路如何设计告警设计告警关系到事中发现，如果我们能够把风险分母理解为一个简单的数学表达式：“每 100 个请求里只允许出现 a 个 xxx 错误。” 我们就可以针对这个非常具体的错误设计告警策略。 设计告警策略最容易出现的失误是没有找到风险分母，一个接口所有错误共用一个异常，甚至一个模块一类流程共用一个异常，这实际上把多个维度的错误混到了一个监控项上，让监控项的阈值配置变得不可能。 好的监控要求我们能够直接从数据中解读系统正在出问题，也可以从线上问题症状直接前往监控项，进一步确认问题实际上出在系统中的哪个环节。 告警体系.xmind 调优手段在调优的问题上，无效的误区往往多于有用的经验。 很多人迷信自己解决既往问题得到的若干经验，也有人迷信在网上某些博客里得到的独得之秘。大家应当相信几个事实： 问题大致上比一个人的经验要复杂。 一个人的若干经验如果只能生硬地使用，那就是一把锤子，锤子往往只能锤一类钉子。 实事求是地分析当前问题比套用经验重要得多。 不要过早优化，要慎用深度优化手段。深度优化手段的影响面往往比大多数人能想象到的大。只有测试明确需要优化，论证可以优化，测试验证确实得到优化以后，我们才可以确认我们的优化是划算的。 避免深度优化的方法是：写好业务逻辑。 应用层调优 面向 gc 编程。 异步化。 并行化。 调整流程。 系统层调优 内核参数调优：调大某些参数，关闭危险参数。 中间件调优存储层调优 工作参数调优。 关闭危险参数。 改变存储模式。 监控指标（待补充） 架构调优 架构隔离。 在架构层面，调整流程。 调整存储层次。 调整负载均衡策略。 冗余手段 无状态的服务：考虑多活问题（物理机房分布、拓扑结构、单元化）、弹性伸缩问题。 有状态的服务：考虑带有共识机制的服务，不带有共识机制的服务，也需要考虑多活问题。还需要考虑紧急场景下存储切换的 sop。 有状态的服务，无状态的服务。 考虑 冗余资源池在哪里，是否可以通过弹性来优化成本，是否有按照业务周期来批量扩容的 sop。 比较容易被忽略的地方：使用隔离来制造冗余（比如制造 liteSet）。 应急手段为什么要有损，用流量整形来降低高负载对系统的影响。 有损类限流，集群级限流、单机限流。限流精确吗？ 降级/熔断阈值怎么设计？ 精细化熔断设计？ 恢复类重试 内存级重试 最大努力事务型重试 想要了解，基本的设计理念和思想，推荐读读这本书： 如何检验高可用建设成果检验我们的高可用体系设计和实现得好不好，最好的方法是常态化压测+攻防演练。 如何做资金安全的风险防控体系基于“账、证、实”的领域模型设计账、证、实是起源于银行和第三方支付的词汇（当然它真实的起源和财务制度有关，非常复杂），大意上讲： 我们做任何一次交易都会产生原始凭证，这种领域模型在金融系统里可以被归为“证”。证模型还可以再细分为“业务凭证”和“资金凭证”。 我们多次的凭证会产生全局汇总变化的台账，这种领域模型在金融系统里可以被归为“账”。 某些汇总变化的全局台账是具有法律效力的，这种领域模型在金融系统里可以被归为“实”。 在我们的现实生活中，账、证、实模型可以说无处不在： 以买水为例，一个用户在便利店靠第三方支付刷卡买了一瓶水，永远都会得到一张购物小票，来表达一次交易，所以我们构建系统的时候必须认真针对交易设计“业务凭证”，刷卡的过程中还会产生一张资金的小票，所以涉及资金流的系统还需要设计“资金凭证”。有交易必然涉及库存和余额等全局汇总信息，所以我们又必须在系统里设计“账模型”。如果要和远端的有法律效力的银行系统交互，还必须设计“实模型”。 资金安全的设计的根本理念是：通过分解得当的领域抽象，找到所有的“账、证、实”模型（不重不漏），保证所有交易被充分地表达清楚（可追溯），且保证模型之间是平衡的。 寻求分解得当和可追溯的模型设计账、证、实并没有看起来那么容易，因为工程师在建模的时候，很容易忘记我们在用户故事里某一段流程，实际上是一段交易。这种时候，如果我们对领域的知识不熟，我们往往会乱发明名词，凭空设计一些“XXXRequest”、“XXXLog”来描述我们的交易。 好的模型应该仅从名字就能表达交易的性质和内容，如果我们出现了“XXXRequest”、“XXXLog”之类的模型设计，就好像我们在店里办业务，没有办法得到正规的购物小票，店家给了我们一段录像带作为业务凭证一样。录像带当然也能够完整地表达清楚交易所有的过程和交易因子，但它不是强领域建模的，也不可能被清晰地自动化处理。 大家可以仔细想一想，在我们的计算机系统出现以前，各种金融系统里面的单据是否齐备，是否仅靠纸张就可以记录以下交易因子？ 时间 地点 性质 涉及人员 金额 状态 如果他们可以，我们的系统也可以。领域驱动设计讲究以领域为师，就是这个道理。 有了好的领域模型，必须的交易因子总是可以从单据中被找到，从而还原出所有的交易细节，推导出其他模型的账实变化。没有好的领域模型，工程师排查问题就必须借助于各种日志系统。一旦出现了这种情况，工程师应该认真反思自己的领域抽象能力是不是真的“分解得当”和“可追溯”。 寻求模型的平衡性用户花 1 块钱买水，一定会得到一张 1 块钱的业务凭证和 1 块钱的资金凭证，他的余额系统里面一定会少掉 1 块钱。如果资金划拨涉及多个系统，则每个系统之间的交互都会产生相应的业务凭证和资金凭证，而且所有的余额的账模型都会因此变更。如果我们做复式记账法，我们会发现所有的凭证存在平衡关系： 不管跨越多少系统，所有的模型必定能够通过交易相关联上。 能够被关联上的模型上的交易因子必定相等，或者能够在正负算式上保持加减平衡。 这种平衡性是业务本身的设计约束，一个逻辑上成功的事务，是具有原子性的，不受任何模型、系统边界的干扰，所有凭证之间的平衡性满足自反性、可传递性和可逆性（这里需要复习一点小学生数学）。 保障交易的平衡性，就保障了所有的资金安全，可以采取如下方法： 在交易中严格保证模型是平衡的。 在交易中和交易后正确地检查出模型是不平衡的。 如果模型是不平衡的，系统应该具有自愈能力，通过补偿让系统达到平衡；或者直接熔断，阻断系统继续在有问题的状态下运行。 我们能够定义好账、证、实，实际上是我们正确理解交易的开始。 要做好基础的防御性编程校验任何时候，我们都应该假定： 上游的输入可能会出错。 下游的返回可能会出错。 本身的运行环境的资源管理可能出现故障（如操作系统文件句柄耗尽、内存枯竭）。 在交易中严格保证模型是平衡的模型是不平衡的，意味着我们的交易中出现了错、漏、重其中一种错误： 错：交易因子判定错误，有人/流程无意地篡改了本流程依赖的交易因子。 漏：系统失去了重试的动力，系统重试状态判定错误（有人/流程无意地篡改了本流程依赖的交易因子）。 重：系统发生了有意无意的重试，而系统缺乏唯一性检查，或者幂等失败。 接下来我们会以一个模拟的保险核心为例，来介绍如何解决这些问题。 任意一张保单是是由多属性组成的单据，它的每个属性是其他交易的交易因子。 不同的售后交易流程需要参考保单的属性，将其作为自己的交易上下文的交易因子（保单是交易流程的一部分），有时候也要参考其他单据的属性（一个子域可能有另一个子域的交易因子）。 售后交易流程可能随时随地发起、执行，比如一个保单可能在批改的同时被发起续期，续期的同时又被退保，退保的同时又发生理赔。因为保险业务有线下收单，线上执行的特性，所以多个交易流程可能存在混合异步、并发的场景。各个流程的执行正确性非常重要。比如： 如果发生了理赔，需要确认当前是否达到了保额的上限 ，这时候如果发生批改，则保额的上限可能发生变动，理赔有没有可能出错？批改影响理赔。 如果一个用户批改了保费保额的上下限，系统又同时发生续期，那么续期的时候，应该扣用户多少钱？批改影响续期。 如果用户理赔了，可能保单的续期责任就豁免了，接下来续期又不收钱了，那么并发执行的续期怎么办？理赔会影响续期。 我们如何保证这些流程的资金安全？ 保证交易因子是正确的一锁二判三更新很多工程师都知道很多状态判定的方法，但所有的技巧都必须依赖于“一锁二判三更新”这个基础框架设计。没有合理的锁策略，任何防资损策略都可能失效。 这是为什么呢？ 分布式系统中的并发，总是比工程师想象得到的多。因为分布式系统的全局状态的单一性和分布式节点的分布，决定了并发天然就在发生（一个具体的例子可以看看许式伟的分享，看看为什么互斥、锁是不可避免的）。事实上，根据《Java并发编程实战》，“当我们无法证明我们的api 是并发安全的时候，我们应该假定它不是并发安全的”。换言之，我们的所有的领域能力 API，都存在潜在的并发问题-各种领域流程的交互过程必然相互干扰，我们随随便便写的任何 if-else，可能都存在 bug，只是我们不知道而已。 我们日常开发过程中，很少感受到这种这种相互干扰。以投退保核心链路为例，我们的正向流程是单向的，只有投保；逆向流程也是单向的，只有退保，我们很难感受到其他金融交易里面混合异步/并发的复杂。但随着我们业务的发展，没有做好并发处理的代码早晚会出问题，所以我们最好有忧患意识-我们应该保证我们所有的原子能力都是并发安全的。今天没有并发问题的领域能力，明天放到一个新的异步流程或者编排方式里，就可能产生并发问题-为了系统安全，还不如今天就把原子能力建成并发安全的。 那么什么是一锁二判三更新呢？ 我们学习并发编程的时候都学过 double-check 的代码，它的第一行 if 是无悲观锁保护的，所以是不准的，可以被去掉。但全世界应该没有任何程序员能够直接去掉第二和第三行的判定，而让这个程序简明而不出错。所以“一锁二判三更新”的意思是：任何写操作，必须在一个悲观锁保护的临界区内，进行乐观锁的判定，保证互斥性+可见性，然后才能保证交易因子是正确的。但我们现实中的代码，去掉这个悲观锁的而不自知的例子，实在太多了。 实际上，我们常用的数据库的乐观锁比对写法，如： 就是在同一行的原子操作里面同时使用了悲观锁（record-lock）和乐观锁（比对 version）。 不要畏惧使用悲观锁但现实中大家都非常畏惧使用悲观锁，理由大概是： 悲观锁很容易造成死锁，引起性能问题。 我们总是能够很巧妙地使用各种唯一性索引 + 数据库的乐观锁来巧妙地实现并发安全的问题，所以我们不需要在应用层面来使用悲观。 这种观点，对悲观锁的态度过于悲观，对乐观锁的态度又过于乐观了。 因为，我们的业务逻辑的判定的实际逻辑往往非常复杂： 复杂的逻辑可能涉及多张单据的多个属性，也可能涉及不同的判定组合，如果只使用“update where version = ”之类的判定逻辑，既难以表达在单行的乐观锁判定里面，也可能难以表达 else 逻辑（update where 的原子能力在失败后很容易抛出异常，导致需要使用异常来指示程序的控制流）。我们要把很复杂的业务判断写在 where 里面，有时候甚至是不可能的，where 语句也经常因为忘记维护而失去可维护性。但我们使用悲观锁就可以大大提高可维护性： 当我们的业务变得复杂的时候，如果使用左边的方式，我们的判定可能会非常复杂，需要在应用代码和 SQL 语句两层代码里面上蹿下跳地维护代码。但如果我们我们把行级锁的锁定范围扩大到应用层，则我们可以得到一个被展开的临界区，维护的难度大大降低，即使是新手，也可以直接写出判定正确的代码。 在现实世界里，我们的项目里有大量的业务层代码是在无锁保护下做判定，只依赖于 update where，这就好像写多线程程序的时候不使用 synchronized 等悲观锁，而使用 atomic 尝试实现 lock-free 的并发安全一样，非常危险。既然有经验的程序员都知道多线程编程的时候，不要自己滥用 atomic，而应该使用 synchronized，那么为什么在定义更广义的并发操作的时候，会畏惧悲观锁呢？ 当然，分布式系统使用悲观锁的时候确实应该处理好一些问题： 必须防止死锁。 必须使用合适的分布式锁，而不能使用简单的线程锁。 锁不能解决可见性问题，可见性问题还需要专门解决-比如必须强制读主库，或者用其他方法来确保分布式场景下的强一致性。 最好的短分布式锁-select for update 悲观锁常见的分布式锁组件有各种各样的实现，也有各种各样的问题（可以参考《martin kleppman 关于分布式锁策略的博客​》）。RPC 类分布式锁都有固有的缺点，即使是强一致性最好的 Zk 类分布式锁，锁也不是事务性的： 如果在事务操作前后使用分布式锁，一旦事务发生异常中断，分布式锁不一定能够得到正确的归还，会降低重试的并发性。 如果持有锁的节点发生长时间 gc，可能导致锁无法续租，其他线程误闯入临界区。 我们能够找到最好的悲观锁是数据库的互斥锁，select for update，它是唯一能够如影随形跟着事务的生命周期运行的锁。 在这里要多说一点，在现实中应该慎用select in share mode，因为它会： 不能阻止写事务互斥地进入临界区。 在升级为互斥锁的时候可能导致死锁。 综上，在现实中使用分布式锁的时候，直接对数据库使用select for update 是一个简明的选择。 领域能力锁定聚合根如果使用领域驱动设计，最好锁定聚合根。 在某些并发理论里面，最好锁定是锁相关性对象，即所有的业务事务都会涉及的对象。只有锁定了这种对象，才能在新增加操作的时候，保证不漏锁定。领域驱动设计下，每个事务实际上是操作一揽子模型，所有的领域能力如果在事务里面操作，公有的聚合根是所有的领域能力的交点。如果有多个架构域、多层领域，那么很多时候只有锁定顶层聚合根。比如，在保单系统里面，最简单的锁定对象应该是保单。 如果锁定了聚合根，我们的锁的颗粒度应该是多大呢？应该尽量只把事务的范围限定在小的领域能力上，而锁也尽量只在这样一个事务里加锁。这样事务的颗粒度也都是可以被接受的。 但这种基于事务的精细化锁定严重依赖于本地事务，我们又必须在数据库物理设计的时候，尽量把相关联的领域对象设计在一个库里。所以就例子而言，所有的业务中台是使用一个保险核心的，保险核心的模型使用 ER-Sharding 技术，保证我们可以把多个系统的事务涉及到的数据库模型分在一个分片上，让所有的分布式事务降级为本地事务。 因为这种 ER-Sharding 的技术的运用，所以保险核心的设计要求所有的领域能力的锁定和防御性编程在同一个领域层-这也是整洁架构在保险核心里的应用之一。这样，我们建设新的领域能力，就有了统一的加锁方针，保证互斥的实现不漏、不重。 使用这种锁定聚合根的方法，还有一个好处，就是我们有意识地通过一把数据库行锁把对某一批事务的隔离级别从可重复读在关键操作里面提升到序列化。 这样，我们就得到了真正分布式并发安全的原子能力，这些能力依然可以被自由编排、异步化。这样我们可以继续使用面向不确定性编程里提到的组合流程。 锁的变种1-使用单据作为锁实现精细化互斥普通的分布式锁是不可能长时间锁定的。尤其是使用select for update 的时候，不可以持有太久的事务。 但我们又有很多流程，需要很长时间的“静态性”，如： 理赔可能持续十天半个月，这期间如果发生续期/保全，则理赔的交易因子可能发生变动，怎么办？ 我们需要基于对保单的锁定，实现领域流程之间的精细化互斥。具体思路是，在每个领域流程的二级聚合根生单之前，精细化地检查有没有与当前流程互斥的其他二级聚合根的存在，或者有没有跟当前流程互斥的一级聚合根的状态。 实现了这种设计，我们在长生命周期里就混合地使用了一级+二级聚合根来表达锁的语义，二级聚合根（赔案或者续期单）就像是 jvm 锁对象头里面的 markword，在它们自身生命周期里，就起到了类似锁的作用。 这种二级锁设计还有一个很特殊的用法，就是可以简单地实现“a 操作与 b 操作互斥，但 b 操作不与 a 操作互斥”等混合并发场景下的精细化互斥，我们可以任意设定互斥的判定条件，决定不同流程的并发程度。 在这里我们也可以看出贯彻领域驱动设计的重要性。只有分解得当，把一二级的聚合根都找到，并用二级聚合根把交易表达出来，我们才有可能实现这种精细化互斥。 实际上，某些互助保险业务里的某些双向互斥和单向互斥，就是通过这种方式实现的。 锁的变种2- 保单挂起这个略微有点复杂，改天再写。 其他措施-见费出单的流程模型当我们设计完模型的状态机，我们就决定了系统的领域流程。 一般的交易系统设计业务凭证和资金凭证的时候，应该把资金凭证设计为业务凭证的衍生品。因为所有的交易都需要业务凭证，但不是所有的交易都产生资金流。大家可以回忆一下，自己平时去银行办业务，是不是不管什么样的业务，都会产生业务凭证作为回执，但只有有资金流的操作才会产生资金相关的回执。 如果我们确定了业务凭证和资金凭证的主次关系，那么我们可以建立一个“见费出单”模型，即：只有资金流交割清楚，我们的业务凭证才能走入终态。 见费出单模型的设计思想是：假设有“资金交割”和“业务交割”两个事务，排在前面的事务可以得到优先补偿，我们认为哪一个事务的失败我们更不能容忍？从资金安全的角度来看，我们应该先补偿资金事务。 这样做的设计的好处是： 在正向流程里，只有用户付清账款以后，保单才出单，这样可以避免保司无资损-实际上保司的保险核心受监管要求，是强制这样设计的。 在逆向流程里，只有用户得到退款后，保单才退保，避免用户侧资损。 阿里/蚂蚁和大部分电商向用户推出的服务，都是符合“见费出单”的设计思想的。这种防资损设计在很多领域、系统实践了很多年，是被验证过的模式。 常见的非见费出单的模式也存在： 搭售保险、后结算的住宿：这种架构模式需要很强的清结算能力，可以说资金安全完全取决于附带的清结算流程是否正确。 一般互联网公司保险商城售卖的商业保险的退保是先退保再付款的：如果退保成功而支付卡单，则用户可能会产生“我已解约而没有收到钱”的愤怒。通常，金融系统的用户也认为资金事务的失败更不能容忍。 其他措施-所有定价设计可追溯的报价单这个略微有点复杂，改天再写。 其他措施-正逆向检查如果我们有了交易锁定的能力，所有的逆向流程要做好如下检查： 逆向流程执行前要自己确认正向流程产生的交易因子，如： 退保保费不能超过投保保费。 理赔保险金不能超过保单保额。 逆向流程执行前要确认自己在多次同类交易中的交易因子，如： 多次退保的累积保费不能超过投保保费。 多次理赔的累积保险金不能超过保单保额。 逆向流程执行前要确认自己与其他交易的交易因子，如： 多次退保的累计保费不能超过保单批改过的保费。 多次理赔后的累积保险金不能超过批改后的保额。 保证系统保持动力我们最常见的编程模式是同步阻塞编程-我们绝大部分的 delegate/api 等服务都是用这个模式设计的，因为这符合我们的思维习惯。但分布式系统发生抖动或者逻辑错误的时候，我们很可能丢失我们的写请求的结果，这会造成难以察觉的错误。 我们的分布式系统通常会跨系统写数据库，所以这类跨系统写问题，都是分布式事务问题（分布式事务问题的存在比我们意识到地要广泛得多）。“本来应该成功而未成功”的写问题，实际上是分布式事务的 liveness 问题-全局事务的成功，应该保证每一个局部事务都是成功的。 如果我们分解得当，跨系统的写实际上是两个模型的跨事务的状态同步问题： 前置状态是为了让我们不漏这个操作，后置状态是告诉我们我们已经做完了这个操作。 通常失败会发生在 1、3、4这三个步骤。 为了解决这种问题，我们通常要给同步流程加上异步补偿流程，实现同异步混合，推拉结合： 实际上我们日常喜欢使用的是第一种方案（各类事务型消息都是此类方案），蚂蚁喜欢使用第二种（这种方法在资金安全的设计里面还有个专门的称呼，叫“单据追平”）。这两种方法是工程的复杂度上各有千秋，但都要求我们的“状态-rpc-状态”的顺序设计得非常准确（这又是一个分解得当的例子，我们有一些订单模型的状态机，是没有做过这么精细的设计的），而且要求我们针对所有的类似场景都考虑补偿。 这类补偿措施在某些文献里被称作反熵过程。 做幂等性检查如上所言，我们的每一个系统之间的写操作都是分布式事务的一个环节，所以我们最好意识到-每一个操作既存在一个隐含的全局事务，又在各个系统里散落着本地事务（所以我们设计流程，就是在设计事务）。这些事务应该共用一个幂等号。 所以我们做设计的时候，要： 定义好每一个本地事务的幂等号应该如何生成-可以直接使用全局幂等号，也可以本地自己生成一个（但必须保证本地幂等号和全局幂等号存在唯一映射关系）。 定义好每一个 api 针对幂等号的唯一行为，而且确保上下游都理解了幂等的语义： 如果有中断流程，是否从中间执行 是否返回一个空成功 其他行为 确认全局全流程的初始幂等号的生成规则。 事实上我们很多服务的幂等设计都不够完善，经常犯的错误有： 没有真正意识到每次交易都应该服从“局部-全局”的幂等映射关系，本地幂等键的生成算法不完备，甚至生成了随机的幂等号。 幂等检查过度依赖于唯一性索引返回的异常。这种做法有两个缺点： 不是所有的幂等都能使用唯一索引来保证不重复的幂等性，如：一张业务凭证下可以有多张失败的支付凭证，但只能有唯一一张成功的支付凭证，简单的状态唯一索引就没有“锁定后查询”来实现幂等容易。所有的唯一索引都可以在应用层等价实现为“锁定后查询”。适用唯一索引号法则的场景是：只靠单一的单据号就可以确认幂等性，而不需要参考“其他可变状态”。只要有“其他可变状态”，就必须依靠锁来对抗交易因子的变动。 使用异常来确认幂等，需要在异常捕获里写控制流，程序的可维护性下降。 只针对外部接口做幂等，没有对领域里的原子化 API 做幂等，这导致任务型的调用有可能产生并发时的重复写或者其他写丢失。 在交易中严格验证模型是平衡的旧对账模式的问题我们都知道，如果交易流程有 bug，我们最终能够通过对账和查账发现问题。 我们通常使用的方案是： 让系统把业务凭证和交易凭证单独出账单-依照账单格式生成多行账单。 财务同学定期核对（通常是以天为单位）。 如果发现核对异常，告知业务 rd，业务 rd 进行排查。 这个方案有几个缺点： 实时性不强：我们只能在 T+1 天的尺度上理解我们的资损，如果系统流量变大，我们可能一天之内就面临巨大的损失。 可解释性不强：我们只做了系统边界之间的模型转化出账单的核对，如果出现了核对不一致，我们需要逐层检查各级模型才能解释问题。 覆盖面不全：我们只做了资金相关的核对，我们并没有核对所有交易因子的一致性。有些交易因子日后会成为其他交易出现故障的原因。 （准）实时核对我们是否可以发挥一点想象力，通过工程化的手段，把发现问题的实时性，推进到小时级，把排查问题的速度也推进到分钟级？ 事实上，我们的系统中的大多数事务的执行时间都很短，如果其中出现了什么资损的问题，立刻会导致全局的“账、证、实”不平衡。譬如一张多米诺骨牌倒了，我们未必需要等到最后一块骨牌倒下才知道系统出了问题。如果我们的系统能够在每一笔交易完成时，立刻针对交易进行“证证核对”、“证账核对”、“账实核对”，我们当场可以知道系统出现了不平衡。 证证核对要注意核对项，主要核对跨事务的交易因子是否匹配。 这种核对和旧对账模式的区别是： 不止核对账单，而是核对所有的“账、证、实”模型，建立简单的两两核对关系，保证交易因子全覆盖 基于大数据和 binlog 方案把可核对数据的产出时间推进到小时/分钟/秒级。 相对于老的方案，这个新方案的特点是工程化程度更深，借助人工的流程变少，人的处理能力不再是系统的瓶颈，可以为后续系统自愈和自动化流程干预打下基础。 设计这套核对系统，是基于测试视角，区别于系统的功能性设计的独立校验系统，不受系统的迭代 bug 影响，独立性更强。设计这套系统，还有如下优点： 能够反推我们设计出低延迟的系统，否则核对可能不准。 纠正不正确的模型设计-我们建立了很多支付模型，会产生大量重复建设的核对脚本。 让我们准确地表达我们对领域模型的理解，帮助我们思考我们的模型的迭代演进关系。 完整的“事前、事中、事后” 事前。我们应该充分评估我们的领域（详细地梳理和设计）： 分解模型，建立对流程的平衡性认识，在设计时做好保证平衡性的设计。 分解事务，理解全生命周期里有多少个事务，事务和事务之间的边界在哪里，事务和事务之间怎样通过凭证关联。 在项目上线以前做好“监控” + “核对”。 在架构基线上充分评估变更的影响范围，考虑兼容方案+上线预案，把变更的变量罗列出来，并逐一评估影响范围，做到不重不漏。看重因果。 做好 review 和测试：新增测试手工测试加旧测试用例回归测试。 变更前要把所有准备措施的变更前置。 事中，只能靠系统的准确问题响应、自愈和人工 sop： 使用通用方案进行灰度、回滚、降级和熔断。 使用专用方案进行灰度、回滚、降级和熔断。熔断、限流、扩容重启的顺序很重要。 仔细观察监控和核对中的平衡性，出现问题及时干预。 怎样快速定位到一台机器上。 使用云原生的基础设施对服务进行巡检。 事后： 我们要做好对结果的运营：有指标跟踪体系的升级迭代（多一个告警策略、多一个核对策略），也有运维体系的升级迭代（多一个 sop）。 基于运营要实现：对特别好的结果和特别差的结果要复盘。 总结金融系统最终比拼的是风险控制力，金融系统应该更加看重风险控制，大型业务应该看重体系化风险防控。 我们在现实之中经常也会看到事前事中事后的反例，如我们建立了一套新的业务在生产上跑了很久，事后才急急忙忙去建立它的资金核算体系，我们并不知道我们的资金是不是安全的-如果我们不能向别人说明这套体系是安全的，我们应该默认它是不安全的。真正理解架构的人，能够清晰地讲出自己的系统什么地方遇到什么风险，有几种防范手段、问题发现手段、干预手段。 金融级系统对一致性的要求，和一般事务的一致性还不太一样，讲究的是全流程的平衡一致性。所以我们解决风险问题，不能仅从单一问题出发，要考虑全局的平衡性和一致性。我们看待失败的时候，不要只简单地看待接口的失败，要更广泛地看待事务的失败和模型之间的不平衡。 基于努力，我们可以在不可靠的环境中构建可靠的系统。现阶段，我们公司的资金安全文化还在草创阶段，我们还没有建立对于高可用和资金安全的深刻认识，我们也缺乏可以依托的基础设施-比如我们并没有通用的全周期核对系统。但如果我们继续努力，我们一定能够在未来把我们的系统的稳定性提升到非常高的水平。 附录何谓失败？如果我们的解决方案出现了逻辑错误，我们会在代码里面留下一各个需要被修复的问题，这一个个问题被称为 bug。 当我们的 bug 在程序运行时真的产生了一个个错误状态，我们的系统中就产生了无数个 error/fault。 一旦 error/fault 产生的意外情况无法被忽略、自动修复，我们就得到了一个个 failure。 我们常说的故障，就是指 failure。 但我们要探讨的失败，又不只是狭义的故障，而是广义的错误。因为正是一个个逻辑的 bug，导致了最终运行时的 error/fault/failure。 一段永远不运行的代码，永远不会失败。但只要程序运行起来，哪怕其中只有一个 bug，也可能最终产生无数个失败。只要有一个失败引起了严重的问题，都可能带来无可估量的损失。 所以程序员可能会忽略 warning、error，甚至一些明知故犯的 bug，但却必须正视失败。失败是实战中的错误，它刺激我们解决我们的系统中的所有错误。 因为实战中我们必须正视失败，所以我们应该面向失败编程。我们平常处理问题，既要处理 failure，最终又要“修 bug”，所以我们最好用一以贯之的思维来理解失败，才能正确地处理失败。本文讨论的面向失败编程，就是“如何体系化地处理失败风险”。"},{"title":"面向不确定性编程","date":"2022-01-10T07:27:26.000Z","url":"/2022/01/10/%E9%9D%A2%E5%90%91%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%BC%96%E7%A8%8B/","tags":["系统架构"],"content":" 本文是如何写《复杂业务系统》和《我眼中的阿里经济体的中台架构演进》的续篇。 本文探讨到底不确定性和复杂性源于何处，并引出互联网业务系统的一种“可适应性架构”，适用于平台型业务系统。 定义问题软件难写，是软件工程师的共同感觉。 特别地，对于中国的互联网公司的“业务团队”的工程师而言，“业务系统”在业务的复杂度堆积到一定程度以后，软件本身的“熵增效应”会特别严重：一个业务系统的内部会充满了难以理解的分层、堆积如山的 if-else 分支，以至于很多工程师都不愿意进入密密麻麻复杂逻辑深处，去做高风险的维护工作。但是，只要公司正常发展，业务总会越做越大/复杂，所以要维持系统的可维护性，成为了一门很重要的学问。 现实中的系统的高复杂度问题，可以简单表述为“不确定性矛盾”：需求具有高度不确定性，一直都在高速变化；而工程师高度倾向于确定实现（因为高度抽象、反复抽象的成本很高），所以具体的实现难以变更，这两种相反的特性难以调和。 其实我们现在遇到的困境，历史上发生过很多次，比如我们现代的很多软件工程理论，就是从历次的软件危机中诞生的。归根结底，软件之所以叫软件（Software），是因为相对于硬件，它应该是易于变更的。这些软件工程理论演化到现代，有两条基本的原则是放之四海皆准的： 计算机程序是写给人看的，恰好能够运行。 软件设计其实就是对于抽象复杂度的控制。 具体地，解决不确定性问题的解法其实是：尽量用分门别类的方法来理清软件的确定部分，保留余地给不确定性，使用特定的表达手法来表达不确定性。可维护性问题只是工程量问题，以不变应万变是工程量最小的方案。 正交分解法系统性问题，需要系统性的解：系统性的问题如果可以下钻，就可以自顶向下地把问题拆解成子问题，如果子问题都有解，那么它们组合起来就会得到一个系统性的解。 笛卡尔的解但应该用什么方法来下钻呢？笛卡尔坐标系可以给我们提供经典思路： 把一个复杂的，让人大脑容量爆炸的问题先扔掉。 先建立一套彼此可以正交组合出无数能力的基础工具系统。 自顶向下地拆解问题。 自底向上地组合问题的解。 捏脸系统 上图是一个网络游戏中常见的建立游戏角色的系统，玩家通常可以指定游戏角色的发型、衣着和眼睛样式。按照笛卡尔坐标系的思路： 我们可以建立三个单一维度：发型、衣着和眼睛样式。 通过穷举的方法，设计和限定每个单一维度的枚举值。 设计一个组合方法，来表达这种组合。 如果建立这种正交体系，则用户的输入是对于不同的枚举值的选择，用户得到的输出是近似向量形式的。 这种向量形式的表达能力极强，仅以上图为例： 用户实际可选的最终结果是这个解空间的笛卡尔积的数量为：233=18 种组合。 每增加一个维度上的枚举值，都可以很简单地放大解空间：在和服之外加上一种“墨西哥服装”，则解空间实际上变为 24 种组合。 每一种枚举值都非常稳定，因为他们彼此互斥，所以非常稳定，不会因为用户的输入而产生混乱的变化。 组合的方法非常有规律，只要把向量的维度顺序排好，按部就班地输出枚举即可，组合逻辑本身并不混乱，也不受枚举值的影响。 我们还可以再通过增加维度的方法，极大地扩充我们的解空间。如果我们在 2 的基础上再增加一个有 3 枚举值的维度“鼻子”，我们的解空间进一步升级为 72 种组合。 这种正交分解法正是面向不确定性编程的方法： 应该尽量把整个解空间分解出多个维度。 在维度上找到具体的解，这种具体的解必须是互斥的、可枚举的、甚至是可演绎的（这套分解方法，也是美团基本功的《金字塔原理》里经常思考的不漏不重），也必须是具体的、可实施的。这些解和维度，就是我们系统的“确定性部分”。 找到一种组合方法，将这种向量组合出来，如果有可能将组合的策略交给用户。这种组合的具体值，就是我们系统的“不确定性”部分。 我们的系统必须先寻找到确定性部分，然后才能支撑不确定性部分的运行。 实际上，现实中的笛卡尔坐标系，只要有一套计算流程，可以表达任意复杂的曲线和图形。 百科全书式的架构师那么如何寻找确定性部分？通常的思维方式是： 到底怎样的穷举、归纳、演绎是好的？引用《软件方法》里的观点：建模带来竞争优势。如果我们运用 DDD 的方法进行分析，我们对核心域的理解决定了我们是不是能够找到确定性的部分。所以对于业务系统的架构师而言，对自己的系统的百科全书式的理解是重要的。理解自己的系统到底有多少个环节，每个环节有多少变化，至关重要。 所以这一段的结论是：复杂系统可以用正交分解来解。 重新说说什么是系统的高度-为什么要旗帜鲜明地反对意大利面条式的代码面向不确定性的系统，必然是可维护的系统，可维护的系统应当是有高度的（这个问题最初在 《我眼中的阿里经济体的中台架构演进》里有提到，但这里还是要再提一次）。 工程量问题在这里要先抛出一个观点：一切可维护性问题，都是工程量问题。内部架构不当的系统，改造工程量特别大。工程量最小的改造方法，是只改造一个模块。 线性复杂度代码难以理解的代码通常是这样的： 有经验的工程师看到这样的代码，第一反应是，这一段代码的维护成本很高。但维护成本到底高在哪里？ 这种意大利面条式的代码，难以维护的原因在于阅读的时间复杂度太高。缺乏结构设计的代码就好像一个扁平的线性表，人脑阅读的时候的处理过程和平扫线性表算法一样，时间复杂度是线性的（O(n)）。人脑天然反感线性复杂度的单调扫描，所以阅读这种代码心智负担（mind burden）很重，既容易出错，也难以维护。更大的阅读量，一定带来更大的改造量。 对数复杂度代码我们经常说好维护的代码是什么样的呢？比如 Spring 自己的核心流程： 这样的代码为什么可维护性好？因为这样的代码把解决问题的方案拼成了树形结构。对上层模块而言，每一行代码都是对下层的模块的点到为止的调用，而不是对同层方法的堆叠，如果存在下层模块，则具体的逻辑全部交给下层模块实施，本层只做策略编排。这种类似多路平衡树的阅读时间复杂度实际上是对数复杂度（O(logN)）（类似数据库的存储搜索方法），这种复杂度对于人脑而言是舒服的，人可以一步一步，精确地定位到特定的范围，逐步解决问题。我们经常提到的 Gof 23 种设计模式，也充满了这种分层解耦的设计思路，运用特别广泛的桥接模式、工厂方法模式和模板方法模式，都使用了这种管理复杂度的技巧。但设计模式又并不仅仅使系统有树形结构，节点和节点之间的连接还是通过扩展点连接的。所以我们在同层里增加具体的枚举值的时候，是用具体值对系统进行扩展，而不是修改（又见 OCP 法则）。 这就是为什么我们在《如何写复杂业务系统》里提到的，坏的代码很像流水账，而好的代码像博士论文。而且好的代码必须保持抽象的层次一致性。 现实中，意大利面条的代码为何总是会让维护者也写成意大利面条式的代码？因为几代维护者已经把线性复杂度的代码写得很长很长，除非遗留代码的维护者制造一个大的结构，把所有的代码分割进小模块里，否则单纯地局部模块化只能制造抽象的层次不一致（违反了上面提到的抽象的层次一致性）。这就是很多时候大家都不愿意重构，总是喜欢重写的原因。修改难以维护的老系统的时候，既要花线性复杂度的时间读完一个大组件的代码，也得仔细斟酌，写出适应这种线性复杂度的 patch（更大的阅读量带来了更大的改造工程量）。 在这里我们可以再谈谈 OCP 原则在实战中的意义：在不能进行有效的复杂度治理的工程里，所有的代码逻辑共用复杂度，原本复杂度为 9 的项目，在新增一个复杂度为 1 的解决方案的时候，可能新解决方案要处理的最终复杂度是 10 而不是 1；而引入了带有组件封装色彩的设计模式以后， 新增一个组件的复杂度就仅止于这个组件的复杂度边界本身。组件和组件之间的封装边界隔离了复杂度，组件支撑起了框架，也实现了复杂度的平行添加而不是线性添加。所以烂代码是把问题和解决方案混合在一起的，通篇都是流水账，好的代码是把问题区分开，把解法挂在问题这个钩子上，只有组件内部是记叙文，组件之间都是一个个模型、对象。 总结一下这个章节的核心观点是：面向不确定性的系统必然是易于维护的系统，易于维护的系统是必然是有高度的系统，有高度的系统的终极形态是：树形的，分层带有专门扩展点系统。工程量的大小，取决于扩展点的大小。 有一类树形系统的演化思路，大概是这样的： 扩展点的学问阿里的 cola 框架的设计哲学是： 有读者可能会问，为什么阿里的代码要使用 context 作为方法参数，而不是使用具体的参数来调用方法？ 从面向框架编程，到面向插件编程这里要引入一个观点：框架决定 API，业务框架决定业务 API，由业务 API 关联业务组件。 现实的日常工作中，我们谈到框架/库的时候，很多时候我们意识不到一点： 我们在为框架写代码，真正调用我们的代码的代码，是框架本身。 我们在调用库的组件里的代码，真正调用库代码的代码，是我们的业务。 好的服务= 好的框架 + 好的组件 但我们和框架的交互非常地简单，很多时候我们甚至感觉不到框架的存在（这从某种意义上来讲是 Spring 之类的框架的成功之处）。 我们常见的微内核操作系统、Spring 框架之类的复杂系统，都要求客户端对根据它的 API 规范进行“组件编程”。 在这种架构模式下面，整体的“策略的编排”是由一个单独的层次实现的，所有的业务方遵循统一的 API 标准，实现业务流程的一部分。基于这种架构写出来的系统有几个优点： 业务策略的编排和策略的实现完全解耦，策略的实现插件化（什么是插件化，业界并没有严格明确的定义，此处借用了这个流行的概念）。插件化是一种未来的开发理念，插件化的终极状态是配置化（反过来也一样）。这是由帕累托法则决定的。 因为有隔离，组件稳定性极强，适合“原子化的组件设计模式” 实际上因为这种原子化的优势，这种设计模式在操作系统驱动领域大行其道；而这种原子化的能力，恰好也适合领域驱动设计里对领域能力“原子化正交化”的要求。插件化架构，很适合领域驱动设计。 假设我们有一个业务框架，处于我们的业务代码和技术框架之间，而我们把我们的业务代码组件化，作为更上层系统的库，我们大概会得到这样一个架构： 这个架构里面： 组件通过扩展点被上层调用。 有一个隐式的框架，管理 context，管理流程，编排插件。 这样就呼应了我们在第一个章节里讲到的“正交分解再组合”的设计思路。因为，指定了 context api 这种标准化扩展点，所以理论上： 每个领域可以无限扩充流程节点 每个领域内部可以无限扩充可枚举的领域策略 基于这两个优点，我们就可以得到一个具有演绎性的系统，如果我们有意识地给这种系统增加层次，我们就呼应了我们的第二个章节的观点，得到了一个有高度的系统。 引入业务身份在这里要引入一个概念：业务身份（bizIdentity）。业务身份实际上是第一章里面向量表达式“f(x1) = (a1, b5, c3, d4)”里的 x1（有 x1 自然会有 x2、x3、x4……，业务身份也是可以穷举、演绎的）。 业务身份可以被理解为一套坐标，由业务身份可以定位选择：流程之间怎么编排、各个领域能力的具体的枚举策略是什么。 产品的完形填空如果一个我们拥有一个业务组件化的系统，我们可以得到得到一个产品发布平台。 这系统解决问题的思路是结构化的。 使用这个系统也就是结构化的。 所以给它提需求也就是结构化的。 以保险为例，理想的保险发布流程是，对于保险产品人员而言，只要在平台上配置一下产品的具体属性和规则： 业务身份 配置 子配置 产品编号 bwyl0001（在这个场景下可以简单一点，就把产品编号作为业务身份） 产品属性 理赔流程 理赔平台产品 1： 流程节点+流程顺序+流程策略 理赔流程 理赔平台产品 1： 流程节点+流程顺序+流程策略 退保流程 续期流程 套用上面的向量形式，大概可以写成 理赔(bwyl0001) = (报案策略 2, 立案策略 3, null, 审核策略 3, 查看策略 1, 支付策略 1)。 中台的所配即所得 这是一个插件化架构。 这是一个可配置架构。 这是一个正交分解，正交组合的架构。 每叠加一种架构特性，这个系统面向不确定性就越容易（也就是说，架构特性也可以被去掉）。 从全域看架构，中台到底解决什么问题？讲了那么多，只讲了系统的解决方案，但没有讲复杂性、系统不确定性从何而来。 业务的不确定性，来自于业务的快速发展，特别是业务线的平行展开（即小前台的平行发展）。但新业务的新，是建立在老系统用例上的新业务用例的新。新业务大部分情况下不用从零搭建一套体系，可以借用老体系来制造变化。 在“大中台、小前台”的架构方针下面，前台为什么会小，中台为什么会大？架构方法并不是什么神奇的魔法，中台不变大，前台无从变小。复杂性绝不会凭空消失，中台始终需要用架构的手法，把复杂度从前台拿到中台来，前台才能变小。 但这种复杂性的移动并不是简单的拿来主义（剪切加粘贴），如果只是简单地把复杂性拿过来，中台就会面对巨大的不确定性和复杂性。中台需要使用前面的拆解和组装方法，做减熵操作：把能力组装成可复制、可复用的形式，以应对变化。 只从第一个需求，推导出一个系统用例-平台能力出来，也是“想大做小”的一个好例子。所以建设平台能力的时候，一定要尽快一步到位，做到产品化，支撑变化。 可配置架构、低代码编程大家可能都听过“convention over configuration”这句话。这句话体现了不同解决方案的工程量的大小。 但我们日常工作中，总想着用开发来解决不确定性，是很难跟上业务的快速发展的。 中台的 2-1 交付，可以从 2weeks，短到 1hour： 在这种开发模式下，即使需要开发代码，开发量也非常小，因为： 整个架构按照领域驱动设计被切分得极好，整个架构里绝少重复代码，新增加一个 dao/领域能力都是原子化的扩展，只要接上扩展点，整个解空间就变大了。 举一个现实的例子，很多 gateway 系统里自带的 agent 服务。 这就是低代码、甚至可配置架构在工程量上立竿见影的价值。 总结 面对不确定性最简单的方法是，以不变应万变： 前台完全不变动，给中台提需求 中台尽量不变动，往低代码方向变动。借助平台的势能，杠杆越大，收益越大。平台升级，所有业务线都收益。 要成为百科全书式的架构师，分层能力不一定有分治能力重要。分类能力也是一种分治能力。领域驱动设计的战略设计-划分领域和有界上下文，收集实体，放之四海皆准。可以参考《为什么说应用架构需要分类思维？》。 架构也没必要乱学、硬上。本文上面讲的，具体的架构部分，可能对其他读者完全无参考意义。但我们要有模式之外的模式，也就是范式。这些范式只适用于某类场景，某类系统，但是技术成熟度高的平台系统一定要有范式。比如这篇《整洁的应用架构“长”什么样？》。 系统分多少层其实也不重要，重要的是，系统之间是不是有通用的扩展点设计。不需要强行追求对数复杂度的结构，但好的复杂度应该向对数复杂度发展。 即使是初学者也能很容易理解分布式系统的设计原则：分治、冗余；但只有极强的工程能力，才能在现实中找到通用性的场景，给出通用性的解决方案（borg+大数据三驾马车）。 插件式开发，还有好多种可能性。比如，有没有可能一个服务是另一个服务的插件？有没有所有的服务共用一个 context？现实中的例子，amspm、繁星、星环、tmf1、tmf2、海盗。 基于 context 的系统有没有缺点呢？它的缺点是：如果策略的使用方一直给策略的实现方提需求，context 的设计会凌乱不堪，腐化而难以维护。这需要设计这套架构的时候指定具体的分类方法，维护者遵循 ocp 的方法严格扩展 context。 配置并不简单，配置其实是一种元数据设计，元数据的设计很有学问。这里有一篇可以参考一下：《干货 | 携程中台化背景下的元数据驱动架构实践》。 配置也不能随便推送，一定要当做代码上线一样：可灰度、可监控、可应急（蚂蚁上线三板斧，违反了要开除）。要建立机制，用机制建立方案，有方案再做实施。 阿里系有人写了另一本书，与本文内容有相同。 "},{"title":"郭东白博士《关于中台的思考和尝试》","date":"2022-01-10T06:16:46.000Z","url":"/2022/01/10/%E9%83%AD%E4%B8%9C%E7%99%BD%E5%8D%9A%E5%A3%AB%E3%80%8A%E5%85%B3%E4%BA%8E%E4%B8%AD%E5%8F%B0%E7%9A%84%E6%80%9D%E8%80%83%E5%92%8C%E5%B0%9D%E8%AF%95%E3%80%8B/","tags":["系统架构"],"content":"FROM：《关于中台的思考和尝试》 围绕中台的争议非常多，但是往往争议的原因是连中台这个概念都完全没有达成共识，可以说是毫无意义的争吵。在 12 月 20 日由极客邦科技举办的 QCon 全球软件开发大会 2020（上海站）上，车好多 CTO 郭东白博士发表了主题演讲《从中台技术谈架构师的独立思考能力》。由于演讲时间有限， 关于中台的思考没办法讲得非常透彻，本文是对演讲的补充，期望能与大家形成思想碰撞。识别文末二维码，可免费下载郭东白博士的主题演讲PPT。 中台的定义我们的讨论先从定义中台这个概念开始。 定义中台我认为可以有两个角度， 一个是从中台本身的价值和出发点来： 中台是在多个部门之间共享的开发资源所提供的业务能力、数据能力和计算能力的集合；另一个定义从中台的相对定位来：前台是面向终端用户的一组业务能力，业务中台是对前台应用的抽象，提供多个前台业务之间共享的业务逻辑、数据和计算能力。 我想特别强调这个定义是相对中性的， 我们能够通过这个定义区分什么东西是中台，什么不是中台。有的中台定义严格来说不是定义， 比如说“中台是提升效率和加速业务增长的一种工具”、“中台是我们的战略目标”、“中台就是一个革命性的设计”，似乎不做中台就成了反革命一样，就是落后生产力的代表。 其实中台本质上是一个对业务能力的抽象和共享的过程，一直存在，也谈不上革命。甚至业务中台这个概念也没有那么新：Oracle Fusion Middleware 早在 2006 年就发布了， 覆盖了包括企业智能、团队协作、内容等多个领域。 我想特别强调中台和前台的定义差别。 前台服务单个业务，目标是就是这个业务的增长；前台必须紧贴业务做好差异化；前台的定位要考虑到竞争环境、目标客群、业务成长阶段、运营人员能力、人才供给、监管环境等因素；前台要有自己的技术内容、定制流程、流程对接和个性化数据应用。 中台服务整个集团，目标往往是降低成本、加强管控，或者是扩大规模优势；中台的定位在以集团利益最大化的前提下最大化服务前台业务的需求；中台有自己的技术实现、研发流程和数据标准。 而后台是不具备任何业务语义的基础计算能力。下图就是对这种定位的一个示意： 对待中台的两种极端态度当前对中台的看法主要有两种极端，一种是认为中台是一个完全错误的方向，要紧急刹车；另一种是认为中台就是技术终局，是业务增长的不二法门。我们先分别讨论一下这两种观点。 我开始考虑 QCon 演讲话题的时候，中台只是多个备选话题之一， 但是当我意识到大家对待这个话题非常极端的时候， 我才觉得有必要把这个话题讲通讲透。最终选择以中台做为架构师独立思考的能力的一个案例。这是题外话。 先说中台是否是个完全错误的方向？想思考清楚这个方向是否错误， 我们可以先看中台最初的动力来自哪里。不论是甲骨文还是后来的阿里， 其实本质动因是一个大公司内部的大业务呈军阀割据现象，导致多条业务线重复造轮子。由此而衍生出其他的问题， 比如说团队之间内耗严重；小业务无资源， 增长乏力；整个公司数字资产不统一， 损失机会成本；业务线也不能对核心系统做打磨，业务线不稳定。因为这些原因， 所以阿里的高管们就以美国海军陆战队和 Supercell 的组织形式为启发， 做了“大 (业务) 中台， 小 (业务) 前台”的策略。这里先不谈中台是否能解决这些问题， 或者是说战略启发是否正确， 但是毫无疑问的是， 中台想解决的问题既没有过时， 也依然正在不同的公司里发生， 所以这些问题还是必须解决。也就是说从问题定义角度来说， 中台是个完全正确的方向。 那么，中台是否是这些问题的完美解决方案？中台是不是万能药？我们已经知道答案是否定了。现在看来中台的解决方案至少有以下几个缺陷： 对创新的遏制： 一个被完全中台化的业务导致集团内部过分分工， 任何前台业务都被认为是中台能力的线性组合。举个例子， 有的公司会有接近或超过千人的供应链中台、搜索广告中台、内容中台等等， 而多数业务前台少则几个人，多不过几十人。前台团队任何一个人哪怕是全职和一个中台域对接， 也无法理解该域的全貌或者跟上这个中台的演变。这意味着前台业务完全无法在这些中台相关的领域做创新。本来的创新业务变成无从创新， 当初的动力变成了中台最大的诅咒。有说法说，一个业务靠拖拉拽就能编排出来了， 这不是创新是什么？事实证明这种创新完全无用。没有任何一个投资人会把自己的钱投到一个可以被大公司拖拉拽出来的商业模式。真正的创新不是现有能力的线性组合。 反人性： 中台自身的场景往往缺乏前瞻设计 ，是对现有场景的抽象。而当某个创新在一个前线业务线孵化出来之后，中台团队会通过强制收编该能力来扩大自己的能力， 同时强迫前台团队下线一个他们研发了很久的创新。这种行为往往造成精英人才的流失， 使得本来就受到遏制的前台创新变得更为匮乏。 过度设计： 中台经常以最全的最复杂的实现来应对任何一个简单的应用场景。大量成熟行业和强监管环境下的需求被带入到了创新业务中。在带来大量运营复杂性的同时增加了用户（买家、卖家、本地运营）的学习难度。这就是我们常讲的膨胀软件（Bloatware）：巨大、复杂、缓慢、低效。 丧失对客户心智的追求： 中台团队的产品和研发的核心技能在于抽象和降本。前台业务的核心能力在于对商业机会的捕捉和新商业机会的创造。这是两种完全不同的技能，往往对应着完全不同类型的人才。一个长期在多个业务中间找共性来降本的人是不会专注在最大化前台业务增长的。 之前做中台的公司往往被以上一个或者多个问题所困扰。也就是说中台事实上不是完美的。为什么呢？ 思考中台的本质我们先思考一下中台的本质。中台本质是把一些分散的重复的开发工作集中起来， 通过共享同一个研发团队来提升不同业务线之间的共性， 也就是通过抽象和统一来获取增量价值。具体的增量可以分成以下几类： 以零成本研发加速上线： 对完全可以复用的标准化功能集中开发，未来以低研发成本上线，比如说一些无状态的计算能力，类似 SDK。 提升业务稳定性： 对产品差异不大的领域，通过集中研发运维而获取更高的业务稳定性。这样一个团队开发的底层服务能够同时服务多个业务场景， 聚合所有的流量来加速积累。同时研发同学也通过更多的场景来加速打磨设计。常见的领域是会员、营销、交易、资金等服务。 加速技术和业务能力扩散： 把整个集团的能力尽量跨 BU 复制。这包括两种类型，一种是类似 SaaS 服务的场景，比如说 Chatbot、直播、内容等领域；另一种是类似 ISV 的场景，由一个中央的团队同时提供研发，对内服务和运营，比如说安全、风控、财务、人力资源等。 统一数据资产： 在集团内部统一数据标准，最大化数据复用， 把一个场景积累的数据优势应用到其他的业务场景中去，逐渐建设企业的数据壁垒。 集团层次的资源高效利用： 把部分资源中央化，变成全集团资源， 比如说商品中台不但包括商品库，也包括商品质量控制体系、背后的货源、相关货源的价格以及服务竞争力。而商家中台，不仅仅是包含商家的信息，还包括商家的合作意愿和对集团品牌的信任，从而使得商家更愿意和一个新孵化的初创业务合作。集团真正想跨 BU 复用的是从一个大业务孵化而来的竞争力，而不是信息本身。 从研发和管理难度来说从１到５逐渐变难，而带来的增量价值也依次变得更大。 从这个本质来看， 那么中台似乎就是完美的， 那么之前提到的不完美又从哪里来的呢？我们有必要更深度的思考一下。 中台的适用范围首先我们思考一下上面的要求， 我们把这些要求归类成六类， 其中第一种场景细分成低成本上线和加速上线两个类别，那么这些类别有以下共同特征： 0.低成本上线：同一个功能模块在多个场景中被使用， 要求该能力的接口确定性高。 1.加速上线：同一个基础能力不需修改或者简单修改即可上线， 也就是模块化支持，要求高 API 确定性和好的功能通用性。 2.提升稳定性：同一个业务能力持续打磨， 要求需求同时具备高的接口稳定性和好的跨业务线通用性。 3.加速能力扩散：基础业务能力可以跨业务线模式， 要求该能力具备比较好的通用性，可以在多个业务线之间共享。 4.统一数据资产：数据模型可以在多个业务线之间统一， 对功能的通用性要求高， 且业务需求相对稳定。 5.集团资源高效利用：业务能力共享， 不仅仅是技术资源， 其实是业务能力有高通用性且需求稳定。 下图把这几个特征分别放在一个四象限图里面。这四个象限的横轴代表技术演化稳定性，竖轴代表功能的通用性。中台的优势领域在第三象限，这个象限技术具有高确定性，业务功能通用。第二象限属于比较稳定但是不通用的小众行业。第四象限属于普遍流行但是高速变化的领域，比如说内容和服饰或者端上的交互。而第一象限属于创新业务，不但定制化程度高且快速演化，比如说面向垂直行业或者初创技术。也就是说：中台的使用范围是有限的，仅仅限于技术演化相对慢且功能通用性高的场景中。这是我们得出的第一个结论。过往中台的失败案例也往往集中在把中台强推到创新业务中的情况。 中台的组织机制那么为什么即便是在相对优势的领域，中台也没有取得类似 Supercell 那样的效率呢？他们不过是 100~200 人便撑起一个独角兽， 甚至是跨多个大洲的超级独角兽。值得一提的类似 Supercell 的中台并非个案， 仅仅百万人口的小国爱沙尼亚就有 4 个独角兽， 他们的中台团队也不过是百人左右。那么国内的中台为啥动辄就是成百上千人的研发团队呢？ 我有幸深度接触过芬兰和爱沙尼亚的几家独角兽， 我觉得导致这个巨大差异的根源在于研发文化和资源环境。这两个国家由于历史和文化传统，造就了崇尚简约、尊重原创和组织扁平的研发文化。而我们国家的高科技从业人口全球第一， 过去的十年间每年又有大量的新从业者。这些新从业者又普遍有大厂情节， 期望为一个技术品牌相对比较高且收入稳定的公司工作。也就是说大厂同时具备了孵化中台的条件且有源源不断的对成长没有太多诉求的劳动力。这其实是不断重复造轮子的必要条件。 当前几乎所有的大厂都有同样的晋升和薪酬激励机制，就是一个人管理的研发越多， 层级越高， 收入也越高。这种机制有个巨大的弊端， 一个奖励组织膨胀的机制必然会带来组织膨胀。而组织膨胀最终因为康威定理的作用也必然导致膨胀的系统， 也就是前面提到的膨胀软件（Bloatware）。这个就是不断重复造轮子的充分条件。 大量的劳动力供给和鼓励膨胀的机制合在一起， 结果就是团队上下不断加速重复造破轮子。下图就是对这个过程示意。某个研发经理从状态 1 开始， 带领一个小团队。这个时候他对应的层级是 2， 收入是 3。某一天， 他启动一个大项目， 给这个项目一个冠冕堂皇的名字， 比如说“拿破仑项目”。他的团队急速膨胀到 4。项目上线时间一到， 不论完成与否质量如何， 他立即对外发战报、做宣讲：我们取得了“滑铁卢大捷！”。紧接着他的上级内举不避亲， 把他从层级 2 提拔到 5， 收入也相应的从 3 调整到 6。然后周而复始， 他再启动“拿破仑二世项目”继续开发膨胀软件。很快他的“成功”也被疯狂复制。公司变得臃肿迟缓。 这个现象当然不局限于中台， 整个公司都在膨胀。但是这种膨胀对中台而言却是灾难性的。一个膨胀的业务线伤害到自己， 但一个膨胀的中台放缓的是整个集团。 所以我们有了第二条重要结论： 中台的建设要有与之匹配的组织文化机制。 寻找中台的合理组织机制那么什么样的机制才是一个合理的组织文化机制呢？很遗憾我自己也不知道正确答案。但是我们或多或少可以从过去的失败中寻求教训，从历史中寻找启发。 先来思考一下过去的失败。我归纳下来大致有这么几个根因： 对哪个团队做中台或者哪个人来设计中台的决策是个自顶而下的中央决策过程。做中台的人没有所必须的抽象能力和业务理解，类似过去封建王朝的分封的过程。受封的仅仅是生在帝王家， 有没有治理和决策能力不重要。 中台的推行机制往往是个掠夺的过程。对业务线的创新直接复制， 不尊重发明者的知识产权和劳动。中台所到处，寸草不生。 中台能力一旦发布， 独家专供， 哪怕功能不完善， 设计不合理也不允许业务团队复制或分支。 中台为了做规模强制向业务线推行，业务线被迫削足适履，消耗严重。每次中台升级，小的 BU 更是叫苦不迭，故障频发。 其实这几个问题并非中台所独有。上面的四个问题其实和封建社会的分封机制类似，本来应该有市场选择、良性竞争和创新来完成的事情变成了强权。其实这个问题是有解决方案的。 伴随工业革命带来的人类劳动力巨大释放（具体见 Berkley 大学 De Long 教授对人类文明史的人均 GDP 分析）背后也有完整的机制，这些机制就是我们可以借鉴的出路： 机会配置由市场决定。 尊重知识产权和创新， 保护参与者的创新意愿。 通过自由准入维持市场活力。 最终由规模效应形成统一的事实标准。 虽然我还不能确定这是不是完整且合理的中台机制， 但是我们的思想实验至少给了我们避免过去的失败的一些希望： 谁来做中台、谁的设计才是真正合理的中台设计，由市场决定。 尊重原创，通过溯源和产权机制保护创新。 自由准入， 不做独家专供。 不强制推行， 设计统一是演化的结果， 而不是行政命令。 中台的演进机制探索不过哪怕有这个机制， 我们还是要认识到中台天然的局限性。 中台不是万能的， 它仅仅合适在高确定性和高通用性场景下创造增量价值。没有合理的期望设定，其实还会让迭代过程漫长而艰苦。在一个竞争环境下， 错误的目标设定不但会带来大量的资本和时间消耗，而且对员工士气打击也很大， 甚至会最终毁掉一家公司。 从公司层面来看， 中台要降低成本， 但是抽象带来的增值是有天花板的。抽象的终局是个零和游戏， 不过就是把前台的事情交割给中台去做。没有价值创造，只有权力转移。另外，中台要加速业务迭代也有逐渐减少的边际收入。 一个健康的行业中需求是永远进化的，不存在超前的完美设计为未来不断创造价值。中台在业务起初产生最大的价值，其后逐渐衰减。 从一个团队或者是 BU 角度来看，小 BU 期望通过中台带来业务增长，但事实上大 BU 的需求总是优先， 会占用几乎所有的中台资源。小 BU 的需求永远排在第二位，会饿死在等待的途中。另外中台靠合理的设计创造价值， 我们期望中台的设计是最优的， 但是真正有能力的架构师不一定在你所依赖的中台团队。你接触的中台边界不一定合理。如果中台很复杂， 跨团队的沟通也会变得更艰难。中台创造的增量价值就越小了。 从个人来看，每个人都期望能力提升， 但是擅于发现机会也擅于抽象的人不一定在中台团队。每个人都期望职业高速发展， 但是高增长的团队往往是高风险的前台团队，而高稳定的中台团队往往变化缓慢。所以没有不论中台还是前台团队， 人才的配置不一定是最优的。 知道了这些局限性， 我们才能对中台设定合理的期望。有了合理的期望， 我们还需要建设合理的迭代机制。这里我们还是可以借鉴其他领域的成功路径。我认为对中台机制探索应该向任何科学探索一样， 是个从假设到实验， 到结果分析， 到修正，最终到正确结论的过程。 我们从相对合理的中台诉求出发， 做合理的机制设计， 通过实施，到效果验证，然后对机制不断修正， 来最终得出逼近真理的一个机制。 车好多的中台实践在分享车好多的中台实现机制之前， 我想先讲一下我为什么要分享车好多的机制。每一个机制的设计和迭代都是一个漫长的过程。虽然我们刚刚开始， 但是我把我们中台的机制完整的分享出来，也欢迎大家采用， 甚至是加入到我们的建设中来。我也想听到反馈， 尤其是你们已经发现机制漏洞的地方，那么我们就能够共同进步。 为什么考虑在车好多做中台首先，考虑在车好多做中台的原因和之前提到的几个原因类似：加速技术能力和业务能力扩散，整合数据资产，最大化公司资源利用。 那么具体什么时间启动有这么几个考虑，第一和下图有关， 就是中台启动之后的复杂度的变化情况。随着时间变化，首先中台服务的调用频次逐渐上升，甚至往往呈指数上涨， 其次是 BU 数目逐渐上升， 最后是变更频次逐渐变少。太早上线其实价值不大， 因为极端情况就是一两条业务线之间做复用， 中台带来的合力还抵不上增加的重构成本、沟通成本和人力开销。这一点上车好多有 8 条不同的业务线， 有了足够的场景复杂度和中台增值空间， 但是也不至于像某些公司有成百条业务线，建设难度非常大。 另外车好多的业务天生是低频业务， QPS 低于传统电商３～４个数量级， 所以做中台有绝对优势。最后车好多的主流业务和新兴业务都在不同层次的迭代当中，所以我们的变更频次比较高， 对做中台也是利好。 以上三个因素，是决定中台的研发复杂度的核心指标，我们可以大致建模为：中台变更复杂度 =（QPS*Count(BU)/ 变更频次)。任何一个服务，QPS 越低，依赖这个服务的 BU 数越少，迭代的越频繁， 那么变更的难度越小， 变更带来的风险越小。 如下图所示。在中台建设期间， 由于自动化测试能力还不够，接口设计不完善， 团队同学的运维和沟通能力也还在成长中， 那么风险上升就会相对比较快。等到中台建设相对完善了，风险的增长和迭代难度就相对变缓。 车好多的优势是 QPS 增长不快，原因是汽车交易本来就是个低频事件， 全年全国不过是千万量级，和传统电商完全没办法比， 而车好多自生的业务迭代速度非常快， 变更频繁， BU 数增长很慢， 也就是车好多的中台变更复杂度随着时间的变化非常慢， 留给车好多的中台建设时间相对就比较充裕。另外车好多最大的两个板块新车和二手车有很大的相似性， 所以建设中台可以从这两个板块的最相似业务线出手来打造能力， 这也是优势。 但是车好多的中台也有自己的挑战：首先三大板块新车、二手车和车后的差异大，而且业务所处的阶段不一样， 有的在做增长，有的在做转型，有的在做赛道探索。所以同样有前面第二节里提到的中台适用范围的挑战。另外整个产业互联网行业还不同于传统互联网，我们的产品技术还在从生产工具到核心生产力的过渡过程中。也就是说，技术的投入是有限的，技术带来的增量价值也待验证，所以研发投入不能过度超前。最后一个挑战是这几大板块对应着数万亿的线下市场，所以车好多的业务与线下高度结合， 流程往往以天计算， 因此变革要和行业的适配能力和期望相符。 车好多的中台定位和组织文化保障在定位上，车好多中台要解决的问题集中在集团高确定性和高通用性领域的技术和数据共享，我们不对创新业务探索加速。车好多中台是技术产业链的规模化之后的分工， 它的核心是对研发成本的优化和某些计算和运营资源的集中化管控和共享。 在组织保障层面上， 我们以加速业务迭代为目标， 通过市场机制加速中台的进化，通过内部开源且允许分支的方式加速进化和保障自由准入。我们鼓励原创，以物质、奖金、股票和晋升激励和固定人员投入来放大团队原创的动力。 在文化保障上，技术上我们关注设计, 崇尚简约，鼓励创新。对中台保持一个客观的态度， 中台回报不一定为正，也要迭代进化甚至消亡。中台既不是管理方式，也不是价值观。我们尊重学术自由， 中台设计没有权威， 逻辑面前人人平等。 下图是车好多的中台构成， 所有的业务线共享数据、计算、研发效能和企业效能中台， 业务线对业务中台形成部分依赖， 算法能力我们还没有中台化， 更多是个共享的组织， 而不是共享的技术能力， 所以用虚线表示。 每个中台域的研发范围如图所示。业务线则按需定制， 我们通过控制业务线的研发人数防止膨胀软件。 对中台软件的要求以前各家公司开发中台， 很少对中台软件做出系统性要求。中台团队想交付什么就交付什么。这些软件的质量参差不齐， 往往是项目的时间节点一到， 中台团队就三呼完美，那时候就有什么算什么， 业务团队如果稍有抱怨， 未来的需求就免不了受打压。为了避免这种情况， 我们对中台的软件做了一个定性要求。这些定性要求又可以大致分成两类， 一类是必要条件， 一类是充分条件。 先说必要条件： 中台软件必须具有可解释性， 也就是中台能力可以被分解成一组可以被完整描述的行为。这里特别要强调完整描述， 有些团队做中台， 先不说自己能做什么， 而是先占领一个关键词之后问你想要什么？你想要什么我们就可以做什么。 这个就是典型的圈地心态。对做什么功能，解决什么问题完全没有任何前瞻思考， 结果就是越做越无序， 前台团队跟着变得越来越低效。 中台必须具备可验证性，也就是说中台和计算的结果可以验证， 中台的交付的功能可以确定性的被证伪或者被证真。这是独立测试和边界稳定需求，很多中台是从业务线里划分出来的。因为需求繁忙， 往往对自己的边界也不做清晰定义， 也没有完备的自动化功能测试，更别说场景集成测试了。哪怕有边界，也经常变动， 没有兼容能力。这个要求就是对能力的验证和兼容性做限制， 避免中台堕入深不可测状态。 再说充分条件： 中台软件必须具备可隔离性，中台能力应该由多个相对独立的模块构成， 每个模块对相关实体的状态改变必须隔离在模块内部。这个要求是确保前台对中台可以做到最小化。而且对中台的依赖可以局限在前台的个别业务模块中， 这样对某个中台的依赖不会带来整个系统的稳定性降低。这个要求可以防止中台过度侵入到前台，无序扩张。 中台的模块必须可以被局部替代，中台的各模块加载独立，且个别模块所封装能力可以被等价接口所替代而不影响剩余的模块功能。这个要求和前面可解释性 / 可验证性一起就可以允许业务线对中台形成部分依赖， 而不是只要依赖某个中台的一个功能， 就必须所有功能全依赖，永远全家桶。 中台能力可以被第三方扩展和传播。也就是说中台的某个模块可以被前台团队重写后发布给全集团使用。这样可以避免中台能力仅仅独家定制，创新被遏制在远离前台的后台团队。 为什么说前面两个要求是必要条件呢？因为他们合在一起就是要解决中台提供能力的可封装性和可用性， 也就是说一个前台团队根据能力的描述可以决定是否使用一个中台功能。而后面三个是充分条件， 就是中台提供的能力前台业务线也可以选择不用， 或者部分使用那些有价值的模块。 这样中台既可用、亦可弃， 才满足了中台做为一个通用能力加速业务线迭代的充分必要条件。 车好多中台的设计原则中台设计和使用上我们有如下原则： 业务优先。多数时候由业务线同学决定架构选型， 而不是中央决策。 反膨胀软件。对中台 API 稳定性和数据模型兼容性做强制要求， 避免中台膨胀过快。避免复杂依赖。 整个中台要求扁平化微服务化设计，降低依赖深度，加速功能发现。 模块化开发。各模块有明确边界，独立文档，可独立设计 / 发布 / 被替代 / 升级。 模块尽量以原子服务模式向往透出，模块间依赖主要是服务依赖。 中台的具体边界和抽象深度是个非常有挑战的问题，往往是个平衡，没有对错。对此我们做了设计追求的建议，就是期望各中台团队在交付压力允许的情况下最大化的做到以下两点： 边界合理：寻找中台的正确边界，平衡研发成本和业务迭代速度。中台的边界应当使得 API 最简化。 中台对多个业务的抽象逼近最优， 模型在信息量最大的情况下能够保持相对稳定。 下面两张图就是个具体的例子， 前一个模型简单， 相对稳定， 但是在这个模型下能够提供的服务粒度粗。第二个模型更复杂， 这个模型下能够提供相对更细粒度的服务。后者能够适用多个车好多业务线的现有模式， 且信息容量更大，所以在当前的业务矩阵之下是个更好的模型。 车好多的中台组织和孵化机制车好多之前没有中台，怎么孵化出中台来也是个挑战。 孵化中台有多个方式： 自由竞争制： 个人或者团队自主入场， 自主投入。代码开源，去中心化研发， 通过统一发现机制对外露出。 中央授权制：由公司做顶层决策，不做团队调整， 做项目强制统一多个技术分支。 集中孵化制： 由公司做顶层决策， 对团队先做整合， 之后由该团队孵化中台。 重点扶持制： 不对称的做研发人员补贴，对特定领域做引导，加速该领域的中台建设。 视情况不同， 我们这几种组织和孵化机制都有采用。 中台的孵化具体有如下几个平行的方向： 逐步建设市场机制： 由前台业务线研发做选型决策，保障业务优先。同时通过 HC 管理引导最优决策，靠市场和预算驱动最经济的决策， 防止中台和前台的膨胀软件。在考核指标上前台考核业务增长；中台则考核前台接入成本、前台新需求延迟、前台定制成本和接口高稳定性。 建设自由准入能力，同时鼓励经营和创新。 除了前面提到的内部开源且允许分支，我们会逐步建设去中心化研发体系，加速分布式创新。同时为了鼓励中台经营， 通过控制业务线分支权利来说防止重复造轮子。 人才流转策略： 中台和前台必须有统一的研发体系和统一的人才流转机制，保持双方的活力。对有基本的能力、偏好和专业度差异的研发人才做定向培养， 支持转岗。 保障业务连续性和人员稳定性： 对中台我们会保留一定程度的顶层设计，避免大范围技术和组织重构。 关于人才最后讲讲人才。不论设计多么完美的机制， 最终还是要靠人来实现。合理的机制仅仅能够避免引人误入歧途， 但是价值创造还是要靠优秀的人才。 车好多对人才的画像可以总结成两句话：做学问要包容求真， 做人要有良知和勇气。 第一点是期望我们的人才能够保持开阔的视野， 对新事物和不同观点的包容，和不断探索寻求真正有价值洞察的欲望， 从而发现别人不能发现的机会。第二点是希望我们的人才能够为公司做正确的决策， 不断让正确的事情发生。同时他也要有勇气，愿意站出来阻止错误的事情发生。我们当下虽然有一些这样的人才，但也渴望更多的这样的人才加入。 结 语中台不是万能的， 但是可以在高确定性和高通用性场景下能创造增量价值。中台应该有合理的应用场景和时间窗口， 需要用一些设计原则来约束， 也需要相应的组织机制支持。中台有自己的生命周期， 要做阶段性的重构和重定位。这就是我对中台的大致理解。 车好多的中台实践不是标准答案，甚至不一定正确。我的分享是仅仅是为了带动高质量的思想碰撞， 也希望得到大家的帮助和反馈。谢谢大家。 原文出处： "},{"title":"我眼中的阿里经济体的中台架构演进","date":"2022-01-10T03:32:33.000Z","url":"/2022/01/10/%E6%88%91%E7%9C%BC%E4%B8%AD%E7%9A%84%E9%98%BF%E9%87%8C%E7%BB%8F%E6%B5%8E%E4%BD%93%E7%9A%84%E4%B8%AD%E5%8F%B0%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/","tags":["系统架构"],"content":"前言中台的定义和理解即使在阿里内部也没有完整的表述，至少笔者没看到。中台即使在阿里内部依然是一个 teenage sex。本文的内容基于公开的文献、自身工作经历和内网论坛的历史帖子归纳总结。阿里虽然提出了中台思想，但内部没有专门的综述的文档。 本文涉及的中台专指阿里的业务中台，数据中台、技术中台不在本文的讨论范围内。 本文之所以会先谈淘系中台再谈蚂蚁中台，是因为淘系中台是演化出来的，蚂蚁中台是规划出来的。好的架构是演化出来的。 中台的定义关于架构的几个基础思考范式讲中台以前，我们需要先讲架构-关于架构师的基本问题，以后还会专文论述，此处先介绍一些简要版本： 定理 1 什么是架构：Martin Fowler 认为，架构应该是“最高层次的系统分解”和“系统中不易改变的决定” -《企业应用架构模式》。 定理 2 架构的价值是什么：Robert Martin 认为，软件架构的终极目标是，用最小的人力成本满足构建和维护系统的需求 - 《整洁架构》。 定理 3 架构的方向：通常在一个组织的大型系统里面，调用的控制流和信息流是自上而下的，下方的系统作为被聚焦的系统，更容易产生技术资产的积淀。 这几个范式，但凡做过架构设计的人都能隐隐约约地理解，是一些正确的废话。但如果真正自身境界提升，能够站在更高的视角来看问题，才能从1 感知范式 到 2 理解范式 到 3 从范式出发。 回顾下洋葱架构的圈层： 开宗明义-架构演化分期一个容易被观察到的事实是，任何一个复杂业务都可以从一个简单的单体应用开始，逐渐演化。一般遵循 SOA 的原则，演化阶段分期是： 其实服务化的另外一个路径是指向微服务化的，这也是另外一个发展路径。 从模块化到服务化以淘宝早年的电商系统为例。电商领域的基础问题很杂乱，复杂度各不相同： 在业务体量不是太大的时候，依葫芦画瓢，就会产生一些庞然大物的单体应用： 这种单体应用通常容易演变成大泥球，随意建这种系统的架构被称作烟囱架构，里面包含了很多庞然大物模块。模块间互相耦合严重，不易于修改，其缺点众所周知： 领域逻辑没有和其他关注点分离，专业的人没法做专业的事情，工作内容相互冲突，新业务扩展难度大-业务复杂度增高。 各个模块的升级、稳定性保障和性能调优都互相掣肘，很多问题没有办法在单一模块里解决-技术复杂度增高。 这个时候一般的架构师就想到要拆分系统，即模块要膨胀成系统，淘系电商当时通过千岛湖、五彩石等项目拆出来的结果大致上是： 服务化是一个巨大的突破，这也就意味着着业务模块的实体，遵循 SOA 的原则被标准化为服务，有了标准的服务形态以后，就可以进行服务治理，引入： 标准化的服务注册形态，诞生了标准的脚手架框架：webx 框架，服务有了注册、发现和池化调度的能力。 连接性问题和观察性问题的分离，诞生了：Dubbo、HSF、TDDL、Notify等分布式中间件（洋葱架构的圈层分隔在这里生效了）。 实际上，2014 年MSA（微服务架构）被提出后，淘系的高级架构师们思考外部的架构演进的过程中，还是看不出 MSA 和传统的 SOA 有什么区别，因为 MSA 只是 SOA 加上八条原则的一种实践版本罢了。但0809 年的拆分给淘系电商系统留下了巨大的技术遗产，一直受益到今天。 从服务化到平台化但同样身为标准服务，服务之间也会有高度、厚度、深度的区别。 何谓高度：见如何写复杂业务系统。 何谓厚度：一个系统到底能够覆盖多广多复杂的业务场景，能够为更上游的系统提供多大的支撑能力？一个有厚度的系统应该像一张桌子，能够放很多很多的书。 何谓深度：一个系统能够把业务流程的复杂性、使用难度封装隐藏得多么好？把复杂的东西留给自己，让别人使用得简单而看不出流程的难度。一个有深度的系统应该像一座冰山，十分之一的复杂度浮出水面被外面的人看到，让被人只和这十分之一的复杂度打交道。 这三个尺度是架构师寻找架构结果的三个比较重要的审美指标，通过这三个指标可以把一些服务显著地同一些其他服务区分开来。 有一部分的服务，就会进化成平台，在上面那个图中，真正能够被称为平台的系统只是少数。 实际上我们现在取名字动不动就叫什么 center、动不动就叫 platform 是不对的，严谨的架构学说应该寻找一些口径把平台系统专门挑出来治理。 系统架构中出现平台系统以后，领导者就会专门组件平台类型的部门，沉淀专门的领域能力；而上层业务系统由专门的业务部门维护，进行快速试错（洋葱架构的圈层分隔在这里又生效了）。 在这里可以观察到的很重要的现实规律是，**系统的架构沿革会与组织架构的变动相依相伴，这甚至是影响架构变更的最重要的外部因素。详情请参阅康威定律**。 从平台化到共享服务化淘系电商快速发展的过程中，在组织内部孵化了阿里巴巴、天猫、聚划算、淘宝旅行、淘宝彩票等业务。各个新业务线的玩法和淘宝的传统玩法有很大不同，各个业务线又要快速实现业务需求，各个新业务线的工程师要如何将自己业务特殊的逻辑落地？ 选项1 - 把所有的业务逻辑都在淘系业务线的架构体系实现： ![选项 1](选项 1.svg) 这当然是不现实的。 选项 2 - 各个业务线各个团队，自己建一整套相似的相关的体系。 为了满足快速上线的需求，重复建设成了一个很正常的选项，但也留下了很深的技术债务的，为接下来的共享服务架构理念诞生，共享事业部的出现埋下了伏笔。 重复建设的问题是： 从整个组织的层面上看，资源产生了极大的浪费，同样一条技术发展路径，需要用不同的团队来从零到一重新走一遍。 每个团队的水平参差不齐，成熟度不统一，发展的历史阶段不同，踩坑的教训和成功的经验并没有很好地汇总到一起，一个业务线无法利用另一个业务线创造的平台能力，进而实现规模优势。 如果出现了跨部门的协同工作，架构上的重复建设极大地增加了创新的沟通成本。快速落地灵活性带来的后续复杂度被低估。 重复建设已经够可怕的了，更可怕的是不断重复建设。 解决重复建设的问题，只能回到资源整合，软件复用的基本思路上来。阿里决定推行共享服务层理念，建立了专门的组织架构-共享业务事业部： 这个时候阿里巴巴在建设系统的时候已经喊出了“厚平台，轻应用”的口号，不断地剥离各个业务线的通用业务能力，下沉到共享业务事业部中。 这个过程中，共享业务事业部遇到的挑战非常大，因为这是跨组织的架构变动，实际难度非常大： 组织抗拒改变：根据康威定律，每一个组织都具有天然抗拒这种剥夺职责的优化的天性，因为职责被优化掉以为了重要性被降低。每个业务线内部都有进行重复建设的优化的人，架构如果进行优化，等于这些人的工作被优化掉。 中台并不易用、好用：每个业务线内部自建业务能力的时候，沟通顺畅如臂使指，如果把所有的业务能力沉淀，剥离到更远的组织边界之外，实际的工作效率反而短期会下降。 架构难度更大：把多个业务线的业务能力重新抽象，并不是找一个地方重新堆叠就完事的，要重新进行聚合抽象。这是很多架构师很难遇到的场景，除了大规模地拆系统，还要大规模地合系统，要进行架构设计难度反而变大。 所以共享事业部一开始诞生的时候并不顺利，并不能立刻像灵丹妙药一样把重复建设的弊病消除掉，反而还带来了一些新的问题： 具体表现在，共享服务事业部大部分能力本身是从淘宝拆出来的，甚至团队也是从淘宝拆出来的，对于非淘宝的 bu 的需求的支持并不那么到位，强行使用共享服务事业部的服务能力反而让效率下降。而且因为某些原因，共享事业部自己也和淘宝、天猫的合作也并不愉快，因为淘宝和天猫对业务的直接共享更大，并不在意共享事业部对上层部门的赋能效应。 这个时候，阿里集团还没有明确地确认这种架构变革思路的重要性。 从共享服务化到中台化到了 2015 年的时候，马老师带领阿里高管参观一个著名的游戏公司Supercell，Supercell从表象看有200多名员工，一个游戏通常4-5个人研发。大致可以分析Supercell采用的策略： 必须容忍很多失败：比如一个新项目在测试之前，团队就要设定一个指标，比如玩家留存、参与度，我们把这个目标告诉全公司的人，游戏进入测试之后，如果达不到指标，它就会被取消。 快速尝试：曾经在两年内，他们只发布了一款游戏《皇室战争》，但期间取消了9个项目，和若干很多优秀的创意原型。 招聘足够优秀的人：采用倒三角的模式组织团队，一个游戏公司等于若干创业小团队，小团队可以决定做什么，但没达成目标就必须中止。这决定了团队的每一个人是足够super的cell。 Supercell由于其游戏业务的特点，或与其它业务的研发模式不同。但有一个共同性思考，就是一个良好的中台首要的支持前台业务的快速创新。几个人干1-2个月，业务可以close，不用心疼。但如果百人月的产品，试错成本太高，时间方向也不满足高速变化的市场需要。 在这之后，阿里领导层提出了中台思想，简言之就是“小前台、大中台”- 等于“厚平台，轻应用”的口号被提升到了更高的战略高度，共享服务层的重要性得到了正名，全集团开始中台化，原有的共享业务事业部系统逐步转化为各个电商中台。 中台化以后的过程视图： 在这个战略高度下，技术资产的大小被分离了，阿里进入了兵团化大规模协同作战的时代： 类比美军作战模式，就可进一步感受中台的作用。美军在二战时期，以军为单位作战；越战时变成以营为单位作战；中东战争时期进化为7人或11人的极小班排作战。之所以美军的“小前端”如此灵活，因为有强大的中台能力，给前端军队提供各种资源支持以及中台炮火群支持打击。 归根结底-何为中台中台的特点： 中：中台要位于中央，既不直接做业务，又把业务最通用的问题解决掉了。中台重点解决业务发展过程中从零到一突破的问题，实现业务破局，最大限度地自底向上提供技术资产复用价值。前台系统在大部分的核心流程被收敛走以后，重点解决自己领域内的问题。例外：如果前台系统本身不存在复杂领域，前台系统甚至可以被省略点，完整的业务流程直接由业务中台端到端交付解决，实现了价值流水线的缩短。 台：中台要有不同于一般平台的深度和厚度，能够打包输出平台能力。按照玄难等人的观点，中台要把打包好的复杂平台能力以一个解决方案呈现给给业务方，如果没有更好地解决上游系统的问题，中台只是空中楼阁，甚至只是把平台换了个名字而已。 微服务思想和中台思想无法兼容，中台需要向上层提供的是“平台产品”（蚂蚁的叫法）/“商业能力”（淘系的叫法），是对复杂流程的门面封装，微服务的实践会急剧增大架构中的编排复杂度。 热问题的冷思考中台很热，可是中台就代表了正确的发展方向么？ 中台也并不是没有缺点综上所述，大家可能已经发现了： 同样一件事，放在业务系统（前台系统）做需要 2 个人力，放在中台系统里至少需要三个人力-《人月神话》里更多。这种局部的效率变低是否是组织可以容忍的。 上游系统永远觉得下游系统难用，下游系统离得越远越难用，跨越组织边界最难用。如果上游系统弱势，中台系统反而会阻碍上游系统开展业务。 中台的限定条件每个组织在看待自己的技术架构，进行技术规划的时候，一定要尊重客观规律，哪怕要进行弯道超车，也要想清楚自己的定位。 王慧文有一句话，全中国只有阿里的组织力是溢出的。在市面上大多数公司的规模都很小，只有极少数的公司是独角兽公司，有极少数公司是大象公司，只有阿里和腾讯是恐龙级公司。而只有阿里才有资本和行动力在许多的战场上利用技术团队发动大规模攻势攻势。 中台对于阿里而言是平台化演进自然而然的结果，对其他公司并不是自然而然的结果，可能是邯郸学步的结果。中台是阿里针对组织变大以后复杂场景提出的解法，是对设计做设计，对研发体系做设计，并不一定就正确。建中台的成本是刚性的，一件事如果交给前台系统自己解决，局部的成本一定低于放在中台层，所以建设中台要在全局算账能够得到最优解，回归架构设计的本源价值-最大化地节约成本。大家最好还是客观地看待追求共性和容纳个性的平衡，事情并不一定都那么美好。阿里内部也在探索中不断反思中台是否真的如预想中的那样能够产生价值，中台思想是一个还在不断证明自己的理论。进行中台建设的时候，要回答几个问题： 中台要支撑的业务场景要非常复杂多变，需要有多变的创新业务场景，展开快速的试错。组织是不是有这样的现实场景和行动力来通过试错来最大化中台价值？ 中台是资源/资产整合的结果，中台很难凭空出现。中台是否真的有足够的深度和厚度，不只是平台换个名称？ 中台的出现很容易就产生剥离效应，中台是前所未有的大衙门，要真正支撑中台的诞生，组织是否有有战略级的推动力，推动组织变革，破解康威定律？ 阿里设想的中台是这个样子的： 如果学中台学得邯郸学步很容易做成这个样子： 奥卡姆剃刀定律：如无必要，勿增实体。套用俞军的产品公式：迁移意愿 = 新解决方案的收益 - 迁移成本 另一种答案-不要跨过复杂度阈值，继续做平台化也很好 短期来看，建设可复用的系统架构的成本很高，“快速上线”是一个非常有诱惑力的毒苹果，要避免诱惑。 长期来看，进行全域架构设计，实现架构统一来构建系统的重要性被严重低估了。 搞架构演进最好不要大跃进，不要要么“先快速上线搞一波”，然后“学习 xxx，全体 xxx 化”，中庸之道，小步每天前进三十公里也许更好：资源整合应该一有空隙就进行，技术债应该一有空就还，即使是在域内做小平台，也是很有价值的事情，好的架构可以产生很多年的收益。 蚂蚁保险的中台保险业务的本质保险并不只是买一个金融产品，然后出事了就赔。 互联网售卖的保险的本质是一份法律合约作为商品出售，商品本身还具有金融属性 从电商视角来看，保单是商品，需要有其他售后流程，要有完善的电商正逆向系统设计。 从金融核心系统来看，保单是金融凭证，要遵循账证实平衡模型和相关流程。 全功能的保险系统要面对的业务场景 搭售场景的保险，通常为短期保险： 正向流程：售卖 逆向流程：理赔、退保、批改 更广义的保险，实际上分为财产险（又可分为车险和非车险）、人身保险（意外险、旅行险、健康险、寿险、万能险等若干类目（认识类目是很不一样的））： 意外险：短期保险为主，售卖方式简单，售后流程最简单，主要是理赔、退保和简单的批改。 旅行险：业务场景与意外险很相似。 健康险：周期可以是长期也可以是短期。正向流程里，售卖方式涉及趸交、期缴，逆向流程较为复杂，涉及退保、批改，售卖场景的交易因子会影响退保和批改，售卖、退保和批改会影响续期、续保，退保、批改、续期、续保会影响理赔。 寿险：寿险都是长周期保险，本身还具有投资品属性，可以像余额宝一样进行批改定投，又具有分红功能（分红还可以提现和复投），还可以进行保单质押和贷款。 车险：保险标的有很多特殊的强领域属性是其他类目没有的，甚至在财产险里也是独一无二的，他的理赔查勘流程也和其他类目的保险不一样。因为车险的流程特别复杂，所以即使是专业的保险公司也需要专门的核心系统来承接相关业务。 财产险：保险标的千变万化，理赔的流程和批改的杂项也因此特别多。 万能险：待补充 实际上保险作为一种金融凭证，可以涉及的交易场景非常多，绝不只是买了退或者赔那么简单。一个交易场景的交易因子会影响其他交易场景的交易因子。 避免升维打击，规划出来的架构 一个木桶如果有短板，装一半水的时候还能运作，装满水的时候就会漏水。 一套业务系统如果覆盖的业务场景不够全面，在业务扩展到需要更多维度的战场的时候，就会因为缺失维度而遭遇失败。 阿里经济体里有很多分代架构的概念，每次做大的架构演进的时候，都要想办法预测本部门若干年内的机遇和挑战，尽量向前架构，争取一套架构解决若干年问题（见上方聚石塔、千岛湖项目，一做完能管很多年）。 如果要用规划的方式来做架构，要尽量有前瞻性地预测业务场景，尽量避免缺失维度，遭受升维打击。 蚂蚁保险很早就准备在未来转型成一家真正的保险公司，所以一开始就思考如何对标全行业的全场景，进行完备的系统建设。 用中台来解放业务线复习一下，中台思想适用的场景： 有复杂多变的业务线，需要快速地铺开队伍。 核心流程从零到一突破的时候，需要厚度和深度进行重点支撑。 core 与 prod，核心中台与业务中台的领域拆分按照传统的贫血模型+transaction script 的写法： service 可以被分为一层。 entity + crud 可以被分为一层。 蚂蚁架构会把 service 模块演化出来的系统称作 prod 系统，把 entity + crud 模块演化出来的系统称作 core 系统。 prod 作为中台被称为业务中台，管0-1 的业务流程。 core 作为中台被称作核心中台，管核心的领域服务。 以售卖流程为例状态机：init -&gt; underwrote -&gt; paid -&gt; valid 架构图略：insmobile -&gt; inslifeprod -&gt; instradeprod -&gt; bxcore -&gt; 金融网关 多余的话 组合式创新 -&gt; 颠覆式创新 郭东白博士对于中台的思考。郭东白给中台提供了精彩的定义，前台系统给用户提供有业务属性的计算能力，中台系统给前台系统提供了较通用的、有业务属性的计算能力，后台系统给中台系统提供不带业务属性的计算能力。 陶文的《中台之“中”》。 架构是关乎组织分工的设计。跳出技术框架来看，bounded context 是有界的，有界的东西可以分解业务。 "},{"title":"在 my 当工程师","date":"2022-01-07T12:04:31.000Z","url":"/2022/01/07/%E5%9C%A8-my-%E5%BD%93%E5%B7%A5%E7%A8%8B%E5%B8%88/","tags":["技术随笔"],"content":"履带理论金融所有板块都是大有可为的，蚂蚁在各个板块都可以成为赢家，所以会不断地靠现金牛业务养活一些特别重要必须取胜的业务板块，砸上十年二十年来完成战略目标。 云通未来和阿里使用不一样的技术栈，但全都部署在可以完全互通的网络环境里面。依照“云通未来“战略，未来和阿里会完全打通，技术栈有可能合并成一个，所有阿里经济体服务都运行在阿里云和阿里兼容中间件之上。 BASIC 五大赛道电商基因 + 金融系统的设计思路的混合产物，中间件是对淘系中间件的再定制版本：Blockchain (区块链)、ArtificialIntelligence（人工智能）、Security（安全）、 IoT（物联网）和 Cloud computing（云计算）。 组织形式不同的工程师属于不同兵种（业务 BU/BG还是技术 BU/BG），不同的战区（投？融？保？销？贷？信用？城市服务？开放平台？区块链？），不同的阵地（接入层系统？前台系统？业务系统？中台系统？后台系统？大数据平台？SRE 系统？中间件？云？），面临的具体问题会极大不同，挑战也极大不同。 员工技能在业务团队要很懂业务，也要很懂技术。在业务团队要懂得在技术平台的基础上运用业务解决业务问题（真刀真枪厮杀），需要有： 很强的领域知识 必须的业务建模能力 - OOA/OOD/OOP/SOA/DDD 业务架构能力 一定的业务趋势的把控能力 极强沟通能力。 在技术团队要非常懂技术，而且能够引领和改变技术趋势： 基础设施团队要从平台级别提升公司技术能力的上下限，挑战也极大 skill set： 价值观，最重要的是客户第一，用户体验不能差，不能有客诉。 有互金系统的分析和设计能力（包括资金安全和高可用问题）。 有低级思维能力，有高级思维能力，有体系化思考、结构化思维能力。 工程师文化 空杯心态 面向不确定性编程 -&gt; 从穷举，到归纳，再到演绎 架构师文化：架构会。架构基线滚动更新。想大做小。以终为始、以始为终。实事虚做、虚事实做。分治、分层、抽象和演化。系统分析师角色。UML + 各种大图。一号位。 优码会/优能会 大后端：全栈 + 架构 + 算法 双能驱动：效能 + 智能 体系化风险防范 忧患意识-三斤螃蟹两斤绳 要做简单的，符合直觉，找到本质解法的设计：与其写一个没有明显 bug 的程序，不如写一个明显没有 bug 的程序。 事前、事中、事后。 上线制度：三板斧：可监控、可应急、可灰度。 资损白皮书： 一锁二判三更新 平衡性检查 实时对账 资损防控基础设施 代码疫苗 过程质量文化 架构演进 第一代架构（？-2015）：场景保险，三套核心系统 第二代架构（2015-2017）：独立 bg、保险超市模式、平台保险、小二精选也开始出现。架构治理、架构统一、核心合一，产品合一；开始执行大中台，小前台战略。 第三代架构（2017-至今）：打法变化，开始从主动制造行业精品：xhb、hyb、qmb，小二精选开始发力。开始在既有的核心域能力上打造爆款。双能驱动、合规标准化，打造新的科技保险。 飞马模型空缺 “2-1-1”交付 “2”指的2周的交付周期，85%以上的需求可以在2周内交付； 第一个”1”指的是1周的开发周期，85%以上的需求可以在1周内开发完成； 第二个”1”指的是1小时的发布前置时间，提交代码后可以在1小时内完成发布。 在极限编程和 scrum 里，2weeks 恰好是一个小迭代周期的单位。 架构师与架构 保险术语（最新修订版） T0048-2015保险基础数据模型.pdf保险基础数据模型(征求意见稿).pdf 微服务-动态配置【蚂蚁金服数字课堂】蚂蚁金融级研发效能实践解析丨全面介绍SOFAStack研发效能组件（LinkE）的特性和主要功能 sofa 的介绍"},{"title":"如何写复杂业务系统","date":"2022-01-07T05:38:33.000Z","url":"/2022/01/07/%E5%A6%82%E4%BD%95%E5%86%99%E5%A4%8D%E6%9D%82%E4%B8%9A%E5%8A%A1%E7%B3%BB%E7%BB%9F/","tags":["系统架构"],"content":"引言本文只是一家之言。 本文是一系列文章的缩略版本（完整版只写了个开头），尽量只讲具体的东西，如果有东西太干了，没有具体的“体感”，是作者的责任。 不喜欢看纯理论分析的可以跳到单一系统层次和模块设计（大多数人可能更加关注这一节，其实前面的部分更重要）。 几个很干的原则 解决复杂问题要用高级思维，不要用低级思维。 蚂蚁/ebay 等若干家企业\b架构师四大原则 - 听过的可以往下跳： 分治（其他所有原则都是从分治里衍生的） 分层 抽象 演化 solid 5 原则很重要很重要 -很多人读过，很多人可能没有读过，温故知新很重要。 注重过程质量，拿到结果质量。 业务系统为什么难写？纯粹的业务驱动：技术的输入和决策完全来源于业务同事，甚至只受业务摆布的团队，架构容易混乱 业务又不懂架构、业务又不懂功能点罗列的合理性，业务只会往技术团队身上扔需求。 怎么把需求和实现分门别类是技术自己的事情。 但技术人员如果一直都很忙，没有自己的空闲时间或者对设计洁癖的坚持，慢慢地就会养成“把需求翻译成代码，然后往老的系统里面扔”（混乱根源 1）的坏习惯- 问题：翻译只是普通的低级思维，不能解决很复杂的问题。 不理解业务 盲人摸象，一群瞎子摸大象，摸到耳朵的人以为大象是一把扇子；摸到肚子的人以为大象是一堵墙；摸到鼻子就以为大象是一根管子： 在复杂业务面前，我们就是瞎子，甚至 pm 都是瞎子。很多时候我们没有机会摸完一头大象，就要做系统设计决策。因此，我们经常只把系统设计成一把扇子、一堵墙和一根管子（混乱根源 2）- 问题：定义问题太简单，设计解决方案太简单 。 很多时候甚至一个 pm 认为耳朵是扇子，技术人员认为耳朵是一张饼，大家以为达成共识了，实际上概念是割裂的，大家也不愿探讨清楚（混乱根源 3）- 问题：技术不要觉得只懂技术就够了，实际上系统的业务越复杂，技术越不重要。 一个系统刚刚设计的时候，最初的架构设计人员已经把层次都分好了。技术人员有惰性，大多数情况下，不会再在已经划分好的层次里面进行横竖切分，制造小模块和小层次（混乱根源 4）。大多数工程师能够习得的最趁手的抽象、最万能的抽象，就是一个 service 里的若干个函数，别的东西，大家什么都不会。所以大家只能把逻辑封装进这两个玩意儿里。 ………………………… 混乱是一切问题的根源，业务系统的熵值太高以后，新的功能不好加，旧的功能不好改，业务系统成为一个大箩筐，里面的东西就腐化了。 以上问题的抽象解法 技术团队要自己有技术驱动的工程师文化，大家志同道合，齐心合力： 理解现有系统，定期架构 review，更新系统基线 从业务输入出发，规划技术路径 专门做技术改造来推动架构演化。 学业务： 学业务流程，多读领域故事，以业务输入为老师，请领域专家为老师。 以对特定的领域有百科全书式的理解为目标-大家都不是搞金融的，一样可以成为金融架构师。 注重需求分析和建模，要先有分析才出设计，而不是边设计边分析。 注重设计： 整体架构设计（这是由定期架构 review来决定的）。 注重单一系统层次和模块设计，后面会专门讲。 设计系统的时候要留有余地（OCP 法则），存有敬畏之心。我们应该只把我们摸到的地方设计成一把扇子、一堵墙和一根管子，其他东西留给以后摸到再设计和实现。 要有穷举能力，要有归纳能力，要有演绎能力，要面向不确定性编程。 单一系统层次和模块设计（大多数人可能更加关注这一节，其实前面的部分更重要）软件工程师做抽象设计的时候，处理的是单元/模块/层次之间的关系，所以要对复杂系统具有横切和竖切的能力。 架构分层和分模块的演进 大家都知道系统很复杂， MVC 模式的样子： 过了十几年，martin fowler 等人开始介绍所谓的《PresentationDomainDataLayering》 模式（有兴趣的同学可以读这本书《企业应用架构模式 [Patterns of Enterprise Application Architecture]》），导致了国内流行了十几年的所谓是三层架构、四层架构： 我们团队现在的系统通常是什么样的？工程规范之分包规范 一个烂系统通常是什么样的？其实所有烂系统都没有高度，别人划分好模块和层次以后，里面都是流水账。特别是 service，上蹿下跳，复杂无比。 好的系统给人的感觉好的系统：结构分明、抽象恰当、职责明确、边界清晰。 坏的系统如流水账，好的系统如一本好书，局部来看是记叙文（可以使用 transaction script），全局来看是议论文（讨论 why、what、how）。 一个系统应该被设计成什么样？没有标准答案，所以大家都乱来。 但合理的设计应该满足一个约束：系统是对业务问题的回答，系统能力能够支持用例。 Step1 搞清楚业务用例和系统用例当我们收到需求，一开始它是这样： 其实这是一个业务视角的业务用例，它背后是由若干系统用例支撑的： 售卖重疾险业务用例拆解为系统用例 而我们的系统中往往已经有过其他业务用例： 新老业务和系统用例 这个地方本来应该画流程图，但没时间不画了，默认用户故事的流程是： 生成投保单 定价 付款 出单 Step2 用例拆双层，能力也拆双层如果用例能够分层（问题空间分层），系统能力也就可以分层（解空间分层），系统实际上就变成这样： 双层能力.drawio 注意看，这里 service 层是一拆二的，很确切地把系统的内部能力按照用例分解为两层（先横切），然后按照领域进行领域划分（竖切）-这里是 eric evans 在 ddd 里推荐的一种拆法。 Step3 使用 OOP 来代替 POP，用命令对象来代替函数调用业务用例层每个模块内可以这样写： 当然也有些人会只写一个 pay 方法，然后在 pay 方法里写 if-else，但这样写的代码一样烂，还是无限接近小学生代码。 如果使用抽象的方法来写，其实会写成这样： 这样做的理由是： 标准的自顶向下设计，越高层的入口应该越抽象，只使用方法嵌套需要设计者的功力极高的功力，不适合大多数人。 流程被完全抽象化了，流程的变动不再是函数套函数，而是对象套对象。对象是一种很适合嵌套和分隔的设计单元，它的多态比函数的重载强大得多。 中国人受贫血模型+事务脚本的设计模式影响太深，很多人都忘记了，23 种设计模式其实都是使用富血对象！在设计的过程中，要注重理解行为型设计模式里面组件沟通的思路，选择对象或者方法作为扩展点-使用方法作为扩展点比较危险，因为继承的耦合强于组合，总是倾向于桥接到更远端的对象是更好的选择，这就诞生了对象的层次。 Step4 引入策略，把变化拆解到领域原子能力颗粒度有人会想，是不是每次新增一个业务用例，我重新派生一个 activity 就行了？ 其实大可不必，新的用户故事本身只是对领域能力的重新编排，在每个 activity 中的变动点无非是： 使用新的不同的领域能力-这要求我们有新增领域能力的能力。 编排不同领域能力的顺序-这就要求我们有新增领域顺序的策略。 以定价为例，我们先提供不同的基础领域能力： 双层能力-细化领域 然后用策略模式把他们包装起来： 假设我们有了这样的层次，则每次我们只要变动： activity 之间的任意顺序。 acitivity 和 strategy 之间的关系。 strategy 的种类。 就可以灵活自顶向下地复用现有的架构来以最小的改动支撑新的业务需求。 原本复杂的流程，简单翻译就是扁平的结构，如果我们通过横切竖切来制造多次抽象，逐渐填充细节，系统就有了高度。 strategy 还有额外的好处：它抹掉了不同领域的具体实现的具体差异，使得很多服务要调用远程服务、数据库所必须的连接性操作、适配性操作，和基础的，完全与用户故事无关的原子能力，完全被 strategy 封装得干干净净。上层应用调用一个 strategy，就像调用一个领域。 有意识地引入层次 Step5 如何实现动态激活策略？引入业务身份和业务配置其实怎么设计 context 和怎么写 context.isActivated() 是最难的。 一个基本的思路，每次用户提需求的时候填一个表： 2/3/4行存入数据库里。 上游业务系统的 请求进来的时候带入这个majorIllnessInsuranceBizIdentity。 请求进入 controller 的时候就把 context 里面的 xxx 能力、xxx 能力的映射表设为 true。 在每个 strategy 里 context.isActivated() 读这张配置表。 理论上流程标准化以后，系统扩展点应该全部存在数据库里面，上产品操作数据库激活扩展点集合。 这就是分层架构 + 标准化流程建模 + 面向不确定性编程思想。蚂蚁的保险使用繁星策略，context 横跨多个系统；阿里淘系使用星环系统，context 可以横跨多个 bu。 整洁架构、六边形架构和洋葱架构清晰架构(01): 融合 DDD、洋葱架构、整洁架构、CQRS…(译) "},{"title":"系分模板","date":"2022-01-05T12:40:50.000Z","url":"/2022/01/05/%E7%B3%BB%E5%88%86%E6%A8%A1%E6%9D%BF/","tags":["系统架构"],"content":"一定要记得保留数字标题前缀，这样可以在目录里恰当地理解结构深度。 图例红色代表变更/新增功能 蓝色/黑色代表原有功能 1、需求分析1.1 原始需求1.2 需求背景1.3 需求收益1.4 术语解释 名称 解释 例子 例子 1.5 流程分析1.6 用例分析1.6.1 业务用例分析1.6.2 系统用例分析2 功能性设计2.1 交互设计2.2 流程变动2.3 领域模型变更2.4 数据模型变更2.5 状态机变更2.6 关键时序对 sla 的需求是什么？写在时序的 Note 里。 2.7 接口变更3 非功能性设计3.1 风险点评估3.1.1 高可用风险3.1.1.1 新增组件/依赖 依赖服务 强弱依赖 风险点 稳定性保障 appkey 弱依赖 接口响应时间超出配给时间，导致用户 xx 环节 xx 接口响应超时。 发现手段：设置 rpc 超时，依赖超时告警。依赖服务保护平台切面的告警（注意监控、注意中断机制）。依赖监控 上报的异常。是否依赖于中间件超时/重试，是否使用服务保护平台超时/重试。恢复手段：通过降级来绕开对某个 appkey 的依赖。是否依赖于中间件降级，还是使用服务保护平台降级？冗余措施：是否有请求落库持久化，支持异步化/重试，是否支持内存级重试。 稳定性保障的子表格 关联对上对上接口 对上 sla 依赖接口名称 依赖 qps 依赖 sla 服务名.方法名 目标 40ms tp9999 86 ms avg26ms对上的 qps 最好能够通过监控看到分钟级数据，对平均值和峰值有所认知 服务名.方法名 500 tp9999 10ms能否在拆解中达到依赖目标？ 3.1.2 资损风险 风险点 发现手段 应对措施 交易型风险：交易失败？错漏重 营销型风险：错漏重？如何核销？ 3.2 上线计划3.2.1 代码变更发布顺序 服务 appkey1 服务 appkey2 前端服务 xxx 3.2.2 配置变更强弱依赖的区别在于，对于核心用例、核心事务的核心组成部分。 强依赖梳理 变更项 变更内容 发 jar 确认版本号发布环境snapshot/release谁来发布 灰度开关 有没有暗部署设计全局开关还是局部开关是不是基于请求因子灰度的要注意设计灰度时间和事件顺序 rpc 服务鉴权 四个环境的子表格，注意变更点要全部列出：包含服务、接口和是否打开鉴权。 动态配置服务 要注意运用好审批功能。四个环境的子表格，注意变更点要全部列出： key 和 value。 静态properties/yaml新属性 四个环境的子表格，注意变更点要全部列出： key 和 value。 分布式任务框架 四个环境的子表格，注意变更点要全部列出：分布式任务名称、 确认执行时间（模式、每次执行时间）、告警模板 mq 四个环境的子表格，注意变更点要全部列出：集群、topic（partition 数、是否延时、死信、有没有负载均衡特殊配置）、消费者（并行消费数、是否延时消费、死信配置、消费异常处理策略） 分布式缓存 四个环境的子表格，注意变更点要全部列出：集群、category、超时时间、命名模板、Value 类型（如有强类型中间件、注意 String 和数值类型的区别）、容量（大规模缓存-如大规模模型的缓存需要专门考虑） Tair 四个环境的子表格，注意变更点要全部列出：area、value、qps、ttl、容量、value 类型 Rds，加 ddl，加新索引 另见Sql SOP 服务保护平台 配置 key、线程池配置（coreSize、maxSize、maxQueueSize）、熔断规则（异常、超时配置）、重试规则（异常、超时配置） 服务网关 协议类型、URL、api名、appkey、服务名、方法名、TTL等，是否已验证，是否已灰度 OpenResty 四个环境的子表格，注意变更点要全部列出：域名、映射规则 分布式事务引擎 四个环境的子表格，注意变更点要全部列出：事务类型、domain、callbackMethod、配置 KMS 四个环境的子表格，注意变更点要全部列出： key 和 value 分布式序列号服务 四个环境的子表格，注意变更点要全部列出： key 和其他配置 业务团队基础数据配置 线上线下元数据配置 触达服务的分环境配置 线上线下消息配置 弱依赖变更 变更项 变更内容 其他服务的标识 其他服务的配置 SqlSOP 正向 Sql： 是否涉及状态、时间、业务主键？ 索引是否唯一？是否有联合索引 物理主键是自动生成还是外部生成-自动生成要考虑全局不唯一，以后迁移到 newSql 或者 NoSQL 会产生冲突。 业务主键是否全局唯一？ 是否有扩展字段，扩展字段的表达空间有多大？ 编号类的列长度是否足够？ 需要考虑单位的列单位是什么？金额类的列精度是否足够？ 基于时间的列是否需要考虑时区问题？是否可空？缺省值是不是 1970-01-01 00:00:00，如果不是可能导致 Java mapping为 null。 mapper 是否总能正确地使用索引？要做 Java 和 Sql 的双校验，通常 Sql 先行，Java 代码后之。 是否可空和缺省值是否能够脱离 Java 代码工作？如果可脱离小心 Java mapping 为 null。 insert 语句遇到异常怎么办，涉及范围多大，是否引起大事务？ select 语句是否涉及分页，最好每页不要超过 1000 条记录。 update/delete 语句的扫描范围多大，是否引起大事务？慎用负向和穷举条件。 归档类操作不能破坏业务完整性，破坏幂等性，破坏 consistency。如果有可能出问题，一定要想办法把订正数据和业务热数据错开。 新加外键列，一定要带有索引。 慎用 now()-current_sys_date 更糟糕。 是否有操作时间，是否有操作人。 逆向 Sql： 操作时间到底要不要还原？ 使用新的操作时间可以将变化同步到数仓。 使用原操作时间可以将数据完全还原。 参考： 《Google API Design Guide (谷歌API设计指南)中文版》。 github 的 REST API 注意 api 的风格、可扩展性、场景的隔离。 List Get Create Update Delete 3.2.3 灰度方案灰度过程要不要分接口灰度、分业务灰度、分环境灰度？ 沿用普通灰度过程，分若干组，逐步达到全量。 观察正常指标： 上游流量监控 下游流量监控 业务大盘监控。 观察异常指标：观察 error 指标（error log 和 error metric，log4j2.xml 的 root level 是否能够包含全部的 appender 和全部的 error level？）。 验收方案： 谁来验收？ 多久时间后验收？ 上线要看多久？发布后至少看一天 沿用普通灰度过程，分若干组，逐步达到全量： 分三个分组。 非高峰期发布。 发布第一分组观察 10 分钟，观察：业务大盘、错误监控 problem、其他核对平台处理结果、第一分组机器日志 无问题继续发布剩余分组，观察 10 分钟再发布下一分组。 验收者： 多方验收：产品、qa 和其他系统工程师，输出结果的验收标准。 发布一天后观察剩余数据： 业务大盘 错误监控 problem 灰度流量设计（要不要压测，要不要灰度开关，要不要调节流量？）暂时不需要打开灰度开关 3.2.4 监控方案复用老监控项 异常指标监控（是否复用监控的兜底异常）： rpc 调用失败数的绝对值大于阈值告警 sql transaction 失败数的绝对值大于阈值告警 rpc 的成功率小于阈值告警 sql 的成功率小于阈值告警 rpc 提供服务失败数的绝对值大于阈值告警 rpc 提供服务成功率小于阈值告警 业务指标监控： 业务核心大盘 基础指标大盘一，业务监控大盘一。 基础指标大盘一，向下监控大盘。 基础指标大盘二，向上监控大盘。 中间件系统指标监控： 服务系统指标监控： 操作系统性能指标监控： 新增监控项 异常指标监控（注意新增监控项一定要基于 exception 打印！在其他监控环境下需要使用专有的错误码。）： 已在系统告警中排除以上异常。 业务指标监控 中间件性能指标监控 服务指标性能监控 系统指标性能监控 监控大盘变更无 监控时间 全天候 午高峰/晚高峰 白天 黑夜 核对方案T+1T+H 3.2.5 应急方案回滚策略回滚上一个包（哪一个包） 如何消除影响：应用全部回滚手段。回滚方案实际上是由发布方案决定的，金丝雀发布（rolling restart）、蓝绿部署和 AB testing。 禁用方案禁用节点，禁用上游，禁用服务端口 扩容方案基于监控的扩容和基于时间策略的扩容 熔断策略超时熔断、基于异常差异化熔断 降级策略降级 sop：包含降级点、降级顺序和恢复顺序 4 项目计划 流程节点 时间 流程节点 时间 需求粗评 需求细评 技术评审 测试评审 提测 st 测试 发布 "},{"title":"神经衰弱和强迫观念的根治法","date":"2022-01-02T09:13:03.000Z","url":"/2022/01/02/%E7%A5%9E%E7%BB%8F%E8%A1%B0%E5%BC%B1%E5%92%8C%E5%BC%BA%E8%BF%AB%E8%A7%82%E5%BF%B5%E7%9A%84%E6%A0%B9%E6%B2%BB%E6%B3%95/","tags":["心理学"],"content":"写在前面的话强迫症是一种观念冲突，不能摆脱这种冲突，则人生的心境进退不得。 神经衰弱是文化发展带来的弊端。Civilization 等同于 Syphilisation。身心过劳，导致神经衰弱，也会治愈神经衰弱。 精神疗法的不切实际，来自于忘却回归自然的原理，滥用脱离实际、纸上谈兵的条条框框。一般街头流行的售药广告，把可怜巴巴的病人毒害得苦不堪言。 当今医学界过分注意物质因素，忽略精神因素。疾病在各方面表露出来的症状，是它自身各方因素综合作用的必然结果，并非神经衰弱加进去的。疲劳导致的痛苦不算神经衰弱。 神经质实际上是由过分看重疾苦，担心患病这种基本精神状态引起的。 用钝感保护自己，注意力不要过度集中，不要强制自己变得乐观。 哪些是长期趋势里一直存在的，我们如何将它分离出来，加以合理对待。 迷惘是无焦点而无法做选择，破除迷惘的方式是试错。 身入深山不见山是常态，不要纠缠于当时的感受，要明白真正的为人处世之道。 不以物喜不以己悲意味着鞍下无马，要把喜放掉，才能放掉悲。而且要先无喜才能后无悲，这个先后顺序让人难以破除人性的诱惑。 太执着于当下只会引发不清醒和迷信，自业自得，自作自受才是平实、正确的宗教观。 可以被忘却的恐怖，是可以被接受和消化的。处之泰然即可忘却。 不要拘泥于固定的预期恐怖。 病和相关的素质有关，要警惕内在成因的必然存在。也要警惕，其实神经质的素质是外部环境施与的，人既无法改变，也就无需自责。 肤浅的观点都是皮毛之谈。 人和人的平庸之处没有什么差别，打磨自己的想法很重要。打破思维定式，是战胜恐怖的首要手段。 烦恼是在认识发达的基础上的一种恶智。本不该去想，非要去想，无法控制而非要控制，是为强迫观念。思想冲突有时候是由智识的进步导致的，人的知识进到了一种更深的境界，解决了一些普通的问题，又被更难的问题难住了。 青年时期有特殊经历的人，没法像常人一样活着。因为他们的心态没有发育成熟，将本自具足发挥出来。 镇静剂不会使强迫观念消失，只会让发作者被禁锢。 姑息一些不好的事情，有时候是一种懦弱。病态的心理和病态的生活方式是人的双重枷锁。 宇宙间的一切现象全都是由相对关系、调节作用和保持均衡等法则构成的。精神的拮抗是一种费力，但有效果的“必须存在”。失去拮抗即失去自然。陪伴也是一种拮抗。 麻痹与僵直，形态相似、成因不同。人在做事时，如何建立和控制对立的观念-比如又想要收获，又想要忍耐。同时持有这两种观点并不一定有益，压力会导致动作变形。 坐忘的本质是超脱拮抗作用。堕肢体，黜聪明，离形去知，同于大通，此谓坐忘。没有积极意识也就没有拮抗意识。人很多时候失控是因为代偿，要么拮抗过盛，要么没有拮抗。 担心犯禁是一种拮抗心理，长期受压使人懦弱。真正的放松，也许是由自己决定的。人失去自我，主要是因为被外部打压。得不到合理的激励和认可，所以采用忽略自己感受的价值体系。 欲望会产生品行障碍，违法犯罪。 应然与实然应该是相互顺应的。迷信带有不切实际的心理，看待世界不客观，所以它是虚伪的。人怕死是天性，人苟且和懦弱也是本性。恶智来自于智，迷信错误的东西无异于抱薪救火。大道理很容易让人领会错误，大道理并不一定能够解决大矛盾，但必然带来思想上的大矛盾-所以道高一尺，魔高一丈。 生老病死是基本问题。细碎的解不是终极的解，纠结不休的话，心智负担太重了。 着急追逐人生的机会，不算是应变。 现实中的乐土是什么，睁开双眼，仔细听听，逍遥大自在。只要你不想着拼命补偿，你便可以少做很多事，也就可以多做很多事。 贪生反倒近乎死，因为生没有乐趣-钻进一个东西里面，人就没有了乐趣。 动物也有记忆，动物没有信息载体。君子性非异也，善假于物也。这是成事的心法。 人不一定能够客观感受到事实，人能够感受到的只是观念。把观念当做事实来感受，是人生的大谬误。 众说纷纭的思想矛盾如何处理，怎么消解生命里的难过？对大部分人而言，决一死战肯定是假的。 视图改变难以改变的客观，徒增烦恼。有些事情，不要进入思考，进入思考才是难的。徒劳的思考浪费努力、耐性和持久力。 心机一旦转变，精神面貌焕然一新，切断思想矛盾，获得无牵无挂的心理状态，就是宗教所说的“法脱”，进入心旷神怡的境地。 注意一些东西是潜意识的天性，反抗不是好的训练方法。不能强行开示，也要注意不把事当事。概念是大体系里的一个尺度。思想是一面镜子，不照就看不见。What you see 不等于 what you know。获取客观认知极难。 苦与乐是正常的，快与慢也是正常的，黑暗生命力从何而来，为何合理？ 病态的人（比如赤面恐怖）也谈不上知耻为耻了。佯狂也是一种病。 每个人心中都有一个地狱。真正的忏悔要直面真实，承受报应，心中的扭结才能解开。 起心动念往嗔怪的方向想，有时候是唯一的解法，但也有可能沦为歪理。 所有的患者都认为自己最痛苦，别人是傻子。意识到视角的偏差，人的自身欲望难以被正确地理解。谁都有值得被欣赏和同情的一面。人的痛苦来自于欲望，因为欲望不欲人知，所以痛苦难以解释清楚。人嘲笑人也是因为放弃了对人的问题的正面理解。 他力的法行得通，自力的法也行得通。很多事情需要依靠“本自具足”这四个字。 强健的体魄提供真正富余的心力。能够协调快脑与慢脑，这种协调和拮抗会导致人心在波动中稳定。 勇猛众生，立地成佛。大彻大悟要用心，也要伴随破坏。彻悟总要破东西，人妖失去才能悟，得到幸福不会彻悟。佛祖就是在极度疲惫中得悟-穷极生智。 真勇是毫不费力的，假勇是心怀侥幸的。 正确的人生观是正确的人生的基石： 正确的观念，树立人生的基本盘。 心灵鸡汤，能够补充能量。 开示能够把扰乱的能量，导入正轨。 睡眠的 ROI 特别高。 人只有顺从自己的命运，得到这种心境才是得到真正的信仰。 欲望和恐怖是人的主要心理活动-这是常人的一生和呼吸一样。 人要认知自己的欲望和恐怖，要理解相对性原理。要引入参照物，要知道没有上则没有下，如果没有生的欲望也就没有死的恐怖。 如果不能理解死的恐怖，也就无法理解生的欲望。人在 100 岁死和 200 岁死，恐怖是一样大的。 无知无觉过一生是一种生存策略，真正的对自我有期待的人，也是一种生存策略。 世界的存在是由生命的体验感知的。思考和时间让变化的世界得已被感知。没有“有”，我们无法建立无。时间是第四量纲。 痛点要用外部观察来解决。反过来察觉自己当时真实的状态，那种状态，叫作初衷。初衷必须两次体察才能理解。"},{"title":"工作居住证","date":"2021-12-29T06:04:24.000Z","url":"/2021/12/29/%E5%B7%A5%E4%BD%9C%E5%B1%85%E4%BD%8F%E8%AF%81/","tags":["生活"],"content":"北京人才工作右下角，在线办事。"},{"title":"故障应急响应方案","date":"2021-12-28T06:12:55.000Z","url":"/2021/12/28/%E6%95%85%E9%9A%9C%E5%BA%94%E6%80%A5%E5%93%8D%E5%BA%94%E6%96%B9%E6%A1%88/","tags":["运维"],"content":"线上事件运营一个线上事件运营平台可以让自己在处理故障的时候按照 SOP 来操作。 执行步骤前置环节：确认是否影响用户，确认是否有告警。 有告警/客诉，但未生成需要运营的事件，可以在事件运营平台手动创建和发起需运营事件。 有告警/客诉，可以点击告警生成需运营事件，进而拉群、开会处理。 正式操作 事件创建。 定级。 公告。 拉会。 指定处理人、专家、协同处理。 添加时间线信息。 处理完成。 公告处理完成。 运营反馈事件是否有效。 事件运营平台基本结构.xmind 先通报，后处理。先止损，后定位。有变更，先回滚。预定级要慎重（与最终定级无关系）。 COE任何公司，发生故障在所难免。 Accident is inevitable。 �错误是学习和改进的机会 COE 一个管理故障生命周期，避免错误重复发生的运营管理工具： 追溯故障根因 追踪修复进展 管理 todo 项。 写好 COE 需要软性素质和发散思维。COE 不是 issue，是把问题暴露出来，帮助我们深挖风险点，提升服务稳定性。对问题进行深入剖析是技术团队的基本素质。写 COE 可以帮我们挽回客户的信心，也可以帮助 Leader 制定工作计划。 写好 COE 是工程师复盘意识良好的体现。 运营关键信息coe 特别容易被忽略的是事实 tag、分析和 todo。因为这些东西需要透彻，才能统计、关联，支持运营。复杂的东西需要支持透视，所以遇到复杂的情形我们需要强调结构。撰写 COE 是一个特别需要强调写作基本功的东西。 影响和定级： 影响：客户视角和技术视角。不管哪个视角，最好直接定量。要有现象，也要有量化指标。量化指标要有量化逻辑。 定级S1、S2、S3、S4、S9 和 Event。 故障类型： 架构设计 第三方 数据库 中间件 业务方逻辑 线上运维误操作 时间点：时间线能够帮助我们理解事故发生中的关键时长，让我们知道我们的系统哪些做得好，哪些不足。时间线决定了原因分析的质量。 时间线最好有截图。 时间跨度最好在 10 分钟内，有 action 没有落实到时间点上会困扰 5 why 分析法 步骤：发生、发现、通知、定位、开始处理、处理完成、影响消除。 发现方/定位方 责任分摊 RootCause：原因分析决定了经验教训和正确做法的质量。 5 why 分析法，从一个问题的答案往后问问题。 要用流程图或者代码逻辑讲明白出根因的逻辑和正常的逻辑。 不要受限于主观心态，或者流于表面。 要环环相扣。 受影响方 故障原因分类 相关先知风险 复盘 review： TODO 项要高于问题本身，这才是我们吸取教训的表现。 TODO 最好形成需求或者 Task，被研发管理工具管理起来。 有共性的问题有没有办法建立规范、机制和工具来解决？ COE BRbar raiser 是跳高比赛里负责抬高杆子的人。 BR 的关注点： 事故的发现和处理的各个时间线是否真的正确：定位的时间和手段是否符合预期？ 事故的处理流程是否符合规范：告警、通知和处理手段是否都使用恰当？ 故障中的原因是否被准确找到了，有没有建立对共性问题的认知，原因分析是否深刻？ TODO 是否满足 SMART 原则，形成确实的抓手。 告警规范 级别 含义 响应时长要求 恢复时长 告警升级 触达渠道 最大发送次数 说明 举例 P0 高危 小于等于 3 mins 小于等于 10 mins 配置升级 电话+IM &lt;=10 明确对线上核心业务流程有影响，多为业务指标，或者核心接口对外指标，以客户为中心为原则，告警即表示对用户造成了实际影响，监控规则保持高敏感度和告警高处理率。如用户订单量、支付成功率支付成功时长等。1. 核心业务或核心接口确实造成了业务损失/客诉。2. 中间件崩溃。 1. 客诉来电入队量连续3分钟（连续 x 分钟，意味着告警实际上是升级过的）上涨30%2. 消息队列积压 200000 条消息。3. 电商生单成功数最近5分钟连续3分钟异常（若为核心大盘推荐使用智能告警）4. 核心接口5分钟可用性低于2个9。5. 核心接口5分钟tp99时延高于50ms。 P1 严重 小于等于 10 mins 小于等于 30 mins 配置升级 电话+IM &lt;=10 明确对线上业务有影响的错误或异常，但影响可控。如服务可降级功能对应指标出现波动、系统出现必须修复的错误、服务运行出现异常，不及时修复会导致业务损失。例如：核心服务所有接口 rpc 成功率下跌、sql 执行失败次数增长。1. 核心业务或核心接口即将造成业务损失/客诉。2. 中间件开始出现严重不稳定。 1. 客诉来电入队量连续1分钟上涨30%2. 消息队列积压 100000 条消息。3. sql 成功率&lt;=90%且失败数&gt;104. 核心接口5分钟可用性低于3个9。5. 核心接口5分钟tp999时延高于50ms。 P2 错误 小于等于 30 mins 小于等于 1 h 无要求 IM &lt;=5 风险报警，系统运行出现了风险，不一定会对业务有明确影响，但需要保持关注和查清原因并修复。1. 非核心业务或非核心接口开始不可用。2. 中间件开始出现不稳定。 1. 某些查询接口，如 nlp 接口可用性低于 99%，且持续 10 分钟异常。2. 消息队列积压 50000 条消息。3. 核心接口5分钟可用性低于4个9。4. 核心接口5分钟tp9999时延高于50ms。 p3 警告 小于等于 3 h 小于等于 1 d 无要求 IM &lt;=5 低风险警告，有需要关注的问题，但时效性不高。1. 系统有些可以自愈的环节开始出现需要频繁自愈的情况。 1. 消息队列积压 开始出现 10000 条消息以内的积压（这种告警一般可以自愈）。2. 清结算系统出现打款积压（这种告警一般可以忍耐时间较久）。 安全生产准则 六要： 要测试 要周知 要审核 要灰度 要观测 要可回滚 两不要： 不要瞒报故障 不要违规变更数据 "},{"title":"面向测试编程","date":"2021-12-28T03:27:55.000Z","url":"/2021/12/28/%E9%9D%A2%E5%90%91%E6%B5%8B%E8%AF%95%E7%BC%96%E7%A8%8B/","tags":["测试"],"content":"Case 分类参考： What is the explicit difference between an edge case and a corner case? What are the difference between an edge case, a corner case, a base case and a boundary case? edge caseAn edge case is a problem or situation that occurs only at an extreme (maximum or minimum) operating parameter. For example, a stereo speaker might noticeably distort audio when played at its maximum rated volume, even in the absence of other extreme settings or conditions. 边缘情况是仅在极端（最大或最小）操作参数下发生的问题或情况。例如，立体声扬声器在以最大额定音量播放时可能会明显失真，即使没有其他极端设置或条件。 corner caseCorner case occurs outside of normal operating parameters, specifically when multiple environmental variables or conditions are simultaneously at extreme levels, even though each parameter is within the specified range for that parameter. (The “outside normal operating parameters” obviously means something like “outside typical combination of operating parameters”, not strictly “outside allowed operating parameters”. That is, you’re still within the valid parameter space, but near its corner.) 在工程中，极端情况 corner case（或病理情况 pathological case）涉及仅在正常操作参数之外发生的问题或情况——特别是当多个环境变量或条件同时处于极端水平时表现出来的问题或情况，即使每个参数都在该参数的指定的范围内。 boundary caseBoundary case occurs when one of inputs is at or just beyond maximum or minimum limits. 当输入之一处于或刚好超过最大或最小限制时，就会发生边界情况。我们常说的 corner case，很大一部分是 boundary case。 base caseBase case is where Recursion ends. 基本情况是递归结束的地方。"},{"title":"持续交付的思想和玩法","date":"2021-12-28T03:13:38.000Z","url":"/2021/12/28/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E7%9A%84%E6%80%9D%E6%83%B3%E5%92%8C%E7%8E%A9%E6%B3%95/","tags":["持续交付"],"content":"环境治理根据 wikipedia，工业界总是把开发环境和生产环境分离出来，中间还有若干个 stages。 结构化的发布管理允许分阶段部署（rollout），测试和在遇到问题时回滚（rollback）。 常见的环境有： 4-tier architecture is development, testing, model, production (DEV, TEST, MODL, PROD), Quality Control (QC), for acceptance testing; sandbox or experimental (EXP) Another common architecture is development, testing, acceptance and production (DTAP) st 的设计初衷可能是为了搭建一个内部使用的验收测试环境。 Development构造对软件的变动的环境，大多数情况下仅仅是开发者的工作站（workstation）。在这个环境里实验变更和进行单元测试。集成环境有时候也可以被认为是开发环境，在集成环境里专门对 repo 里的源代码 copy 进行构建和单元测试。 Testing执行对新代码的自动化或非自动化测试的环境，在这个环境里测试失败需要联系开发者消除错误，在这个环境测试全通过则可以把代码晋升到下一个部署环境。 StagingA stage or staging environment is an environment for testing that exactly resembles a production environment. Staging 环境要尽可能地合生产环境相似，达到 replicate 的程度。它寻求尽可能完全镜像化生产环境，可能会连接生产的服务和数据，比如数据库（大多数公司，生产、预发、staging 使用一套数据库）。这类环境通常处于一套远程服务器上，和 dev 和 testing 有本质区别，会真正影响系统的网络活动。 staging 环境的首要用途是在应用到生产环境之前，测试安装、配置和迁移脚本和过程。 staging 环境可以拿来做性能测试-但这对 staging 环境的物理机条件有一定要求（可能需要完全复制生产环境的物理配置），staging 环境唯一的好处是可以隔离生产流量。 staging 环境也可以被用来预览新特性或者挑选顾客进行新的外部依赖的新版本集成-这一功能事实上就是大家经常用来进行 ab testing 的灰度环境（Gray/Grey/Canary）。 staging 环境没有真实消费者流量。 staging 环境可以直连生产数据库，也可以专做一个 staging db，专门存放 dummy value。 生产环境经常被称作“活/直播”环境，因为它直接和真实的消费者交互。 除非拥有热替换/热部署的能力，否则安装新代码总是会引起重启，这要求应用有被打断的功能，我们要么在 LB 背后逐一重启应用，要么提前重启应用后再切换流量。 为了防止 last-minute problems 能被发现，部署的 fraction 不一样。 分支模型分支模型.xmind pipeline 设计CI source：code light merge build test &amp; deploy： scan JUnit test pod deployment Test：automation interface acceptance test Test source：code light merge build test &amp; deploy： pod deployment Test： 接口自动化测试 手工测试 迭代覆盖率卡点 STAGING SOURCE：在不同的场景，这个节点有不同的含义，有时候意味着自动 lightMerge，有时候意味着 code review Approval Deployment： build deploy 验收 Prod SOURCE Build： Deployment deploy 验收 构建系统发布前检查 与干系人确认允许上线（PM/QA等） 无遗留待解决问题（sonar问题/过程缺陷等），达到准出条件 依赖的jar包已升级为正式版本 代码依赖方已发布 数据库变更已执行 动态配置变更已配置 缓存变更已配置 KMS变更已配置 消息队列变更已配置 下游服务鉴权已配置 任务平台任务已配置 回滚预案已明确 自测相关自测 checklist 本次需求改动所有对应的正向和逆向用例 需求影响的其他范围业务场景回归 历史接口和场景用例通过 上下游集成测试通过 涉及接口压测的，压测结果符合预期 测试模块 测试场景 操作步骤 期望结果 实际结果 是否通过 1 2 3 4 5 6 自测报告 自测报告 自测负责人(*) QA对接人(*) 相关成员(*) 自测结论(*) 测试通过 方案设计与改动点 1.技术方案设计链接2.详细改动点 自测记录(*) 自测用例执行结果 问题和风险 说明：无 CI或自测流水线(*) 通过 CI或研发自测流水线链接 预发流水线(*) 通过 预发流水线链接 联调测试 无 若有性能测试，写明性能测试结果 单元测试认识单元测试定义最容易被搞混的就是单元测试的定义。 在计算机编程中，单元测试（英语：Unit Testing）又称为模块测试，是针对程序模块（软件设计的最小单位）来进行正确性检验的测试工作。程序单元是应用的最小可测试部件。在过程化编程中，一个单元就是单个程序、函数、过程等；对于面向对象编程，最小单元就是方法，包括基类（超类）、抽象类、或者派生类（子类）中的方法。 四种测试的区别 测试类型 测试粒度 测试目的 测试人员 测试时间 测试方法 单元测试 最小（模块内部） 消除局部模块的逻辑和功能上的缺陷 开发人员 开发阶段 白盒测试 集成测试 居中（模块间） 找出与软件设计相关的程序结构、模块调用关系、模块间接口方面的问题 测试人员 测试阶段 黑盒测试 系统测试 大（整个系统） 对整个系统进行一系列的整体、有效性测试 测试人员 测试阶段 黑盒测试 验收测试 最大（产品） 确保产品符合交付标准 产品或用户 验收阶段 黑盒测试 单元测试的原因 注意看单元测试发现的缺陷最多而修复成本最低，因为它是开发中的测试。 越接近界面，测试要越写越少。 有团队做过实验，进行单元测试，编码阶段时间增加，但整体交付时间变少。 最佳实践 RD 是单测第一责任人。 要在开发前设计单元测试，边开发边写单元测试。 边写边验证，本地程序打包时批量验证，CI 流水线批量验证。 原则 A：Automatic，全自动执行，非交互式用例可以被定期执行-daily、nightly、push hook。应该使用自动断言来代替人肉检查。 I：Independent，用例之间绝不可相互调用，也不能有依赖关系。 R：Repeatable，可重复执行，不依赖于网络、服务、中间件。 如何做单元测试统一的单元测试框架 JUnit AssertJ Mockito Jacoco 正确的验证策略验证结果：断言检查结果是否符合预期 验证交互：是否调用了期望调用的方法 合理的 MOCK 与测试方法FAKEFake 是那些包含了生产环境下具体实现的简化版本的对象。 StubStub 是那些包含了预定义好的数据并且在测试时返回给调用者的对象。Stub 常被用于我们不希望返回真实数据或者造成其他副作用的场景。 Stub 是一个真正的有限功能的 proxy。 MockMock 代指那些仅记录它们的调用信息的对象，在测试断言中我们需要验证 Mock 被进行了符合期望的调用。 Mock 是一个被录制的对象。 mock 实践如何测试 controller 层MockMvcBuilder 即可。 如何测试 Dao 层在 test/resources 里引入 h2。 参数化测试@ParameterizedTest@CsvSource 可衡量的用例质量测试组件设计执行报告：有效性分析、执行成功率、测试覆盖率、有效测试占比。 自动化测试生成工具怎样覆盖数值边界条件？"},{"title":"Surefire、Failsafe、Jacoco 与 maven 插件","date":"2021-12-27T11:45:35.000Z","url":"/2021/12/27/Surefire%E3%80%81Failsafe%E3%80%81Jacoco-%E4%B8%8E-maven-%E6%8F%92%E4%BB%B6/","tags":["Java","Maven","测试"],"content":"Apache Maven SurefireApache Maven Surefire 本身是一个测试框架。 Maven Surefire Plugin 和 Maven Failsafe Plugin 都是这个项目的模块。 surefire 插件surefire 是在 maven 的构建生命周期里面，test phase 执行单元测试的插件。surefire 的意思是“完全，一定成功的”。任何单元测试失败，都会导致构建失败。surefire 跑测试失败，会在现场留下名如hs_err*的文件。 用法这个插件只有一个 goal，就是 test。 因此，使用它都不需要配置什么 configuration 和 phase。 它默认就会在 test phase 被执行： 不管底层的 test provider 是 JUnit 还是 TestNG，甚至只是一个 pojo，它都可以运行测试。 对于pojo，插件可以自动运行类里面的 public testxxx 方法，也可以使用 JDK 1.4 时代以后使用的断言。 对于 JUnit 之类的 test provider，可以使用以下配置进行并行测试： 类路径太长问题 整体而言，就是有些 OS 的命令行不允许太长的类路径。 解决这个问题的思路是，不在命令行内传递类路径，而使用进程内部的参数传递机制。由此诞生的解决方案有： 单独的类加载器。这样可以通过执行一个伪的 booter 程序来绕开类路径的直接限制，在程序内部再 load 我们的目标程序。这个方法也有缺点。首先，java.class.path 这个系统变量不会包括启动 jar。如果应用程序需要关心这个点，可能会导致问题。其次，程序内部可能会调用Classloader.getSystemClassLoader()而不是使用缺省的类加载器（也就是我们这个 isolated 类加载器）来加载特定的类，这会导致？问题（日后专文讨论）。 使用一个 Manifest-Only 的 Jar。这个 Jar 几乎为空，只有一个MANIFEST.MF 文件。JVM 会把这个清单文件里的类路径 honor 起来当做 directive。比如我们可以用一个单独的 Class-Path 的 attribute 来填写我们的很长的类路径。 failsafe 插件failsafe 是在 maven 的构建生命周期里面，test phase 执行集成测试的插件。failsafe 看起来是 surefire 的同义词，但事实上它使用更安全的方式运作。集成测试的失败，和构建过程解耦了，构建不会因此失败。 JaCoCoJaCoCo 本质上是是一个 java agent，基于 Java 的 Instrumentation API。可以对类文件进行 on-the-fly 的 instrumentation。它是在 class loading 的阶段通过 in memory 字节码增强的形式，进行类型补强。 JaCoCo 本身支持三种数据采集模式： 写入文件系统 作为一个 server 让其他客户端采集 作为一个 client 去连接某个 TCP 端点获取数据 JMX 的接口本身是没有鉴权和授权机制的，所以使用的时候要分清什么是 trusted server。 JaCoCo java agentJaCoCo 以一个 jar 的形式发布。下载地址，注意它的发布包有 osgi bundle的版本。当做 javaagent 使用，我们应该使用jacocoagent.jar，如果使用它的命令行接口，我们应该使用 jacococli.jar 。它遵循通常的 Java agent 的启动命令语法： 但如果我们使用 JaCoCo Ant tasks 或者 JaCoCo Maven plug-in javaagent 可用的 options 见这个表格。 JaCoCo Maven plugin要使用 jacoco 的插件，第一步是获取 maven 的的引用： 这个插件自带的 goal 分别是： help prepare-agent(最重要的 goal，大部分情况下只使用这个 goal) prepare-agent-integration merge report-aggregate check dump instrument restore-instrumented-classes 使用这个插件最起码要配的属性： 然后在使用插件的时候，我们引用了这个 path 上面这个 goal 的主要用处就是准备一个 maven property，用来给其他插件作为 VM argument。详细的含义见这里，在这个例子里，argLine 是一个专门为 surefire 准备的 maven property。 这样下面的 surefire 插件本身就可以把这个生成的 maven property 内插进自己的命令行参数里面： 更详细的配置（包含如何写 report） 参考资料 What is the difference between the Maven Surefire and Maven Failsafe plugins? "},{"title":"日程管理模板","date":"2021-12-24T06:59:04.000Z","url":"/2021/12/24/%E6%97%A5%E7%A8%8B%E7%AE%A1%E7%90%86%E6%A8%A1%E6%9D%BF/","tags":["管理"],"content":" 分类 本日 明天 本周 本月 本半年 本年 个人+组织 换行换行 个人：需要消费的东西 个人：对别人的承诺/责任 个人：需要干掉的东西 个人：生活上的下一步 个人：需要掌握的技能 组织：基本任务 个人：基本功锻炼 "},{"title":"领导梯队笔记","date":"2021-12-16T06:54:14.000Z","url":"/2021/12/16/%E9%A2%86%E5%AF%BC%E6%A2%AF%E9%98%9F%E7%AC%94%E8%AE%B0/","tags":["管理"],"content":"何谓领导梯队定义领导梯队：英文(leadership pipeline)应该更合适，不同层级更像是一个管道，会流转会转弯。这个转弯非常重要，每个人不是通过走直线，而是需要通过转折完成转变。在每一层级都需要不同的工作技能、时间分配方式、价值导向。如果你不能很好地意识到这个转变，就不利于完成这个转变。在公司里面如果某个层级出现问题，这级管道堵塞了，那么剩下的都会出问题。因为人才培养除了自己努力，直接上级是起很重要作用的，不然会阻碍下级的提升，所以有一级管道堵住了后面就会没有水。 比较科学的组织结构，是Enterprise-BG-BU。 管理自己——管理他人——管理管理者——管理职能(FM)——管理事业部(BM)——管理事业群(BGM)——管理企业(EM) 德鲁克说过：没有能力或者不愿意因新职位的需求而做出改变。管理者继续沿用先前的成功方法二不能进化，几乎是注定要失败的。德鲁克还说：管理本质上不是science（科学），而是practice（实践）。没有实践并不能真的学会。所以实践是关键。但理论框架体系的支撑也很重要，它决定了最终成就的高度。《领导梯队》提高了认知起点，不用在很低水平去反复摸索，然后通过实践可以站稳在这个起点上，再看是否有机会往前推进。这是这本书的意义。 有几个门槛特别有意思： 从 MS 到 MO：从成就自己到成就他人。 从 MO 到 MM：从管理业余选手到管理专业选手，被管理者也有管理意识。 从 MM 到 MF：要很懂，做到这个 function 里特别特别懂的人，能压得住事情。 从 MF 到 MB：特别特别困难。一个集团要有自己的总经理发展计划，能够做职能的轮岗，通过转换大量实践。FM 是可以转成 GFM 的，也可以转成 BM。当一个 FM 可能会是最懂这个 function 的人，但 BM 要相信自己的 FM 比自己更懂这个 function。BM不比下属更懂专业领域事情的时候，BM怎样建设和团结这样的团队，就成为至关重要的事情（这是一种“能上能下”）。一旦成为BM，做决策是责无旁贷的。其实往上推也不可能做出太好的决策，BGM能给出一些辅助意见或者经验积累，但是上一层级是没有BM有那么全面信息的。所以指望上一级帮你做各种决策，短期看来OK，长期也是搞不好业务的。BM是一个信息最聚集的节点，有大量的信息。信息通过传递总会有大量的损失，所以必须BM够强，能够接受各种信息，抗住各种压力，做出各种决策。一方面要信息输入，另一方面要信息输出。哪怕这个BM不是非常善于言辞，不喜欢高调出镜，也必须有一定的 visibility 的能力。能把想清楚的事情给其他人讲清楚，是最累，最有挫折感的事情。不要忽视短期不创造价值的方向（人士和财务），不要忽视自己擅长的领域（重视自己不擅长的领域是一种进步，重视自己擅长的领域的下属是一种更难的进步）。 从 MB 到 BGM：？ 一个 business group 里面会有几个事业部，BGM也会需要 group 层面的职能 head，比较典型的是财务、人力资源，也可以有技术、产品、设计、品牌等。再往上的话，可以发展为整个企业的某一个 function manager，比如 CFO 是公司整个财务 function 的 EFM 。BM 和 GFM 之间是有可能转换的；BGM 和 EFM 之间也有可能转换的。 BM 是一个特别重要的阶段，要真正为损益表负责。商业一方面是创造，一方面是竞争，战争也是竞争，是赌注最大的竞争。《孙子兵法》开篇就说，“兵者，国之大事，死生之地，存亡之道，不可不察也”，说的是战争的胜败赌注太大了，不可不重视。“道、天、地、将、法”，总经理项目讲的就是“将”的部分。《孙子兵法》讲怎么选将，观点非常清楚，“智、信、仁、勇、严”，“智”放在了第一位，作为一个将领“智”是非常重要的。所谓的智是热爱思考、懂得思考、懂得训练思考、懂得在思考中运用智慧。成为一个 BM 的过程非常复杂，所以智既依赖于天赋，也依赖于训练。要正面认知到智的重要性，也要通过行动改变自己的思考。要平和地看待自己还不懂的很多东西，要平和看待很多事情的信息量非常复杂。这也是懂得思考的表现之一。 聪明程度不变的前提下，做事的机会却发生了天翻地覆的变化。以前没有机会，人就没有办法通过实践去领悟，也没有人来 coach 他的职业素养。各行各业，全时段都有无数聪明的人。国运非常重要，时时刻刻都会变。本来商业社会里面要有人才培养有流动，整个体系才是比较完备的（互联网行业有一个好处是 IBM 、微软和 Google 之前培养了不错的工程师和产品经理，这些人才是有的。在后来中国互联网兴起的时候，这些人可以转移过来，所以给中国互联网提供了产品经理和工程师。）。人不能在一个有清晰的晋升通道的环境里待着，最后可能浪费自己的天赋。 很多人没有坐过一个特定的位置，或者名义上坐过一个位置，这都是不够的，一个位置的权责不完整。根据“彼得定律”，一个人总是被升到不能胜任的职位。如果企业发展，能够胜任的人总是能够晋升到更高的位置。如果公司没有大发展的话，那么最后剩下的都是不胜任的人。这是一个听起来很荒谬但是逻辑上很清晰的事情。胜任的领导者又可以分两类，一类是可以开创新业务，另一类是能够接管和持续发展原有业务。只有能创业才能守业。如果一个领导者不具备从 0 到 1 创立新业务的能力，只去守业务的话，可能只是短期OK，中长期来看如果不能足够敏锐地感受到变化，就会出问题。 要有耐心。一个组织要相信一个周期才能成一件事，资源不够对一个人没有耐心也没办法。一个人如果急于获得进展，换方向而无积累，本身也不利于这个人的发展。 另一种角度的导读个人贡献者职业意识、专业技能、高绩效表现。可能还需要加上项目管理能力，沟通软技能等其他 skill set。 一线经理 领导技能 工作计划 知人善任 分配任务 激励员工 教练辅导 绩效评估 时间管理 部分时间用在管理工作上 工作理念 重视管理工作而不是亲力亲为 通过他人，完成任务 当我们没有这么做的时候，我们是不是事后想一想，如果我们这么做，会不会更好。 在第一阶段，一线经理的转型会遇到各种挑战，忽略与直接下属的沟通重要性，不愿意花时间去倾听下属的意见，还是按照以往的工作套路去完成任务。更多的时候是直接帮助下属完成工作，事必亲躬，而不是辅导下属如何去做。 无法提高下属的胜任力是一线经理在转型时遇到的关键挑战，这主要体现在以下几个方面： 1）把下属提出的问题当成是障碍；2）补救下属工作失误，而非教会如何正确去完成挑战性工作；3）拒绝与下属分享成功，逃避对下属的问题和失败；4）没有给予足够的支持和建立员工的文化价值观。 一个好的领导者如果不能把机制建立起来是无用的。 部门总监 领导技能 选拔人才担任一线经理 为一线经理分配管理工作 教练辅导 评估一线经理的进步 超越部门，全局性考虑，有效协作 时间管理 主要时间用在管理工作上 工作理念 管理工作工作比个人贡献重要 重视其他部门的价值和公司整体利益 事业部副总经理 领导技能 新的、高超的沟通技巧 制定业务战略实施计划 与其他部门协作、同时争夺资源 时间管理 花时间学习本专业以外的知识 工作理念 大局意识 每一级都要给下一级以辅导，不过初级的管理者要给任务的辅导，高级管理者要给管理的辅导。 事业部总经理 领导技能 制定业务战略规划 管理不同职能部门 意识到各部门利益、顺畅沟通 与各方面的人共同工作 兼顾长远目标与短期目标 对支持性部门的欣赏 时间管理 花更多的时间分析、思考和沟通 工作理念 从盈利的角度考虑问题 从长远的角度考虑问题 集团高管 领导技能 评估财务预算和人员战略规划 教练辅导事业部经理 管理新的业务 评估业务的投资组合策略 冷静客观地评估管理的资源和核心能力 时间管理 花时间学习本专业以外的只是 工作理念 大局意识 长远思考 首席执行官 领导技能 善于平衡短期与长期利益，实现可持续发展 决定公司发展方向 确保执行到位 管理全球化背景下的公司 培育公司的软实力，激发全体员工的潜能 时间管理 不能忙于外部应酬，忽视内部管理 要在公司软实力建设方面投入时间 工作理念 推进公司渐进的变革与转型 长期与短期之间寻找平衡点并有效地执行 保持与董事会密切沟通与协作 倾听各利益相关方意见 "},{"title":"What is the best comment in source code you have ever encountered? [closed]","date":"2021-12-13T06:31:28.000Z","url":"/2021/12/13/What-is-the-best-comment-in-source-code-you-have-ever-encountered-closed/","tags":["软件工程","幽默"],"content":"What is the best comment in source code you have ever encountered? [closed]"},{"title":"MyBatis 关键代码分析","date":"2021-12-10T11:43:51.000Z","url":"/2021/12/10/MyBatis-%E5%85%B3%E9%94%AE%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","tags":["Java","数据库","MySQL","MyBatis"],"content":"如何创建 SqlSessionorg.apache.ibatis.session.defaults.DefaultSqlSessionFactory 缓存问题参考《深入浅出mybatis之缓存机制》。 xml 配置 org.apache.ibatis.executor.BaseExecutor 参数cacheEnabled控制MyBatis使用的执行器类型，cacheEnabled 为 false 使用 BaseExecutor，里面一样有一个 localCache。 参数localCacheScope控制的是BaseExecutor内部的缓存策略，确定 localCache 是否真的要被使用-它可以优化同一个 session 内的重复查询。 org.apache.ibatis.cache.CacheKey org.apache.ibatis.executor.CachingExecutor localCacheScope 控制的是一级缓存的配置，这是一个经常忘记被关闭的缓存的配置。 cacheEnabled 控制的是二级缓存的配置，人们往往记得关闭它。 这两个缓存可以被同时激活。 "},{"title":"JDBC 问题","date":"2021-12-08T08:26:34.000Z","url":"/2021/12/08/JDBC-%E9%97%AE%E9%A2%98/","tags":["MySQL Java"],"content":"参考《mysql JDBC URL参数解析》 ![JDBC 数据源配置.png](JDBC 数据源配置.png)[JDBC 数据源配置.xmind](JDBC 数据源配置.xmind)"},{"title":"理赔自动化问题","date":"2021-12-01T03:01:37.000Z","url":"/2021/12/01/%E7%90%86%E8%B5%94%E8%87%AA%E5%8A%A8%E5%8C%96%E9%97%AE%E9%A2%98/","tags":["保险","人工智能"],"content":" 撒餐 异物 未熟 变质 "},{"title":"安全体系建设","date":"2021-11-17T13:33:58.000Z","url":"/2021/11/17/%E5%AE%89%E5%85%A8%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE/","tags":["安全"],"content":"一种维度： 反爬 内容安全 营销安全 数据安全 产品安全 另一种维度： 账号安全：登录体系。 权限管理：权限矩阵。 日志规范：要打什么日志，日志要接入到哪里，什么操作必须记入日志，什么内容不能记入日志。 编码安全：不要使用有漏洞的组件。 移动安全 营销安全 数据安全 服务日常设计、上线和运维过程中要关注这些问题，回答好这些问题。"},{"title":"质效运营分类","date":"2021-11-16T12:33:23.000Z","url":"/2021/11/16/%E8%B4%A8%E6%95%88%E8%BF%90%E8%90%A5%E5%88%86%E7%B1%BB/","tags":["管理","研发效能"],"content":" 开发 测试 交付 运维 项目管理 关怀 "},{"title":"《2021年上半年互联网财产保险市场研究报告》解读","date":"2021-11-02T03:38:55.000Z","url":"/2021/11/02/%E3%80%8A2021%E5%B9%B4%E4%B8%8A%E5%8D%8A%E5%B9%B4%E4%BA%92%E8%81%94%E7%BD%91%E8%B4%A2%E4%BA%A7%E4%BF%9D%E9%99%A9%E5%B8%82%E5%9C%BA%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A%E3%80%8B%E8%A7%A3%E8%AF%BB/","tags":["保险"],"content":"《2021年上半年互联网财产保险市场研究报告》 背景：新冠疫情、平台经济反垄断。特点：业务恢复性增长、产品业态丰富化、市场发展规范化。 业务恢复性增长行业只有70余家财产保险公司。上半年互联网财产保险保费规模排名，前三名为【众安保险】、泰康在线和人保财险。 产品业态丰富互联网车险凭借其优于线下传统渠道的运营效率和客户服务体验，有效吸引了客户。这是互联网的技术优势。 互联网意外健康险（也被算在财产险里？）：规模占比超40%，产品创新迫在眉睫。尤其是短期健康险，由于其价格低、保额高、保障范围相对较广等特点，在近三年呈现高速增长。以百万医疗险、城市定制型补充医疗保险（以下简称“惠民保”）等为代表的短期健康险的逐步普及，为提高大众风险保障意识起到了积极作用。 互联网信用保证险：助力实体经济，保费实现高速增长。 场景保险值得注意的有： 酒店取消险。 退货运费险。 宠物保险。 这些保险要解决数据积累、风险识别、理赔标准建立、反欺诈管控、服务提升等问题。特别要小心逆选择。 《互联网保险业务监管办法》下发后，行业经营更加规范化，专业中介机构保费占比上升。2021年上半年，互联网财产保险业务各渠道保费占比呈差异化发展，其中，专业中介渠道累计保费收入为214亿元，占比为45%，较2020年底提升13个百分点；保险公司自营平台累计保费收入为104亿元，占比为22%，较2020年底下滑2个百分点；营销宣传引流累计保费收入为150亿元，占比为32%，较2020年底下滑10个百分点。 互联网财产保险凭借其普惠性、易触达等优势，有效满足广大人民群众多元化的保障需求，真正实现保险业经济社会发展的稳定器作用。 市场发展规范化互联网保险的优势 效率高。 体验好。 易触达 科技引领变革。 这都是技术带来的边际效应。 政策背景《中共中央关于制定国民经济和社会发展第十四个五年规划和二〇三五年远景目标的建议》提到，健全多层次社会保障体系，坚持应保尽保原则，按照兜底线、织密网、建机制的要求，加快健全覆盖全民、统筹城乡、公平统一、可持续的多层次社会保障体系，这为接下来保险业向高质量发展、提升服务社会民生和经济发展水平的转型提供了重要着力点。 已知的挑战 行业自律不够，侵犯消费者权益。 大数据风控水平需要提升。 新产品风险大。 "},{"title":"标准研发流程","date":"2021-10-29T05:43:27.000Z","url":"/2021/10/29/%E6%A0%87%E5%87%86%E7%A0%94%E5%8F%91%E6%B5%81%E7%A8%8B/","tags":["管理","敏捷软件开发"],"content":"有 qa 的模式 需求阶段 需求收集 预沟通 需求梳理 需求澄清 开发阶段 技术方案设计及排期 开发/联调 代码评审 自测 提测 测试计划/用例准备 测试用例评审 测试阶段 功能测试 集成测试/回归 ST 回归（业务方 PM 验收） 部署阶段 发布阶段 无 qa 的模式 需求阶段 需求收集 预沟通 需求梳理 需求澄清 开发阶段 技术方案设计及排期 开发/联调 代码评审 自测流水线 测试阶段 自测：测试流水线 集成测试/回归 ST 回归：业务方 PM 验收 部署阶段 发布阶段 周报一本周重点关注事项下周重点关注事项业务进展架构升级稳定性提升线上问题团队建设个人思考周报二正文包括本周产出、下周计划和问题感想。 几点要求 要有总结提炼能力，不要写成流水账 说人话，底线是不是本组的人也能读懂。具体就是做什么事、目标是什么、进度是什么、问题是什么、有什么解决计划？ 复盘、思考才是进步的动力，每周强迫自己想点事情，我们的系统缺陷、流程协作、产品方向 细化标准 本周产出 比对上周计划，找到偏差 最TOP的3件事，避免流水账 每件事有头有尾 重点突出、结论先行、条理清晰 下周计划 忌空、忌瞎写 符合SMART原则 问题感想 站在Leader的角度看问题 个人认知迭代、成长收获、不足反思、印象深刻的事 给团队的建议 周报三本周产出 xxx事情，需求分析和设计完成，预计xx月xx号提测​正常 xxx事情，由于xxx原因，预计延迟一周，xx月xx日投放​延期 xxx事情，因为xxx问题不能进行联调，目前xxx进度未知，风险较大​严重Delay 下周计划 xxx开发，提测 xxx投放 跟进xxx不可用问题 团队问题 新人跟进培养情况 其他成员问题：成长辅导、状态等等。 问题感想 某某事情进展不顺，主要是由于项目管理缺失导致，并且暴露不及时，导致严重Delay，后续…… 另最近xx事情较多，我方系统能力不能与之对齐，建议增加xxx， xxxxx有什么看法？ 个人周报应在周五下班前发出，团队周报应在周五24点前完成并发出。"},{"title":"任务优先级排序","date":"2021-10-12T07:22:54.000Z","url":"/2021/10/12/%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%85%88%E7%BA%A7%E6%8E%92%E5%BA%8F/","tags":["管理"],"content":"1.线上正在发生的问题优先级最高，我们必须采取任何必要措施，确保所有问题的影响消除。2.已经达成承诺的需求次之，其中业务需求的优先级又高于技术需求。3.1上面交代的与组织要求有关的改进。3.2没有达成承诺的业务需求。4.没有达成承诺的技术需求。 其中 3 和 4 的优先级排序又受事情的 ddl 影响，按照对交付的预期进行灵活排序。 只要我们自己维护一个任务的优先级队列，然后每个正在做的事项，取得利益相关方的共识（比如一件事大家都认为是 p1，那么 p1 出现在某个工程师的优先级队列里就应该排序比大家公认的 p2 高）。"},{"title":"JDK 的广泛分支","date":"2021-10-09T07:56:17.000Z","url":"/2021/10/09/JDK-%E7%9A%84%E5%B9%BF%E6%B3%9B%E5%88%86%E6%94%AF/","tags":["JVM","Java","JDK"],"content":"Oracle Hospot JDKjava 8 特定版本以后就不再免费了。 Open JDK 是一种 adopt 的工程，和 Oracle Hospot JDK 只有少数有专利的源码的差别。 Eclipse Temurin JDKThe Eclipse Temurin™ project provides code and processes that support the building of runtime binaries and associated technologies that are high performance, enterprise-caliber, cross-platform, open-source licensed, and Java SE TCK-tested for general use across the Java ecosystem."},{"title":"Java 并发编程笔记","date":"2021-10-07T08:40:11.000Z","url":"/2021/10/07/Java-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/","tags":["JVM","Java"],"content":"写在前面的话并发编程最早的实践都在操作系统里。 理论和实践之间是有鸿沟的，要弥合这种鸿沟，通常需要我们去学习别人的实践。比如并发的标准设计思想来自于操作系统里的管程，我们应当学习管程，进而了解标准的并发模型。 juc.xmind JMMVolatile JUC 总体设计原则 依赖状态、队列和 CAS 操作来完成对同步机制的实现。 Doug Lea 特别热衷于使用顺序状态来表达初始、中间态和终态，往往使用 &lt;= 中间态当作初始态，&gt;= 中间态当作完成态（包括 normal 和 exceptional）。 有一些变量内存不安全，强依赖于 happen-before relation 的巧妙实现，也需要参考Volatile。 Doug Lea 的 if 条件写得非常复杂，不易于拆解，而且有些 if 的约束是隐藏在内部的 cas 和自旋里的。 Doug Lea 不喜欢写大括号。 Doug Lea 喜欢把 volatile 变量写在局部变量，减少多次对 volatile 变量的求值，避免对缓存机制的扰乱，也保证了变量的线程封闭性。 对于所有的计时等待而言，0 意味着无限等待 Unsafe 的应用JUC 强依赖于 Unsafe，它提供了硬件级别的CAS原子操作。通常 Unsafe 的使用模式是compareAndSwapXXX，一个典型的函数是： obj是我们要操作的目标对象 offset表示了目标对象中，对应的属性的内存偏移量 expect是进行比较的原值 update是拟写入的新值。 它需要获取 field： 进而获取 field 的偏移： 很多 AtomicXXX 原子类，底层都依赖于 Unsafe 的 CAS 操作。 函数式接口区别 Runnable 和 CallableRunnable 本身是不抛出异常的，但 Callable 本身耗时比较长，而且还会抛出异常（这个设计会最终导致我们进行函数式编程的时候，有时候我们需要在 Runnable 内部处理异常，有时候我们要在 Callable 外处理异常）： AQSJUC 有个 locks 包，所有的锁和基于锁的并发基础设施都在这个包里隐藏。这些数据结构被称为同步器，而同步器本身是为了并发安全而存在的（相应地应该也存在原子化的解决方案、隔离的解决方案，我们改天再探讨）。AQS 是为了实现同步器而设计的框架，作为 basis of a synchronizer，它提供了 queuing and blocking mechanic。 AQS虽然被定义为抽象类，但事实上它并不包含任何抽象方法。这是因为AQS是被设计来支持多种用途的，如果定义抽象方法，则子类在继承时必须要覆写所有的抽象方法，这显然是不合理的。所以AQS将一些需要子类覆写的方法都设计成protect方法，将其默认实现为抛出UnsupportedOperationException异常。如果子类使用到这些方法，但是没有覆写，则会抛出异常；如果子类没有使用到这些方法，则不需要做任何操作。 全部使用 protected 方法也是抽象类的设计方法之一。 AQS 的设计原则 Node 代表线程。 Node 组成的链表代表了所有与锁相关的线程。其中头结点代表了拥有锁的线程，而链表的其他部分意味着阻塞队列。等待队列遵循 FIFO 的原则，因此能够实现公平锁。能够实现公平锁是能够实现非公平锁的基础。 Node 的状态代表着线程-锁的关联状态，如线程是否取消争抢线程的锁。 AQS 自身的状态代表着锁的状态，这些状态都是 transient volatile 的，重点关注锁是被 acquired 还是 released 。锁操作的实质就是对状态的维护。这其中又大量使用 CAS 操作，CAS操作是最轻量的并发处理动作。 CAS操作保证了同一个时刻，只有一个线程能修改成功，从而保证了线程安全，CAS操作基本是由Unsafe工具类的compareAndSwapXXX来实现的；CAS采用的是乐观锁的思想，因此常常伴随着自旋，如果发现当前无法成功地执行CAS，则不断重试，直到成功为止，自旋的的表现形式通常是一个死循环for(;;)。 所有的状态都是 atomic 的，这些状态可以被序列化，但 queue 通常不能直接被序列化，需要序列化器实现 readObject 方法才行。 所有的“同步属性”，都是某个类内部的非公开内部帮助类（如 ReentrantLock 内部的 abstract static class Sync）。 aqs 不实现任何 synchronization interface，其他同步器或者具体锁真正需要做的是使用 acquireInterruptibly 等方法。就锁的获取操作而言，子类必须重写 tryAcquire方法。 互斥框架的标准伪代码 线程池 Pooling is the grouping together of resources (assets, equipment,personnel, effort, etc.) for the purposes of maximizing advantage orminimizing risk to the users. The term is used in finance, computingand equipment management.——wikipedia “池化”思想不仅仅能应用在计算机领域，在金融、设备、人员管理、工作管理等领域也有相关的应用。 在计算机领域中的表现为：统一管理IT资源，包括服务器、存储、和网络资源等等。通过共享资源，使用户在低投入中获益。除去线程池，还有其他比较典型的几种使用策略包括： 内存池(Memory Pooling)：预先申请内存，提升申请内存速度，减少内存碎片。 连接池(ConnectionPooling)：预先申请数据库连接，提升申请连接的速度，降低系统的开销。 实例池(ObjectPooling)：循环使用对象，减少资源在初始化和释放时的昂贵损耗。 Doug Lea 对线程池的期待有： 改善性能。 有界地利用资源（多次强调 bounds）。 提供统计。 线程池继承体系 Executor 接口将任务提交和任务执行进行解耦（decoupling the execution mechanic）。用户无需关注如何创建线程，如何调度线程（scheduling）来执行任务，用户只需提供 Runnable 对象，将任务的运行逻辑提交到执行器(Executor)中，由 Executor 框架完成线程的调配和任务的执行部分。 JUC 里所有的解耦设计都不一定是异步的，它只是解耦，所以执行器本身也是可以同步执行的： 一般而言可以认为，executor 会 spawns a new thread for each task. ExecutorService 接口增加了一些能力： 扩充执行任务的能力，补充可以为一个或一批异步任务生成 Future 的方法（）： 提供了管控线程池的方法，比如停止线程池的运行。 shutdown 拒绝接收任务，触发 rejection policy。shutdownNow 除了 shutdown 的功能以外，还会强制触发线程中断。 Memory consistency effects：future.get 满足 JSL 定义的 Memory consistency properties，也就是 happens before relation。 理解 happens before relation 一定不要按照硬件的工作方式来理解（Flushing model is fundamentally flawed (it is just not how hardware works)），最好从 JLS 的规范出发： AbstractExecutorService将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。 ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。 The Executors provides convenient factory methods for these Executors. 线程池如何维护自身状态线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，如下代码所示： ctl这个AtomicInteger类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。通过阅读线程池源代码也可以发现，经常出现要同时判断线程池运行状态和线程数量的情况。线程池也提供了若干方法去供用户获得线程池当前的运行状态、线程个数。这里都使用的是位运算的方式，相比于基本运算，速度也会快很多。 运行状态 状态描述 RUNNING 能接受新提交的任务，并且也能处理阻塞队列中的任务。 SHUTDOWN 关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。 STOP 不能接受新任务，【也不处理队列中的任务，会中断正在处理任务的线程。】增加了两条措施，是一个更严厉的状态，理论上只要线程被中断完，线程池就可以走向关闭 TIDYING 所有的任务都已终止了，workerCount (有效线程数) 为0，这个状态的意思不是整理中，而是整理完了。 TERMINATED 在terminated() 方法执行完后进入该状态。 其中 running 既是初始态，也是中间态，所以才有private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));作为初始化块的一部分。 尝试关闭线程池 线程池如何管理任务每个线程池的 Worker 管理的实质上是 FutureTask，它既是 callable，也是 future： 线程池使用一个把 Runnable 转变为 Callable 的适配器（Callable 转 Runnable 理论上也是容易做到的，但应该没有必要转换），来兼容把 Runnable 传进 submit 的场景： FutureTask 实现了 RunnableFuture，它本质上是一个携带 Runnable 和 state 的任务。 首先看它的状态： 值得一提的是，任务的中间状态是一个瞬态，它非常的短暂。而且任务的中间态并不代表任务正在执行，而是任务已经执行完了，正在设置最终的返回结果，所以可以这么说：只要state不处于 NEW 状态，就说明任务已经执行完毕。注意，这里的执行完毕是指传入的Callable对象的call方法执行完毕，或者抛出了异常。所以这里的COMPLETING的名字显得有点迷惑性，它并不意味着任务正在执行中，而意味着call方法已经执行完毕，正在设置任务执行的结果。 换言之，只有 NEW 状态才是 cancellable 的。 它的状态管理方法： 实际被工作线程调度的 run 方法： run 有一个重跑版本，这个版本会重复执行，但不会影响 get 的结果： 在 FutureTask 里有三类终态方法： 如果程序进入终态，则 get 终于可以得到合理的结果： 其中等待流程见： 然后就把outcome 通过 report 传出来： 任务执行提交任务调度 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务。 如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。 如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。 如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 任务缓冲任务缓冲模块是线程池能够管理任务的核心部分。线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是（阻塞的本质即为此）：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 名称 描述 ArrayBlockingQueue 一个用数组实现的有界阻塞队列，此队列按照先进先出(FIFO)的原则对元素进行排序。支持公平锁和非公平锁。 DelayQueue 一个实现PriorityBlockingQueue实现延迟获取的无界队列，在创建元素时，可以指定多久才能从队列中获取当前元素。只有延时期满后才能从队列中获取元素。 LinkedBlockingDeque 一个由链表结构组成的双向阻塞队列。队列头部和尾部都可以添加和移除元素，多线程并发时，可以将锁的竞争最多降到一半。 LinkedBlockingQueue 一个由链表结构组成的有界队列，此队列按照先进先出(FIFO)的原则对元素进行排序。此队列的默认长度为Integer.MAX_VALUE，所以默认创建的该队列有容量危险。 LinkedTransferQueue 一个由链表结构组成的无界阻塞队列，相当于其它队列，LinkedTransferQueue队列多了transfer和tryTransfer方法。 PriorityBlockingQueue 一个支持线程优先级排序的无界队列，默认自然序进行排序，也可以自定义实现compareTo()方法来指定元素排序规则，不能保证同优先级元素的顺序。 SynchronousQueue 一个不存储元素的阻塞队列，每一个put操作必须等待take操作，否则不能添加元素。支持公平锁和非公平锁。SynchronousQueue的一个使用场景是在线程池里。Executors.newCachedThreadPool()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。 任务申请 任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。 任务的执行主要有 submit-&gt;execute，submit 的主要逻辑是： execute 的主要逻辑是： 这需要用到尝试增加线程 线程池如何管理线程核心线程的 idle 不影响核心线程的创建；非核心线程的 idle time 会导致它们退出。 尝试增加线程注意 addWorker 只是 execute 的一个子分支而已。 Worker 可以被认为是线程和锁的结合体，它的使命就是不断地把 runnable 从缓冲队列里拿出来，放在自己的 thread 里执行，其中关键的方法是 addWorker： 线程执行 线程的执行强依赖于 worker 本身的实现： 在一个工作线程里，worker delegate 调用给线程池的 runWorker： 回收线程 Worker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反映线程现在的执行状态。 1.lock方法一旦获取了独占锁，表示当前线程正在执行任务中。2.如果正在执行任务，则不应该中断线程。 3.如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 4.线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。 线程池使用中可能遇到的问题线程池的调参有几个难点： 如果核心线程数过小，则吞吐可能不够，遇到流量矛刺可能导致 RejectExecutionException；但值得警惕的是，如果核心线程数很大，可能导致频繁的上下文切换和过多的资源消耗（不管是 cpu 时间片还是操作系统的内核线程）。 如果队列过长，导致请求数量增加时，大量任务堆积在队列中，任务执行时间过长，最终导致下游服务的大量调用超时失败。 那么，如何计算这些参数呢？有一个基本的原则是： 计算密集型的线程数本身应该尽量贴进 cpu 核数。 io 密集型的线程数要注意伸缩，要配合阻塞队列使用，要有承受拒绝失败的的准备。 我们常见的计算方式主要来自于《Java并发编程实战》： 现实中可选的线程数计算公式最好是取一个并发 qps 数和 cpu 数的折中。通常可以认为 单任务的 rt/1ms 可以得到单一线程的吞吐数，qps 除以吞吐数可以得到 qps 相应的线程数，但这个方案没有考虑cpu 核数和上下文切换的问题。所以这样算出来的线程数的实际 qps 表现应该低于理论 qps，但可以通过估算和压测不断让理论值逼近实际值。 线程池的可替换方案其他可替代方案，都不如线程池的调优方案成熟（在可以使用新技术的前提下，我们是否还有调优旧方案的魄力呢？）： 名称 描述 优势 劣势 Disruptor框架 线程池内部是通过一个工作队列去维护任务的执行的，它有一个根本性的缺陷：连续争用问题。也就是多个线程在申请任务时，为了合理地分配任务要付出锁资源，对比快速的任务执行来说，这部分申请的损耗是巨大的。高性能进程间消息库LMAX使用了一个叫作环形缓冲的数据结构，用这种这个特殊的数据结构替代队列，将会避免申请任务时出现的连续争用状况。 避免连续争用，性能更佳 缺乏线程管理的能力，使用场景较少 协程框架 协程是一种用户态的轻量级线程，其拥有自己的寄存器上下文和栈，当调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。这种切换上下文的方式要小于线程的开销。在瓶颈侧重IO的情况，使用协程获得并发性要优于使用线程。 侧重IO情况时，性能更佳。与多线程策略无冲突，可结合使用 在Java中缺乏成熟的应用 Actor框架 Actor模型通过维护多个Actor去处理并发的任务，它放弃了直接使用线程去获取并发性，而是自己定义了一系列系统组件应该如何动作和交互的通用规则，不需要开发者直接使用线程。通过在原生的线程或协程的级别上做了更高层次的封装，只需要开发者关心每个Actor的逻辑即可实现并发操作。由于避免了直接使用锁，很大程度解决了传统并发编程模式下大量依赖悲观锁导致的资源竞争情况。 无锁策略，性能更佳，避免直接使用线程，安全性更高 在Java中缺乏成熟的应用，内部复杂，难以排查和调试 缺乏管控能力就不适合调优。 最终解决方案通过监控线程池负载，制定告警策略： 线程池活跃度 = activeCount/maximumPoolSize。看看这个值是不是趋近于 1。 监控队列的capacity 和 size 的比例。 监控 RejectExecutionException 的出现。 加引入线程池动态管控能力，基于告警制定 sop，确定是否要动态调节线程数和拒绝策略。 如果还是解决不了问题，需要考虑全局动态扩容的方案。 参考资料： 《一行一行源码分析清楚AbstractQueuedSynchronizer》 《Java线程池实现原理及其在美团业务中的实践》 《Keep Coding》 "},{"title":"《亚马逊逆向工作法》札记","date":"2021-10-07T07:39:38.000Z","url":"/2021/10/07/%E3%80%8A%E4%BA%9A%E9%A9%AC%E9%80%8A%E9%80%86%E5%90%91%E5%B7%A5%E4%BD%9C%E6%B3%95%E3%80%8B%E6%9C%AD%E8%AE%B0/","tags":["亚马逊"],"content":" 复制亚马逊的准则未必能够复制亚马逊的创新文化。复制文化并不能习得文化，通过践行文化拿到结果，才能习得文化。 “我们坚信，股东的长期利益与客户利益完全一致”亚马逊企业文化的四方面描述：“顾客至尚”（Obsess Over Customers），“长期主义”（It’s All About the Long Term），“我们将继续同时从成功和失败中学习”（We will continue to learn from both our successes and our failures），“卓越运营”（Operational Excellence”）。 一家企业发展过程中有一些至关重要的时刻，一定要被经历，企业才能壮大起来。 学习亚马逊的逆向工作法，就是在经营框架搭建和业务日常管理中更多地关注可控输入指标（controllable input metrics）：在哪里收集这些指标？在哪里汇总这些指标？在哪里探讨这些指标？怎么归因这些问题？怎么优化这些指标？ 从指标推导经营框架的逻辑 结果指标意味着结果。 过程指标意味着中间可控。 原因指标意味着原因可控。 结果指标是有限的，中间指标是有限，影响力从大到小排序的。 那么控制这些中间指标的能力就是我们的核心能力，核心能力的排序应该参考影响力的排序（当然也应该考虑建设这些能力的 ROI）。 不要把中间指标当作原因指标。 业务模式的选择，决定了关键指标的多寡，和对指标的要求。价值链全环节的指标多，短环节的指标少。根据 STP 理论，我们的 segmentation 越小，我们做事情的难度可能也越小。 关注输入指标更多是一个理念，既可用于独立业务管理，也可用于部门、项目、个人的工作管理。可控的输入指标能让人更早地发现关键的信号，是更清晰的行动指南。而输出指标是输入指标影响下的结果，滞后、不直接可控、只显示结果而无法揭示原因。 虽然逆向工作法中强调“对可控输入指标的关注在任何层级都适用，不论哪个层级的管理者，从个人贡献者到CEO，都要详细了解并高度聚焦输入指标”，但亚马逊达到这种状态（如果是的话）也是经过了与之配套的漫长的时间投入和庞大的管理精力投入的。运动式的学习并不值得鼓励：深切领会和熟练运用输入指标并不容易，全面、猛然转向有可能出现“学走样”、“影响原有经营框架稳定性和业务动作延续性”的风险。 关注输入指标也不应仅停留在定义、监控乃至分析层面，而应该融入日常的业务管理和经营动作当中，融入OKR、绩效等管理工具当中，切实有效地改善输入指标。 如何找出这些指标？高手可以看出量变引起质变的东西。做业务模式有可能存在两种方法： 先建立经营框架，然后通过迭代指标，寻找对业务本质的理解。 先找到对业务本质的理解，然后梳理指标，依托指标建立经营框架，通过框架迭代运营，逼近商业本质的最优结果，或者迭代我们对商业本质的理解。 如果把 1 和 2 串起来，我们会发现它也可以组成一种增长飞轮。 指标的分类输出指标输出指标实际上是商业目标，是商家自身关心的，需要在长期商业活动里达成的目标。在亚马逊的增长飞轮里，输出指标只有一个，就是增长 Growth。 输出 指标应该保持关注，但不应该只关注 输出 指标的波动和归因。归因不只是从数学视角看，也要考虑一些对根因的理解（能从量变看出质变来）。 输入指标在亚马逊的输入指标里面，一个指标会驱动另一个指标，几个循环应该是： Selection（选品） -&gt; Customer Experience -&gt; Traffic（这里是流量的意思） -&gt; Sellers -&gt; Selection Growth -&gt; Lower Cost Structure -&gt; Lower Prices -&gt; Customer Experience 可以看出这个指标里飞轮的存在甚至可以让输出指标驱动输入指标。 增长可以解决成本的问题，优化价格又会带来更好的客户体验。所以长期主义本身是资本主义扩大化再生产的玩法。 相比输出指标，输入指标往往是更以客户为中心的。比如在零售中，用户会关心低价、更多商品选择、商品有货且能快速收货、能快速在App上找到所需商品、客服人员的服务效率，这些就是好的输入指标。用户不会关心公司的收入、客户数等，这些是输出指标。著名的“亚马逊飞轮”其实是在零售行业中输入指标和输出指标关系的集中体现：在一个闭环的体系内，一组可控的输入指标驱动了一个关键的输出指标（增长），强化任意一个输入指标，都能让飞轮转得更快。更好的客户体验-更多流量-更多卖家-更广选品-更好的客户体验，这个闭环驱动了增长，进而降低了成本，带来更低价格，从而提升客户体验。 可以看出亚马逊的增长飞轮只选取了 6 个输入指标，围绕一个输出指标转。 我们对输入指标的监控应该考虑输入指标对输出指标的作用周期可能会很长的问题（对于一些输入指标的持续关注和改善往往需要一些信念，这些信念通常来自于对用户价值的理解和追求），独立地监控、改善输入指标和独立地监控、改善输出指标，是同样重要的。 输入指标不能被简单地理解为过程指标，更恰当的类比是“原因指标”（输出是果，输入是因）。如果一定要跟过程指标联系的话，这里的过程应该指的是价值创造的过程，而不简单是用户转化过程、商品流通过程、数学加乘过程。在交易平台领域，比较典型的价值创造过程有：供给线上化、供给数字化、供给标准化、供给分级分类、用户连接、用户需求识别、用户需求表达、供给推荐/供需匹配、信用背书、风险分担、交易转化、履约交付、售后服务等等。 生活中输入指标的例子：多喝水，少熬夜，多读书。 第三种指标：观测型指标观测型指标指的是那些对输出指标有较大影响、但并不可控的指标。团队观测第三类指标，一方面可以帮助解释输出指标的变化，一方面在外部环境发生变化时能快速反应。 应该慎重把握观测型的使用范围。面对某个指标，首先应当尝试弄清楚它是什么层级、什么重要度的输出或输入指标，而不是轻易地归为观测型指标。即使归为观测型指标，也应该明确观测目的和预警逻辑，有助于我们理解观测型指标背后的业务含义。观测型指标不是思考尚不充分的借口或缓冲区。 如何使用指标框架亚马逊倡导，“不懈地聚焦于可控的输入指标（a relentless focus on input metrics），而非输出指标（output metrics）”。 对可控输入指标的关注在任何层级都适用，不论哪个层级的管理者，从个人贡献者到CEO，都要详细了解并高度聚焦输入指标，否则就无法正确认知和控制输出指标。正如亚马逊“Deliver Results”这条领导力原则所说，“领导者要聚焦于业务的关键输入指标，并保质保量地及时交付（leaders focus on the key inputs for their business and deliver them with the right quality and in a timely fashion）”。 可控输入指标不仅适用于成熟业务，对于新业务也是如此。亚马逊早期每个Two-pizza team成立时都需要跟S-Team开立项会，S-Team要确认团队有明确的目标（需要解决什么问题、有什么结果）、清晰的责任划分、明晰的进展衡量方式（选取哪些可控输入指标驱动团队达到目标、指标所需数据能否可靠地收集）。这个过程被称为instrumentation（工程词汇，指在自动化系统中建立起负责观测、衡量和控制的仪器和系统）。 第一步是定义输出指标、明确不同输出指标的目标和优先级，这一步容易被忽略，很多团队会直接从第二步甚至第三步开始。虽然输出指标通常比较有限，往往是围绕增长/规模、利润/盈亏的几个指标，但准确地定义它们、明确不同指标的合理目标和优先级往往是战略级问题。例如xx业务是“每天a单，每单赚x毛钱”还是“每天2a单，每单赚x块钱”，就是一个重要的战略选择。 第二步是定义客户。无需特别纠结某个群体是否是传统意义上的客户，还是回到输入指标的本质，如果这个群体的某个诉求是当下对于业务增长影响很关键的维度，就可以将其纳入输入指标的选取范围。 第三步是定义客户价值，无非是多快好省。注意，客户价值不是输出指标，也不是输入指标。输入指标是有排序的。 第四步是定义指标来衡量我们能在多大程度上满足第三步中的用户价值，这些指标往往就是一级输入指标。好的指标能够直接体现用户价值，有些指标难以获取，需要考虑成本问题，可以考虑替代方案，替代方案的精确性和有效性需要得到保证。比如我们算不出市占率出来，可以直接用自身规模来衡量一个业务。输入指标并不是从输出指标出发、做数学意义上的拆解产生的，但一定是对输出指标有最大影响的可控因素。建设收集所需数据的工具也要花不少时间精力，常常要从多个分散的系统里提取、处理、展示。这里不能妥协去降低标准，要做必要的投资，否则做业务就是在“盲飞”。深入地去看数据是怎么提取的有助于发现潜在问题。比如同样是衡量“有存货率（in-stock rate）”这个指标，你可以在每晚11点看一个截面数据，也可以看全天累计的数据，后者的数据收集成本显然更高，但它更准确地反映了客户在这一天中体验到的有存货情况，是更以客户为中心的（而不是数学拆解出来的）。 输入指标要做好分类、分层，尽量 MECE，考虑特定资源和组织能力的限制，输入指标不需要太多，但针对那些对输出指标影响很大的输入指标，不能有大类上的遗漏。 关注输入指标是一种实战心法，要在实操中跑通整个框架，清除 blocker。 按照亚马逊的定义-衡量-分析-改进-控制五步法(DMAIC)，国内的人容易做错的事情包括： 在衡量上偷工减料，没有办法去除噪声。 在分析上没有 dive deep，打破砂锅问到底。 在改进时盲动，在信息不完整的时候做不懂的事情。 不懂得只看异常，把正常指标的边界扩大，看数据不敏感。 正文札记引言亚马逊屡次处于失败的边缘，但屡次被拉起。Andy Jassy 原本是 AWS 的 ceo，现在是整个亚马逊的 ceo。 成为亚马逊人Jeff 在 2015 年的致股东信中写道：“你当然可以轻易地用纸和笔写下公司的企业文化，但是这么做并不能创造一种企业文化。”好的企业文化是活动的，它活在在人的身上，不断地起着化学作用。学会亚马逊的文化，比直接加入亚马逊这家公司更容易成为亚马逊人（如果加入亚马逊而学不会这些东西，恐怕也不能算是亚马逊人）。亚马逊文化有不少东西是他们自己发明的，也有不少是从其他经营方法里学习来的，比如 dive deep 的可能就是从丰田的精益制造的 5 why 里来的。 亚马逊的历史创造了他们的文化、机制和领导力准则。亚马逊人很早就预见到了有些种子会长成参天大树。 贝索斯很看重客户信誉，认为一个坏的客户信誉抵得上数百个好的客户信誉。 领导力准则历史性的增长导致了亚马逊需要建立一些机制，能够让公司从上到下贯彻创始人制定的标准。 如果要记住一些原则，而不是实践一些原则（如在日常工作中遵循高标准），这是公司文化没有融入公司的信号。 机制使用机制来贯彻领导力准则：op1 和 op2，S-Team Goals。 亚马逊有大量的、详细的目标，产生运营规划OP1，然后在一个短周期里生成年度规划 OP2。 S-Team Goals 有三个特点：数量异常多、细节水平高、进取性强。亚马逊认为能够完成 S-Team Goals 的四分之三就可以了。 抬杆者在招聘决策出现抬杆者之前，有出现野草般的扩张，新员工开始面试新员工是一个危险的信号。 录用相似的人会让团队视野狭隘，意见不充分，有可能招聘形形色色的人对团队来讲是好事。不合格的员工很快就会被同事识别出来。 一个好的招聘决策应该开会充分探讨信息，宝恒招聘决定正确。 单线程领导模型（Single Thread Leader）让员工兼职工作，可能会让真正重要的、困难的初创业务始终得不到高优处理。 快速创新要求团队快速创新，如果给予团队非常大的权限，他们就可以摆脱依赖，足够敏捷，但这需要坚持高标准。 公司大了以后如果我们花更多时间协调，而不是更多时间创造，我们可能就不够敏捷。工程人员不再能够独立完成工作的时候，他们就需要依赖于其他团队了。如果一个团队需要一些东西，但它自己无法自己创造，它就需要花时间协同。 亚马逊流速最快的地方是一个 Obidos 的村庄，这个地方流速最快是因为它最窄。一个员工经常要高速输出一些东西，除了证明他能力强，也证明了他可能成为系统里一个潜在的瓶颈（系统亦如是）。我们需要优化这个瓶颈。 软件架构的紧密耦合（tightly-coupled）会导致快速冲刺变成套袋赛跑-每个团队的步调注定是不一致的，拖慢整个系统不可避免。 鼓励创新意味着我们应该消除沟通，而不是优化沟通-通过消除来优化。Jeff 鼓励系统通过系统接口来交谈而不是邮件和会议。 亚马逊早期通过 NPI 来优化依赖问题，但项目价值的评审挫伤了士气。士气也是生产力的一种。一间公司如果管理混乱，意味着人事和制度没有建立好。 two pizza team 是第一个回应方案，但后来被 STL 代替了，要求团队高度自治。SOA 是经过认真反思得到的结果，提供了架构上的隔离。任何人如果要从该隔离区域获得东西，必须通过 API 提出被明确记录的服务请求。微服务有个一个不被人注意的特点：负责人明确。 自治团队有以下特点： 团队目标明确。 职责界限清晰。 一致同意进展的衡量目标。 two pizza team 的特点： 规模小。 保持自治性。 通过定义明确的健康度函数（fitness function）。 实时监控。 成为业务负责人。这种范式转变要求团队对结果负责。 由拥有多领域技能的一流领导者带领。 独立的成本中心。 事先获得 S-Team 的批准。 为了快速行动，最好慢点开始-想清楚 70% 的问题再开始。 但 two pizza team 通常面对如下问题： 只有产品开发团队受复杂依赖关系的困扰，其他团队不适合 two pizza team。 出色的 two pizza team 领导人很难寻找。 two pizza team 成功的精髓不在于团队足够小，而在于是否有一个适合的领导人带领团队专注工作。有时候人多是刚需。 一个团队是否有充分的自治权：是否依赖别的团队来推出新的功能。如果团队不够自治，需要把可以自治和重复的东西单拎出来-不要害怕重复。 亚马逊认真思考，而且花了很长的时间过了以后，确立了 NPI -&gt; two pizza team -&gt; STL 的制度，而且得出一个结论：在愿景上固执，在细节上灵活（be stubborn on the vision but flexible on the details）。 Six Pager好的材料应该启发思考，而不是破坏思考，分散注意力（PPT 太容易分散注意力了）。 Six Pager 最长只有六页。 最重要的是想法，而不是演讲者。 阅读记叙文可以吸收更多信息。亚马逊要求领导者 dive deep，知道执行的非常多的细节，阅读记叙文可以在更深层次上更好地了解公司重要计划。 愚蠢的想法是遮掩不住的，说话不清楚只是因为想法混乱。想法是人话语的上限，极少数人拥有清晰的想法和恰如其分的表达（呈现）能力。 Jeff 有一种神奇的能力，他能读出别人读不出的东西。他假设他读到的每个句子都是错的，除非能证明它不是错的。他在质疑句子内容，而不是作者的动机。 逆向工作法亚马逊的高管会深入研究新产品的功能。 新业务有不如老业务的地方，关键在于如何平衡长中短期的策略。要收集数据以确定经营策略。要花大量时间去思考整个业务，没有搞清楚一些事的做法是不被认可的。it’s all about ideas。 写 PR/FAQ 是为了首先从客户角度来看待这项业务，从公司的视角转变为客户视角是很不容易的，因为这需要客服公司的 ego。 写 PR/FAQ 的目的不是让你解释你所做的所有的优秀的工作，而是分享工作中提出来的思想。很多时候人们认为更多意味着更好-更详实的内容会意味着更好。限制篇幅会培养更好的思考者和沟通者。PR/FAQ 试图从客户痛点角度，来说明新的产品形态拥有几个更好的关键要素或者客户体验，进而可以获取成功。索尼的例子是，试图先建立一个对公司有益的业务/产品，然后强行把它当作一个能够满足客户需求的东西推出，最终就会失败。 大公司里，只有最优秀的人才能爬到顶端。“如果难题得到解决就能得到实质的价值，我们不应该担心遇到难题。”勇敢地面对困难，产生和评估伟大的想法是逆向工作法的真正好处。 管理输入而不是输出Jeff 认为关注输出指标并不能经营好一间公司（因为无法控制这些指标）。关注错误的信号或者缺乏洞察真正业务趋势的能力。 如果管理得当，采取正确的行动会推动业务朝积极有意义和积极方向发展的行动。 密切关注业务WBR 一定要全面看待业务。 指标生命周期DMAIC 来源于六西格玛规范。它的最后一步往往被人所忽略，就是在 control 中只关注异常指标。流程时不时会失灵，所以 control 很重要。 在改进一个系统以前，要先理解输入为什么能影响输出。要不然更改输入，要不然更改系统本身。这非常重要，有时候一个系统的某些关键变量。 输出指标（如股价）对亚马逊一直都很重要，但亚马逊的领导者要一直能够理解输入指标。 不同 category 的指标不一定一样。发现一个指标以后，可能还会发现第二个更好的指标（比如指标还可以下钻，还可以聚合，还可以从其他维度得到另一种指标。在同一个时间周期里，用不同的视角来看同一个问题，会产生不同的指标），我们要沿着思考的延长线推理，而且勇于迭代。而且要相信自己会犯错，要反复试错。一个团队要相信建立 instrumentation 的意义。 DMAIC 具有很强的可扩展性，你的投入水平应与你拥有的资源匹配。 测量数据的时候，很容易被偏见所误导，想要成功，想要表达成功是人的天性。报告无偏的真相至关重要，寻求真相的态度应该渗透到团队的每一部分。在亚马逊，财务团队的使命就是报告无偏见的真相，逆向工作法其实就是寻求真相的过程。不恰当的输入指标会导致不恰当的输出指标，无法实事求是地做决策。 要重分析，要相信真正的问题根因不隐藏在当前这个答案里，一个藏得很深的问题实际上需要问好几层问题才能问到真正好的答案。要相信 5 why 的力量。通常当天能够得到的答案不一定是好答案。 DMAIC 是一个小循环，这里面的逻辑框架是重要的。 WBR 有一个特点，就是不同的业务特点带来不同的业务模型。在订单层面和系统指标层面上要关注的数据是不一样的。但要相信业务里总是存在不变的东西要关注的。 好的资料使用一致的格式。人们总是喜欢谈论自己的领域，但我们要关注差异，而不是把时间浪费在（讨论我们已经）达成预期上。 把数据呈交 WBR 以前应当先看看，正确分析、归因。 我们应当创造一个让人们谈到自己领域中出现的问题，不会害怕的环境。坦诚错误应该是个让所有人学习经验的机会，勇于承担很重要。不要掩盖错误。 输出指标远不如输入指标能反应趋势原因。当时局与传闻不一致时持怀疑态度。 关于边际利润（Contribution Profit CP）可以说明异常报告的形式。 很多公司都在学习丰田，来应对复杂公司业务流程里的问题。 以前亚马逊的领导力原则要求领导者大多数的时候决定是对的，但也承认自己会犯错。坦诚沟通的目的是为了“赢得信任”。领导者不要怕自己难堪。 证据表明，惩罚性环境会留下不可磨灭的印记。 在亚马逊，了解指标的正常范围是指标所有者的责任。 发明机器要发明你必须进行实验，如果你事先知道它是可行的，那就不是实验了。要允许失败，在实践中成功。 要 think long term。很多时候我们要真正解决客户需求需要很长的时间，我们要认识到提升客户体验需要很久很久的时间，要花笨功夫。但这东西就像数字石油，如果钻出来，回报很丰富。 许多公司会放弃在短期内不可获取回报的计划。如果没有预算，就不要发明，如果预算有限，那么保持耐心和足够节俭也可以成功发明一些东西。 有时候发明是为了实现一些差异化的东西，昨天不能做的事情，今天也许就能做了，这时候发明的时间就到了。技能导向的公司通常寻找与现有技术和能力完全匹配的新商业机会（技能导向的公司实际上是在寻求局部最优解，全局的最优解、长期的最优解可能并不是这样推导出来的），但这是从公司的视角出发，而不是从客户的需求出发。 Fire Phone 是一款生不逢时的手机。这提醒我们，PR/FAQ 能提供成功几率，但并不能保证成功。 要保证创新要能容忍失败，双向门和单向门都要用，不过单向门要慎重。 高管要学会看财务报表，财务报表才会反映真实情况。 在小业务上负责多年，也可以学到很多东西。小业务里容易犯的错误是降低标准，因为认为注定不成功，所以随意上线。在一个既得利益根深蒂固的成熟行业，要建立新业务并且在变革时期领航，需要异常的耐心和坚定的领导（领导者要有自己的远见卓识）。 贝索斯转向数字化的决定的故事告诉我们：贝索斯先不去思考是什么，而是先去思考由谁做和如何做-把一个问题转化为若干个前置问题可能让我们得到真正正确的答案。时代已经变了的话，我们必须尽早采取行动。但任何一个油田都可能会枯竭，仅仅优化我们的成本效率是不足够的，我们要能够创造出不曾存在的东西才能应对这种问题。 发明比快速跟随者战略更有挑战，因为发明没有路线图。 进入新的领域可能需要新的能力，比如数字媒体业务和实体媒体零售业务有根本区别，它的价值链的构成不同，亚马逊处在价值链上的位置不同，能够做价值整合所采取的策略不一样，有些核心竞争力来自于你在价值链上的位置。 一间公司的长期成功和生存取决于你目前没有的特定能力，那么公司必须制定通过自行建立计划或收购方式获得这类能力的机会。外包是一个成本更高的做法，因为它的客户体验风险更高的选择。 配送中心的经验是：先 end-2-end 地看全流程的成本，然后再想局部优化的方案。 管理的谬误：习惯性肯定（institutional yes），习惯性否定指大型企业中员工出于好意拒绝新想法的倾向。保持当前的路线可以为管理人员提供宽慰和确定性，即使短期确定性的代价是不稳定并损害长期价值。一线经理通常把最有能力的人安置在当前项目，拒绝参与可能会失败也可能在未来获得丰厚回报的高风险实验的原因。 推出好的服务/产品，应该优先关注客户体验，而不是关注对手。Unbox、Fire Phone 和以前苹果的 Newton 的失败说明，软硬件不能恰当地适配，只会造成不可逆转的用户体验问题。 Jeff 认为，如果我们解雇了一个创造新事物时失败的人，就失去了从失败经历中吸取教训的好处。 亚马逊做好莱坞制片公司的时候，只追求最好的剧本，争取节约时间。 亚马逊网络服务AWS 是从联盟计划开始的，从允许其他工程师在亚马逊的服务器上编程开始。联盟计划本来是一个站在公司立场上看问题的东西，AWS 是一个允许从外部的工程师角度来看问题的东西。我们应当思考我们产品的形态，我们应该成就一个很多人需要用的系统，而不是一个没人用的系统。 亚马逊有若干从小种子长成大树的业务：Prime 会员、AWS。这些业务在早期并不需要在诞生之日就拥有巨大的规模，但必须在诞生的时候就拥有强大的潜力、高度创新和差异化。亚马逊不轻视小业务的成功。 传统的 IT 解决方案需要用户购买各种构件自行组合，但亚马逊只要搞明白一件事：它们不发明这些构件，如何在云中以 Web 服务的方式提供即可。这种设想基于这样一种逻辑，服务器对亚马逊很容易，对于大多数人很难。这是云时代的本质，也是 AI 等一系列高科技时代变革的本质。 成本模型-定价模型-业务存续。Jeff 坚持逆向工作法，坚持让工程师写 word。要搞清楚我们要构建什么东西以及为什么我们要构建。 结论：成为亚马逊人不需要进入亚马逊也能成为亚马逊人。因为亚马逊工作法是一种奇妙的分形，适用于任何规模和范围。亚马逊工作法提供了 严格时间限制下应对艰巨挑战，并争取拿到最好结果的成就感。 早期信条质量 over 速度。 不是为了赚钱而销售，而是通过帮助顾客做出购买决定来赚钱。 客户遍便利 over 公司便利。 不依靠良好的意愿来解决问题，发明并建立可靠（验证过，可扩展）的系统来消除问题。 贝索斯的一些基本观点 符合常识，使用硬数据。 持续积累的优势，而不寻求单一优势的领先。 Communication is terrible。 Always day 1。互联网还有很多未知的地方，等待我们去探索。 为自己的选择而自豪而不是为自己的天赋而自豪。 将你的战略建立在不会改变的事情上。 Obsess over customers. “客户至尚” “如果你想有创造力，你必须愿意失败。” 指标文化。基于事实的决策的另一种诠释是：数据驱动。 空椅子。不在场的人是房间里最重要的人。 数次大规模故障以后，决定推行 SOA 架构。 乐观。 杰夫有两件事做得比任何人都好：一件是他试图找到当时最好的真相。杰夫拒绝接受传统的做事方式。 要有明确的决策框架（clear decision-making framework），才能消弭管理层的分歧。 睡眠很重要，更多的时间其实是拿出来做更多的决定用的，但做出更多的决定未必能够更好地解决问题。 零和游戏在比赛中、选举中常见；在商业竞争中几个竞争对手可以做得很好。要想在竞争中取得好成绩，(无论是在商业竞争中，还是在与军事对手的竞争中)–最重要的是既要强大又要灵活。 敏捷性的最重要因素是决策速度（decision-making speed）。第二个最重要的因素是愿意尝试（being willing to be experimental）。你必须愿意承担风险。你必须愿意失败，而人们不喜欢失败。 我总是指出，有两种不同类型的失败。一种是实验性失败（experimental failure），这是你应该感到高兴的失败。还有一种是运营失败（operational failure）。多年来，我们在亚马逊建立了数百个物流中心，我们知道如何做到这一点。如果我们建立了一个新的物流中心，但它却十分糟糕了，那这只是糟糕的执行。这不是好的失败。但是，当我们正在开发一个新的产品或服务，或以某种方式进行试验，而它没有成功，那也没关系。这就是伟大的失败。而你需要区分这两种类型的失败，并真正寻求发明和创新（invention and innovation）。 要维持这种状态，你需要合适的人;你需要有创新精神的人。有创新精神的人如果不能做决定和承担风险，就会逃离组织。你最初可能会招募他们，但他们不会呆很久。建设者喜欢建设（Builders like to build）。很多东西都很简单，真的。它只是很难做。而关于竞争的另一件事是，你不希望在一个公平的竞争环境中竞争。这就是为什么你需要创新，特别是在太空和网络等领域。一个公平的竞争环境对周一晚上的足球来说是很好的。几十年来，我们在太空和技术等领域享有不公平的竞争环境。我非常紧张，这种情况正在迅速改变。要想保持领先，并保持这种不公平的竞争环境，唯一方法是创新，这也是你希望的。 公司最大的遗产之一很可能是他们对管理科学的贡献。 “赢得信任（earn trust）的方式，建立声誉（develop a reputation）的方式”，“就是一遍又一遍地把困难的事情做好。” “真的就是这么简单。但同时也复杂，”贝索斯说：“因为要把困难的事情做好，就必须要正直（integrity）且有能力（competence）。这意味着你说过要做的事情就要做到并交付。” 建立信赖关系是领导者必须有的能力。 亚马逊的历史是对公司管理学的贡献，03-05 年，亚马逊发明了很多东西，如流程和 Prime、AWS、Device、Primie Video、Fulfillment，都是由亚马逊这个发明机器创造出来的。-那一年我还是个高中生，我们比较先进的电子消费品仍然是索尼的 walkman。 亚马逊成立 S-Team 的目的是使之成为跨部门业务线的沟通平台，要建立一套透明、包容和协作的机制来制定重大决策。S-Team 是一支非常熟悉彼此、团结协作的、高效率的高管团队。为了做出高质量的决策，S-Team 需要了解细节并深入了解每个运营领域。S-Team 的领导者都是非常有成就的领导者。但贝索斯很聪明，他的想法很突出，而且会产生一些奇特的见解，也懂得把产生这些见解的过程向大家展示一遍。所有人讨论一个话题是一种低效的方式。每个人都要参与一个话题的原因是，需要大家迅速地解决跨领域的问题。贝索斯寻找 S-Team 成员的标准是：高判断力、能够快速浏览信息，能够就其专业或职责范围之外的领域提出关键问题的人。 贝索斯会拒绝“非此即彼”的决策，希望大家尽量跳出框架思考（think out of the box），决策是一个反复迭代的过程。 亚马逊认为速率是一个标量，而速度是一个向量。有时候低速率但正确的方向会更快地达到目标。 亚马逊的 OP1 在每年的9月-11月制定，OP2在1月下旬、2月制定。 S-Team 在一起早餐会有时候会讨论时事，不讨论公司议题，作为团建。 "},{"title":"如何写好年度/年中战略规划","date":"2021-09-30T10:14:37.000Z","url":"/2021/09/30/%E5%A6%82%E4%BD%95%E5%86%99%E5%A5%BD%E5%B9%B4%E5%BA%A6-%E5%B9%B4%E4%B8%AD%E6%88%98%E7%95%A5%E8%A7%84%E5%88%92/","tags":["管理"],"content":"借假修真的用意不在写了什么，而在掌握了这个框架。op1 op2 部门输出指标（预算）一览表一张表格指标名称，amount：细分年份，再细分 act、目标办 est、op1，YoY%,bps。 xxxx年目标达成及策略落地情况复盘建议篇幅0.5页。主要阐述以下内容：可酌情做简化或挑选适用的问题进行响应 1.这一年关键业务和财务指标较预算的完成情况如何？较往年的增长情况如何？和市场主要玩家相比进展如何？是否符合预期？超出预期部分和不达预期部分的主要驱动因素有哪些？（建议尽量定量拆解不同驱动因素带来的影响，对于探索期业务适度放宽对定量的要求）对于不及预期的部分，实际情况和当初形成预期时的假设出现了哪些差异、为什么会有这些差异？从中总结出了哪些经验教训？ 2.这一年度策略的执行情况如何？哪些事情应该停下来不要做或者减少资源，哪些事情应该加大资源投入、提升优先级？为什么？ 3.这一年的组织保障是否有效？ 通常要思考的问题要跟着更大团队的问题走，比如技术赋能、架构演进、交付效能及团队建设。 技术赋能能够阐明做了什么实现了什么指标的增长。架构演进要能说明稳定性、伸缩性、可用性、一致性等方面取得了什么进展。交付效能方面，要能统计完成了多少需求，达成率和延期率的指标结果如何。团队建设方面，确定团队梯度如何。 有哪些超出预期和不及预期的东西，为什么。 认知迭代有什么。 市场变化及机会判断建议篇幅0.5页。可酌情做简化或挑选适用的问题进行响应；此外，要适当进行长期和体系化的思考，体现平台建设的特点和长期支持业务发展的定位。 1.我们所在的市场有哪些关键变化和潜在机会？如宏观环境（PEST—政策/经济/社会/技术）、客户需求和场景、供给、竞对的产品和策略、利益相关者关切等。（以上为思考框架，不用逐一写到，只写有重大变化的部分即可，可以视需要增补/删减/组合。） 2.这些变化会如何影响行业规模、商业模式、市场格局？ 下一年年输出指标（预算） 什么项目什么问题什么指标到多少 什么项目什么问题什么指标到多少 什么项目什么问题什么指标到多少 下一年关键输入和举措（1）关键输入。（1）尽量不超过3个；（2）依据各自特点，聚焦交付、能力、效能之一，不必三者面面俱到。（2）关键输入指标。 （3）关键举措。 组织保障和预算。。。"},{"title":"如何做好远程规划","date":"2021-09-27T12:32:39.000Z","url":"/2021/09/27/%E5%A6%82%E4%BD%95%E5%81%9A%E5%A5%BD%E8%BF%9C%E7%A8%8B%E8%A7%84%E5%88%92/","tags":["管理"],"content":"核心摘要回顾当前发展阶段，确定机会、挑战，确定方向和策略，推导出目标。 远程规划客户洞察、市场洞察及认知迭代客户洞察先确定我们的客户是谁，我们能够为他们创造什么价值，我们的商业模式是什么，我们的核心能力什么？ 市场洞察看同业，看同业的发展状况，他们的发展阶段、结构、现状。 引述分析人士的观点。 认知迭代对商业产生了什么洞察。 战略方向和长期目标 方向是什么（喊口号）？ 建设目标是什么？ 要有业务大图和应用大图。 长期策略建设阶段按年拆分发展计划。 战略重点项目xxx 化项目，带出背后的思考逻辑出来。xxx 化项目，带出背后的思考逻辑出来。 xxxx 年的目标及关键策略xxxx 年的目标及关键策略重点建设哪个项目，为什么，怎么建。 资源保障组织架构要不要相应调整，哪只团队和哪只团队合作，hc 会不会变？"},{"title":"SRE-谷歌运维揭秘","date":"2021-09-15T05:47:13.000Z","url":"/2021/09/15/SRE-%E8%B0%B7%E6%AD%8C%E8%BF%90%E7%BB%B4%E6%8F%AD%E7%A7%98/","tags":["系统设计","运维"],"content":"SRE-谷歌运维揭秘.xmind"},{"title":"如何做好技术规划，二","date":"2021-09-14T03:43:46.000Z","url":"/2021/09/14/%E5%A6%82%E4%BD%95%E5%81%9A%E5%A5%BD%E6%8A%80%E6%9C%AF%E8%A7%84%E5%88%92%EF%BC%8C%E4%BA%8C/","tags":["项目管理"],"content":"背景共性问题想得少 -&gt; 闭门造车 -&gt; 不会做规划 -&gt; 不知道怎么带人 -&gt; 不会讲 成长机制人才盘点、培训 + 沙龙、导师/教练+项目 什么是规划 为解决现有问题所做的技术方面的改进，旨在提升系统效率。 个人的成长计划。 对某个项目或需求做出的整体技术方向和设计。 前瞻性的为业务需要的技术储备做一些计划。 "},{"title":"如何做好技术规划，一","date":"2021-09-14T02:36:23.000Z","url":"/2021/09/14/%E5%A6%82%E4%BD%95%E5%81%9A%E5%A5%BD%E6%8A%80%E6%9C%AF%E8%A7%84%E5%88%92%EF%BC%8C%E4%B8%80/","tags":["项目管理"],"content":"技术规划的背景技术规划的问题主要暴露在晋升中 想得少：讲的东西就偏浅。 闭门造车：对行业内的认识偏少，对谁做得好，对谁做得不好，了解得不够充分。 不会规划：在材料上体现出来，目标不明确。 不会带人：使用威逼式管理。让员工恐惧。 不善表达：不善于组织材料。 每年最重要的规划是 LRP。 规划定义why、what、how、when 这四个问题要按顺序回答。 困难与困惑 细分项 细分项解释 业务结合 如何避免技术规划脱离实际业务，出现假大空的情况？技术规划如何跟业务发展更好地匹配？如何在业务发展和技术规划之间做平衡，如何明确业务发展的规划和节奏，如何做到技术规划能满足业务的长期发展诉求。 长期规划 不了解未来业务的发展方向。看不清楚方向，某一个领域可能同时有多个方向的技术在演进，如何选择？业务总是在变，计划不如变化。规划和业务需求冲突，规划不好体现价值，往往让位于紧急需求。 目标制定 衡量维度，对应的指标，比如迭代方面、迭代速度等。如何确保目标的延续性和合理性，避免出现半途而废、方向偏差、风险失控等问题，导致目标不能落地？长期目标与短期目标之间的平衡，长期需要坚忍，大部分的资源是在围绕短期目标来做。 规划落地 技术在实施过程中和预期的不一致，导致换技术方案。容易规划得很好，但最后无法完成。规划的目标被业务需求打乱节奏，重点投入最后没有发挥应有的价值。 什么是技术规划 融合多要素的发展愿景。 对未来整体性、长期性、基本性问题的思考。 设计全面长远的发展计划和行动方案。 目标-路径-执行-调整定义目标是规划的起点。目标定义得好和坏。 规划 vs 计划规划有以下特性： 前瞻性：预测到未来的发展趋势。 全局性：不要只看到一个点，要看全局。 战略性：？ 方向性：要有方向性。 规划的意义 灯塔、前进方向。 大处着眼、小处着手。 有积累的事。 规划的层次目的： 三个层次：解决现有问题-&gt;抽象需求-&gt;理想情况 目标： 三个层次：系统性 -&gt; 方向性 -&gt; 前瞻性 怎么做技术规划 业务分析：要搞清楚业务当前的情况是什么。业界对标：最基本的东西是谁做得好，高级一点的东西是知道演化路径，它为什么能够做得好（这是不会被分享出来的）。我们在业内做的事情都能找到直接或者间接的对标。路径：别人是怎么做的？ 目标很重要沈向阳：要让最聪明的人来做目标的设定。否则做得越多，错得越多。目标演进关系：下单率 -&gt; 访购率 -&gt; UVCTR -&gt; QVCTR -&gt; BadCase。 目标因素收益：收入、效率、体验。技术：现有扩展 or 深度挖掘。团队：方向探索、趋势判断。 怎么做 全景图： 对系统规划性描述，执行者看清楚自己的位置。 Excel -&gt; 脑图 -&gt; 架构图。 五视图法：逻辑架构，开发架构，运行架构，物理架构，数据架构。逻辑架构和数据架构是比较容易受关注的。基础架构比较差的时候，才需要关注运行架构和物理架构（一般由基础架构团队来关注这些东西）。 方向规划： 水平分层 功能树 任务分解： 明确可执行 开始-&gt; 目标、风险、收益 -&gt; 优先级、人力资源 -&gt; 合作 -&gt; 子任务 -&gt; 里程碑 从现状到目标，最重要的是里程碑：我要达到的中间态是什么。要有阶段性产出，给其他人信心： 小步快跑，前期要分阶段快速出成果： Demo 尝试 应用 基于时间的设定 第一个月细化到周 三个月内细化到月 能够讲清楚关键策略的达成方式就可以了，不需要细化到天级别。 确定目标： 了解需求 明确方向 任务分解： 全景图 方向划分 执行计划： 优先级 人力排期 里程碑 风险评估： 管理风险 技术风险 贯彻执行： 定期总结 及时调整 技术规划常见问题bad case：没有讲清楚业务价值。只是讲一些正确的废话。 good case：针对具体目标设定具体目标。原来的 xx 指标是多少，未来的 xx 指标应该是多少。 规划 = 计划特点： 规划 = 项目集合 没有明确方向、不成系统 多个目标、无所适从解决方案： 区分技术方向与产品功能 寻求高阶指导 方向细分、多个规划 目标 = 实现系统特点： 目标清晰 子系统分解，任务明确 分解后，无法 check 目标解决方案： 里程碑的设定 寻求可量化 评估整体目标实现 走一步看一步特点： 还没想清楚 做一步再考虑下一步 问题： 很容易跑偏，长期风险大 解决方案： 长期方向必须明确、短期规划清楚 半途效应特点： 执行到中途半途而废问题： 心理及环境因素的负面影响较大 周期较长，中间没有达到期望 解决方案： 目标合理性、任务分解有效性 负责人的意志力：如果所有人都对事情产生怀疑，事情可能就会烂尾。 晋升为什么会失败做了很多事，缺乏思考。 平台化为什么难以落地缺乏顶层设计，偏演化的思路：是先喊口号，系统会慢慢演化出来。 我们都会有很多困惑自己的问题，我们会不会遇到半途效应？我们怎么实现从规划到落地，主要取决于规划。 如何做好多要素的平衡其实规划要平衡多要素，但多要素分别是什么，每个人有自己的理解。 工程师可能会选择先让能力做起来，哪怕用不着还有用的。"},{"title":"Unix 与 coredump","date":"2021-09-11T13:52:35.000Z","url":"/2021/09/11/Unix-%E4%B8%8E-coredump/","tags":["Linux","Unix"],"content":"coredump 是什么当程序运行的过程中异常终止或崩溃，操作系统会将程序当时的内存状态记录下来，保存在一个文件中，这种行为就叫做Core Dump（中文有的翻译成“核心转储”)。 我们可以认为 core dump 是“内存快照”，但实际上，除了内存信息之外，还有些关键的程序运行状态也会同时 dump 下来，例如寄存器信息（包括程序指针、栈指针等）、内存管理信息、其他处理器和操作系统状态和信息。 core dump 对于编程人员诊断和调试程序是非常有帮助的，因为对于有些程序错误是很难重现的，例如指针异常，而 core dump 文件可以再现程序出错时的情景。 为什么会产生coredump文件core产生的原因很多，比如过去一些Unix的版本不支持现代Linux上这种gdb直接附着到进程上进行调试的机制，需要先向进程发送终止信号，然后用工具阅读core文件。在Linux上，我们就可以使用kill向一个指定的进程发送信号或者使用gcore命令来使其主动出core并退出。 如果从浅层次的原因上来讲，出core意味着当前进程存在BUG，需要程序员修复。 从深层次的原因上讲，是当前进程触犯了某些OS层级的保护机制，逼迫OS向当前进程发送诸如SIGSEGV(即signal 11)之类的信号, 例如访问空指针或数组越界出core，实际上是触犯了OS的内存管理，访问了非当前进程的内存空间，OS需要通过出core来进行警示，这就好像一个人身体内存在病毒，免疫系统就会通过发热来警示，并导致人体发烧是一个道理（有意思的是，并不是每次数组越界都会出Core，这和OS的内存管理中虚拟页面分配大小和边界有关，即使不出core，也很有可能读到脏数据，引起后续程序行为紊乱，这是一种很难追查的BUG）。 coredump产生场景上面说当程序运行过程中异常终止或崩溃时会发生 core dump，但还没说到什么具体的情景程序会发生异常终止或崩溃，例如我们使用 kill -9 命令杀死一个进程会发生 core dump 吗？实验证明是不能的，那么什么情况会产生呢？ Linux 中信号是一种异步事件处理的机制，每种信号对应有其默认的操作，你可以在 这里查看 Linux 系统提供的信号以及默认处理。默认操作主要包括忽略该信号（Ingore）、暂停进程（Stop）、终止进程（Terminate）、终止并发生core dump（core）等。如果我们信号均是采用默认操作，那么，以下列出几种信号，它们在发生时会产生 core dump: Signal Action Comment SIGTRAP Core Trace/breakpoint trap SIGSEGV Core Invalid memory reference SIGQUIT Core Quit from keyboard SIGILL Core Illegal Instruction SIGABRT Core Abort signal from abort 当然不仅限于上面的几种信号。这就是为什么我们使用 Ctrl+z 来挂起一个进程或者 Ctrl+C 结束一个进程均不会产生 core dump，因为前者会向进程发出 SIGTSTP 信号，该信号的默认操作为暂停进程（Stop Process）；后者会向进程发出SIGINT 信号，该信号默认操作为终止进程（Terminate Process）。同样上面提到的 kill -9 命令会发出 SIGKILL 命令，该命令默认为终止进程。而如果我们使用 Ctrl+\\ 来终止一个进程，会向进程发出 SIGQUIT 信号，默认是会产生 core dump 的。还有其它情景会产生 core dump， 如：程序调用 abort() 函数、访存错误、非法指令等等。 造成程序coredump的原因有很多，这里总结一些比较常用的经验 内存访问越界a) 由于使用错误的下标，导致数组访问越界。 b) 搜索字符串时，依靠字符串结束符来判断字符串是否结束，但是字符串没有正常的使用结束符。 c) 使用strcpy, strcat, sprintf, strcmp,strcasecmp等字符串操作函数，将目标字符串读/写爆。应该使用strncpy, strlcpy, strncat, strlcat, snprintf, strncmp, strncasecmp等函数防止读写越界。 多线程程序使用了线程不安全的函数。 应该使用下面这些可重入的函数，它们很容易被用错： asctime_r(3c) gethostbyname_r(3n) getservbyname_r(3n)ctermid_r(3s)gethostent_r(3n) getservbyport_r(3n) ctime_r(3c)getlogin_r(3c)getservent_r(3n) fgetgrent_r(3c) getnetbyaddr_r(3n)getspent_r(3c)fgetpwent_r(3c) getnetbyname_r(3n) getspnam_r(3c)fgetspent_r(3c)getnetent_r(3n) gmtime_r(3c) gamma_r(3m)getnetgrent_r(3n) lgamma_r(3m) getauclassent_r(3)getprotobyname_r(3n)localtime_r(3c) getauclassnam_r(3)etprotobynumber_r(3n)nis_sperror_r(3n) getauevent_r(3)getprotoent_r(3n) rand_r(3c) getauevnam_r(3)getpwent_r(3c)readdir_r(3c) getauevnum_r(3) getpwnam_r(3c) strtok_r(3c)getgrent_r(3c)getpwuid_r(3c) tmpnam_r(3s) getgrgid_r(3c)getrpcbyname_r(3n) ttyname_r(3c)getgrnam_r(3c) getrpcbynumber_r(3n)gethostbyaddr_r(3n) getrpcent_r(3n) 多线程读写的数据未加锁保护。 对于会被多个线程同时访问的全局数据，应该注意加锁保护，否则很容易造成coredump 非法指针 a) 使用空指针 b) 随意使用指针转换。一个指向一段内存的指针，除非确定这段内存原先就分配为某种结构或类型，或者这种结构或类型的数组，否则不要将它转换为这种结构或类型的指针，而应该将这段内存拷贝到一个这种结构或类型中，再访问这个结构或类型。这是因为如果这段内存的开始地址不是按照这种结构或类型对齐的，那么访问它时就很容易因为bus error而core dump。 5，堆栈溢出 不要使用大的局部变量（因为局部变量都分配在栈上），这样容易造成堆栈溢出，破坏系统的栈和堆结构，导致出现莫名其妙的错误。 coredump文件配置 在终端中输入ulimit -c 如果结果为0，说明当程序崩溃时，系统并不能生成core dump。 使用ulimit -c unlimited命令，开启core dump功能，并且不限制生成core dump文件的大小。如果需要限制，加数字限制即可。ulimit - c 1024 默认情况下，core dump生成的文件名为core，而且就在程序当前目录下。新的core会覆盖已存在的core。通过修改/proc/sys/kernel/core_uses_pid文件，可以将进程的pid作为作为扩展名，生成的core文件格式为core.xxx，其中xxx即为pid 通过修改/proc/sys/kernel/core_pattern可以控制core文件保存位置和文件格式。例如：将所有的core文件生成到/corefile目录下，文件名的格式为core-命令名-pid-时间戳. echo “/corefile/core-%e-%p-%t” &gt; /proc/sys/kernel/core_pattern 当前系统配置：/proc/sys/kernel/core_pattern core文件所在目录：/opt/logs/logs/core/ coredump如何排查业务程序（以java为例）排查方式可以参考《JDK core dump分析》。 总而言之，jmap、jstack 都可以直接分析 core，也可以把它转成 hprof 格式的文件，进行进一步地可视化分析。gdb $JAVA_HOME$/bin/java core-26492/data/soft/jdk/bin/jstack /data/soft/jdk/bin/java core.26492/data/soft/jdk/bin/jmap /data/soft/jdk/bin/java core.14652/data/soft/jdk/bin/jmap -dump:format=b,file=dump.hprof /data/soft/jdk/bin/java core.14652 进入gdb上下文后再执行bt命令，可以看到进程退出时的线程栈。 代码块gdb /data/soft/jdk/bin/java core.11668 GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-80.el7 Copyright (C) 2013Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 orlater  This is free software: youare free to change and redistribute it. There is NO WARRANTY, to theextent permitted by law. Type “show copying” and “show warranty” fordetails. This GDB was configured as “x86_64-redhat-linux-gnu”. For bugreporting instructions, please see:… Reading symbols from/data/soft/jdk1.8.0_141/bin/java…Missing separate debuginfo for/data/soft/jdk1.8.0_141/bin/java Try: yum –enablerepo=’debug‘install/usr/lib/debug/.build-id/c9/0f19ee0af98c47ccaa7181853cfd14867bc931.debug(no debugging symbols found)…done. [New LWP 14367] … [New LWP14355] [New LWP 11685] [Thread debugging using libthread_db enabled]Using host libthread_db library “/lib64/libthread_db.so.1”. Missingseparate debuginfo for/data/soft/jdk1.8.0_141/jre/lib/amd64/server/libjvm.so Try: yum–enablerepo=’debug‘ install /usr/lib/debug/.build-id/43/a2bc419314aa566cd5ba54779ae18b47022cad.debugMissing separate debuginfo for/data/soft/jdk1.8.0_141/jre/lib/amd64/libverify.so Try: yum–enablerepo=’debug‘ install /usr/lib/debug/.build-id/b3/de2701fa3aef182d8e7b2db8d294a91af1eb7c.debugMissing separate debuginfo for/data/soft/jdk1.8.0_141/jre/lib/amd64/libmanagement.so Try: yum–enablerepo=’debug‘ install /usr/lib/debug/.build-id/ee/7e746ef83f2c2fbe8ea0cb42706b63cd74de3f.debugMissing separate debuginfo for/data/soft/jdk1.8.0_141/jre/lib/amd64/libinstrument.so Try: yum–enablerepo=’debug‘ install /usr/lib/debug/.build-id/13/552fe85b2af551ab806735bc5e5f2a5e00fbb1.debugCore was generated by `/data/soft/jdk/bin/java-Djava.util.logging.config.file=/data/home/aics/taskbot’. Program terminated with signal 6, Aborted.#0 0x00007f50d652b1d7 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56 56 returnINLINE_SYSCALL (tgkill, 3, pid, selftid, sig); (gdb) bt#0 0x00007f50d652b1d7 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56#1 0x00007f50d652c8c8 in __GI_abort () at abort.c:90#2 0x00007f50397417f4 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() () from/data/home/aics/taskbot-tomcat/temp/tensorflow_native_libraries-1545395060637-0/libtensorflow_framework.so#3 0x00007f5039721cf0 in tensorflow::monitoring::CollectionRegistry::Register(tensorflow::monitoring::AbstractMetricDefconst*, std::function&lt;void(tensorflow::monitoring::MetricCollectorGetter)&gt; const&amp;) () from/data/home/aics/taskbot-tomcat/temp/tensorflow_native_libraries-1545395060637-0/libtensorflow_framework.so#4 0x00007f501520951f in ?? () from /data/home/aics/taskbot-tomcat/temp/tensorflow_native_libraries-1545633543384-0/libtensorflow_jni.so#5 0x00007f50151334db in ?? () from /data/home/aics/taskbot-tomcat/temp/tensorflow_native_libraries-1545633543384-0/libtensorflow_jni.so#6 0x00007f50d6efd1e3 in call_init (env=0x7f50d00c4460, argv=0x7ffe7bc01488, argc=21, l=) at dl-init.c:82#7 _dl_init (main_map=main_map@entry=0x7f50249fa900, argc=21, argv=0x7ffe7bc01488, env=0x7f50d00c4460) at dl-init.c:131#8 0x00007f50d6f018f6 in dl_open_worker (a=a@entry=0x7f503b2f7b98) at dl-open.c:560#9 0x00007f50d6efcff4 in _dl_catch_error (objname=objname@entry=0x7f503b2f7b88,errstring=errstring@entry=0x7f503b2f7b90,mallocedp=mallocedp@entry=0x7f503b2f7b80,operate=operate@entry=0x7f50d6f01540 , args=args@entry=0x7f503b2f7b98) at dl-error.c:177#10 0x00007f50d6f00feb in _dl_open (file=0x7f5024008550 “/data/home/aics/taskbot-tomcat/temp/tensorflow_native_libraries-1545633543384-0/libtensorflow_jni.so”,mode=-2147483647, caller_dlopen=, nsid=-2, argc=21, argv=0x7ffe7bc01488, env=0x7f50d00c4460) at dl-open.c:650#11 0x00007f50d68b8fbb in dlopen_doit (a=a@entry=0x7f503b2f7da0) at dlopen.c:66#12 0x00007f50d6efcff4 in _dl_catch_error (objname=0x7f5024ae73e0, errstring=0x7f5024ae73e8, mallocedp=0x7f5024ae73d8,operate=0x7f50d68b8f60 , args=0x7f503b2f7da0) atdl-error.c:177#13 0x00007f50d68b95bd in _dlerror_run (operate=operate@entry=0x7f50d68b8f60 ,args=args@entry=0x7f503b2f7da0) at dlerror.c:163#14 0x00007f50d68b9051 in __dlopen (file=, mode=) at dlopen.c:87#15 0x00007f50d5e2a24e in os::dll_load(char const*, char*, int) () from /data/soft/jdk1.8.0_141/jre/lib/amd64/server/libjvm.so#16 0x00007f50d5c2198c in JVM_LoadLibrary () from /data/soft/jdk1.8.0_141/jre/lib/amd64/server/libjvm.so#17 0x00007f50d4ac7df8 in Java_java_lang_ClassLoader_00024NativeLibrary_load () from/data/soft/jdk1.8.0_141/jre/lib/amd64/libjava.so 非业务程序原则上不建议随便升级容器内部的各种库，如gcc，glibc等，这种随机安装可能导致容器组件不稳定 短期应急方法关闭相应组件，例如crond程序经常产生core，可以通过/etc/init.d/crond stop关闭。 长期处理方法非业务程序的coredump，可以联系运维人员。 coredump截断问题coredump截断分两种情况第一种：通过ulimit的方法限制coredump生成的大小，比如通过ulimit -c命令限制coredump的大小。 但是这个命令无法限制容器内的coredump的大小。 被ulimit限制后生成截断的大小都是固定的。 第二种：没有限制coredump的大小，但是每次都是随机出现coredump截断的情况。 一般这种情况coredump的core文件本身就已经是完全乱了，导致存储coredump大小的数据也是不准确的。 这种情况下生成的coredump的大小是随机的，每次core大小都不固定。 怎么分辨是什么原因导致的截断 方法1：查看每次生成的core的大小，如果每次生成的coredump的大小都是固定的，那么说明是通过生成coredump的脚本文件限制的 处理方法：业务可以TT到SRE，绑定取消coredump限制。具体方法：取消coredump大小限制 方法2：可以查看生成coredump的Py脚本，查看在生成coredump的时候有没有大小限制。 方法3：如果每次生成的coredump的大小不固定。 这时可以查看tcmalloc等内存管理是不是异常。 有一个比较明显的现象是生成coredump的时间和 tcmalloc异常的时间点每次都是基本吻合，这时候可以找《hulk技术支持》确认即可。 这种情况下tcmalloc的问题修复了，那么coredump被截断的情况也就消失了 coredump截断的影响 在通过gdb调试core文件的时候会提示coredump的大小异常，无法进行gdb的调试。 Linux 支持的信号列表一共有 64 种。 "},{"title":"伊斯兰教与清真食品","date":"2021-09-08T07:12:19.000Z","url":"/2021/09/08/%E4%BC%8A%E6%96%AF%E5%85%B0%E6%95%99%E4%B8%8E%E6%B8%85%E7%9C%9F%E9%A3%9F%E5%93%81/","tags":["宗教"],"content":"伊斯兰教概况世界三大宗教，世界五大宗教。伊斯兰意为“顺从”、“和平”。希吉拉是伊斯兰教历元年（622 年），穆罕默德离开麦加前往麦地那。 穆罕穆德时代。古莱什部落宗教。 四大哈里发（继承者）时代。阿拉伯半岛的一个民族的宗教。 阿拉伯帝国时代。阿拉伯半岛和波斯湾的宗教。 奥斯玛帝国时代。世界的宗教。 主要派别 逊尼派：70%。 什叶派：30%，伊朗、伊拉克。 哈瓦利吉派：穆罕穆德时期的宗派。 苏菲派：奥斯曼帝国的哲学思想。 六大信仰 信安拉：严格一神教。 信天使：四大天使。 信经典：古兰经成书以后没有改过。 信先知：六大使者。穆罕穆德是第六。 信来世：和其他宗教差不多。 五大功课 念功：清真言。 礼功：礼功。 斋戒：赖买单月。 天课：宗教税。 朝觐：规定的时间内正朝、副朝。 伊斯兰教在中国 610 年，穆罕穆德宣布自己被安拉选为使者。隋代穆罕穆德统一阿拉伯半岛。伊斯兰教于651 年传入中国。传播路径：陆上丝绸之路-波斯。海上丝绸之路-泉州。中国有 10 个少数民族信仰伊斯兰教。34000 座清真寺，教职人员 45000 多人。元代传入上海，松江清真寺。四大阿訇中有三个在上海。 清真食品从伊斯兰教的文化，变成少数民族的饮食习惯和生活方式。 清真食品不包含死物、血液和猪肉等禁忌物，必须念诵经文后宰杀，而且必须切掉特定的部位。 清真（哈拉李 Halal）主要是因为不洁，一是指不卫生，二是指宗教意义上的不纯洁。 海里的东西是合法的，酒不清真。但有些作料的酒精不可避免。 在我国，除了“清真寺”、“清真言”专用词汇以外，“清真”一词单独使用专指已转变为相关民族习俗的清真饮食。一方面，真的清真食品的生产经营应该清真；另一方面，要明确禁止“清真”概念泛化到食品以外的领域，影响宗教和民族团结。 每个国家都有自己的清真标识。中国的清真标识不再使用阿拉伯文或英文，进口的清真标识仍然可以保留。 我国是政教分离国家，宗教不再参与清真的认证，有民宗局或者民宗办认证。 要坚持从少数民族风俗习惯的角度来定义与管理清真食品，不能以伊斯兰教法界定，防止宗教干预群众的正常生产生活。要将清真食品概念限定在含有动物肉类及其衍生物的范围之内，不含动物油脂、乳类成分的食品不得冠以清真字样。以伊利为例子。清真餐厅的厨师要满足特定的民族比例。 斋戒期间可以售卖清真食品。因为清真食品的顾客 99% 都不是穆斯林。清真食品和非清真食品不可以一起存放。"},{"title":"基本编程范式、模型和风格","date":"2021-09-05T10:21:33.000Z","url":"/2021/09/05/%E5%9F%BA%E6%9C%AC%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E3%80%81%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%A3%8E%E6%A0%BC/","tags":["系统设计"],"content":"盒子模型表达式由一系列盒子组成，这些盒子相互决定位置和大小。 流水线模型模式-动作范式一系列的输入会被每个模式所检查，模式匹配时，执行相应的输入。 复杂流程总-分架构流程被分为：step1、step2、step3；stage1、stage2、stage3；phase1、phase2、phase3。 数据只要可以在同层内串联，每一层就可能被抽象成 step。如果 step 的输入输出是无关的，则需要使用 context 模式；否则使用 stream 模式，每个 step 可以由&lt;T,R&gt;指定输入输出类型，每个 step 的输出会成为下一个阶段的输入。。每一步如果可以在实现上变化，可以使用策略模式，如果需要实现差异化的聚合，需要使用组合模式。 我们使用 Step 的时候最好先指定&lt;T,R&gt;。"},{"title":"蔡康永的说话之道","date":"2021-08-28T05:21:14.000Z","url":"/2021/08/28/%E8%94%A1%E5%BA%B7%E6%B0%B8%E7%9A%84%E8%AF%B4%E8%AF%9D%E4%B9%8B%E9%81%93/","tags":["心理学","蔡康永"],"content":" 阅读本来是赏心悦目的事情。 透过说话，懂得把别人放在心上，这就是我相信的、蔡康永的说话之道。 做自己和没礼貌，常在一线之间。刺耳并不等于简单的“直”。 把话练好，是最划算的事情。把话练好，就是练练把人放在心上。 你有没有能力想象听你讲话的人是什么心情，想听到什么。 练习说话很方便。说话其实就关乎你和别人的想法的交流。单单研究话是没有用的，研究人和人的想法有用。 我们心里其实藏了很多，我们自己都没法搞清楚的事情。 我们应当尽量把我们相信的事，和我们说的话变为一体。 能够打动别人的话，包含了很多“生命能量”，而不只是巧言令色，别有居心。 梦想拥有天使的外表，不如修炼一颗天使的心。与其嫉恶如仇，不如隐恶扬善。 已经很讨人喜欢的你，在未来会更讨人喜欢 转述第三方的赞美，更可信。 你说什么样的话，你就是什么样的人。 人把自己内心深处的想法隐藏起来，只会让自己错乱、分裂。 说话和想法的因果有时候会反直觉。 不要简单责备人，修复问题的效果不一定好。 外表好不好看，绝对不是人生的决胜点 讨不讨人喜欢，还比较重要一点。甚至超越一般的、基于能力的量化评价标准。 别人并不是为了伺候你而存在的。要提供一个可选的解决方案，再去拒绝别人。 沉默没问题的，沉默很正常的 人在乱放音乐的时候的放松是最自然的。 为了防止尴尬，大人们喜欢在聊天时放大音量的电视，让电视的声音填补尴尬的空白。 不要逼自己找话题。 把无谓的胜利让给别人，懂得认输的人很懂说话 任何强势的胜负，都是无意义的。无损原则，可以一笑置之。 侃侃而谈，可以很有想法，但不要说到对方哑口无言。哑口无言，意味着别人还有话说不出来。 人缘差的人，没法打团队战。 智者说过：每个人都是自己小领土的国王。 情侣之间，维持爱是最重要的。胜负没有任何意义。 把对方看在眼里，放在心里 最好三不五时地，带着情感看着对方，让对方感觉两个人之间有暧昧的电流在流动。 约会就是约会，要含情脉脉。 并不是懂美食美酒，就是有品位的人。 应该“以你为尊”，而不是“吃喝为尊”。 被重视是关键词，重要的是“视”。 不会 Game Over，让人接得下去的话 遇上对方提起了一个你完全不想接的话题，不必急着要抵抗，而是轻巧地把对方热衷的话题连接到一个很生活的方向就行了。 “比赛会赢吗？”“你会下多大的注？”“你以前的女朋友会怎样想？” 话题卡住了，就换话题，不要恋战 谈话是发生在当下的事情，快速转换话题或者结束话题都是好的。 不要坚持拿没有子弹的枪，去敲敌人的头。 谈话是发生在当下的事。 问的问题越具体，回答的人越省力 有选项：封闭式。 有退路：所有问题的答案都有话可讲。 我们应当看待交往带有目的这件事。交谈轻松、愉快就行了。 聊天时，每个人都想聊自己 当你自己想要被别人喜欢的时候，你只要把别人放在你自己的位置上来想，那就轮到你来扮演这个“最上道”的朋友了。 人和人相处得最如胶似漆的时候，也是活在各自的世界里，而不是彼此的世界里的。 最专心听你讲话的人，是你“最上道”的朋友。 多说你，少说我。谁也不是陪酒的牛郎。 问题很尖锐，可以倒推回去两三步 人生难免出现尖锐的问题，逃得过就逃，这是我们的天性。但逃不过的话，就处理吧。 不要问“你是不是在吸毒”，要问“你最近是不是过得很痛苦”。 不要理所当然地带有优越感地去跟别人谈话。 尖锐的问题，可以引入“假设的第三方”。 内容里措辞变多了，可以软化一些细节。 适度地挑衅，能让谈话热络 人很敏锐，能听得出谁在敷衍谁。跟在敷衍自己的人谈话，就好像对着墙壁练习挥网球拍一样。 提要求和接要求，和价值观有关系，不同的价值观需要的价码是不一样的。 不想交浅言深的话，应该避开地雷 交情深，谈得深。这两个条件，缺一不可。 不要随便刺痛别人最脆弱的地方。 谈话工作者的工作内容就就是交浅言深，踩地雷。但这是为了表演效果。 财务状况、健康状况、感情状况、孩子的成绩，肯恩是别人的苦衷。政治立场可能是别人的强硬坚持这都很容易出争执。 硬生生地报出数字，很难记住 不要理直气壮地聊敏感数字。 "},{"title":"基本业务架构设计方法","date":"2021-08-25T11:44:27.000Z","url":"/2021/08/25/%E5%9F%BA%E6%9C%AC%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/","tags":["系统架构"],"content":"如何实现自己的 validation"},{"title":"DDD Sample 的分层","date":"2021-08-24T06:12:56.000Z","url":"/2021/08/24/DDD-Sample-%E7%9A%84%E5%88%86%E5%B1%82/","tags":["领域驱动设计","DDD"],"content":"codebase 主轴线是先分层，非领域层根据用例/工具类型划分，领域层根据领域/聚合做垂直切分（而不是按照 class 类型垂直切分）。工具类、公共类就近在轴线附近部署，如有必要放在 common 包、common 模块中。 interfaces 层：定义用例动词的接口，包括 facade 定义、web 接口定义、webservice 定义、facade 实现。 application 层：定义业务用例，动作的延伸，引用领域能力和 repo。它可以引用同层的 service，但同层 service 如果是类领域能力的实现，需要放在 infrastructure 层实现。 domain：定义基础的领域模型子类型：Entity、Event、ValueObject。所有对象按照聚合边界划分和组织。service 是跨 aggregate 边界的。 infrastructure：实现 repo、application 层的 service、domain 层的 service。 config：bean 工厂。 dddsample-core.xmind"},{"title":"卓越面试官","date":"2021-08-20T11:48:44.000Z","url":"/2021/08/20/%E5%8D%93%E8%B6%8A%E9%9D%A2%E8%AF%95%E5%AE%98/","tags":["面试"],"content":"如何去做正确的行为面试找到最优秀的人是领导者很重要的职责，做好卓越面试官不是一句空话。 用人部门是招聘的第一责任人。 找对人比做对事更重要。 了解理论更要了解背后的逻辑是什么。 面试官的担忧和痛点面试官的“目标”冰山模型招聘的底层模型是冰山模型。 表象的任职资格/门槛性要求 经验 知识 技能 潜在的胜任素质/优才标准 能力、潜能（能做） 个性，特质（适合做） 动力，价值观，兴趣（愿意做，值得做，做得开心） PECL 模型潜力出众（Potential）一两年内是否可以晋升到下一级。 专业过硬（Expertise）做这个决策要考虑当前团队的实际情况，超出当前岗位 50%以上。 文化匹配（Culture Fit）做这个决策要考虑当前团队的实际情况，能否融入当前团队。 管理卓越（Leadership）做这个决策要考虑当前团队的实际情况，能否带好当前团队，取得成功。 面试官的“工具”使用 PECL 面谈指引来工作。 行为面试的提问和追问的技术行为面试是用过去的行为来预测未来的行为，未来的行为决定了未来的绩效。 连贯性过去的事情发生过一次以上，证明这不是偶然发生的。适当地引入 STAR 法则，一个行为应当是一个完整的 STAR。我们应当看重行为，而不只是结果，结果可能受外部因素影响。行为才是连贯的，结果不是。 提问的艺术 问行为性的问题。 正面和负面的问题结合。 一次一个问题，负面放后面。 巧用“还有类似事例吗？” 匹配度 能不能做？ 愿不愿意做？ 是否能够长久地做下去？ 问题的区别 要区别理论性问题（没有发生的问题）、引导性问题（让候选人知道你的关注点，知道了潜在的答案）和行为性问题。 要关注最近的问题，极端化的问题、框架化的问题，可以把候选人的行为模式识别出来。 要注意负面问题的重要性，不要忽视负面问题。但负面的问题应该留在最后。 一次只有一个问题，免得大家记不住，思维不连贯。如果有必要，引入一个挂图。 要识别真假 STAR：带有假设的信息是假的 STAR，有实际的案例才是真的 STAR。 要照顾候选人的情绪，在需要考察的点已经考察清楚了的时候。 有能力不等于有意愿。 我们要注意能力的延展性，而不是结果的延展性（非典期间销售绩效很好，不代表来了本公司的销售绩效也很好）。 文化匹配性的标准技巧：When/What/Why 让你高兴/沮丧。 文化匹配的评估时机和提问、追问技巧开场澄清简历时关于这份工作，你的职责是什么？最喜欢的是什么？最讨厌的是什么？离开这个团队，你最开心的是什么？最讨厌的是什么？ 指定价值观评估“谈谈什么叫以客户为中心”。 收集 STAR 遇到情绪化时这个过程中最来劲的是什么？什么是不大喜欢的？ 候选人提问时候选人关心工作的内容和素质的要求的问题，体现了候选人和岗位的文化匹配。 吸引人才的技术展现专业的面试 把握面试节奏：对面试各环节用时预估和执行妥当 营造面试分为：正面 STAR 及时肯定 + 善意回应负面 STAR 恰到好处地“销售”岗位/团队/公司 了解公司的“卖点”。 岗位/团队的“卖点”。 收集候选人的“喜欢/不喜欢”，并及时“销售”。 当我们吸引人才时还需要注意什么 面试前 面试中（笑脸、哭脸矩阵） 面试后 试用期中 录用决策的技术评语有论点，再用论据支撑。 评分参考 PECL 模型。 评级参考当前团队的实际情况，和公司的理论能力模型，要看是取高，还是取低？ 是否录用不要取平均分，要关注我们真正要录取的同事需要的能力，也要关注候选人暴露出的缺点。"},{"title":"如何写系统规划","date":"2021-08-18T12:57:29.000Z","url":"/2021/08/18/%E5%A6%82%E4%BD%95%E5%86%99%E7%B3%BB%E7%BB%9F%E8%A7%84%E5%88%92/","tags":["系统架构"],"content":"列出背景 列出现状。 列出当前组织的 okr，分析机会和挑战。 将当前系统的视图勾勒出来，要能理解信息流和资金流。 列出痛点，分析需要实现的技术能力。 对标 对标其他团队的成功经验。 分析背景和成功原理。 要有架构图。 解决方案 要有目标架构图 有问题拆解：什么服务，是什么问题域的解空间，拥有什么能力，建设路径分几期，需要多少人力成本。 全团队分工： 本团队产品怎么分工 本团队后端怎么分工 本团队前端怎么分工 本团队数据怎么分工 本团队算法怎么分工 其他团队怎么分工 里程碑 按照绝对时间拆解 按照任务事件拆解 如何画简单的架构图 水平分层极其重要，每一层左边在层次里会有层次说明。 要用圆角都用圆角，要用直角都用直角。 重点：要填满整个空间： 深底色配白字。 模块之间的应该要直，不然应该优美、松弛。 图像应该紧凑，不留缝隙。 越处于背景之中，颜色越浅。 有时候，利用立体图形是好的。 要有阴影。 要玻璃化。 "},{"title":"如何删除 idea 的缓存","date":"2021-08-16T03:10:01.000Z","url":"/2021/08/16/%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4-idea-%E7%9A%84%E7%BC%93%E5%AD%98/","tags":["Idea"],"content":"~/Library/Caches/JetBrains/IntelliJIdea2021.2/caches"},{"title":"如何构建一个服务保护平台","date":"2021-08-02T06:44:23.000Z","url":"/2021/08/02/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E4%BF%9D%E6%8A%A4%E5%B9%B3%E5%8F%B0/","tags":["系统架构"],"content":"为什么要有这样一个平台随着业务的发展，公司内部的服务负载能力、复杂程度、稳定性要求随之上升。 常见的服务的保护措施有： 业务突发流量上升，超过了服务的负载能力，有可能导致服务不可用； 有些特殊的业务场景，开发环境没有测试到位，在线上暴露出来，没有一种兜底措施； 部分服务因为负载超荷，响应时间很长，很有可能导致整条业务链奔溃； 线上出现故障时，没有一套成熟应急预案。 因此，我们需要一套保障服务高效、稳定运行的系统，也就是针对以上场景提供服务保护能力的平台。 常见功能 熔断降级 流量控制 SOP预案 主动GC 资源隔离（线程池） 禁用主机 方法重试 故障模拟（对混沌工程场景有用） 功能实现的一些思路预案管理一个健康的故障处理的正反馈链路通常包含四个步骤： 故障发生 故障定位 故障处理 故障复盘与演练。 从SOP预案的执行形态来划分，SOP预案的发展大致分为以下三个阶段：人工执行阶段、一键执行阶段、自动执行阶段-从降级到熔断，其实是一种执行自动化的升华过程。 线程池设计服务保护平台线程池.xmind 流量控制器流量控制器.xmind 主动垃圾回收主动垃圾回收.xmind"},{"title":"如何排查线上问题","date":"2021-07-20T09:13:12.000Z","url":"/2021/07/20/%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/","tags":["JVM","线上问题排查"],"content":"cpu 偏高问题排查![cpu 偏高问题排查.png](cpu 偏高问题排查.png)[cpu 偏高问题排查.xmind](cpu 偏高问题排查.xmind) 数据库问题排查数据库问题排查.xmind![数据库问题排查（rds泛指一切关系型数据库，主要看 MySQL）](数据库问题排查（rds泛指一切关系型数据库，主要看 MySQL）.png)"},{"title":"如何做一个优秀的系统 owner","date":"2021-07-19T13:06:07.000Z","url":"/2021/07/19/%E5%A6%82%E4%BD%95%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BC%98%E7%A7%80%E7%9A%84%E7%B3%BB%E7%BB%9F-owner/","tags":["职场"],"content":" 协同 勇气 务实 细节 坚持 科技 担当 创新 "},{"title":"如何实现正确的微基准测试","date":"2021-07-19T07:20:11.000Z","url":"/2021/07/19/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%AD%A3%E7%A1%AE%E7%9A%84%E5%BE%AE%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/","tags":["JVM","Java"],"content":"原问题FROM：《How do I write a correct micro-benchmark in Java?》 Tips about writing micro benchmarks from the creators of Java HotSpot: Rule 0: Read a reputable paper on JVMs and micro-benchmarking. A good one is Brian Goetz, 2005. Do not expect too much from micro-benchmarks; they measure only a limited range of JVM performance characteristics. Rule 1: Always include a warmup phase which runs your test kernel all the way through, enough to trigger all initializations and compilations before timing phase(s). (Fewer iterations is OK on the warmup phase. The rule of thumb is several tens of thousands of inner loop iterations.) Rule 2: Always run with -XX:+PrintCompilation, -verbose:gc, etc., so you can verify that the compiler and other parts of the JVM are not doing unexpected work during your timing phase. Rule 2.1: Print messages at the beginning and end of timing and warmup phases, so you can verify that there is no output from Rule 2 during the timing phase. Rule 3: Be aware of the difference between -client and -server, and OSR and regular compilations. The -XX:+PrintCompilation flag reports OSR compilations with an at-sign to denote the non-initial entry point, for example: Trouble$1::run @ 2 (41 bytes). Prefer server to client, and regular to OSR, if you are after best performance. Rule 4: Be aware of initialization effects. Do not print for the first time during your timing phase, since printing loads and initializes classes. Do not load new classes outside of the warmup phase (or final reporting phase), unless you are testing class loading specifically (and in that case load only the test classes). Rule 2 is your first line of defense against such effects. Rule 5: Be aware of deoptimization and recompilation effects. Do not take any code path for the first time in the timing phase, because the compiler may junk and recompile the code, based on an earlier optimistic assumption that the path was not going to be used at all. Rule 2 is your first line of defense against such effects. Rule 6: Use appropriate tools to read the compiler’s mind, and expect to be surprised by the code it produces. Inspect the code yourself before forming theories about what makes something faster or slower. Rule 7: Reduce noise in your measurements. Run your benchmark on a quiet machine, and run it several times, discarding outliers. Use -Xbatch to serialize the compiler with the application, and consider setting -XX:CICompilerCount=1 to prevent the compiler from running in parallel with itself. Try your best to reduce GC overhead, set Xmx(large enough) equals Xms and use UseEpsilonGC if it is available. Rule 8: Use a library for your benchmark as it is probably more efficient and was already debugged for this sole purpose. Such as JMH, Caliper or Bill and Paul’s Excellent UCSD Benchmarks for Java. 规则 0：阅读有关 JVM 和微基准测试的知名论文。 Brian Goetz, 2005 是一个很好的例子。不要对微基准期望过高；它们仅测量有限范围的 JVM 性能特征。 规则 1：始终包含一个预热阶段，它会一直运行您的测试内核，足以在计时阶段之前触发所有初始化和编译。 （预热阶段的迭代次数较少。经验法则是数万次内循环迭代。）几万次足以预热大部分东西。 规则 2：始终使用 -XX:+PrintCompilation、-verbose:gc 等运行，这样您就可以验证编译器和 JVM 的其他部分在您的计时阶段没有做预期之外的工作。如果做了它会打印出来。 规则 2.1：在计时和预热阶段的开始和结束时打印消息，以便您可以验证在计时阶段没有规则 2 的输出。如何做到呢，依靠 JMH 吧。 规则 3：注意-client和-server之间的区别，以及 OSR 和常规编译之间的区别。 -XX:+PrintCompilation标志用 at 符号报告 OSR 编译，以表示非初始入口点，例如：Trouble$1::run@2（41 bytes）。如果您追求最佳性能，则更喜欢服务器而不是客户端，并且更喜欢 OSR。我真的看得懂 OSR 的日志吗？ 规则 4：注意初始化效果。不要在计时阶段第一次打印，因为打印会加载和初始化类。不要在预热阶段（或最终报告阶段）之外加载新类，除非您专门测试类加载（在这种情况下只加载测试类）。规则 2 是您抵御此类影响的第一道防线。类加载是一种容易被忽略的性能瓶颈，打印是另一种。 规则 5：注意反优化和重新编译的影响。不要在计时阶段才第一次使用任何代码路径，因为编译器可能会根据早先的乐观假设，即根本不会使用该路径，而重新编译代码。规则 2 是您抵御此类影响的第一道防线。 规则 6：使用适当的工具来读懂编译器的想法，并期望对它生成的代码感到惊讶。在形成关于什么使某事更快或更慢的理论之前，自己检查代码。不要以为自己懂编译器。 规则 7：减少测量中的噪声。在安静的机器上运行您的基准测试，并运行几次，丢弃异常值。使用 -Xbatch 将编译器与应用程序序列化，并考虑设置 -XX:CICompilerCount=1 以防止编译器与自身并行运行。尽量减少 GC 开销，设置 Xmx（足够大）等于 Xms 并在可用时使用 UseEpsilonGC。可以使用无操作垃圾收集器。 规则 8：为您的基准测试使用一个库，因为它可能更有效，并且已经为此目的进行了调试。例如 JMH、Caliper 或 Bill and Paul’s Better UCSD Benchmarks for Java。 Also, never use System.currentTimeMillis() unless you are OK with + or - 15 ms accuracy, which is typical on most OS + JVM combinations. 不要使用 System.nanoTime() 和 System.currentTimeMillis() 这两个 api。但 System.nanoTime() 始终是单调钟，虽然不精确，总是向前的。 样例工程 JMH 教程参考《JMH 应用指南》。 《基准测试神器 JMH —— 详解 36 个官方例子》 基本概念 Iteration - iteration 是 JMH 进行测试的最小单位，包含一组 invocations。 Invocation - 一次 benchmark 方法调用。 Operation - benchmark 方法中，被测量操作的执行。如果被测试的操作在 benchmark 方法中循环执行，可以使用@OperationsPerInvocation表明循环次数，使测试结果为单次 operation 的性能。 Warmup - 在实际进行 benchmark 前先进行预热。因为某个函数被调用多次之后，JIT 会对其进行编译，通过预热可以使测量结果更加接近真实情况。 API@BenchmarkMode Throughput - 整体吞吐量，例如“1 秒内可以执行多少次调用”。 AverageTime - 调用的平均时间，例如“每次调用平均耗时 xxx 毫秒”。 SampleTime - 随机取样，最后输出取样结果的分布，例如“99%的调用在 xxx 毫秒以内，99.99%的调用在 xxx 毫秒以内” SingleShotTime - 以上模式都是默认一次 iteration 是 1s，唯有 SingleShotTime 是只运行一次。往往同时把 warmup 次数设为 0，用于测试冷启动时的性能。 All - 所有模式 @Warmup上面我们提到了，进行基准测试前需要进行预热。一般我们前几次进行程序测试的时候都会比较慢， 所以要让程序进行几轮预热，保证测试的准确性。其中的参数 iterations 也就非常好理解了，就是预热轮数。为什么需要预热？因为 JVM 的 JIT 机制的存在，如果某个函数被调用多次之后，JVM 会尝试将其编译成为机器码从而提高执行速度。所以为了让 benchmark 的结果更加接近真实情况就需要进行预热。 @Measurement iterations - 进行测试的轮次 time - 每轮进行的时长 timeUnit - 时长单位 @Threads每个进程中的测试线程，这个非常好理解，根据具体情况选择，一般为 cpu 乘以 2。 @Fork进行 fork 的次数。如果 fork 数是 2 的话，则 JMH 会 fork 出两个进程来进行测试。 @OutputTimeUnit这个比较简单了，基准测试结果的时间类型。一般选择秒、毫秒、微秒。 @Benchmark方法级注解，表示该方法是需要进行 benchmark 的对象，用法和 JUnit 的 @Test 类似。 @Param属性级注解，@Param 可以用来指定某项参数的多种情况。特别适合用来测试一个函数在不同的参数输入的情况下的性能。 @Setup方法级注解，这个注解的作用就是我们需要在测试之前进行一些准备工作，比如对一些数据的初始化之类的。我们可以在每一次 Invocation 以前做一次 Setup。 @TearDown方法级注解，这个注解的作用就是我们需要在测试之后进行一些结束工作，比如关闭线程池，数据库连接等的，主要用于资源的回收等。这个东西需要很慎重。 @State当使用 @Setup 参数的时候，必须在类上加这个参数，不然会提示无法运行。State 用于声明某个类是一个“状态”，然后接受一个 Scope 参数用来表示该状态的共享范围。 因为很多 benchmark 会需要一些表示状态的类，JMH 允许你把这些类以依赖注入的方式注入到 benchmark 函数里。Scope 主要分为三种。 Thread - 该状态为每个线程独享。 Group - 该状态为同一个组里面所有线程共享。 Benchmark - 该状态在所有线程间共享。 解读输出报告 注意标准差： STDEV 基于样本估算标准偏差。标准偏差反映数值相对于平均值(mean) 的离散程度。 ops/us - operations (benchmark method executions) per microsecond Cnt - total number of trials (forks*iterations) Score - benchmark result Error - standard error value. Means how much different trials results differAlso: thrpt - Throughput mode (how much full benchmark method executions were made in a trial) avgt - Average Time mode (how much measuring units took benchmark method execution on average) 有兴趣还可以试试这两个网站：JMH Visual ChartJMH Visualizer 另外一种解释，参考《使用JMH进行基准性能测试》： 数字只能告诉我们 what，通常不能告诉我们 when、where、how 和 why。搞懂 why 是人的工作： REMEMBER: The numbers below are just data. To gain reusable insights,you need to follow up on why the numbers are the way they are. Useprofilers (see -prof, -lprof), design factorial experiments, performbaseline and negative tests that provide experimental control, makesure the benchmarking environment is safe on JVM/OS/HW level, ask forreviews from the domain experts. Do not assume the numbers tell youwhat you want them to tell. 记住：下面的数字只是数据。要获得可重复使用的见解，您需要跟进 为什么数字是这样的。使用分析器（参见 -prof、-lprof），设计因子实验，执行提供实验控制的基线和负面测试，确保 基准测试环境在 JVM/OS/HW 级别是安全的，请咨询领域专家。不要假设数字告诉您您希望他们告诉您的内容。 块 说明 参数信息（1-10行） 1：jmh版本2：jvm版本信息3：jvm程序（jdk安装路径）4：jvm参数配置5：预热参数：预热次数、每次持续时间6：测试参数：测试次数、每次持续时间7：每次测试迭代超时时间8：每个测试进程的测试线程数9: 测试的模式10:测试的方法 测试过程（12-75行） 12-23：第1次fork测试 （fork可以理解为1个独立的进程）12：测试完成进度，预计剩余需要时间13：当前第几次fork14-18：预热执行，每次预热执行耗时19-23：正式测试执行，每次测试执行耗时25-36：第2次fork测试38-49：第3次fork测试51-62：第4次fork测试64-75：第5次fork测试 测试结果（78-95行） 78-81：测试结果，包括测试的方法、平均耗时[平局耗时的比例]、最大最小 耗时、测试结果数据离散度（stdev）等84：测试总耗时86-90：对测试结果的解释92-93：测试结论{测试的方法、测试类型（Mode）、测试总次数(Cnt)、测试结果(Score)、误差(Error)、单位(Units)}95：结束 "},{"title":"漫长的道别","date":"2021-07-11T15:17:55.000Z","url":"/2021/07/11/%E6%BC%AB%E9%95%BF%E7%9A%84%E9%81%93%E5%88%AB/","tags":["文学"],"content":" 交际有时候很重要。 自己坐飞机，用旅行的方式可以走私毒品。一个混乱的城市，到处都有非法行医，滥用麻醉品和酒精的人。 峡谷里也藏有苦命人，也许是虚伪的人。 喝酒是为了逃避什么吗？逃避人生。 富家女的婚姻只是一种形式，糜烂的生活方式是不会改变的。 人年轻的时候可以忍受很多痛苦和惩罚，年近四十就不那么容易复原了。 对自己不满的人，不爱自己，反而会憎恨自己。 派拉蒙在五十年代就有很好的电影了。 不要公开羞辱别人，成为众矢之的。 酒会放纵自己，对话都大同小异。 走入晚风中，随风飘零。 克制自己的疲惫，才能克制自己的欲望，秩序和人生的希望是否有关系。 酒鬼不再是原来的自己，不可轻信。 酬劳。 在酒醉里寻找秘密。 一生只有一次难以置信的爱。 不要教育人，要辅导人。 空酒杯什么都没有，什么寻欢什么都得不到。 坏习惯是一种伪装。 怪诞的念头，来自于高度发展的想象力。 自省，找出自己的本心。 大多数人一生要用一半的精力来保护从未存在的尊严-在人际关系中的尊严。 犯罪和生意惟一的区别：生意需要本钱。 有开关的小机械会折磨人。 有自尊也充满失望的一个城市。 等咖啡凉了，烟燃尽了，我就跟他道别。 洛杉矶-好莱坞。 人因为种种事，要找种种人。 爱惜、珍惜的东西，给人以困扰。 有钱人会有有钱人的烦恼，金钱并不一定能够让人融洽地过一生，金钱解决不了性格缺陷的问题。 偷情的客房是幽静的。 作家都是好演员，女人也是。撒谎要撒得恰到好处。 搞清楚生活的意义和目的。 法律系统里有重重陷阱，迷住了所有人。 人死亡在所有语言里都是最冰冷的字眼。 做梦的空心大美人。 司法机关本身也受社会折磨。 穷人和好人是最沉默的。 说得对没有用。 人不会为了一目了然的事情浪费时间。 人崩得太紧就会断掉。 当过代罪羔羊的，随时可能再当代罪羔羊。 重遇失落的东西，遇到的只剩下空壳。时间流逝可以让人变得卑贱，道德败坏。 广东人有一句话，先敬罗衣后敬人。 无声无息地走路，仿佛随风漂流。 找不到摆脱警察的方法，因为他们从不道别。 不写浮夸的东西，做个不诚实的人，没法发达。 硬汉小说写了对社会浮华的冷眼旁观，以一个“边缘好人”的视角，对不诚实的世界，进行了道德批判。 撒谎之前，小心翼翼。 好人死得无声无息。 星期四，仆人休假。 警察对这个世界充满不满。道德沦丧，赌博和毒品是这个社会的病症。病因是金钱。 "},{"title":"人才能力模型","date":"2021-07-11T02:31:07.000Z","url":"/2021/07/11/%E4%BA%BA%E6%89%8D%E8%83%BD%E5%8A%9B%E6%A8%A1%E5%9E%8B/","tags":["职业发展"],"content":"π 型人才 项目管理 架构能力 产品： 审美 沟通基本功 沟通 "},{"title":"针对风控的性能优化","date":"2021-07-08T02:50:40.000Z","url":"/2021/07/08/%E9%92%88%E5%AF%B9%E9%A3%8E%E6%8E%A7%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","tags":["性能"],"content":"性能优化的目标 提高功能可用性。 提升用户体验（这一点常被人所忽略）。 降低机器成本（这一点也常被人所忽略）。 衡量指标对应目标，主要衡量指标也有三个： 可用性衡量指标：与性能相关的主要是客户端请求超时率。注意，不是服务端的可用性，作为服务提供方，最应该被关注的是服务被调用后，最终是否可用。 用户体验衡量指标：主要看 TP50、TP90、TP99这几个指标。TP999、TP9999属于长尾请求的指标，一般和可用性正相关。对于长尾请求，根据服务量级，不可用请求造成的业务损失来决定是否需要优化，因为长尾请求的根因复杂且多样，解决起来耗费人力。 机器成本衡量指标：单机吞吐量。这里我们一般也只看高峰期压测数据，因为下游不只服务于我们，下游在高峰期也会有性能问题，调用的下游依赖较多时，下游的性能可能会影响上游服务的吞吐。 风控系统的一般业务场景通常每个风控平台都服务于多个业务线。 每个业务线有多个风控场景，一个风控场景包含多条规则，一条规则使用多个参数，部分参数需要实时去调用外部依赖获取。一条流量进入风控平台后，通过已经加载在机器上的配置，并行调用一个或者多个场景，每个场景内并行的调用需要的外部依赖获取规则需要的参数，最后并行的执行规则，返回规则结果。风控平台在执行过程中大量用到并行化处理，并包含大量的IO调用和CPU密集型的规则运算。 思维工具箱风控性能优化.xmind 遇到性能问题，先套用该模板，看看有哪些点疏漏了，没有考虑到。然后对于每个点评估以下三个问题： 是否存在问题？ 解决后可观测的指标能提高多少？能维持多久？ 解决方案有几种（复杂问题一般都有多种方案，要求自己至少想三个），每种方案耗费的人力成本，优缺点都有哪些？ 这三个问题决定了工作优先级，好的优先级可以更快的解决问题，让客户满意，让自己有成就感。"},{"title":"如何写一个消息队列","date":"2021-07-07T11:52:26.000Z","url":"/2021/07/07/%E5%A6%82%E4%BD%95%E5%86%99%E4%B8%80%E4%B8%AA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","tags":["消息队列"],"content":"重平衡问题标准的重平衡算法是 kafka 的重平衡算法。 可以覆写的重平衡算法默认生产者行为每个机房的生产者优先生产到本机房的 broker。 默认策略同机房集群—&gt;同地域跨机房集群—&gt;跨地域集群 同机房集群优先向同机房的全部集群发送消息。 某些 mq 的实现不能向全部集群发送消息，会按照一个负载均衡列表按顺序选择集群，控制这个负载均衡列表实际上就能控制负载均衡策略。 同地域集群优先优先向同地域内的全部集群发送消息。 某些 mq 的实现不能向全部集群发送消息，会按照一个负载均衡列表按顺序选择集群，控制这个负载均衡列表实际上就能控制负载均衡策略。 全部集群不区分服务端集群的机房信息，向全部集群发送消息。 默认消费者行为所有消费者都可以参与所有集群的消费。 指定分配不要轻易指定这个策略。 这个策略有它的危险性：指定 partition 消费，服务端将不对该消费组的 partition 进行分配，完全交给客户端负责，如果客户端死掉，可能出现 partition 无人消费的情况。 同机房优先/地域敏感尽可能降低由于网络传输带来的时延问题：按照同机房优先、同地域优先、跨地域优先。从前到后优先级越来越低的方式进行参与者划分；具体分配方式仍使用原有的集群粒度 partition 分配。 每次只有一种策略被激活： 同机房优先不会激活同地域优先：如果说本 broker 有同机房的消费者，哪怕这个消费者的消费能力比较差，负载均衡也不会让本 broker 的 partition 被跨机房的消费者消费，这会导致积压。如果激活同地域优先，则同机房的 broker 能够被同机房的 consumer 消费，同地域的 consumer 可以消费无主的 broker-某些“地域敏感”实现更进一步，即使 broker 可以被同机房消费，也可以被同地域消费。 同地域优先不会激活跨地域优先：如果说本 broker 有同地域的消费者，哪怕这个消费者的消费能力比较差，负载均衡也不会让本 broker 的 partition 被跨地域的消费者消费，这会导致积压。 积压问题可能出现积压的几种原因： 客户端没有正确启动。 客户端虽然启动了，但出现消息卡单-这种情况可以通过 JStack 发现问题。 消费能力不足：更下游有些慢阻塞操作，阻塞了 ConsumerFetcherThread ，特别是更下游如果有阻塞服务的话问题更大。 延迟问题消费组级延迟消费组延迟生效在消费端，大概原理可以理解为客户端收到消息之后延迟一定时间之后再调用业务消费逻辑进行消费。 这种方法的实现通常不用改代码，但可能需要消费端有个缓冲区。如果缓冲区的大小固定，则消息可能会丢失。 消息级延迟消息粒度延迟的原理大概是客户端在发送消息之后，不会马上发送到broker,而是先把消息暂存到带有 zset 之类的数据结构的 kv 存储中，等延时时间到达才正式发送消息到broker。每条消息的延迟时间可以不同，通过代码控制。"},{"title":"提问的智慧","date":"2021-07-05T08:35:30.000Z","url":"/2021/07/05/%E6%8F%90%E9%97%AE%E7%9A%84%E6%99%BA%E6%85%A7/","tags":["黑客文化"],"content":" FROM： 原文版本历史目录 声明 简介 在提问之前 当你提问时 慎选提问的论坛 Stack Overflow 网站和 IRC 论坛 第二步，使用项目邮件列表 使用有意义且描述明确的标题 使问题容易回复 用清晰、正确、精准且语法正确的语句 使用易于读取且标准的文件格式发送问题 精确地描述问题并言之有物 话不在多而在精 别动辄声称找到 Bug 低声下气不能代替你的功课 描述问题症状而非你的猜测 按发生时间先后列出问题症状 描述目标而不是过程 别要求使用私人电邮回复 清楚明确的表达你的问题以及需求 询问有关代码的问题时 别把自己家庭作业的问题贴上来 去掉无意义的提问句 即使你很急也不要在标题写紧急 礼多人不怪，而且有时还很有帮助 问题解决后，加个简短的补充说明 如何解读答案 RTFM 和 STFW：如何知道你已完全搞砸了 如果还是搞不懂 处理无礼的回应 如何避免扮演失败者 不该问的问题 好问题与蠢问题 如果得不到回答 如何更好地回答问题 相关资源 鸣谢 声明许多项目在他们的使用协助/说明网页中链接了本指南，这么做很好，我们也鼓励大家都这么做。但如果你是负责管理这个项目网页的人，请在超链接附近的显著位置上注明： 本指南不提供此项目的实际支持服务！ 我们已经深刻领教到少了上述声明所带来的痛苦。因为少了这点声明，我们不停地被一些白痴纠缠。这些白痴认为既然我们发布了这本指南，那么我们就有责任解决世上所有的技术问题。 如果你因寻求某些帮助而阅读本指南，并在离开时还觉得可以从本文作者这里得到直接帮助，那你就是我们之前说的那些白痴之一。别问我们问题，我们只会忽略你。我们在这本指南中是教你如何从那些真正懂得你所遇到软件或硬件问题的人取得协助，而 99% 的情况下那不会是我们。除非你确定本指南的作者之一刚好是你所遇到的问题领域的专家，否则请不要打扰我们，这样大家都会开心一点。 简介在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。本指南将教你如何正确的提问以获得你满意的答案。 不只是黑客，现在开源（Open Source）软件已经相当盛行，你常常也可以由其他有经验的使用者身上得到好答案，这是件好事；使用者比起黑客来，往往对那些新手常遇到的问题更宽容一些。然而，将有经验的使用者视为黑客，并采用本指南所提的方法与他们沟通，同样也是能从他们身上得到满意回答的最有效方式。 首先你应该明白，黑客们喜爱有挑战性的问题，或者能激发他们思维的好问题。如果我们并非如此，那我们也不会成为你想询问的对象。如果你给了我们一个值得反复咀嚼玩味的好问题，我们自会对你感激不尽。好问题是激励，是厚礼。好问题可以提高我们的理解力，而且通常会暴露我们以前从没意识到或者思考过的问题。对黑客而言，”好问题！”是诚挚的大力称赞。 尽管如此，黑客们有着蔑视或傲慢面对简单问题的坏名声，这有时让我们看起来对新手、无知者似乎较有敌意，但其实不是那样的。 我们不讳言我们对那些不愿思考、或者在发问前不做他们该做的事的人的蔑视。那些人是时间杀手 —— 他们只想索取，从不付出，消耗我们可用在更有趣的问题或更值得回答的人身上的时间。我们称这样的人为 失败者（撸瑟） （由于历史原因，我们有时把它拼作 lusers）。 我们意识到许多人只是想使用我们写的软件，他们对学习技术细节没有兴趣。对大多数人而言，电脑只是种工具，是种达到目的的手段而已。他们有自己的生活并且有更要紧的事要做。我们了解这点，也从不指望每个人都对这些让我们着迷的技术问题感兴趣。尽管如此，我们回答问题的风格是指向那些真正对此有兴趣并愿意主动参与解决问题的人，这一点不会变，也不该变。如果连这都变了，我们就是在降低做自己最擅长的事情上的效率。 我们（在很大程度上）是自愿的，从繁忙的生活中抽出时间来解答疑惑，而且时常被提问淹没。所以我们无情的滤掉一些话题，特别是拋弃那些看起来像失败者的家伙，以便更高效的利用时间来回答赢家（winner）的问题。 如果你厌恶我们的态度，高高在上，或过于傲慢，不妨也设身处地想想。我们并没有要求你向我们屈服 —— 事实上，我们大多数人非常乐意与你平等地交流，只要你付出小小努力来满足基本要求，我们就会欢迎你加入我们的文化。但让我们帮助那些不愿意帮助自己的人是没有效率的。无知没有关系，但装白痴就是不行。 所以，你不必在技术上很在行才能吸引我们的注意，但你必须表现出能引导你变得在行的特质 —— 机敏、有想法、善于观察、乐于主动参与解决问题。如果你做不到这些使你与众不同的事情，我们建议你花点钱找家商业公司签个技术支持服务合同，而不是要求黑客个人无偿地帮助你。 如果你决定向我们求助，当然你也不希望被视为失败者，更不愿成为失败者中的一员。能立刻得到快速并有效答案的最好方法，就是像赢家那样提问 —— 聪明、自信、有解决问题的思路，只是偶尔在特定的问题上需要获得一点帮助。 （欢迎对本指南提出改进意见。你可以 email 你的建议至 esr@thyrsus.com 或 respond-auto@linuxmafia.com。然而请注意，本文并非网络礼节的通用指南，而我们通常会拒绝无助于在技术论坛得到有用答案的建议）。 在提问之前在你准备要通过电子邮件、新闻群组或者聊天室提出技术问题前，请先做到以下事情： 尝试在你准备提问的论坛的旧文章中搜索答案。 尝试上网搜索以找到答案。 尝试阅读手册以找到答案。 尝试阅读常见问题文件（FAQ）以找到答案。 尝试自己检查或试验以找到答案。 向你身边的强者朋友打听以找到答案。 如果你是程序开发者，请尝试阅读源代码以找到答案。 当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并不是一个不劳而获且浪费别人的时间的提问者。如果你能一并表达在做了上述努力的过程中所学到的东西会更好，因为我们更乐于回答那些表现出能从答案中学习的人的问题。 运用某些策略，比如先用 Google 搜索你所遇到的各种错误信息（搜索 Google 论坛和网页），这样很可能直接就找到了能解决问题的文件或邮件列表线索。即使没有结果，在邮件列表或新闻组寻求帮助时加上一句 我在 Google 中搜过下列句子但没有找到什么有用的东西 也是件好事，即使它只是表明了搜索引擎不能提供哪些帮助。这么做（加上搜索过的字串）也让遇到相似问题的其他人能被搜索引擎引导到你的提问来。 别着急，不要指望几秒钟的 Google 搜索就能解决一个复杂的问题。在向专家求助之前，再阅读一下常见问题文件（FAQ）、放轻松、坐舒服一些，再花点时间思考一下这个问题。相信我们，他们能从你的提问看出你做了多少阅读与思考，如果你是有备而来，将更有可能得到解答。不要将所有问题一股脑拋出，只因你的第一次搜索没有找到答案（或者找到太多答案）。 准备好你的问题，再将问题仔细的思考过一遍，因为草率的发问只能得到草率的回答，或者根本得不到任何答案。越是能表现出在寻求帮助前你为解决问题所付出的努力，你越有可能得到实质性的帮助。 小心别问错了问题。如果你的问题基于错误的假设，某个普通黑客（J. Random Hacker）多半会一边在心里想着蠢问题…， 一边用无意义的字面解释来答复你，希望着你会从问题的回答（而非你想得到的答案）中汲取教训。 绝不要自以为够格得到答案，你没有；你并没有。毕竟你没有为这种服务支付任何报酬。你将会是自己去挣到一个答案，靠提出有内涵的、有趣的、有思维激励作用的问题 —— 一个有潜力能贡献社区经验的问题，而不仅仅是被动的从他人处索取知识。 另一方面，表明你愿意在找答案的过程中做点什么是一个非常好的开端。谁能给点提示？、我的这个例子里缺了什么？以及我应该检查什么地方比请把我需要的确切的过程贴出来更容易得到答复。因为你表现出只要有人能指个正确方向，你就有完成它的能力和决心。 当你提问时慎选提问的论坛小心选择你要提问的场合。如果你做了下述的事情，你很可能被忽略掉或者被看作失败者： 在与主题不合的论坛上贴出你的问题。 在探讨进阶技术问题的论坛张贴非常初级的问题；反之亦然。 在太多的不同新闻群组上重复转贴同样的问题（cross-post）。 向既非熟人也没有义务解决你问题的人发送私人电邮。 黑客会剔除掉那些搞错场合的问题，以保护他们沟通的渠道不被无关的东西淹没。你不会想让这种事发生在自己身上的。 因此，第一步是找到对的论坛。再说一次，Google 和其它搜索引擎还是你的朋友，用它们来找到与你遭遇到困难的软硬件问题最相关的网站。通常那儿都有常见问题（FAQ）、邮件列表及相关说明文件的链接。如果你的努力（包括阅读 FAQ）都没有结果，网站上也许还有报告 Bug（Bug-reporting）的流程或链接，如果是这样，链过去看看。 向陌生的人或论坛发送邮件最可能是风险最大的事情。举例来说，别假设一个提供丰富内容的网页的作者会想充当你的免费顾问。不要对你的问题是否会受到欢迎做太乐观的估计 —— 如果你不确定，那就向别处发送，或者压根别发。 在选择论坛、新闻群组或邮件列表时，别太相信名字，先看看 FAQ 或者许可书以弄清楚你的问题是否切题。发文前先翻翻已有的话题，这样可以让你感受一下那里的文化。事实上，事先在新闻组或邮件列表的历史记录中搜索与你问题相关的关键词是个极好的主意，也许这样就找到答案了。即使没有，也能帮助你归纳出更好的问题。 别像机关枪似的一次”扫射”所有的帮助渠道，这就像大喊大叫一样会使人不快。要一个一个地来。 搞清楚你的主题！最典型的错误之一是在某种致力于跨平台可移植的语言、套件或工具的论坛中提关于 Unix 或 Windows 操作系统程序界面的问题。如果你不明白为什么这是大错，最好在搞清楚这之间差异之前什么也别问。 一般来说，在仔细挑选的公共论坛中提问，会比在私有论坛中提同样的问题更容易得到有用的回答。有几个理由可以支持这点，一是看潜在的回复者有多少，二是看观众有多少。黑客较愿意回答那些能帮助到许多人的问题。 可以理解的是，老练的黑客和一些热门软件的作者正在接受过多的错发信息。就像那根最后压垮骆驼背的稻草一样，你的加入也有可能使情况走向极端 —— 已经好几次了，一些热门软件的作者从自己软件的支持中抽身出来，因为伴随而来涌入其私人邮箱的无用邮件变得无法忍受。 Stack Overflow搜索，然后 在 Stack Exchange 问。 近年来，Stack Exchange 社区已经成为回答技术及其他问题的主要渠道，尤其是那些开放源码的项目。 因为 Google 索引是即时的，在看 Stack Exchange 之前先在 Google 搜索。有很高的机率某人已经问了一个类似的问题，而且 Stack Exchange 网站们往往会是搜索结果中最前面几个。如果你在 Google 上没有找到任何答案，你再到特定相关主题的网站去找。用标签（Tag）搜索能让你更缩小你的搜索结果。 Stack Exchange 已经成长到超过一百个网站，以下是最常用的几个站： Super User 是问一些通用的电脑问题，如果你的问题跟代码或是写程序无关，只是一些网络连线之类的，请到这里。 Stack Overflow 是问写程序有关的问题。 Server Fault 是问服务器和网管相关的问题。 网站和 IRC 论坛本地的使用者群组（user group），或者你所用的 Linux 发行版本也许正在宣传他们的网页论坛或 IRC 频道，并提供新手帮助（在一些非英语国家，新手论坛很可能还是邮件列表）， 这些地方是开始提问的好首选，特别是当你觉得遇到的也许只是相对简单或者很普通的问题时。有广告赞助的 IRC 频道是公开欢迎提问的地方，通常可以即时得到回应。 事实上，如果程序出的问题只发生在特定 Linux 发行版提供的版本（这很常见），最好先去该发行版的论坛或邮件列表中提问，再到程序本身的论坛或邮件列表提问。（否则）该项目的黑客可能仅仅回复 “用我们的版本”。 在任何论坛发文以前，先确认一下有没有搜索功能。如果有，就试着搜索一下问题的几个关键词，也许这会有帮助。如果在此之前你已做过通用的网页搜索（你也该这样做），还是再搜索一下论坛，搜索引擎有可能没来得及索引此论坛的全部内容。 通过论坛或 IRC 频道来提供使用者支持服务有增长的趋势，电子邮件则大多为项目开发者间的交流而保留。所以最好先在论坛或 IRC 中寻求与该项目相关的协助。 在使用 IRC 的时候，首先最好不要发布很长的问题描述，有些人称之为频道洪水。最好通过一句话的问题描述来开始聊天。 第二步，使用项目邮件列表当某个项目提供开发者邮件列表时，要向列表而不是其中的个别成员提问，即使你确信他能最好地回答你的问题。查一查项目的文件和首页，找到项目的邮件列表并使用它。有几个很好的理由支持我们采用这种办法： 任何好到需要向个别开发者提出的问题，也将对整个项目群组有益。反之，如果你认为自己的问题对整个项目群组来说太愚蠢，也不能成为骚扰个别开发者的理由。 向列表提问可以分散开发者的负担，个别开发者（尤其是项目领导人）也许太忙以至于没法回答你的问题。 大多数邮件列表都会被存档，那些被存档的内容将被搜索引擎索引。如果你向列表提问并得到解答，将来其它人可以通过网页搜索找到你的问题和答案，也就不用再次发问了。 如果某些问题经常被问到，开发者可以利用此信息来改进说明文件或软件本身，以使其更清楚。如果只是私下提问，就没有人能看到最常见问题的完整场景。 如果一个项目既有”使用者” 也有”开发者”（或”黑客”）邮件列表或论坛，而你又不会动到那些源代码，那么就向”使用者”列表或论坛提问。不要假设自己会在开发者列表中受到欢迎，那些人多半会将你的提问视为干扰他们开发的噪音。 然而，如果你确信你的问题很特别，而且在”使用者” 列表或论坛中几天都没有回复，可以试试前往”开发者”列表或论坛发问。建议你在张贴前最好先暗地里观察几天以了解那里的行事方式（事实上这是参与任何私有或半私有列表的好主意） 如果你找不到一个项目的邮件列表，而只能查到项目维护者的电子邮件地址，尽管向他发信。即使是在这种情况下，也别假设（项目）邮件列表不存在。在你的电子邮件中，请陈述你已经试过但没有找到合适的邮件列表，也提及你不反对将自己的邮件转发给他人（许多人认为，即使没什么秘密，私人电子邮件也不应该被公开。通过允许将你的电子邮件转发他人，你给了相应人员处置你邮件的选择）。 使用有意义且描述明确的标题在邮件列表、新闻群组或论坛中，大约 50 字以内的标题是抓住资深专家注意力的好机会。别用喋喋不休的帮帮忙、跪求、急（更别说救命啊！！！！这样让人反感的话，用这种标题会被条件反射式地忽略）来浪费这个机会。不要妄想用你的痛苦程度来打动我们，而应该是在这点空间中使用极简单扼要的描述方式来提出问题。 一个好标题范例是目标 —— 差异式的描述，许多技术支持组织就是这样做的。在目标部分指出是哪一个或哪一组东西有问题，在差异部分则描述与期望的行为不一致的地方。 蠢问题：救命啊！我的笔记本电脑不能正常显示了！ 聪明问题：X.org 6.8.1 的鼠标光标会变形，某牌显卡 MV1005 芯片组。 更聪明问题：X.org 6.8.1 的鼠标光标，在某牌显卡 MV1005 芯片组环境下 - 会变形。 编写目标 —— 差异 式描述的过程有助于你组织对问题的细致思考。是什么被影响了？ 仅仅是鼠标光标或者还有其它图形？只在 X.org 的 X 版中出现？或只是出现在 6.8.1 版中？ 是针对某牌显卡芯片组？或者只是其中的 MV1005 型号？ 一个黑客只需瞄一眼就能够立即明白你的环境和你遇到的问题。 总而言之，请想像一下你正在一个只显示标题的存档讨论串（Thread）索引中查寻。让你的标题更好地反映问题，可使下一个搜索类似问题的人能够关注这个讨论串，而不用再次提问相同的问题。 如果你想在回复中提出问题，记得要修改内容标题，以表明你是在问一个问题， 一个看起来像 Re: 测试 或者 Re: 新 bug 的标题很难引起足够重视。另外，在不影响连贯性之下，适当引用并删减前文的内容，能给新来的读者留下线索。 对于讨论串，不要直接点击回复来开始一个全新的讨论串，这将限制你的观众。因为有些邮件阅读程序，比如 mutt ，允许使用者按讨论串排序并通过折叠讨论串来隐藏消息，这样做的人永远看不到你发的消息。 仅仅改变标题还不够。mutt 和其它一些邮件阅读程序还会检查邮件标题以外的其它信息，以便为其指定讨论串。所以宁可发一个全新的邮件。 在网页论坛上，好的提问方式稍有不同，因为讨论串与特定的信息紧密结合，并且通常在讨论串外就看不到里面的内容，故通过回复提问，而非改变标题是可接受的。不是所有论坛都允许在回复中出现分离的标题，而且这样做了基本上没有人会去看。不过，通过回复提问，这本身就是暧昧的做法，因为它们只会被正在查看该标题的人读到。所以，除非你只想在该讨论串当前活跃的人群中提问，不然还是另起炉灶比较好。 使问题容易回复以请将你的回复发送到……来结束你的问题多半会使你得不到回答。如果你觉得花几秒钟在邮件客户端设置一下回复地址都麻烦，我们也觉得花几秒钟思考你的问题更麻烦。如果你的邮件程序不支持这样做，换个好点的；如果是操作系统不支持这种邮件程序，也换个好点的。 在论坛，要求通过电子邮件回复是非常无礼的，除非你认为回复的信息可能比较敏感（有人会为了某些未知的原因，只让你而不是整个论坛知道答案）。如果你只是想在有人回复讨论串时得到电子邮件提醒，可以要求网页论坛发送给你。几乎所有论坛都支持诸如追踪此讨论串、有回复时发送邮件提醒等功能。 用清晰、正确、精准且语法正确的语句我们从经验中发现，粗心的提问者通常也会粗心的写程序与思考（我敢打包票）。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。 正确的拼写、标点符号和大小写是很重要的。一般来说，如果你觉得这样做很麻烦，不想在乎这些，那我们也觉得麻烦，不想在乎你的提问。花点额外的精力斟酌一下字句，用不着太僵硬与正式 —— 事实上，黑客文化很看重能准确地使用非正式、俚语和幽默的语句。但它必须很准确，而且有迹象表明你是在思考和关注问题。 正确地拼写、使用标点和大小写，不要将its混淆为it&#39;s，loose搞成lose或者将discrete弄成discreet。不要全部用大写，这会被视为无礼的大声嚷嚷（全部小写也好不到哪去，因为不易阅读。Alan Cox 也许可以这样做，但你不行）。 更白话的说，如果你写得像是个半文盲[译注：小白]，那多半得不到理睬。也不要使用即时通信中的简写或火星文，如将的简化为d会使你看起来像一个为了少打几个键而省字的小白。更糟的是，如果像个小孩似地鬼画符那绝对是在找死，可以肯定没人会理你（或者最多是给你一大堆指责与挖苦）。 如果在使用非母语的论坛提问，你可以犯点拼写和语法上的小错，但决不能在思考上马虎（没错，我们通常能弄清两者的分别）。同时，除非你知道回复者使用的语言，否则请使用英语书写。繁忙的黑客一般会直接删除用他们看不懂语言写的消息。在网络上英语是通用语言，用英语书写可以将你的问题在尚未被阅读就被直接删除的可能性降到最低。 如果英文是你的外语（Second language），提示潜在回复者你有潜在的语言困难是很好的：[译注：以下附上原文以供使用] English is not my native language; please excuse typing errors. 英文不是我的母语，请原谅我的错字或语法。 If you speak $LANGUAGE, please email/PM me;I may need assistance translating my question. 如果你说某语言，请寄信/私讯给我；我需要有人协助我翻译我的问题。 I am familiar with the technical terms,but some slang expressions and idioms are difficult for me. 我对技术名词很熟悉，但对于俗语或是特别用法比较不甚了解。 I’ve posted my question in $LANGUAGE and English.I’ll be glad to translate responses, if you only use one or the other. 我把我的问题用某语言和英文写出来，如果你只用一种语言回答，我会乐意将其翻译成另一种。 使用易于读取且标准的文件格式发送问题如果你人为地将问题搞得难以阅读，它多半会被忽略，人们更愿读易懂的问题，所以： 使用纯文字而不是 HTML (关闭 HTML 并不难）。 使用 MIME 附件通常是可以的，前提是真正有内容（譬如附带的源代码或 patch），而不仅仅是邮件程序生成的模板（譬如只是信件内容的拷贝）。 不要发送一段文字只是一行句子但自动换行后会变成多行的邮件（这使得回复部分内容非常困难）。设想你的读者是在 80 个字符宽的终端机上阅读邮件，最好设置你的换行分割点小于 80 字。 但是，对一些特殊的文件不要设置固定宽度（譬如日志档案拷贝或会话记录）。数据应该原样包含，让回复者有信心他们看到的是和你看到的一样的东西。 在英语论坛中，不要使用Quoted-Printable MIME 编码发送消息。这种编码对于张贴非 ASCII 语言可能是必须的，但很多邮件程序并不支持这种编码。当它们处理换行时，那些文本中四处散布的=20符号既难看也分散注意力，甚至有可能破坏内容的语意。 绝对，永远不要指望黑客们阅读使用封闭格式编写的文档，像微软公司的 Word 或 Excel 文件等。大多数黑客对此的反应就像有人将还在冒热气的猪粪倒在你家门口时你的反应一样。即便他们能够处理，他们也很厌恶这么做。 如果你从使用 Windows 的电脑发送电子邮件，关闭微软愚蠢的智能引号功能 （从[选项] &gt; [校订] &gt; [自动校正选项]，勾选掉智能引号单选框），以免在你的邮件中到处散布垃圾字符。 在论坛，勿滥用表情符号和HTML功能（当它们提供时）。一两个表情符号通常没有问题，但花哨的彩色文本倾向于使人认为你是个无能之辈。过滥地使用表情符号、色彩和字体会使你看来像个傻笑的小姑娘。这通常不是个好主意，除非你只是对性而不是对答案感兴趣。 如果你使用图形用户界面的邮件程序（如微软公司的 Outlook 或者其它类似的），注意它们的默认设置不一定满足这些要求。大多数这类程序有基于选单的查看源代码命令，用它来检查发送文件夹中的邮件，以确保发送的是纯文本文件同时没有一些奇怪的字符。 精确地描述问题并言之有物 仔细、清楚地描述你的问题或 Bug 的症状。 描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：Fedora Core 4、Slackware 9.1等）。 描述在提问前你是怎样去研究和理解这个问题的。 描述在提问前为确定问题而采取的诊断步骤。 描述最近做过什么可能相关的硬件或软件变更。 尽可能的提供一个可以重现这个问题的可控环境的方法。 尽量去揣测一个黑客会怎样反问你，在你提问之前预先将黑客们可能遇到的问题回答一遍。 以上几点中，当你报告的是你认为可能在代码中的问题时，给黑客一个可以重现你的问题的环境尤其重要。当你这么做时，你得到有效的回答的机会和速度都会大大的提升。 Simon Tatham 写过一篇名为《如何有效的报告 Bug》的出色文章。强力推荐你也读一读。 话不在多而在精你需要提供精确有内容的信息。这并不是要求你简单的把成堆的出错代码或者资料完全转录到你的提问中。如果你有庞大而复杂的测试样例能重现程序挂掉的情境，尽量将它剪裁得越小越好。 这样做的用处至少有三点。第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加；第二，简化问题使你更有可能得到有用的答案；第三，在精炼你的 bug 报告的过程中，你很可能就自己找到了解决方法或权宜之计。 别动辄声称找到 Bug当你在使用软件中遇到问题，除非你非常、非常的有根据，不要动辄声称找到了 Bug。提示：除非你能提供解决问题的源代码补丁，或者提供回归测试来表明前一版本中行为不正确，否则你都多半不够完全确信。这同样适用在网页和文件，如果你（声称）发现了文件的Bug，你应该能提供相应位置的修正或替代文件。 请记得，还有许多其它使用者没遇到你发现的问题，否则你在阅读文件或搜索网页时就应该发现了（你在抱怨前已经做了这些，是吧？）。这也意味着很有可能是你弄错了而不是软件本身有问题。 编写软件的人总是非常辛苦地使它尽可能完美。如果你声称找到了 Bug，也就是在质疑他们的能力，即使你是对的，也有可能会冒犯到其中某部分人。当你在标题中嚷嚷着有Bug时，这尤其严重。 提问时，即使你私下非常确信已经发现一个真正的 Bug，最好写得像是你做错了什么。如果真的有 Bug，你会在回复中看到这点。这样做的话，如果真有 Bug，维护者就会向你道歉，这总比你惹恼别人然后欠别人一个道歉要好一点。 低声下气不能代替你的功课有些人明白他们不该粗鲁或傲慢的提问并要求得到答复，但他们选择另一个极端 —— 低声下气：我知道我只是个可悲的新手，一个撸瑟，但...。这既使人困扰，也没有用，尤其是伴随着与实际问题含糊不清的描述时更令人反感。 别用原始灵长类动物的把戏来浪费你我的时间。取而代之的是，尽可能清楚地描述背景条件和你的问题情况。这比低声下气更好地定位了你的位置。 有时网页论坛会设有专为新手提问的版面，如果你真的认为遇到了初学者的问题，到那去就是了，但一样别那么低声下气。 描述问题症状而非你的猜测告诉黑客们你认为问题是怎样造成的并没什么帮助。（如果你的推断如此有效，还用向别人求助吗？），因此要确信你原原本本告诉了他们问题的症状，而不是你的解释和理论；让黑客们来推测和诊断。如果你认为陈述自己的猜测很重要，清楚地说明这只是你的猜测，并描述为什么它们不起作用。 蠢问题 我在编译内核时接连遇到 SIG11 错误，我怀疑某条飞线搭在主板的走线上了，这种情况应该怎样检查最好？ 聪明问题 我的组装电脑是 FIC-PA2007 主机板搭载 AMD K6/233 CPU（威盛 Apollo VP2 芯片组），256MB Corsair PC133 SDRAM 内存，在编译内核时，从开机 20 分钟以后就频频产生 SIG11 错误，但是在头 20 分钟内从没发生过相同的问题。重新启动也没有用，但是关机一晚上就又能工作 20 分钟。所有内存都换过了，没有效果。相关部分的标准编译记录如下…。 由于以上这点似乎让许多人觉得难以配合，这里有句话可以提醒你：所有的诊断专家都来自密苏里州。 美国国务院的官方座右铭则是：让我看看（出自国会议员 Willard D. Vandiver 在 1899 年时的讲话：我来自一个出产玉米，棉花，牛蒡和民主党人的国家，滔滔雄辩既不能说服我，也不会让我满意。我来自密苏里州，你必须让我看看。） 针对诊断者而言，这并不是一种怀疑，而只是一种真实而有用的需求，以便让他们看到的是与你看到的原始证据尽可能一致的东西，而不是你的猜测与归纳的结论。所以，大方的展示给我们看吧！ 按发生时间先后列出问题症状问题发生前的一系列操作，往往就是对找出问题最有帮助的线索。因此，你的说明里应该包含你的操作步骤，以及机器和软件的反应，直到问题发生。在命令行处理的情况下，提供一段操作记录（例如运行脚本工具所生成的），并引用相关的若干行（如 20 行）记录会非常有帮助。 如果挂掉的程序有诊断选项（如 -v 的详述开关），试着选择这些能在记录中增加调试信息的选项。记住，多不等于好。试着选取适当的调试级别以便提供有用的信息而不是让读者淹没在垃圾中。 如果你的说明很长（如超过四个段落），在开头简述问题，接下来再按时间顺序详述会有所帮助。这样黑客们在读你的记录时就知道该注意哪些内容了。 描述目标而不是过程如果你想弄清楚如何做某事（而不是报告一个 Bug），在开头就描述你的目标，然后才陈述重现你所卡住的特定步骤。 经常寻求技术帮助的人在心中有个更高层次的目标，而他们在自以为能达到目标的特定道路上被卡住了，然后跑来问该怎么走，但没有意识到这条路本身就有问题。结果要费很大的劲才能搞定。 蠢问题 我怎样才能从某绘图程序的颜色选择器中取得十六进制的的 RGB 值？ 聪明问题 我正试着用替换一幅图片的色码（color table）成自己选定的色码，我现在知道的唯一方法是编辑每个色码区块（table slot），但却无法从某绘图程序的颜色选择器取得十六进制的的 RGB 值。 第二种提问法比较聪明，你可能得到像是建议采用另一个更合适的工具的回复。 别要求使用私人电邮回复黑客们认为问题的解决过程应该公开、透明，此过程中如果更有经验的人注意到不完整或者不当之处，最初的回复才能够、也应该被纠正。同时，作为提供帮助者可以得到一些奖励，奖励就是他的能力和学识被其他同行看到。 当你要求私下回复时，这个过程和奖励都被中止。别这样做，让回复者来决定是否私下回答 —— 如果他真这么做了，通常是因为他认为问题编写太差或者太肤浅，以至于对其它人没有兴趣。 这条规则存在一条有限的例外，如果你确信提问可能会引来大量雷同的回复时，那么这个神奇的提问句会是向我发电邮，我将为论坛归纳这些回复。试着将邮件列表或新闻群组从洪水般的雷同回复中解救出来是非常有礼貌的 —— 但你必须信守诺言。 清楚明确的表达你的问题以及需求漫无边际的提问是近乎无休无止的时间黑洞。最有可能给你有用答案的人通常也正是最忙的人（他们忙是因为要亲自完成大部分工作）。这样的人对无节制的时间黑洞相当厌恶，所以他们也倾向于厌恶那些漫无边际的提问。 如果你明确表述需要回答者做什么（如提供指点、发送一段代码、检查你的补丁、或是其他等等），就最有可能得到有用的答案。因为这会定出一个时间和精力的上限，便于回答者能集中精力来帮你。这么做很棒。 要理解专家们所处的世界，请把专业技能想像为充裕的资源，而回复的时间则是稀缺的资源。你要求他们奉献的时间越少，你越有可能从真正专业而且很忙的专家那里得到解答。 所以，界定一下你的问题，使专家花在辨识你的问题和回答所需要付出的时间减到最少，这技巧对你有用答案相当有帮助 —— 但这技巧通常和简化问题有所区别。因此，问我想更好的理解 X，可否指点一下哪有好一点说明？通常比问你能解释一下 X 吗？更好。如果你的代码不能运作，通常请别人看看哪里有问题，比要求别人替你改正要明智得多。 询问有关代码的问题时别要求他人帮你调试有问题的代码，不提示一下应该从何入手。张贴几百行的代码，然后说一声：它不能工作会让你完全被忽略。只贴几十行代码，然后说一句：在第七行以后，我期待它显示 &lt;x&gt;，但实际出现的是 &lt;y&gt;比较有可能让你得到回应。 最有效描述程序问题的方法是提供最精简的 Bug 展示测试用例（bug-demonstrating test case）。什么是最精简的测试用例？那是问题的缩影；一小个程序片段能刚好展示出程序的异常行为，而不包含其他令人分散注意力的内容。怎么制作最精简的测试用例？如果你知道哪一行或哪一段代码会造成异常的行为，复制下来并加入足够重现这个状况的代码（例如，足以让这段代码能被编译/直译/被应用程序处理）。如果你无法将问题缩减到一个特定区块，就复制一份代码并移除不影响产生问题行为的部分。总之，测试用例越小越好（查看话不在多而在精一节）。 一般而言，要得到一段相当精简的测试用例并不太容易，但永远先尝试这样做的是种好习惯。这种方式可以帮助你了解如何自行解决这个问题 —— 而且即使你的尝试不成功，黑客们也会看到你在尝试取得答案的过程中付出了努力，这可以让他们更愿意与你合作。 如果你只是想让别人帮忙审查（Review）一下代码，在信的开头就要说出来，并且一定要提到你认为哪一部分特别需要关注以及为什么。 别把自己家庭作业的问题贴上来黑客们很擅长分辨哪些问题是家庭作业式的问题；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由你来搞定，你会从中学到东西。你可以要求给点提示，但别要求得到完整的解决方案。 如果你怀疑自己碰到了一个家庭作业式的问题，但仍然无法解决，试试在使用者群组，论坛或（最后一招）在项目的使用者邮件列表或论坛中提问。尽管黑客们会看出来，但一些有经验的使用者也许仍会给你一些提示。 去掉无意义的提问句避免用无意义的话结束提问，例如有人能帮我吗？或者这有答案吗？。 首先：如果你对问题的描述不是很好，这样问更是画蛇添足。 其次：由于这样问是画蛇添足，黑客们会很厌烦你 —— 而且通常会用逻辑上正确，但毫无意义的回答来表示他们的蔑视， 例如：没错，有人能帮你或者不，没答案。 一般来说，避免用 是或否、对或错、有或没有类型的问句，除非你想得到是或否类型的回答。 即使你很急也不要在标题写紧急这是你的问题，不是我们的。宣称紧急极有可能事与愿违：大多数黑客会直接删除无礼和自私地企图即时引起关注的问题。更严重的是，紧急这个字（或是其他企图引起关注的标题）通常会被垃圾信过滤器过滤掉 —— 你希望能看到你问题的人可能永远也看不到。 有半个例外的情况是，如果你是在一些很高调，会使黑客们兴奋的地方，也许值得这样去做。在这种情况下，如果你有时间压力，也很有礼貌地提到这点，人们也许会有兴趣回答快一点。 当然，这风险很大，因为黑客们兴奋的点多半与你的不同。譬如从 NASA 国际空间站（International Space Station）发这样的标题没有问题，但用自我感觉良好的慈善行为或政治原因发肯定不行。事实上，张贴诸如紧急：帮我救救这个毛绒绒的小海豹！肯定让你被黑客忽略或惹恼他们，即使他们认为毛绒绒的小海豹很重要。 如果你觉得这点很不可思议，最好再把这份指南剩下的内容多读几遍，直到你弄懂了再发文。 礼多人不怪，而且有时还很有帮助彬彬有礼，多用请和谢谢您的关注，或谢谢你的关照。让大家都知道你对他们花时间免费提供帮助心存感激。 坦白说，这一点并没有比清晰、正确、精准并合法语法和避免使用专用格式重要（也不能取而代之）。黑客们一般宁可读有点唐突但技术上鲜明的 Bug 报告，而不是那种有礼但含糊的报告。（如果这点让你不解，记住我们是按问题能教给我们什么来评价问题的价值的） 然而，如果你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。 （我们注意到，自从本指南发布后，从资深黑客那里得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些黑客觉得先谢了意味着事后就不用再感谢任何人的暗示。我们的建议是要么先说先谢了，然后事后再对回复者表示感谢，或者换种方式表达感激，譬如用谢谢你的关注或谢谢你的关照。） 问题解决后，加个简短的补充说明问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个说明比较恰当。 最理想的方式是向最初提问的话题回复此消息，并在标题中包含已修正，已解决或其它同等含义的明显标记。在人来人往的邮件列表里，一个看见讨论串问题 X和问题 X - 已解决的潜在回复者就明白不用再浪费时间了（除非他个人觉得问题 X的有趣），因此可以利用此时间去解决其它问题。 补充说明不必很长或是很深入；简单的一句你好，原来是网线出了问题！谢谢大家 – Bill比什么也不说要来的好。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇大论更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。 对于有深度的问题，张贴调试记录的摘要是有帮助的。描述问题的最终状态，说明是什么解决了问题，在此之后才指明可以避免的盲点。避免盲点的部分应放在正确的解决方案和其它总结材料之后，而不要将此信息搞成侦探推理小说。列出那些帮助过你的名字，会让你交到更多朋友。 除了有礼貌和有内涵以外，这种类型的补充也有助于他人在邮件列表/新闻群组/论坛中搜索到真正解决你问题的方案，让他们也从中受益。 至少，这种补充有助于让每位参与协助的人因问题的解决而从中得到满足感。如果你自己不是技术专家或者黑客，那就相信我们，这种感觉对于那些你向他们求助的大师或者专家而言，是非常重要的。问题悬而未决会让人灰心；黑客们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次提问时尝到甜头。 思考一下怎样才能避免他人将来也遇到类似的问题，自问写一份文件或加个常见问题（FAQ）会不会有帮助。如果是的话就将它们发给维护者。 在黑客中，这种良好的后继行动实际上比传统的礼节更为重要，也是你如何透过善待他人而赢得声誉的方式，这是非常有价值的资产。 如何解读答案 RTFM 和 STFW：如何知道你已完全搞砸了有一个古老而神圣的传统：如果你收到RTFM （Read The Fucking Manual）的回应，回答者认为你应该去读他妈的手册。当然，基本上他是对的，你应该去读一读。 RTFM 有一个年轻的亲戚。如果你收到STFW（Search The Fucking Web）的回应，回答者认为你应该到他妈的网上搜索。那人多半也是对的，去搜索一下吧。（更温和一点的说法是 **Google 是你的朋友**！） 在论坛，你也可能被要求去爬爬论坛的旧文。事实上，有人甚至可能热心地为你提供以前解决此问题的讨论串。但不要依赖这种关照，提问前应该先搜索一下旧文。 通常，用这两句之一回答你的人会给你一份包含你需要内容的手册或者一个网址，而且他们打这些字的时候也正在读着。这些答复意味着回答者认为 你需要的信息非常容易获得； 你自己去搜索这些信息比灌给你，能让你学到更多。 你不应该因此不爽；依照黑客的标准，他已经表示了对你一定程度的关注，而没有对你的要求视而不见。你应该对他祖母般的慈祥表示感谢。 如果还是搞不懂如果你看不懂回应，别立刻要求对方解释。像你以前试着自己解决问题时那样（利用手册，FAQ，网络，身边的高手），先试着去搞懂他的回应。如果你真的需要对方解释，记得表现出你已经从中学到了点什么。 比方说，如果我回答你：看来似乎是 zentry 卡住了；你应该先清除它。，然后，这是一个很糟的后续问题回应：zentry 是什么？ 好的问法应该是这样：哦~~~我看过说明了但是只有 -z 和 -p 两个参数中提到了 zentries，而且还都没有清楚的解释如何清除它。你是指这两个中的哪一个吗？还是我看漏了什么？ 处理无礼的回应很多黑客圈子中看似无礼的行为并不是存心冒犯。相反，它是直接了当，一针见血式的交流风格，这种风格更注重解决问题，而不是使人感觉舒服而却模模糊糊。 如果你觉得被冒犯了，试着平静地反应。如果有人真的做了出格的事，邮件列表、新闻群组或论坛中的前辈多半会招呼他。如果这没有发生而你却发火了，那么你发火对象的言语可能在黑客社区中看起来是正常的，而你将被视为有错的一方，这将伤害到你获取信息或帮助的机会。 另一方面，你偶尔真的会碰到无礼和无聊的言行。与上述相反，对真正的冒犯者狠狠地打击，用犀利的语言将其驳得体无完肤都是可以接受的。然而，在行事之前一定要非常非常的有根据。纠正无礼的言论与开始一场毫无意义的口水战仅一线之隔，黑客们自己莽撞地越线的情况并不鲜见。如果你是新手或外人，避开这种莽撞的机会并不高。如果你想得到的是信息而不是消磨时光，这时最好不要把手放在键盘上以免冒险。 （有些人断言很多黑客都有轻度的自闭症或亚斯伯格综合症，缺少用于润滑人类社会正常交往所需的神经。这既可能是真也可能是假的。如果你自己不是黑客，兴许你认为我们脑袋有问题还能帮助你应付我们的古怪行为。只管这么干好了，我们不在乎。我们喜欢我们现在这个样子，并且通常对病患标记都有站得住脚的怀疑）。 Jeff Bigler 的观察总结和这个相关也值得一读 (tact filters)。 在下一节，我们会谈到另一个问题，当你行为不当时所会受到的冒犯。 如何避免扮演失败者在黑客社区的论坛中有那么几次你可能会搞砸 —— 以本指南所描述到的或类似的方式。而你会在公开场合中被告知你是如何搞砸的，也许攻击的言语中还会带点夹七夹八的颜色。 这种事发生以后，你能做的最糟糕的事莫过于哀嚎你的遭遇、宣称被口头攻击、要求道歉、高声尖叫、憋闷气、威胁诉诸法律、向其雇主报怨、忘了关马桶盖等等。相反地，你该这么做： 熬过去，这很正常。事实上，它是有益健康且合理的。 社区的标准不会自行维持，它们是通过参与者积极而公开地执行来维持的。不要哭嚎所有的批评都应该通过私下的邮件传送，它不是这样运作的。当有人评论你的一个说法有误或者提出不同看法时，坚持声称受到个人攻击也毫无益处，这些都是失败者的态度。 也有其它的黑客论坛，受过高礼节要求的误导，禁止参与者张贴任何对别人帖子挑毛病的消息，并声称如果你不想帮助用户就闭嘴。 结果造成有想法的参与者纷纷离开，这么做只会使它们沦为毫无意义的唠叨与无用的技术论坛。 夸张的讲法是：你要的是“友善”（以上述方式）还是有用？两个里面挑一个。 记着：当黑客说你搞砸了，并且（无论多么刺耳）告诉你别再这样做时，他正在为关心你和他的社区而行动。对他而言，不理你并将你从他的生活中滤掉更简单。如果你无法做到感谢，至少要表现得有点尊严，别大声哀嚎，也别因为自己是个有戏剧性超级敏感的灵魂和自以为有资格的新来者，就指望别人像对待脆弱的洋娃娃那样对你。 有时候，即使你没有搞砸（或者只是在他的想像中你搞砸了），有些人也会无缘无故地攻击你本人。在这种情况下，抱怨倒是真的会把问题搞砸。 这些来找麻烦的人要么是毫无办法但自以为是专家的不中用家伙，要么就是测试你是否真会搞砸的心理专家。其它读者要么不理睬，要么用自己的方式对付他们。这些来找麻烦的人在给他们自己找麻烦，这点你不用操心。 也别让自己卷入口水战，最好不要理睬大多数的口水战 —— 当然，这是在你检验它们只是口水战，并且未指出你有搞砸的地方，同时也没有巧妙地将问题真正的答案藏于其后（这也是有可能的）。 不该问的问题以下是几个经典蠢问题，以及黑客没回答时心中所想的： 问题：我能在哪找到 X 程序或 X 资源？ 问题：我怎样用 X 做 Y？ 问题：如何设定我的 shell 提示？ 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？ 问题：我的程序/设定/SQL 语句没有用 问题：我的 Windows 电脑有问题，你能帮我吗？ 问题：我的程序不会动了，我认为系统工具 X 有问题 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？ 问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？ 问题：我能在哪找到 X 程序或 X 资源？ 回答：就在我找到它的地方啊，白痴 —— 搜索引擎的那一头。天哪！难道还有人不会用 Google 吗？ 问题：我怎样用 X 做 Y？ 回答：如果你想解决的是 Y ，提问时别给出可能并不恰当的方法。这种问题说明提问者不但对 X 完全无知，也对 Y 要解决的问题糊涂，还被特定形势禁锢了思维。最好忽略这种人，等他们把问题搞清楚了再说。 问题：如何设定我的 shell 提示？？ 回答：如果你有足够的智慧提这个问题，你也该有足够的智慧去 RTFM，然后自己去找出来。 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？ 回答：试试看就知道了。如果你试过，你既知道了答案，就不用浪费我的时间了。 问题：我的{程序/设定/SQL 语句}不工作 回答：这不算是问题吧，我对要我问你二十个问题才找得出你真正问题的问题没兴趣 —— 我有更有意思的事要做呢。在看到这类问题的时候，我的反应通常不外如下三种 你还有什么要补充的吗？ 真糟糕，希望你能搞定。 这关我屁事？ 问题：我的 Windows 电脑有问题，你能帮我吗？ 回答：能啊，扔掉微软的垃圾，换个像 Linux 或 BSD 的开源操作系统吧。 注意：如果程序有官方版 Windows 或者与 Windows 有互动（如 Samba），你可以问与 Windows 相关的问题， 只是别对问题是由 Windows 操作系统而不是程序本身造成的回复感到惊讶， 因为 Windows 一般来说实在太烂，这种说法通常都是对的。 问题：我的程序不会动了，我认为系统工具 X 有问题 回答：你完全有可能是第一个注意到被成千上万用户反复使用的系统调用与函数库档案有明显缺陷的人，更有可能的是你完全没有根据。不同凡响的说法需要不同凡响的证据，当你这样声称时，你必须有清楚而详尽的缺陷说明文件作后盾。 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？ 回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的 Linux 使用群组者寻求实际的指导吧（你能在这儿找到使用者群组的清单）。 注意：如果安装问题与某 Linux 的发行版有关，在它的邮件列表、论坛或本地使用者群组中提问也许是恰当的。此时，应描述问题的准确细节。在此之前，先用 Linux 和所有被怀疑的硬件作关键词仔细搜索。 问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？ 回答：想要这样做，说明了你是个卑鄙小人；想找个黑客帮你，说明你是个白痴！ 好问题与蠢问题最后，我将透过举一些例子，来说明怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。 蠢问题： 我可以在哪儿找到关于 Foonly Flurbamatic 的资料？ 这种问法无非想得到 STFW 这样的回答。 聪明问题： 我用 Google 搜索过 “Foonly Flurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？ 这个问题已经 STFW 过了，看起来他真的遇到了麻烦。 蠢问题： 我从 foo 项目找来的源码没法编译。它怎么这么烂？ 他觉得都是别人的错，这个傲慢自大的提问者。 聪明问题： foo 项目代码在 Nulix 6.2 版下无法编译通过。我读过了 FAQ，但里面没有提到跟 Nulix 有关的问题。这是我编译过程的记录，我有什么做的不对的地方吗？ 提问者已经指明了环境，也读过了 FAQ，还列出了错误，并且他没有把问题的责任推到别人头上，他的问题值得被关注。 蠢问题： 我的主机板有问题了，谁来帮我？ 某黑客对这类问题的回答通常是：好的，还要帮你拍拍背和换尿布吗？，然后按下删除键。 聪明问题： 我在 S2464 主机板上试过了 X 、 Y 和 Z ，但没什么作用，我又试了 A 、 B 和 C 。请注意当我尝试 C 时的奇怪现象。显然 florbish 正在 grommicking，但结果出人意料。通常在 Athlon MP 主机板上引起 grommicking 的原因是什么？有谁知道接下来我该做些什么测试才能找出问题？ 这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。 在最后一个问题中，注意告诉我答案和给我启示，指出我还应该做什么诊断工作之间微妙而又重要的区别。 事实上，后一个问题源自于 2001 年 8 月在 Linux 内核邮件列表（lkml）上的一个真实的提问。我（Eric）就是那个提出问题的人。我在 Tyan S2464 主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决这一问题的重要信息。 通过我的提问方法，我给了别人可以咀嚼玩味的东西；我设法让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，并邀请他们与我共同探讨。通过告诉他们我所走过的弯路，以避免他们再浪费时间，我也表明了对他们宝贵时间的尊重。 事后，当我向每个人表示感谢，并且赞赏这次良好的讨论经历的时候， 一个 Linux 内核邮件列表的成员表示，他觉得我的问题得到解决并非由于我是这个列表中的名人，而是因为我用了正确的方式来提问。 黑客从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我像个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，这直接导致了本指南的出现。 如果得不到回答如果仍得不到回答，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。 总的来说，简单的重复张贴问题是个很糟的点子。这将被视为无意义的喧闹。有点耐心，知道你问题答案的人可能生活在不同的时区，可能正在睡觉，也有可能你的问题一开始就没有组织好。 你可以通过其他渠道获得帮助，这些渠道通常更适合初学者的需要。 有许多网上的以及本地的使用者群组，由热情的软件爱好者（即使他们可能从没亲自写过任何软件）组成。通常人们组建这样的团体来互相帮助并帮助新手。 另外，你可以向很多商业公司寻求帮助，不论公司大还是小。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了 —— 完全可能如此 —— 你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。 对像是 Linux 这种大众化的软件，每个开发者至少会对应到上万名使用者。根本不可能由一个人来处理来自上万名使用者的求助电话。要知道，即使你要为这些协助付费，和你所购买的同类软件相比，你所付出的也是微不足道的（通常封闭源代码软件的技术支持费用比开源软件的要高得多，且内容也没那么丰富）。 如何更好地回答问题态度和善一点。问题带来的压力常使人显得无礼或愚蠢，其实并不是这样。 对初犯者私下回复。对那些坦诚犯错之人没有必要当众羞辱，一个真正的新手也许连怎么搜索或在哪找常见问题都不知道。 如果你不确定，一定要说出来！一个听起来权威的错误回复比没有还要糟，别因为听起来像个专家很好玩，就给别人乱指路。要谦虚和诚实，给提问者与同行都树个好榜样。 如果帮不了忙，也别妨碍他。不要在实际步骤上开玩笑，那样也许会毁了使用者的设置 —— 有些可怜的呆瓜会把它当成真的指令。 试探性的反问以引出更多的细节。如果你做得好，提问者可以学到点东西 —— 你也可以。试试将蠢问题转变成好问题，别忘了我们都曾是新手。 尽管对那些懒虫抱怨一声 RTFM 是正当的，能指出文件的位置（即使只是建议个 Google 搜索关键词）会更好。 如果你决定回答，就请给出好的答案。当别人正在用错误的工具或方法时别建议笨拙的权宜之计（workaround），应推荐更好的工具，重新界定问题。 正面的回答问题！如果这个提问者已经很深入的研究而且也表明已经试过 X 、 Y 、 Z 、 A 、 B 、 C 但没得到结果，回答 试试看 A 或是 B 或者 试试 X 、 Y 、 Z 、 A 、 B 、 C 并附上一个链接一点用都没有。 帮助你的社区从问题中学习。当回复一个好问题时，问问自己如何修改相关文件或常见问题文件以免再次解答同样的问题？，接着再向文件维护者发一份补丁。 如果你是在研究一番后才做出的回答，展现你的技巧而不是直接端出结果。毕竟授人以鱼不如授人以渔。 相关资源如果你需要个人电脑、Unix 系统和网络如何运作的基础知识，参阅 Unix 系统和网络基本原理。 当你发布软件或补丁时，试着按软件发布实践操作。 鸣谢Evelyn Mitchel 贡献了一些愚蠢问题例子并启发了编写如何更好地回答问题这一节， Mikhail Ramendik 贡献了一些特别有价值的建议和改进。"},{"title":"“描绘人内心的全部深度”——《罪与罚》总序","date":"2021-07-03T14:07:21.000Z","url":"/2021/07/03/%E2%80%9C%E6%8F%8F%E7%BB%98%E4%BA%BA%E5%86%85%E5%BF%83%E7%9A%84%E5%85%A8%E9%83%A8%E6%B7%B1%E5%BA%A6%E2%80%9D%E2%80%94%E2%80%94%E3%80%8A%E7%BD%AA%E4%B8%8E%E7%BD%9A%E3%80%8B%E6%80%BB%E5%BA%8F/","tags":["文学"],"content":"FROM： 解读作家是难事，何况是陀思妥耶夫斯基这样的作家。一个半世纪以来，文学家、思想家、评论家，以至革命家们，虽然对陀氏其人其文多有阐发，却是众口异词，甚或径相抵牾。然而，陀氏的面貌终究还是深印在人们的心中，只是每个读者心目中的陀思妥耶夫斯基不尽相同。这首先是因为陀思妥耶夫斯基作品本身的多义性，由此引出了后来的批评家们大相径庭的评论。这种现象，许多大作家都有。因为“大”，就多了包容，才生出种种阐释。那么作家真正的本义在哪里呢？当然是在作品里，但要使本义外化，又须通过阅读，而阅读的主体却又各有各的立场和观念，于是转而为无尽的，甚至相悖的评论。作品的本义游弋在阅读和评论之间。这种说法显得像一个悖论，却是事实。所以像陀思妥耶夫斯基这样的作家，最好还是不去寻求一劳永逸的解读，因为它不曾有，也不会有，就像不会有一劳永逸的文学批评理论一样。我们从批评家那夫等人却并不出身于平民，相反倒有优裕的生活来保证他们的写作，就像当时俄国历史上第一次有组织有纲领的十二月党人起义偏偏发生在一批贵族青年中一样，俄国的思想和变革的号角是在知识阶层里吹起的。陀思妥耶夫斯基虽然也不出身平民，但在俄国作家里，他的一生踬蹶困顿，充满了悲剧性的变故。疾病对他的折磨也造成他精神上的创伤，这在相当程度上反映在他的作品里。一八二一年十一月十一日陀思妥耶夫斯基出生在莫斯科。父亲是一名普通的军队医官，薄有田产，也取得了贵族身份。青年陀氏醉心于文艺，还在莫斯科一所寄宿中学读书的时候，就在老师的影响下接触了当时俄国和西欧的文学，涉猎了从莎士比亚到西欧浪漫主义和现实主义经典作家的作品。 但父亲的普通医官职务和小农奴主的身份只能勉强供陀思妥耶夫斯基求学。中学毕业后，他依照父亲的意愿，进了彼得堡军事工程学院，以冀将来在军队里谋职。一八三九年他父亲被自己田庄上的农奴殴打致死。一八四三年他从工程学院毕业后只工作了一年，就辞去公职，决然从事文学翻译和创作。彼得堡的生活，扩大了他对俄国社会的了解，他开始关注并决心“用一辈子”来探索“人和人生”之谜。经过短暂的准备，包括翻译巴尔扎克的长篇《欧也妮·葛朗台》之后，一八四五年发表第一部中篇《穷人》。这个篇幅不大的中篇引起当时俄国文坛极大反响，如别林斯基认为这是“社会小说的第一次尝试”，涅克拉索夫甚至惊呼是“新的果戈理出现了”。这是陀思妥耶夫斯基文学之路的第一次回响。革命民主主义派和“自然派”发现了陀思妥耶夫斯基，并引以为同道。但是陀氏在《穷人》中开掘了“小人物”主题之后，似乎并不满足于“社会小说”的界定。马上在一八四六年发表了另一个中篇《双重人格——高略德金先生的奇遇》，把眼光从社会问题转入了人物的内心世界、心理过程。正反两种对立的性格，其实是存在于一个人的身上，作家把他们幻化为性格迥异的两个同貌人，借助荒诞的手法把人性中的怯懦与野心、本分与嚣张、老实与与无耻等等，作了极端的对比表现。从解剖社会转入解剖人性，预示了陀思妥耶夫斯基的创作不同凡响的多样化趋向。“双重人格”的倾向在这里只是最初的开端，它将在嗣后的作品里不断深化，成为陀氏最主要的母题之一。这部作品当然受到了以别林斯基为首的革命民主主义批评家的反对。这是文艺理论中政治倾向性的差异。陀氏当时对文学性的侧重，例如强调文学的“想象”和“幻想”，即后来所谓的“幻想的现实主义”，与革命民主主义派对社会使命的重视，强调文学应同专制农奴制度作斗争并宣传革命和社会主义的主张产生分歧。陀氏认为“这是强加给文学的……有辱于它身份的使命”。其实这不单是一种文艺论争。这种分歧，终于在一八四七年公开化，致使后来的许多批评家认为陀氏脱离了革命民主主义正确的主张。现在从陀氏的创作个性和作品整体来看，这种分道扬镳恐怕是必然的。然而，四十年代终究是陀氏创作生涯中一个重要的开始。接着发表的中篇小说《女房东》（1847）、《白夜》（1848）、《脆弱的心》（1848）以及未完成的《涅陀契卡·涅兹凡诺娃》（1849）等作品，都表明此时已经形成带有陀氏个性并在他后来小说里反复出现的一些旋律，如：“小人物”、“双重人格”、“幻想家”、“罪恶与情欲本能”、“被伤害与侮辱的”等等。这表明陀氏的小说真正的着眼点也许并不全在正面的写实上，更在审视人的本身、剖视人性以及挖掘人生本义上。 然而，陀氏四十年代的创作却中断在蓄势待发的状态里。在文学观念上他虽然和别林斯基发生了分歧，但他在政治思想上依然信奉法国空想社会主义，而且参加了当时俄国著名的彼得拉舍夫斯基小组的活动，是积极成员之一。一八四九年陀思妥耶夫斯基和小组其他成员一起被沙皇政府逮捕，他因在小组上朗读过别林斯基有名的反农奴制度的信《致果戈理》，以及其他的“罪名”，被剥夺了贵族身份，并处死刑。在临刑前改判为流放苦役并期满后当兵。长达九年的苦役和兵营生活，对陀思妥耶夫斯基的一生有着不可磨灭的影响。一方面，亲历底层生活极大丰富了他对生活的认识，积累了大量的文学素材，对社会和人生的思考更趋深刻，形成了独特的哲理性探索，但长期亲历流放和苦役，无可否认也加重了他对人生苦难和社会阴暗的感觉。与底层生活的紧密接触，使他更关注人民的思绪，特别是根植在民间的宗教意识，一种寻求权力阶层和平民之间和解的倾向在他身上开始显现。加之生理上癫痫病发作日趋频繁，沙皇鹰犬无时不在的监视跟踪，更增添了他精神上的抑郁，以致他的创作也隐含了某些病态、痉挛的风格。这也是后来许多评论家所说陀氏思想消极面的由头。 经历了无数磨难，他在五十年代末返回彼得堡，开始了他创作生涯的新阶段。这一时期发表的中篇小说《舅舅的梦》（1859）、《斯捷潘奇科沃村及其居民》（1859）和长篇小说《被伤害与侮辱的人们》（1861）还继续着四十年代的风格，在长篇中除了描写社会和家庭的道德堕落以外，已经出现宣扬正教受苦受难精神、人要在苦难里寻求幸福、以苦难来净化心灵的说教。对社会真实的揭示和借宗教解脱的药方，是这一时期创作里很明显的矛盾倾向，出现了所谓“苦难救赎”的主题。一八六一年正值俄罗斯农奴制度改革，陀氏却在文学观念和政治主张两个方面明确宣告自己的主张。一八六一年他针对杜勃罗留波夫而发的一篇论文《——波夫先生和艺术问题》，明确反对艺术的“功利主义”，虽然他并不赞同“为艺术而艺术”的主张，但强调艺术的“主要本质”是“灵感的自由”。在政治主张上陀氏更接近的是俄国的斯拉夫主义，一八六二年发表《两个理论家阵营》，文章主要针对当时的“自由主义”代表如卡特科夫的主张，但同时也表明了自己与革命民主派的分歧，提出“根基论”主张，强调人民的信仰才是“根基”，是道德理想的根源，俄国的改革必须与人民的“根基”相结合，西欧的革命方式不适用于俄国，应该寻求在君主和正教教会指引下的和解和团结，利用普及“文化和教育”促使两者的联合。这一点是历来评论家对陀氏思想最有非议的地方，常常被视作对革命民主主义派的攻击。但就在这个时期，以作家亲身经历为素材的长篇笔记小说《死屋手记》（1861—1862）发表了。小说展示了苦役犯可怕处境和精神状态，从社会和生活的因果深入剖析人性“善”、“恶”的变异。人性中兽性一面发展成“恶魔化”的个性，出现了“强者与弱者”的论题。俄国思想家赫尔岑说“以戴着镣铐的手为自己的难友画像，竟然将西伯利亚一座牢狱的风尚习俗，创作成米开朗琪罗式的壁画”，屠格涅夫更把它比作但丁《神曲》的《地狱篇》。一八六四年发表的中篇《地下室手记》更是从心理分析的角度来剖析一种“自卑”的内心世界，触及了人的潜在意识问题。在“幻想家”之后，又出现了“地下人”主题，但长期以来都流传着一种说法，似乎《手记》一书是针对车尔尼雪夫斯基的长篇《怎么办？》中“合理的利己主义”而发，后来高尔基更认为此书是对虚无主义和无政府主义的辩解。这部很深入描绘了人的心理和意识的小说，承担了太多的政治重负。 一八六二年陀思妥耶夫斯基第一次走出国门，接触西欧社会。六月到八月间，在巴黎、伦敦和日内瓦的逗留，看到的一切使他对西欧的文明和发展道路产生极大的疑惑。归国后不久，就写了散记体小说《冬天记的夏天印象》，第一次触及“西欧道路与俄国方式”的母题。这是他的“根基论”最早的文学表述。这一母题在后来的几部大作品里都有程度不同的开拓，尤其是在七十年代下半叶的《作家日记》和最后的长篇《卡拉马佐夫兄弟》里更有综合性的探讨。陀思妥耶夫斯基的创作至此似乎是在为最后的四部厚重的长篇作准备。一八六六年长篇小说《罪与罚》出版，这部小说给作家带来了世界性的声誉，作品表面的谋杀情节遮掩着作家对社会和人性的深入探索。小说涉及的十分广泛的论题早已冲破故事框架，所以读者掩卷后存留在脑际的往往是各种论题，如涉及“超人与庸人”的超人哲学、有关“强者与弱者”的权力真理，更有人在言语行为里不自觉的“潜意识”泄漏，以及再一次回响起的“苦难救赎”等等。由于每个论题都有相当的雄辩性，小说作为一个体裁竟第一次彰显出某种互不相让的思想争论的品格。这被后来的文学评论家巴赫金称作为小说的“复调结构”，影响着此后一百多年长篇小说结构上的发展，且至今被认真地讨论和研究着。 《白痴》（1868）、《鬼》（1871—1872）分别体现了两种不同风格的小说。《白痴》是一部色彩斑斓的长篇小说，探讨了“罪恶与圣洁”的题目，在一个由伪善虚假织成的罗网里，一旦有人捅破那层薄薄的遮掩，这妖魔化的世界便不成体统，梅诗金公爵这个“自然人”，以十分单纯无邪的处世态度来对待周围的一切，结果呢？一切都是颠倒的：善良成了白痴，仁爱变成无用，狂暴显示为力量，怯懦装扮成理性，美命定了要被践踏和毁灭，恶却愈加肆无忌惮、扰乱一切。梅诗金公爵并没有能撼动这张根深蒂固的网，他并不能为这个世界做什么，仍然回到他那瑞士的净土。作家以强烈的激情揭示了当时俄国社会的腐朽和道德丧尽的世象。梅诗金公爵像一面镜子，返照出腐败的群象。《鬼》则把社会政治与人性的善恶本质紧密结合起来作深入的剖视，在一个政治事件里发现人性里兽性——妖魔化的依据。《鬼》从情节上看是一部涉案小说，在社会政治层面上有“反虚无主义”的主题，也表明了作者对社会变革中欧洲道路的评价，但作品更多的是从共性、抽象的角度考察革命的暴力与道德人性、社会主义思想里无神论的得失等很值得深思的问题。由于当时的俄国正处在剧烈的革命变革时期，这些敏感的问题引起很大的争议。深谙文学的高尔基也从政治上评价《鬼》，说过这是“七十年代对革命运动进行恶意攻击的无数尝试中最富于天才也最恶毒的一次”。但就作品思考的深度、对沙皇政府的揭露，以及对“自由主义”的批判，此书的意义恐怕远在具体的社会事件之外，且要深刻得多。如果我们稍加注意，也许可以发现在法国存在主义作家萨特的剧作《肮脏的手》里呼应着类似的共通主题。 《卡拉马佐夫兄弟》（1879—1880）是陀思妥耶夫斯基的压卷之作。计划中有上、下两部，最后只写成了第一部。评论界一般把这部小说视为作家最成熟的作品。作家曾经开拓过的种种主题，如：“幻想家”、“双重人格”、“灵与肉”、“被伤害与侮辱的”、“超人哲学”、“权力真理”、“偶合家庭”、“恶魔性格”、“苦难救赎”等等，在这部书里都作了探讨。小说把社会现实生活的揭示、人物类型的刻画、俄国社会发展道路和人类命运的思考等一系列问题融合在一起，涉及了政治、社会、人性、哲学、伦理、道德等各个方面的论题。书中展示的人物，从老卡拉马佐夫到德米特里、伊万、阿列克塞三兄弟，以及身为厨师、实为老卡拉马佐夫私生子的斯乜尔加科夫，这个“偶合家庭”里的所有成员，都有着十分鲜明的性格，代表着不同的主题。作家从人物的心理和意识着手，写出了“俄罗斯性格”的不同方面。这些性格要素是认识俄罗斯社会和人性的重要依据。长期以来，“俄罗斯性格”似乎只是一个褒词，其实作为民族性格来讲，它“既伟大，又孱弱”，充满正反矛盾和斗争的习性才是正常的。就像果戈理《死农奴》里的地主们，也正是“俄罗斯性格”某些方面的体现。高尔基曾经写了两篇文章专论“卡拉马佐夫习性”，但这何尝不是民族性格的一部分，只是消极面凸显得更明晰罢了。《卡拉马佐夫兄弟》把俄罗斯人的生活观念、宗教意识、民族特性和人性欲望都作了透彻的解剖，脱略在具体画面之上的含义正是陀氏所追求的目标。嗣后的作家们也看到了这一点，所以在二十世纪现代主义文学兴起时，诸多现代派作家会把陀氏视作为自己的师承。但陀氏作品的丰富性，表明他依然是写实主义的杰出代表。他的作品的真实往往是通过人物的自身感受、内心分析以及近乎乖张的行为来体现，散发出强烈的时代气氛，形成别具一格的真实。陀氏说：“人们称我为心理学家，不，我是高度意义上的现实主义者，我的意思是，我描绘人的内心的全部深度。”这恐怕是理解陀思妥耶夫斯基的关键所在。 六十至七十年代陀氏还创作过两个长篇《赌徒》（1866）和《少年》（1875）。《赌徒》题材不大，写人被嗜好和物欲控制，无法自拔的状态，对沉湎于赌博的心态有极为传神的描绘。人性的弱点反过来控制人本身，带着悲剧性的意味。这也牵涉到作家自己曾经有过的一段经历。该书的创作过程成就了一段佳话。陀氏一生为金钱所困，为了偿还哥哥米哈伊尔身后的债务，他与出版社约定在规定的期限里交出一部作品，但合同规定，如逾期不交，将影响陀氏作品的版权。作家无奈之下，只能聘用女速记员安·格·斯尼特金娜，由他每天口述小说内容，斯尼特金娜打字整理成文稿，最后在二十六天的时间里赶完书稿，同时也成就了作家第二次婚姻。斯尼特金娜即后来的陀思妥耶夫斯卡娅，陀氏去世后，她对陀氏遗稿的整理作了许多贡献。《少年》写了俄国资本主义进程里人们浮躁的心态和欲望的变化。七十年代人们急切的发财欲望腐蚀着年轻一代人的灵魂。作家对特定历史时期的普遍极端个人主义，表示出明显的担忧，他想从宗教思想里找到适合的药方，当然是不现实的。但小说生动地见证了这个剧变时期的人心浮躁的状态。也许至今还有现实意义。陀思妥耶夫斯基另外的一些作品，如中篇《永久的丈夫》（1870）、“幻想性的故事”《温顺的女性》（1876）和《一个荒唐人的梦》（181877）都各有侧重，不相雷同。特别是《一个荒唐人的梦》把“幻想家”的主题上升到对“人类黄金时代”的憧憬，说明陀氏思想的变化。 从一八七三年到一八八一年陀氏陆续在刊物上发表《作家日记》，体裁不一，有政论、文学评论、回忆录、特写、谈话式的随笔以及一部分小说。长期以来，俄国评论界认为《作家日记》体现了作者思想中软弱以至反动的一面，其实这是研究陀思妥耶夫斯基的一部极其重要的资料，是正确理解陀氏其人其事的钥匙。陀氏一生，磨难不断，除了政治上的迫害，经济窘迫也是他和俄国其他大作家不一样的地方，往往预支计划中作品的稿费，以解眉急。这在某种程度上也影响着他的写作风格，而为有些评家所诟病。但陀氏的写作风格正是冲动型的，不加掩饰的内心激动，急于表达的思想观念，形成陀思妥耶夫斯基别具一格的文风。他不可能像托尔斯泰或屠格涅夫那样字斟句酌地反复修改文稿。感情的激流一路狂泻，有时甚至显得痉挛纠葛的文风，构成了陀氏小说的别样格调。很难说他写的是美文，但有着不作掩饰的内心披露，深入骨髓的无情解剖，作家自己常常会忘情于展示严酷的真实，以致只求将它们如实呈现于读者的眼前，不作表面的抑扬，却把判断留给读者自己。 陀氏小说对世界和人性的思考和剖视，把小说这个文学体裁推到了思想的前沿。小说家不是政治家或哲学家，重要的不在他能提出什么医治人生和社会的良方，因为这时他们往往是既幼稚又可笑的。文学的力量在于敏锐的发现，表现的深刻，在感性的图像里展示世界的真相和人性深处的奥秘。就这一点来说，陀思妥耶夫斯基是做得非常出色的，可以说达到了前所未有的时代的高度。高尔基虽然对陀氏有些作品颇有微词，但他承认陀思妥耶夫斯基是“最伟大的天才”，“就表现力而言，他的才能可能只有莎士比亚堪与媲美”。读过陀思妥耶夫斯基的作品，就知道这并非溢美之词。 一八八一年一月二十八日陀思妥耶夫斯基在圣彼得堡逝世。此后的一百多年时间里，臧否不一的评论从来不曾间断过，这主要是对他的政治倾向性和宗教意识而言，至于对他在世界文学中崇高的地位，他对小说文体的巨大贡献，似乎并不见太大的异议。倒是随着现代小说风格的演进，陀氏小说的价值正越来越引起人们的注意。 变幻的母题旋律小说通常都以题材分类，例如司各特的《艾凡赫》被称作“历史小说”，巴尔扎克的《人间喜剧》是以“场景”来归类，如“巴黎场景”、“外省场景”之类，托尔斯泰的《战争与和平》通常被称作“史诗小说”，更有完全具体如英国作家哈代的被统称为“威塞克斯小说”的一组作品。但陀思妥耶夫斯基写的故事虽然大都发生在彼得堡，但并没有评论家称他的小说为“彼得堡小说”。原因是陀氏小说不断开拓的是一种“母题”，他像音乐家那样，找到活跃在生活里的种种“旋律”，构成他小说的主要元素。这在以往的作家那里并不多见。 “小人物”是俄国文学里固有的一个母题，从普希金的《驿站长》开始，果戈理的《外套》，到后来契诃夫的《一个文官的死》，这个母题被开拓得淋漓尽致。陀思妥耶夫斯基的第一部作品《穷人》奏响的就是这个旋律。陀氏崇敬普希金，他的第一部作品献给了这样一个题目，也许并不偶然。因为他说过：“我们都是从普希金门下走出来的。”但《穷人》里的主人公杰武什金虽然有着和其他“小人物”一样的命运，在心里占主导地位的却是对自己人格的意识。“我有良心和思想，我是人”，“我的一块面包是我自己的，是用劳力挣来的”。社会的不公，贫富的对立使他愤懑，他意识到自己软弱，又不能有所作为，他告诉读者，“在一个最浅薄的人类天性里面有着多么美丽的、高贵的和神圣的东西”（别林斯基语）。陀氏把“小人物”的内心世界、心理过程，十分清晰地展示给读者看。这是他比前辈们要更深刻的地方。 探索人的内心奥秘，是一条很复杂的路。重视文学社会历史作用的评论家们对他承袭俄罗斯文学写“小人物”传统褒奖有加的时候，陀氏却悄悄转向，把他的探索推进到人的“双重人格”母题上，创作了小说《双重人格》（又译《孪生兄弟》、《性格迥异的同貌人》等）。历来的小说都是善恶分明，在英国小说里有“happy ends”，就连法国巴尔扎克也未能免俗，总要在小说里分出这样的壁垒。但陀思妥耶夫斯基用形象说明，善与恶常常会共同栖居在一个人身上，人的本性里就有兽性与人性，当兽性占上风的时候，就出现恶行，人性却支持着人的善行。在《双重人格》里，作者只是把这个问题提了出来，因为在一个中篇里也不可能有太深入的开掘。这个旋律，还要在作家后来的长篇里作为回旋曲反反复复地出现。但这个中篇已经把问题十分明确地提了出来。当然引起评论界一片哗然，好像陀氏忽然误入歧途。这一点甚至影响着中国的评论界。其实只消读一下陀氏嗣后的作品，就能知道《双重人格》正是作家小说母题深化的一个前兆。《罪与罚》里的斯维德里加依洛夫、《鬼》里的尼古拉·斯塔夫罗金，以及《卡拉马佐夫兄弟》中的德米特里·卡拉马佐夫和伊万·卡拉马佐夫等，都对这一个重要母题有更深入的开拓。很难设想，如果在陀思妥耶夫斯基的作品里没有“双重人格”的母题，小说的思想魅力和人物的生动个性将会是什么样子？ 小说作为一种思想现象，和其他人文学科是处在同一发展长河中的，只是文学是借助着形象来表现和认识世界，它和哲学之借助于抽象和共性、概念和逻辑来演绎世界，至少在方法上是不同的。但是人类认识的发展在不同的学科中却往往有着同步性。因为人都生活在同一个历史进程里。一个有趣的现象是，陀思妥耶夫斯基在自己的小说里用形象演绎的母题，却在后来的哲学家和心理学家的发现里得到了印证。十九世纪德国哲学家尼采出生在一八四四年，比陀思妥耶夫斯基整整晚了二十三年，他在一八九五年出版的《权力意志》一书里的基本思想，陀氏在一八六六年出版的长篇《罪与罚》里通过拉斯柯尔尼科夫的对权力的思考，作了形象的表述。主人公基本上表达了“超人哲学”和“权力意志”的观念。 按拉斯柯尔尼科夫的理论，“人按照天性法则，大致可以分成两类：一类是低的人（平凡的人）……他们是一种仅为繁殖同类的材料，而另一类则是……具有天禀和才华的人，在当时的社会里能发现新的见解。……第一类人就是一种材料……第二类人则永远是未来的主人。第一类人保持着这个世界，增加他们的数目；而第二类人推进这个世界……”“芸芸众生，人类中的普通材料，生存在世界上只是为着经过某种努力，通过某种……血统的交配而终于生出了多少具有独立精神的人，甚至一千人中只有一个。也许一万人中出一个，……几百万人中出几个天才，而伟大的天才，也许是世界上有了几十万人以后才出现的”，“真正的统治者，他才可以为所欲为，攻破土伦，在巴黎进行大屠杀，忘记在埃及的一支军队，在莫斯科远征中糟蹋了五十万条人命，……拿破仑、金字塔、滑铁卢……”这里说的几百万人中才能出一个的人，其实就是“超人”。拉斯柯尔尼科夫说：“这种人有权利昧着良心去逾越……某些障碍，但只是在为实现他的理想（有时对全人类来说也许是个救星）……如果开普勒、牛顿的发现，由于某些错综复杂的原因，没有能够为大家所知道，除非牺牲一个，或者十个或者百个，或者更多妨碍者的生命，那么牛顿为使自己的发现能让全人类知道，就有权利，甚至有义务……消灭这十个人或者百个人。”“立法者们和人类社会的建立者们……他们无一例外都是罪犯，……他们也不怕流血，只要流血对他们有利，人类社会中多数这些超人和建立者都是非常可怕的刽子手。所有这些人都是伟大的……”这类几十万以至几百万人中才有一个的“超人”可以使千千万万人毁灭，可以踏过尸体和血泊，人们却认为这是为人类造福。 常常有人说尼采的《权力意志》是法西斯主义的理论基础，但它的出现，距陀氏演绎理论和形象描绘这种事实，已经过了好几十年。人类的认识，都差不多在同一个时期进化到一个新的境地，有时是哲学家用推理和演绎的方法先作了预示，有时却由伟大的文学家用形象来先期作了表现。陀氏之所以伟大，还因为他要比弗洛伊德更早触及了人的“潜意识”。陀氏并没有提出任何理论，但是在他作品中的人物，有许多涉及潜意识的行为。他对弑父现象的描绘，梦境的暗示，人对自己行为的文饰作用，自虐倾向，甚至后来由弗洛伊德的学生荣格探讨的人在潜意识里的自卑意念的表现等许多问题，作家都有极其精细的描写。这一点，比陀思妥耶夫斯基晚生三十多年的弗洛伊德的著作是最好的证明。作为精神病学专家兼心理学家，他一方面用医案来说明他的潜意识理论，但陀思妥耶夫斯基的作品，当然地成了他理论的佐证。他那篇著名的《陀思妥耶夫斯基与弑父意识》就成了《卡拉马佐夫兄弟》的注脚。关于梦的解析以及潜意识问题的解释，陀氏成了一个提供形象材料的先驱。这是很值得玩味的现象。陀氏自己说“我描绘人内心的全部深度”，以探索人类心灵的奥秘为己任，这说明他十分自觉地从人的内心、心理、意识上切入去了解人心的秘密。但他不是哲学家，也不是心理学家，不以推论的形式来表述他的看法，但他创造的文学形象是厚重的，有着充分的心理的和哲学的依据。这也是陀氏的心理剖视要高出于文学中一般心理描写的道理。 陀氏作品里常遭非议的部分是他对宗教的态度。其实宗教问题是俄罗斯文学里一个不可逾越的论题，有着深厚的俄罗斯文化历史背景。俄罗斯是欧洲最后的封建王朝，是农奴制取消最晚的国家。农奴制借着宗教的力量在民间形成很普遍的“苦难救赎”的思想，这是无助百姓的精神寄托。东正教以苦难来救赎原罪的观念根深蒂固，在人世用苦难来净化自身，用宽恕他人来寻找内心慰藉和平衡，变成了很高尚的行为准则。在陀氏的作品中，许多矛盾都是借助这种“苦难救赎”的思想来处理的。在《被伤害与侮辱的人们》中，女主人公涅莉、娜塔莎受尽侮辱与伤害，但对待“恶魔化”的瓦尔科夫斯基之流却是正教所提倡的百般容忍和承受苦难。“痛苦能洗尽一切”，这是深入俄国农民性格里的一种意识，它只能加剧恶的横行。但这种意识至少在当时已经成了俄罗斯性格的消极组成部分。当然作为一个伟大的艺术家，陀思妥耶夫斯基在小说里还是让涅莉在临死前说出了她的诅咒“我不久前读了福音书。那里说，要宽恕自己所有的仇敌。我读了，而他（瓦尔科夫斯基）我终究没有宽恕”。这一段话，和陀氏在《被伤害与侮辱的人们》以及其他小说里一再宣扬的通过受苦来净化自身的“救赎”母题是不相吻合的，这也说明艺术的逻辑在艺术家身上终究还是要起作用的。 “灵与肉”、“兽性与神性”、“理智与情欲”这些母题，陀思妥耶夫斯基在最后一个长篇《卡拉马佐夫兄弟》里都放在“偶合家庭”这个总概念下面作了详尽的探讨。由于老卡拉马佐夫令人不齿的行为，这个家庭里的成员，没有十分牢固的精神上和感情上的联系，像几个偶然相遇的人生活在一个屋檐下，在长子德米特里身上有着老卡拉马佐夫听任自然欲望的一面，也有曾经是一名军人和体面人的痕迹，在他身上明显的“灵与肉”斗争，使他完全成了一个“双重人格”的人。为了情欲，他和老父亲争夺情妇格露莘卡，甚至扬言要杀死自己的父亲。但内心却还存留着一丝做人的尊严，也思考人间的种种苦难。所谓“所多玛城的理想”与“圣母马利亚的理想”一直在他身上斗争着。所以当老卡拉马佐夫真的被杀之后，人们理所当然地认为他是凶手，但这时的德米特里却不想为自己辩白，俄罗斯人意识里那种根深蒂固的“救赎”观念竟占了上风。他决定用苦难来净化自己，自我完善。虔诚地忏悔自己的罪孽，寻求精神的“复活”，这情节很像后来托尔斯泰在一八九九年出版的长篇《复活》的基调。我们的评论，常常直言主人公的“伪善”。在俄罗斯宗教文化的背景上，这也许并非“伪善”两字可以概括的。就像德米特里被欲望驱使时候的不顾一切，在他决定“救赎”自己的时候，也是一样的认真，这也正是俄国宗教文化背景下的“俄罗斯性格”的一种表现。同一母题在二十年后由托尔斯泰的《复活》再次奏起并作为全书的主题的时候，俄罗斯人意识里这种深藏着的宗教文化积淀，是再也不该忽视了。这种宗教文化意识，它彰显为崇高一面的时候是“救赎”，露出它破釜沉舟一面的时候则是“自虐”。《白痴》中女主人公娜斯塔霞·菲立波夫娜，在无法摆脱自己被欺凌和玩弄的命运时，虽然遇见了梅诗金公爵，但终于不愿接受公爵的帮助，宁肯随粗鲁不堪的商人罗果静而去，她拒绝“新生”，却手焚十万卢布来嘲弄报复这一群心怀鬼胎的人，明白无误地表现了一种“自虐”的倾向。在陀氏作品的母题中，也有诸如“幻想家”、“地下人”、“自然人”这样的人性概念。早期的中篇《女房东》、《白夜》、《脆弱的心》或多或少都写出当时年轻人沦为无所作为的“幻想家”的母题，但其中有些作品如《白夜》，主人公内心的纯真和善良，不计利害的自我牺牲的爱心，说明作家对这一代年轻人的期望和同情。陀思妥耶夫斯基被人称作为“残酷的天才”，因为他对人物内心解剖的犀利与无情，常常令人不寒而栗。但《白夜》里的主人公给人以一种美好的希望。人性的善良哪怕是一种“幻想”，也显得那么令人向往。这是陀氏作品里少有的充满动人诗意和明邃风格的作品。晚年的《一个荒唐人的梦》则体现了一种对于“人类黄金时代”的幻想。 在陀氏的作品中，这种不断变幻的母题旋律，是很值得注意的现象，说明作家对这个世界有着十分概括性的认识。他通过这些关键概念演绎了他对人生的思考和对社会、历史的认识。这是他的创作与其他作家十分不同的地方。陀氏的这些认识，在相当程度上还有预见性，往往会在后来的历史里找到佐证。例如被评论家阐释得很多的《卡拉马佐夫兄弟》第五卷中“宗教大法官”那一节，历来有种种解释，但这一节涉及的问题，对于人类、世界、社会秩序、暴力与奴役等等问题的探讨，无疑带着某种寓意的性质。我们习惯于对一个作家描绘的内容作出判断，陀思妥耶夫斯基却总想留下一点让人遐想的余地，包括俄国评论家定义的陀思妥耶夫斯基小说的“复调结构”，正是这种特殊风格的表现。 独特创新的小说艺术小说艺术的经典样式从文艺复兴时期到十九世纪的三百余年时间里，经过从塞万提斯、拉伯雷到司汤达、巴尔扎克、狄更斯、托尔斯泰等一大批作家的创新，已经到了相当完美的境地。陀思妥耶夫斯基却使小说的内涵层次有了更饱满的展现，并在经典的小说样式中添加了新的元素，所谓“复调”现象。 历来小说理论的着眼点，或在小说体裁的限定，如长篇、中篇、短篇；记事体、传记体、虚构体、书信体，或人物小说、事件小说、家庭小说、社会小说、历史小说、哲理小说、抒情小说、纪实小说等；或在构成小说的要素，如：情节、人物、场景、语言、风格、主题等。小说的要素是小说存在的形式，是小说之所以为小说的理由，是小说区别于其他文学体裁的依据。但小说的价值还取决于它的内涵层次，不同类型的小说有不同的内涵。陀氏的小说却通常能提供更加饱满的阅读层次。不同的读者，在陀氏作品里可以找到不尽相同的内涵。这种见仁见智的现象，虽然在其他大作家那里也不乏表现，但在陀思妥耶夫斯基绝对是一种特色。 小说的内涵是分层次的。小说可以在故事情节层次上被阅读，也称作事件层次。这是可以用叙述梗概的方式来表达的那一部分内容。一个年龄不小的小公务员杰武什金和一个苦命的、饱受凌辱的年轻姑娘杜勃罗谢洛娃相爱，而终因周围世界中人、事和生计的迫促，只得深受别离之苦而抱憾终身的故事。主人公善良而软弱、自尊而无奈、深情而无力的处境，社会与生活对小人物的重压和摧残，贫苦情侣在生活重担下无出路的状态等等，这就是陀氏第一部小说《穷人》的故事情节层次。一个读者，单读这个感人而痛苦的爱情故事，也可以受到感动。再看另一所谓“偶合家庭”的故事。父子、兄弟五人间种种思想的、感情的、物欲的、精神的冲突，在冲突、矛盾，以致仇视的过程中，引出一起弑父的案件。这是陀思妥耶夫斯基最后的长篇小说《卡拉马佐夫兄弟》的故事情节层次。这个事件对于读者也一样有它的吸引力，它显示了一个家庭悲剧，每个人物都有着自己的性格和行为的理由。读者也看到了人性的罪恶与奸诈，情欲对人的毁灭力量。这样的事件，在生活里是可以得到印证的。许多小说在这个层次上就结束了。这类小说被称作为情节小说，或者事件小说。但陀氏的小说通常还可以进入第二个层次的阅读。 社会历史的层次较之情节和故事要更进一步，因为它着眼在与故事相关的社会、政治、历史的主题，也就是时代的层次。这些主题也许并不具有永恒共通的意义，但它们有着时代的迫切的内涵。不仅促使当代人思考，而且是长久的历史鉴照。《穷人》在这个层次上表达了社会的混乱和失衡。好人受苦，恶人当道；有活力的青春被毁灭，为非作歹者左右他人的命运，一个是非颠倒的社会，它的出路在哪里？谁的罪过？这是十九世纪俄罗斯社会的写照。对于生活在这个社会里的人们有着震撼人心的力量，所以它会引起别林斯基等人的惊呼，但它也会引起后来某些社会阶段里人们的共鸣。在《卡拉马佐夫兄弟》里，处在这一个层次上的问题表面上并不十分显著，但是作家从六十年代初开始关注的“西欧道路与俄国方式”的社会变革观，在这里得到了综合性的表述。作家在一九六三年发表的《冬天记的夏天印象》里尖锐批判的西方资产者的贪欲与自私、伴随西方式自由与平等而来的罪恶，在《卡拉马佐夫兄弟》里以文学形象作了充分的展示。深植在人民土壤里的宗教意识与文化知识载体的完美结合，成了陀思妥耶夫斯基心目里的“俄国方式”。这是《卡拉马佐夫兄弟》这部作品中时代的层次，是当时整个俄国社会都以不同的方式关心着的社会历史内涵。是当时俄国具有相当迫切性的主题。但这样的母题，对于中国的读者来说可能会因为文化宗教背景产生现实的距离，但对今天的俄国社会和文化来说，始终是一个十分引人关注而且一时难于解决的问题。“西欧道路与俄国方式”、“欧洲与亚洲”、“东方与西方”，这些思考从一九一七年以来俄国八十余年历史进程中，从来也不曾消停过。俄国方式的宗教影响依然是一种潜在的激流。 个别的事物走向本质的共通，具体的形象趋于抽象的普遍。小说在经过了故事情节画面、社会历史含义之后，最后的境界是永恒共通的哲理。它是无数具体故事情节和社会历史图像的普遍概括。它不会因事过境迁而失去活力，却能把表象指归到本质。并不是所有的小说都具有这样的品格，但陀思妥耶夫斯基的作品的着眼点，往往正是在这人性共通的哲理上。陀思妥耶夫斯基对哲学有相当透彻的了解，这从他论述到的哲学家的数量上可以证明，但他不是哲学家，作为小说家，他必然要透过人性来观察现象的本质。他说过要“在人身上发现人”，所谓“窥视心灵的奥秘”。这是作家最终的着眼点。如果说一部《穷人》，苦难的爱情是它的情节，善恶的失衡是它的现实，那么主人公心理的变幻是它最终要探索的奥秘。就像《双重人格》，情节是一个精神错乱的小公务员的故事，我们完全可以把它理解为一个精神病人的感觉和体验。所指社会现实是弱肉强食，强力和扩张对软弱与安分的排挤，但作家在永恒的人性层次上要说明的却是善与恶原本就共存于一体，人性与生俱来有着“双重”性，魔鬼与天使共居一处乃是人的天性，人性的复杂和变异都来源于此。当然，这一命题在这里还只是一个开篇，更深的探究还有待后来的几部大作品，《罪与罚》中斯维德里加依洛夫性格里那种善与恶、崇高和卑鄙的难以想象的结合，《鬼》里斯塔夫罗金幻觉里看到的那个可怕之至的“蜘蛛”，其实就是他内在本性里恶的幻化。他那种对善恶界限虽然内心清楚，却行为放浪、淫乱无耻、不断作恶，两种相互排斥的思想可以同时宣教，却并不相信其中任何一种，“我……希望做好事，并从中感到愉快，同时我又希望干坏事，并且也感到愉快”，终于在无法解决的矛盾里以自杀了结生命。《卡拉马佐夫兄弟》中伊万与“鬼”谈话，正是一个人身上善因与恶因的交锋。在陀思妥耶夫斯基的作品里这类题目有许多，例如“人的社会性与生物性”、“人的非逻辑行为”、“潜在意识与外部行为”、“直觉现象”、“偶然与必然”、“理智与感情”、“诱惑与理性”、“灵与肉”、“真性情与无个性”等等。总之，他善于把真正人性面上那一层遮掩物毫不顾惜地揭开，示世人以人类本性的真相。所以永恒共通的层次是陀氏作品中最值得关注的部分。在这个层次上来读小说，可能具体的情节故事和社会历史画面反倒显得不那么重要，因为这时作家探讨的是在抽象共通层面上的题目，所谓“义主文外”，“秘响旁通”的部分。它们超脱了具体的图像和事件，进入共通的境界，把人身上最最隐秘的部分呈现在读者的面前。涉及永恒哲理的层次有许多，人性的奥秘是重要方面，当然也有超出人性范畴的命题，如“真实与假象”、“宗教与道义”、“教条式与创造性”、“生命的本质”等等。这些题目的产生，当然并非完全抽象的永恒，而有陀氏自身的历史限定性，但他所提供的思考角度，至今仍不乏现实意义，所以对陀氏作品的不同层次的内涵，是非常值得关注的，因为它们都包含着作家十分独特的发现。 二十世纪现代主义文学兴起，虽然在最初颠覆传统的时刻，也有一些流派宣告过要把陀思妥耶夫斯基扔进大海，但随着现代主义文学的深入发展，许多现代主义的代表人物，却开始谬托师承，把陀思妥耶夫斯基奉为现代主义的偶像。这是很值得思索的现象。其实陀思妥耶夫斯基与现代主义虽说也可以强调某些传承关系，但陀氏终究还是经典小说的代表。不过他小说里的创新，的确有十分独特的个性。十九世纪俄罗斯的小说是以它的思考深度、现实诉求和批判热情为主要特点的。所以后来在俄国有了“批判现实主义”的说法。这是从思想特征上来评价。但俄罗斯小说艺术，也有着相应的创新和变革。其中陀思妥耶夫斯基小说的创作尤其让人觉得有着某种新意。直到俄国文艺评论家米·巴赫金出版专著《陀思妥耶夫斯基的创作问题》（1928），其中提出陀氏小说的“复调结构”问题，才引起评论界注意。可惜的是该书的主要思想与当局一统的文艺政策和理论体系不合，未能广泛流传。而作者本人也因莫须有的罪名，于次年被投入北方集中营，后又辗转流放到南方。身心横遭摧残。但他的著作却在西方得到了广泛的流传。巴赫金的理论直到五十年代终于引起当时苏联文学理论界的争议，于是在一九六三年经过修改后以《陀思妥耶夫斯基的诗学问题》为名发行新版。在苏联依旧争论不绝，但此时在国外已经把巴赫金的理论作为小说理论的重要创新，甚至把巴赫金视作小说理论发展的一个分水岭。现在即使在中国，一谈起陀思妥耶夫斯基，就会联想到巴赫金，似乎“复调小说”理论才是唯一能说明陀氏创作的理论。这是一个很繁复的论题。我们不在这里讨论。但“复调”之说，的确在相当程度上表达了陀氏小说的特点。这是小说写法的一个变革。在陀氏本人，也许并不十分明确地意识到这一点，因为他本人从来也没有谈论过类似的概念。但读者如果没有先入之见，在读完他的小说后，常常会有一种感觉，似乎作者在小说里通过人物之口，讨论了许多问题，或者通过作家的描写涉及了种种情景，但读者在掩卷沉思时，又常常会觉得无所适从。因为作者最终也没有在他的书里投下一个十分明确的结论。但他促使你对书中的叙事进行思考，每一个人物的声音都可以在你耳边絮叨，都在表明自己存在的理由，作家本人到底站在哪一个人物的后面，反而很难让人捉摸。这就是所谓的“复调”。这个理论是借用了音乐上的一个术语。好比音乐的声部，原来的小说都是一个基调，伴随着和声，但现在像巴赫的赋格，出现了平等的声部，就像钢琴演奏，本来是右手的基调，左手是低音的和声，现在两个相互争鸣的声部，出现了复调音乐。其实这仅仅是一种比喻，在小说里并不可能真有那样繁复。但经典的小说通常是作家定下基调，然后安排人物的行为和言语，在相互的关系中，善恶忠奸，壁垒分明，即使在巴尔扎克的小说里通常也是善人善终，恶人恶报。陀思妥耶夫斯基却往往在一个人的性格里放进了两重的变数，这是一。另外作为善、恶典型的人物，都可能一语道破事物的真谛。善恶两类主人公的行为往往会发生突变。每种行为也都有自己的理由。作者并不一定要清楚地表现出他的倾向性。根据巴氏的理论，这样的小说结构，会产生行为以外、语言以外的含义，不一定都有明确的结论。所以就能促使读者的思索，扩大小说的容量。这是现在一般对所谓“复调”的理解，事实上这个理论要涉及许多其他方面的问题，这是一种把文学与语言学结合起来考察的十分重视文本细读的理论。《罪与罚》里拉斯柯尔尼科夫的理论，其中侦查科长波尔菲里·彼得罗维奇与拉斯柯尔尼科夫的“法与理”之争论，索菲娅·马尔美拉陀娃的宗教教义与拉斯柯尔尼科夫的“超人哲学”之争，到底是谁说服了谁？无非是一种思索，一种更为深入思考的趋向。 尤其是巴赫金论及陀氏小说中“对话”的概念，主人公的自我意识是对话化的；这个自我意识在自身的每一点上，都是外延的，同自身、同他人、同第三者有着一种对话的关系。这就关系到小说文本中的潜在文本。一个单一的文本在极大的程度上扩大了自身容量。 读陀氏的小说，当然不能完全用“复调”的理论来解析。但这是一个很值得关注的特点。 通常的陀氏评论，总是把着眼点放在作者着力描绘的社会现实画面，故事情节发展，人物性格发展上。但陀思妥耶夫斯基作品的故事，却往往信手拈来，他的大作品，通常都是涉案故事，一般都是从报刊上得来某个报道，以此敷衍成篇，却成一个精彩的长篇故事。之所以精彩，是因为作者注入了他的思考和对人性的挖掘。陀氏的小说，是思想的小说，是剖视人性的小说，故事与情节只是他借以使人物和事件活动起来的要素而已。 陀氏小说十分注重人物的自我意识，所以形成一种思想的类型。他并不十分注意性格刻画和典型塑造。他要创造的是一种思想类型。他们存活在和不同的思想声音的“对话”中，甚至这种对话是潜在的、只是在上下文中隐含着的。所以作者往往会虚化故事的环境、日常生活的细部刻画，转而用不同性质的对话来表现作品的容量。他的人物很难用传统的术语来定义，如性格、典型、正面主人公、反面人物等等。因为作家自己的声音和评价也混迹在人物的相互关系或对话里，而且作者的声音也未必能左右人物和情节的发展。所以在阅读陀氏作品的时候，不妨以读者自己固有的心态和感觉来与作者的思想对话，完全不必抱定一种文学批评的理论或观念，来生硬地分析作品。让每一次阅读都成一次冒险，看看读完后你会产生什么感觉。这是一种很有趣的阅读过程，在阅读中加上读者自己的一路思考，陀氏的作品将给你十分独特的感觉。 对陀氏这样的作家最好还是不抱先入之见，随着作者的安排，先领略他的思想，然后再来作认真的思索。它不是消闲的读物，却能长人心智。 夏仲翼二〇〇四年九月"},{"title":"高级思维模型","date":"2021-06-26T04:00:00.000Z","url":"/2021/06/26/%E9%AB%98%E7%BA%A7%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B/","tags":["认知迭代"],"content":"我们和这些人物同处于一个时代，一个世界。他们的想法，也可以适用于我们。 芒格的思维模型高级思维模型最好的解释 简化问题，做出显而易见的重大决策。 数学是上帝的语言，在日常生活中运用数学。 对待问题，要逆向思考。 最好且最实用的智慧，是学术智慧。 参考： 《查理·芒格的思维方式是怎样的？》 《什么是Lollapalooza效应》 马斯克的思维模型第一性原理（first principle thinking）：追根问底，到底什么才是起源的决定性因素 “第一性原理”是马斯克挂在嘴边的理论之一，他要确保自己了解极大多数事情背后的基础科学原理或规则——这可以减少他花费大量时间去学习新概念，认知事物便有了一个平滑上扬的认知曲线。 马斯克的观点是，从 physics approach 产生 mind set 或者 mind model。 Space X 火箭的例子：汽车可以重复驾驶，轮船可以重复出航，那为什么火箭不能重复升空呢？ 乔布斯的例子：如果用户出门只带一个电子设备，那会是什么？ 第一性原理有三个基石假设是： 1、本体论：它必须是一个抽象的概念。真正不变的是复杂事物背后的支配力量。 2、简一律：所有复杂系统，只建立在一个基本原理之上。世界的本原，一定是极简的。只有找到一，才是真正发现了现象背后的本质。 3、动力因：就是所有问题的源头，找到了支配事物的那个发动机，自变量。 基于这三个基石假设，想运用第一性原理需要具备两点前提： 1.善用演绎法而不仅仅是归纳法去思考事物 我们分析事情得出结论主要有两种方法，归纳法和演绎法。 归纳法是针对我们观察到的案例，通过分析其共性，从而得出一个结论。 归纳法是我们大多数情况下分析问题所采用的方法。 归纳法符合人类认知的历史积累过程。 我们大多数的人生经验都是用归纳法所获得的。 但是归纳法有一个巨大的缺陷。由于我们无法穷尽所有的可能性，所以归纳法往往会犯以偏概全的毛病。 演绎法是另外一种研究事物的方法。 通过已经确知的元知识，用科学的逻辑分析推理出一个新的理论。 这个过程是不是和第一性原理要求的从最底层组合推导更高层次，如出一辙？ 第一性原理是一个哲学上的概念。 它是系统中的动力因，它符合简一律。 它是你看不到的、却决定你看得到的任何事物背后的那个本体论。 芒格曾说，在科学界和商界有一个古老的法则，它分两个步骤： 第一步，找到一个简单的、基本的道理； 第二步，非常严格地按照这个道理行事。 快速学习模型-语义树从知识汇总以后勾勒启示： 马斯克说，他相信大多数人可以学到比他们目前知道的更多的东西。当谈到普通企业家时，马斯克声称，他们通常不会突破自己认为的极限，尝试超越现有能力去学习。换句话说，他们不知道如何勾勒出他们掌握的信息，从而得出进一步的启示。 在一次关于Reddit的谈话中，马斯克讨论了他的学习方法和使用的结构：“一点建议：把知识看作是一棵语义树是很重要的——在你进入叶子/细节之前，确保你理解了基本原理，即主干和大分支，否则它们就没有基础作为支撑了。” 这就是埃隆·马斯克的第一条学习法则：确保你建立了一棵知识树。 联系是学习的动力。人本身的排序能力很差，但检索能力极强。所以认知要在排序上补足劣势： 马斯克的才华体现在他的第二条学习法则上，这条法则强调了他在多个领域建立巨大而高耸的智慧之树的能力，那就是——你记不住自己无法联系的事物。 时间管理小时间盒子（Time Boxing）： 通常人们安排日程，会是9点到10点做任务一，10点到11点做任务二，呈线性分布。可有时任务一延误就会影响任务二，提前做完了任务一可能还要等到10点做任务二，这样根据时间线来制定的工作计划，看似井井有条实际上却有些脆弱。 而“TimeBoxing”对未来需要执行的每件事项设定了明确的预算时长，例如任务一要在15分钟内完成，任务二要在10分钟内完成……。完成任务一之后，可以立刻开始进行下一件最适合进行的任务，而不一定是任务清单上排第二的任务。 马斯克深谙Deadline才是第一生产力的道理，给每项任务安排足够且最少的时间，这样就让自己时刻处于Deadline临近的影响下，这样效率也最高。 但这个方案对底层人员不可执行，底层人员总是被第一时间被拉向各种高优的需求。 时间一定会被工作排满的： 帕金森定律（Parkinson’sLaw）是官僚主义或官僚主义现象的一种别称，被称为二十世纪西方文化三大发现之一。也可称之为“官场病”、“组织麻痹病”或者“大企业病”，源于英国著名历史学家诺斯古德·帕金森1958年出版的《帕金森定律》一书的标题。帕金森定律常常被人们转载传诵，用来解释官场的形形色色。帕金森在书中阐述了机构人员膨胀的原因及后果：一个不称职的官员，可能有三条出路，第一是申请退职，把位子让给能干的人；第二是让一位能干的人来协助自己工作；第三是任用两个水平比自己更低的人当助手。这第一条路是万万走不得的，因为那样会丧失许多权利；第二条路也不能走，因为那个能干的人会成为自己的对手；看来只有第三条路最适宜。于是，两个平庸的助手分担了他的工作，他自己则高高在上发号施令，他们不会对自己的权利构成威胁。两个助手既然无能，他们就上行下效，再为自己找两个更加无能的助手。如此类推，就形成了一个机构臃肿、人浮于事、相互扯皮、效率低下的领导体系。1帕金森得出结论：在行政管理中，行政机构会像金字塔一样不断增多，行政人员会不断膨胀，每个人都很忙，但组织效率越来越低下。这条定律又被称为“金字塔上升”现象。 要睡觉，要洗澡： “当我睡得不够时，我发现我会变得很暴躁 …我也可以减少睡眠时间，但那样我的思维敏捷程度就会受到影响。”马斯克回忆道。从那以后，他又回到了一个更“可持续”的每周工作80到90小时的状态。 为了能高效工作的人，马斯克变得非常重视休息。在2013 年计算机历史博物馆举办的一次访谈中，他提到自己最合适的睡眠时间是 6-6.5小时，一般他会在晚上 1 点入睡，早上 7 点起床。 第二天起床，为了节省时间，他经常不吃早餐，偶尔吃的时候也是很快地喝一杯咖啡和吃一个煎蛋。在马斯克的字典里，与其吃早饭，还不如去洗澡。 洗澡通常能缓解肌肉酸痛，增加血液循环，减轻疲劳感，帮助提高注意力，这成为了他最重要的日常习惯。他曾亲自在Reddit（美国某线上社区）回贴：洗澡这件事，对他的人生产生了“最积极正面的影响”，没有之一。 发挥潜能，异步沟通，尽量让自己演独角戏，发挥效率： 为了把时间的价值发挥到最大，马斯克用了很多时间管理手段，包括深入一线，磨练敏锐直觉；异步沟通，用电子邮件与团队协作；以及激情的投入，最大化的激发潜能。 相信认知可以通过外部载体来延续： 在接受欧洲数字出版社Axel SpringerCEO访谈时表示：“人类历史上最伟大的发明是语言（而非车轮）”，语言之外就是写作，“写作就像是一个硬盘驱动器，让事物超越人本身来延续。如果你想用口述史的方式来保存一切东西，是非常困难的。” 高效、高标准。 结构化思维 完整 有序 非结构化 遍历顺序比较多样 "},{"title":"结构思考力","date":"2021-06-21T12:25:21.000Z","url":"/2021/06/21/%E7%BB%93%E6%9E%84%E6%80%9D%E8%80%83%E5%8A%9B/","tags":["认知迭代"],"content":"透过结构看世界，洞悉事物本质思维的结构是重要的。透过结构看思考表达。 透过结构看思考表达-最最核心的底层应用。 透过结构看演讲呈现。 透过结构看问题解决。 透过结构看项目管理。 透过结构看商业创新。 透过结构看商业论证。 结构思考力不但是一种洞悉本质是思考艺术，更是一种透过结构看世界的生活态度。 三层次模型，结构思考力的核心理念结构思考力的三个层次： 理解（隐性思维显性化） 重构（显性思维结构化） 呈现（结构思维形象化） 金字塔结构，结构思考力的训练工具麦肯锡的三十秒电梯原理：无论面临多么复杂的项目，必须用三十秒在电梯里讲清楚。 以事实为基础 以假设为导向 严格的结构化 芭芭拉明托：哈佛商学院第一位女学员，麦肯锡第一位女性咨询顾问。《金字塔原理》是提高写作力至关重要的东西。 子结构：横向结构、纵向结构。先总后分：不要直奔细节，先把问题看清、看全，然后挑重点来说，要有路径。直奔细节意味着自己是急性子。别人没有和说话的人一样的，在思考路径上高速的移动速度，所以可能表达的效果一定会打折。 改学员 ppt 的例子：把结论表达清楚，主标题应该是结论。能够把工具类的问题讲清楚，是讲的人的职责。我们到底能不能够把文档梳理出简单的结构出来？ 理解：如何打破“只可意会不可言传”的僵局 理解：隐性思维显性化 识别：信息中的事实及观点 判断：事实观点对应关系 概括：简洁概括所有内容 重构：显性思维结构化 论：结论先行 证：以下统上 类：归类分组 比：逻辑递进 呈现：结构思维 配：配关系 得：得图示 上：上包装 适量是一种隐性经验，特别容易潜移默化。这是中西文化里不同的思维方式。 结构化思维看装大象进冰箱的问题，会先找结构，然后发现把大象装冰箱的关键一步会出问题。 结构化的文章，有价值的东西（结论）出现在最显要的地方；散文之类的文章，有价值的东西可能隐藏在任何地方。 用一句话概括全文的万能公式：在什么什么的基础上，从 xxx，xxx，xxx 几个方面，说明了 xxxxx。 面对纷繁复杂信息，有自己审视问题的坐标系标准答案，在社会上可施展的空间越来越小。 在不确定的时代，我们唯有学会独立思考。 分三个层次：结论，理由，事实。内容和内容之间有相互联系，有论证关系。 花露是欧阳修发明的。 透过结构看世界。 任何复杂的信息，都可以用一句话讲清楚要分类，要总结和提炼。 清不清晰，要看是不是有简洁的结构。 “论”-结论先行 ，一句话百分百传达你的意思听的人想听结论，而且是结论先行。我们有多喜欢先听结论呢？ 不喜欢讲结论，不是中国人特有的文化。 能不能得出结论来，是最难的。 结论先行的好例子：政府的工作报告、麦肯锡的报告。 先说观点，再说要点，再阐述要点。每一层是上一层的结论，最底层叫数据和事实。 罗列数据是很重要的，但要从数据里洞察出结论来，罗列数据才有用。 小学的时候总是会说总分总。 开会得不到结论，主要是罗列的内容太多。 有些人忘记从标题开始讲起。 “证”-以上统下，让你的观点经得住挑战质疑、结论概括理由，理由支撑结论。 一眼看到底。 论证类比是四个原则，不是四个元素。论和证是纵向递进联系，类和比是横向联系。 老板看问题，不先看内容，先看结构。 “类”-归类分组，让你的表达清晰全面且容易记大脑有自动将有共同特点的事务进行归类组织的能力。 人脑有 7+1-2 之类的分类和记忆能力。写东西不要超过 7 点，最好要 3 点就行了。 分类会让问题变得简单。 mece 原则：互斥穷举。做不到这一点，没有办法把问题考虑周全。 减少其他，其他证明没想清楚。 思考和表达是两个场景。 创新有个定义：打破现有思考框架，建立新的思考框架。 结构罗盘 一张图说清所有工作内容形象化表达是结构化思考的最佳输出方式，结构化思考是形象化表达的基础。 配关系 得图示 上包装 简化 -&gt; 整合 -&gt; 引用 -&gt;类比 ppt 最忌文字多，就好像电影开幕了，演员不出来，只是剧本在播。 隐性经验显性化，显性经验结构化，结构经验形象化。 配关系，四大模式十六种结构流动模式 线性、流程、循环、关联 作用模式 对立、合力、平衡、阻碍 关系模式 并列、重叠、包含、分割 比较模式 成分、排序、序列、关联 “上包装”，让观点更吸引人、更容易记简化 拆隔删突 类比 形象行为 整合 词语字母数字颜色 -每个公司文化不一样 引用 广告、歌曲、名言、流行语"},{"title":"《搞定》","date":"2021-06-21T05:13:25.000Z","url":"/2021/06/21/%E3%80%8A%E6%90%9E%E5%AE%9A%E3%80%8B/","tags":["认知迭代"],"content":"决定总是会消耗心力。不能做决定也是一种做决定。【先做一些不能有确定结果的行动，然后观察它，至关重要】。用行动代替思考，用手分担眼和脑的工作，可以缓解内心的焦虑。 三个关键原则养成收集的习惯确定“下一步行动”学会关注结果"},{"title":"《原则》","date":"2021-06-21T03:51:56.000Z","url":"/2021/06/21/%E3%80%8A%E5%8E%9F%E5%88%99%E3%80%8B/","tags":["认知迭代"],"content":" 你能几步做成一件事？瑞达里奥认为，通常有 5 步。 警惕邪教：独立思考，形成原则。 Professional Mistake maker：和其他放过自己错误的人不同，形成自己的错题集，反复思考。 "},{"title":"Lambda VS ECS","date":"2021-06-21T03:48:35.000Z","url":"/2021/06/21/Lambda-VS-ECS/","tags":["云计算"],"content":"Lambda 的好处 按使用付费（云计算都有这个特点）。 把资源（ CPU 或内存分配）的 quota 封装得很好。 无需关心监控和运维。 自动扩展（无需关心物理 nodes。node 既意味着系统可拆解，也意味着系统可联结）。 Lambda 的坏处 多步执行环节很慢 特定 function 的执行隔离不好，可能多个用户相互踩踏 ECSECS 云基础设施在架构上更易扩展，只要稍加改造就能和系统集成。 参考：《我们为什么从 Lambda 迁移到了 ECS？》"},{"title":"平安投保流程","date":"2021-06-20T04:16:12.000Z","url":"/2021/06/20/%E5%B9%B3%E5%AE%89%E6%8A%95%E4%BF%9D%E6%B5%81%E7%A8%8B/","tags":["保险"],"content":"主流程 填写投保材料-健康告知、健康状况和意外状况很详细。 投保、缴费。 签名，回访。 数据结构： 1、投保材料。2、电子保单：包含主险和附加险，以及份数。"},{"title":"如何治疗松鼠症","date":"2021-06-19T16:48:23.000Z","url":"/2021/06/20/%E5%A6%82%E4%BD%95%E6%B2%BB%E7%96%97%E6%9D%BE%E9%BC%A0%E7%97%87/","tags":["心理学"],"content":"断·舍·离断 = 不买、不收取不需要的东西；舍 = 处理掉堆放在家里没用的东西；离 = 舍弃对物质的迷恋，让自己处于宽敞舒适，自由自在的空间。"},{"title":"如何设计一套风险系统","date":"2021-06-16T05:49:57.000Z","url":"/2021/06/16/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E5%A5%97%E9%A3%8E%E9%99%A9%E7%B3%BB%E7%BB%9F/","tags":["风控"],"content":"基本方法论 识别风险 构建相应的应对模块 识别风险 业务风险：不可避免的意外、业务的荣枯和服务体验的优劣导致的某些指标的起落。 欺诈风险：恶意用户恶意骗取保险金。 系统性风险：自然业务发展过程中出现的意料之外的灾害。 建立事中监视模块建立特定的风控监控模块，应用策略。 要搞清楚如何评价用户在此场景下的风险指数，有可能需要借助其他场景的数据。"},{"title":"OKR 笔记","date":"2021-06-16T05:40:47.000Z","url":"/2021/06/16/OKR-%E7%AC%94%E8%AE%B0/","tags":["管理"],"content":" OKR 的历史ORK 是目标管理领域的新工具。诞生于 Intel，帮助 google 取得成功。在国内主要是美团和字节在使用。 上世纪 50 年代，管理科学（management science）兴起，主要用意是提高公司效率。Peter Drucker 发明了 MBO（Management By Objectives，目标管理制度）。MBO 是一个过程，在该过程中，管理者和员工共同设定一个目标，然后定义各自需要做什么才能完成这一目标。 MBOs 显然是 Objectives and Key Results (OKRs) 的前辈。在 OKR 模型中，经理 设定一个目标之后，不再插手细节管理（micromanaging），而是信任自己的团队能够完成 这一目标 —— 和工业时代的管理方式相比，这是一种巨大和高效的转变。从很多方面 来说，这是第一种真正与新的信息时代相匹配的管理哲学。所以计件式的微管理意味着管理者还不能信任下属能够达成这一目的，但 OKR 就意味着简单高效了。 到了 20 世纪 80 年代早期，SMART goals （George T. Doran 设计）和 Key Performance Indicators (KPIs) 成了大公司设置目标的流行方式。KPI 引入了基于 指标考核（metric-validated）的绩效评估。广告行业有一个老梗：“我们的广告只有一 半在起作用。但我不知道是哪一半。”但互联网和数据科学的兴起已经解决了这一问题。现 在，我们有可能搞清哪一部分是有效的，以及是什么导致了这些 KPI 的增长。 后来，SMART 的组成元素进入了 OKR，尤其是 results-focused 和 time-bound。 我最初接触 OKR 也是在 Intel，那时还是 20 世纪 70 年代。当时，Intel 正在从内存 公司向微处理器公司转型。AndyGrove 和他的管理团队希望所有员工能专注在一些高优先 级的事情上，以确保转型的成功。OKR 系统的发明在这个过程中发挥了巨大作用，我们都非常喜欢。我还记得自己当时着迷于设定每个季度的“灯塔”或“北极星”，以区分手头的任 务优先级。另外，还有一件事情让我非常振奋：我能看到Andy 的 OKR，我的直属经理的 OKR，以及我所有同事的 OKR。这些信息很快让我将个人工作和公司目标直接联系起来。 我将自己的OKR 用大头钉钉在办公室，并且每个季度都会制订新的 OKR，正是从那时起， OKR 系统开始伴随我的职业生涯。 在 Grove 著名的管理手册 High Output Management (Penguin Random House, 1995) 中，他以回答两个简单问题的方式提出了 OKR： 我想去哪？（Where do I want to go?） 如何确定我正朝着那里前进？（How will I know I’m getting there?） 本质上，这里问的是： 我的目标（objective）是什么？ 我需要取得那些关键成果（key results），才能确保我离目标越来越近？ 什么是 OKR？OKR 是 Objective and Key Results（目标和关键成果）的缩写。其中， Objective 是定性的（qualitative） Key Results（大部分情况下会设置三个）是定量的（quantitative）。 这几个 KR 用于将某个人或某个组专注在一个大目标（bold goal）上 Objective 设定的目标有一定期限，通常是一个季度（quarter）。到这个期限结束 时，会用 Key Results 来检查是否达到了当初设定的 Objective。 1.1 Objectives（目标）Objective 要能用一句话概括，并满足下列特点： 1、定性、鼓舞人心（Qualitative and inspirational） 设定的目标，要能让大家在早上满怀兴奋地起床。CEO 和风险投资家们可能会因为能在 谈判上多拿三个点的收益而在早上愉快地起床，但大部分普通人的兴奋来源是体会到 工作的意义和进展。使用你的团队平时使用的语言风格来描述目标。如果他们平 时随口飙俚语，那描述目标时也就用这种风格。 2、有截止日期（Time-bound） 例如，能在一个月或一个季度内完成的事情。每个 Objective 都是一个清晰的、通往某个目标（ goal）的分段目标（sprint）。如果你想完成的事情需要一年的时间，那它可能是一个 战略（strategy）甚至企业使命 （mission），但不是 Objective。 3、团队能独立完成（Actionable by the team independently） 对创业公司来说这通常都不是问题，但对大公司来说，团队或个人间经常相互依赖， 导致 Objective 无法独立完成。你设定的 Objective 必须真的是你自己能够独立完成 的，不能有“市场部没有对我的 Objective 进行宣传”这样的借口。 Pusher 是一个提供 API 服务的小创业公司，其使用 OKR 来提升公司业务。在回顾第一个 OKR 时（“How We Make OKRs Work”），他 们写到： 我们学到了下面这些东西： 设定的 Objective 不要依赖其他团队的输入（input），除非你和对方商量好了，他们 能高优先级支持你 设定的 Objective 不要涉及/依赖我们还没招的人 对实现每个 Objective 需要花多少时间，自己心里要有数（Be realistic） 每个 Objective 都像一个短期（a shorter period of time）的使命声明（mission statement）。一个好的 Objective 要能够： 激励团队 在规定的时间内完成有难度（但并非不可能） 能够由设定这个 Objective 的个人或团队独立完成 下面几个例子是比较好的 Objective： 拿下南湾区 direct-to-business 咖啡零售市场 打造一个超级单品 改变 Palo Alto 地区的优惠券使用习惯 下季度再融一轮，一把梭！（使用你的团队习惯的语言，译者注） 下面是几个反面教材（poor Objectives）： 销售额提升 30% 用户数翻倍 筹集 B 轮 500 万美元融资 为什么这几个 Objective 不好呢？可能是因为：它们已经是 Key Results。 Key Results（关键成果）Key Results 将 Objective 中鼓舞人心的定性描述进行量化（quantify it）。问 几个简单的问题，你就可以确定 Key Results，例如： 哪些指标可以说明我们已经达到了设定的 Objective？哪些指标会发生变化？ 这会强迫你定义什么是所谓的 “awesome,” “kill it,” or “pwn.”（Objective 中的描述性 内容）。“killing it” 表示的是访问者增加？还是营收？满意度？或者是这些方面的综合 ？ 每个 Objective 通常应该有三个 Key Results。Key Results 基于任何可以衡量 的东西。下面是几个例子： 增长 参与度 营收 业绩 品质（质量） 最后一个可能会让人感到困惑，因为品质似乎很难衡量的。但有了 Net Promoter Score (NPS) 之类的工具，品质也是可以量化的。NPS 是一个用户满意度调查工具，用数值衡量客 户将一款产品推荐给朋友的愿意程度。（见 “The Only Number You Need to Grow” . Harvard Business Review, December 2003.） KR 选择地合理，你就可以在增长和业绩，或者营收和品质之间取得平衡 —— 确保你有相互 制约的两方面力量就行了。 在 Work Rules! 一书中，Laszlo Bock 写到： 既有品质（quality ）指标又有效率（efficiency ）指标非常重要，否则工程师会通过牺牲一个指标来达成另一个。如果系统能给出最优结果，但需要等待三分钟，那也是不能 接受的。我们既需要强调正确性，又需要强调速度。 作为一个 Objective，“打造一个超级单品” 可能会有下面几个 KR： 40% 用户一周内两次回头使用该产品 推荐值达到 8 分 50% 转化率 注意到这些 KR 有多难实现了吗？ KR 应当是困难的，但并非不可完成OKRs always stretch goals（OKR 永远会对普通目标进行延伸）。一种较好的方式是 为每个 OKR设置一个信心值，从 5 到 10。这样就可以说，“我有 50% 的信心完成这个任务 ”。 信心值为 1 表示，“要完成这个任务需要奇迹”。 设置 OKR 时，应该寻找那些能推动你自己以及你的团队做更大的、但并非不可能的事 情（bigger things）的任务。我认为，只有一半信心值的事情正适合于此。 信心值为 10 意味着，“没问题，这件事很快就能搞定”。这意味着你把目标定地太低，通 常称为“沙包”（sandbagging）。在失败就会受惩罚的公司中，员工很快会学会不要尝试可 能会失败的事情。如果想完成伟大的任务，你必须找到一种让员工能安全地尝试达到更高 目标、做别人之前没做到过的事情的方式。 看一眼设置好的 KR。如果你的内心想法是，“我们必须全力推广我们的 A 游戏才能达到这 个目标”，那这个 KR 可能刚好合适。如果你的想法是，“这个目标注定要失败”，那这些 KR 就太难了。反过来，如果你的想法是，“我可以完成这些任务，付出一些努力就行了”，那它 们可能又太简单了。 为什么要用 OKR？okrs.com 的创始人 Ben Lamorte 讲过这样一个故事 ： 我的导师 Jeff Walker，也就是带我入门 OKR 的人，曾经问我，“当你决定去徒步时，你 是否有目标？”我迟疑了一下，因为不清楚 Jeff 这话是什么意思，然后他接着说，“当你 和家人一起去山里徒步时，如果你喜欢随便走走，看看路上的风景，那没有什么问题；但 如果是在这里工作，那你必须非常清楚你的目标；否则，你就是在浪费你自己的、我的以 及这里所有和你一起工作的人的时间。” 你的 OKR 为你的团队设置了目的地，因此不要浪费他们的时间。 很多公司采用 OKR，都出自下面三个主要原因之一： 专注核心目标（Focus）：作为一个公司，我们做什么和不做什么？在这里的 result-focused 大致上等于国内公司的以终为始。 公司上下一致（Alignment）：如何确保整个公司都在精力用在最重要的事情上？这里的 strategic alignment 就是国内的互联网公司经常讲的拉通对齐。 提升团队潜能（Acceleration）：你的团队真的发挥了他们的潜能了吗？ 专注核心目标（Focus）在 Duxter —— 一个游戏玩家的社交网络 —— 团队采用了 OKR 来解决一个经典的创业公司问 题：新奇事物综合症（shiny object syndrome）。CEO Adam Lieb 写到： 和所有创业公司一样，我们为所有高优先级的事情而忙碌。在我们公司，也许说的最多（ 或过多）的说法是：“有更重要的事要办”（biggerfish to fry，直译“有更大的鱼要炸” ）。我们有两个大“鱼”： 第一：大家对哪个鱼是“大鱼”持有不同意见。很多情况下，这些差异显著的观点会导致冲 突和低效。 第二：我们的大鱼可能每周甚至每天都会变。让公司内的每个人能清楚地知道自己的核心 精力应该放在哪里，变得越来越难。 引入 OKR 对解决这两个问题带来了明显帮助。 公司上下一致（Alignment）在一次采访中 —— Dick Costolo —— 前 Google 员工和 Twitter 前 CEO，被问到是否有东 西是他从 Google 学到的，然后带到了 Twitter。他分享到： 有一样东西是我在 Google 看到，并毫不迟疑地用到了 Twitter 的：OKR。这是一种帮助公司内的每个人理解哪些是重要的东西（what’s important），以及如何衡量什么 是重要的东西的（measure what’simportant）良好方式。 本质上，这是一种很好的沟通战略以及如何衡量战略的方式。这就是我们如何尝试使用OKR的。在带领一个公司成长的过程中，随着规模扩大，唯一最困难的事情就是沟通 。沟通是出了名的难。OKR是一种让大家理解你将如何衡量成功和战略的良好方式。 在团结整个公司方面，OKR 要比 KPI 更加有效，因为它既包含了定性目标，又包含了定量目标。Objective 是鼓励性的，它可以发动那些 less metrics-oriented 的员工，例 如设计或客户服务。KR 让数字驱动的员工找到家的感觉，例如审计和销售。因此，一个好 OKR 可以将整个公司团结在一个重要的目标上。 提升团队潜能（Acceleration）下面的内容来自网站 Re:Work，Google’s official guide to OKRs ： Google 通常会设置一些刚好超出能完成范围（threshold of what seems possible）的目标，有时称为“延伸目标”（stretch goals）。设置不可完成的目标是一件很棘手的事情，因为人们可能会将其视为故意给团队设难题，要让团队注定要失败。但更多的时候，这种类型的目标反而会吸引最优秀的人，创建出最令人振奋的工作环境。另外，如果目标定地很高，那即使最后失败了，最终的结果也会带来巨大的提升。 这里的关键是清晰地传达出： 延伸目标的本质（nature of stretch goals） 成功的阈值是什么 Google 在设置 OKR 时，习惯将完成 70% 的 Objective 视为成功，而 100% 完成则视为杰出绩效（extraordinary performance）. 从长期来看（这个过程也称为“登月计划”），这类延伸目标是取得杰出成就的基石。 由于 OKR 永远是延伸目标，会鼓励员工持续拓展自己的边界。你永远不知道自己的能 力极限在哪里，直到你开始你的登月计划。 至此，这里已经是 OKR 中最 tricky 的部分。既然我们已经在讨论登月计划了，那我 们就来用一个《星际迷航》（Star Trek）中的隐喻。 Scottie 总是说，“发动机已经不行了”。但每次他总是能拿出奇迹，使发动机引擎能够继续 运转。 Geordie 会说，“在发动机熄火之前你有五分钟时间”。如果他有解决办法, 他会告诉你，但 你并不是刚知道这些问题，应该早做准备的。 最为船长，你是希望有一个想当英雄的人（someone who likes to be a hero），还是一个知道公司真正能做什么的人（someone who knows what the company can actually do）？ 我很清楚我自己的选择。 如果你将 OKR 和绩效考评、奖金关联到一起，员工将永远低估他们所能做的事情。将目标 设地太高风险太大了，假如没达到目标怎么办？另一方面，如果你鼓励大胆的 OKR，然后根 据实际表现来做绩效考评，员工将根据他们所做的事情 —— 而不是他们多会隐藏（避 免犯错） —— 得到奖赏。 毕竟，在登月的过程中，我们有时会获得 Tang, Sharpies, and Velcro 这样的人才。这些 难道不值得奖励吗？ 如何实施 OKR？某些公司尝试使用 OKR 但失败了，他们就将问题归咎于这套系统。但如果你不遵循系统的 要求，那任何系统都是无法奏效的。在季度初设置一个目标，然后期望到了季度末它自己就 能神奇地完成，这种想法太天真了。把握好承诺和庆祝（commitment and celebration）节奏非常重要。 Scrum 是一种工程师用来对进度做出承诺的技术，它可以使团队成员彼此可信赖，互相支持 。每周，工程师会分享上周发生了哪些事情，接下来的一周她将做什么（承诺），以及提出 任何可能会妨碍自己完成目标的事情（blockers）。在更大的公司中，还会主持一个 “ scrum of scrums”，来确保不同团队之间也能相互信赖以达到特定的目标。 每周一：作出承诺（Monday Commitments）每周一，团队成员应该碰个头，过一遍 OKR 的进度，并承诺自己将完成哪些任务，以帮助 达到公司的 Objective。这里我推荐一种四象限格式（图 2-1）： 每周五：小结和庆祝（Fridays Are for Winners）将目标设置地很高远的团队经常会失败。虽然目标高远是一件好事，但未完成目标 —— 而且 也看不到自己到底走了多远 —— 经常是一件令人沮丧的事情。这也是为什么周五的庆祝环节 如此重要的原因。 在这个环节，所有团队会尽已所能地展示自己。工程师会展示他们开发地的代码，设计 师会展示 mockup 和设计图。销售可以分享他们拿下了哪个客户，客户服务团队可以分享他 们帮助的那些客户，业务开发可以分享 deals。 OKR 是一种目标管理（MBO）抓手OKR 与 KPI 的区别传统的 KPI 是工业时代的产物。那时候劳动生产率易于通过指标统计，所以产生了 OKR。 指标是一种容易产生消极反馈的惩罚工具。实际上真正的绩效指标是很难有统一的评定标准的。员工普遍认为绩效管理更多是惩罚，而不是为了提高绩效。绩效反馈更多地是在找差距和不足。 我们设立 MBO 的主要目的是为了提高劳动生产率，高劳动生产率是共同富裕的基础。 OKR 是“我要做的事情”，KPI 是要“我取得的成果”。 为什么 KPI 不适应移动互联网时代的组织特点VUCA。这时代我们的目标是高度不确定的，我们每个人都有责任去回答这个问题，我们的目标是什么。 OKR 比较灵活，可以在过程中通晒，也可以在组织的目标达成过程中不断调整。它可以帮我们找到大体方向，找到可衡量的大体结果（衡量比量化更加灵活）。 用 OKR 用得特别好的公司谷歌（John Doeer）、英特尔（完成企业业务的转型，帮助全球的员工协同，快速沟通）、豌豆荚（目标感强、反应迅速、目标感强，OKR 是一种思维管理工具）。 高科技企业从事创新兴工作，我们很难简单评价我们的产出和目标的设定是不是足够对的，足够好的。 在现实中，组织遇到的挑战有哪些沟通基本功永远练不完。高效的沟通，并不只是坦诚、正直开放就可以做到的，高效的沟通是能够通过交流把复杂的问题讲清楚，把答案找出来。 大量的目标在设置的时候，暴露了大量的沟通的问题，不讲 why，各自有各自的视角。 是不是有了 OKR 以后，就能解决自驱力问题？谨慎接受。没有 OKR，我们很容易在执行的过程中，遇到动作变形的问题。上下对、左右对，我们才知道我们的目标是清晰的。如果没有目标对齐，员工就了解组织目标，不清晰组织对自己的期望。 情景剧的例子 告诉大家，xxx 这个目标是怎么来的。 让大家讲讲目标拆解完以后，各自能完成多少。 大家探讨一下，我们是不是可以调整一下，有没有什么可以改进的。 一个组织即使不关注人，也不能忽视：人的情绪就在那里。 人的潜力可以通过目标的沟通和规划激发出来。 怎么在一个 BG 里做真正的 OKR 工坊的时候，我们要做两层。做两层有心理意义。如果做对焦，一定还有定义不清晰的部分，对 BM 是有养分的，对参与者也有意义，让他们参与其中，他们才有承诺，解决执行力不够的问题。 OKR 要层级地去做，是贯穿地去做，要把业务的发展阶段连起来，也要把部门连接起来。有自上而下，也有自下而上（能够切实地支撑）。 撰写目标的建议《高效能人士的七个习惯》里的观点：观为得，结果是靠关注产生的。 如何撰写目标 不要写现状。 使用明确的语言。 使用积极的语言：减少吃垃圾食品 -&gt; 多吃健康食品。 使用简单的规则。 以动词开始，是个行动。 使用通俗易懂的文字撰写，避免缩写、行话（行话不如土话）。 可以对目标进行补充说明。 如何撰写关键结果 可衡量的。可衡量（增或者长就可以）可量化（增长多少）。 充满挑战性、激励人的。 具体的 有具体负责人 有流程和过程管理的 对齐的（横向和纵向对齐） 推动正确的行为 撰写 KR 的注意事项 找出关键结果，而非结果（每个季度招聘 10 个工程师）。 描述结果，而非任务方案清单（与 VP 开会讨论）。 不要使用“帮助、协助、参与”等辅助性动作。 使用积极的语言，（增加），消极语言：降低。 保持语言简单与清晰，避免误解（降低离职率）。 迎接所有的可能性，不要设想结果。 确定负责人。 OKR 管理确定 OKR 是否落实到人，员工的状态（情绪） 站会周会例会 你做了什么帮助团队？ 计划做什么帮助团队？ 有什么阻碍因素吗？ 哪些做得好（认可） 需要什么资源？ 周报 一对一辅导 OKR 管理无法完成 OKR 的要素 缺乏沟通，不理解目标。 没有做好实施规划。 没有把时间花在重要的事情。 轻易放弃。 有参与感才会有承诺感。 OKR 的建议 要有耐心。第一次基本不会成功。 找到一个 OKR 专家，最好是管理层。 全员参与。 由上而下和由下而上。要让员工的个人创新体现在工作目标的设定上。 实施工具。 保持流程简便。 经常检查战略目标。 OKR 的层次公司事业群 -&gt; 业务单元/部门 -&gt; 团队/项目组 -&gt; 个人 团队 OKR 的例子 质量和效率 基础的能力（赋能） 团队建设（高效敏捷or学习型） "},{"title":"Team Topologies","date":"2021-06-15T12:08:43.000Z","url":"/2021/06/15/Team-Topologies/","tags":["管理"],"content":"团队是执行力的基础产品的差异来自于执行力的差异，执行力的差异来团队的差异。人口红利的消失，呼唤精细化管理。 软件开发是一个富有创造性的职业，产品的质量、产品的迭代速度有很大程度上依赖于架构师和工程师的水平。如何让人更高效的发挥自己的价值，并且让个人价值更好的服务于整个团队需要，绝对是一项很重要也很体现个人水平的技能。 两种团队过分务虚过分务虚的团队对于业务和技术都比较缺乏深入的见解，运用了许多组织模型但却缺乏明确的解决问题的方向，我相信这些团队长期一定难以做出应有的影响力。 过分务实过于务实的团队指的是更关注于底层技术细节的准确性，但是缺乏更深层次更高维度的对业务整合的理解、对解决什么问题的解构、对团队协作和团队文化的建设；这种类型很容易很吃力但没什么真正的影响力、或者人心涣散。 系统设计从团队设计开始这是根据康威定律很自然的一个延伸，当年决定团队架构的时候，你就已经在决定系统架构了。 管理者是不是需要懂技术？根据这条原则管理者是需要懂她负责的业务的，而且需要非常懂。当然业务在这里很多情况下指的就是技术，但不仅限于技术本身，还包括技术和产业的结合，需要解决什么样的问题，技术、资源配置和优先级之间的权衡等。管理者不一定是团队里最精通相关业务的，但一定是业务大局观最好的。 懂业务和懂技术，和是不是写代码无关，归根结底是能不能 hands-on，懂实操。 团队是执行任务的最小单元书中的另外一个原则就是团队是执行任务的最小单元。“团队”这个词在书中有明确的概念：一个拥有5到9人、有共同目标的稳定小组。作为执行任务的最小单元，公司应该把任务分配给团队而不是个人。 高效的团队有以下的特征： 团队规模不应过大，比如贝佐斯的两个披萨原则：Every internal team should be small enough that it can be fed with two pizzas. 书中引用了许多理论和研究来佐证，业界推荐的智力工作型团队最佳人数为5-9人。 业务上“高内聚，低耦合”。 连续性和稳定性，团队需要经历一段时间的招募、磨合和成长才能进入高产期，频繁的变换团队架构(reorg)一般来说都不是好现象。 明确的团队目标和团队的边界。 合理的团队Cognitive Load（认识负荷）。 四种团队类型书中认为所有高效的公司，团队类型需要最终都能被四种类型覆盖： Stream-aligned team：流式团队，迭代业务输出、交付用户价值的主要团队类型。一个公司里大部分团队都应该属于这个类别。其它团队都是围绕着怎么支持stream-aligned team（流式团队）来构建的——减少Stream aligned team的Cognitive Load（认知负荷），使之更高效。（对于Stream的理解。Stream就是用户value在产品中从设计到交付的一个过程/流/周期。Stream-aligned 的这种团队设计方式，有利于团队对最终交付负责，并得到用户反馈，持续改进提供给用户的价值。) Enabling team: 赋能团队，一般是由专家、顾问或者培训师组成，帮助另外的团队onboard某个新系统或者建立某种能力。一般来说都会有一个明确的赋能exit criteria和任务时间，最终的目的是让被赋能的团队可以独立运行。比如team A开发了一套新框架，某个stream-aligned team B决定采纳，team A决定在一个quarter的时间里协助他们迁移到新框架上并且培训team B让他们可以独立运行(exit criteria)。 Complicated system team: 复杂子系统团队，负责某个具体高门槛的核心技术的实现、维护和提升，并通过提供工具或接口的方式赋能其它团队。比如一个具体的数学库、或者语音识别的算法库，如果普通的团队要掌握的话一般需要付出很多的精力。这个时候我们可以招募一批专家负责封装细节和提供self-serviced服务。 Platform team: 平台团队，实现对底层细节的屏蔽，帮助Stream-aligned team更高效的关注业务层面，交付更快。 有些区分其实还挺隐晦的，比如infra team和platform team其实有着本质的区别，而清醒的认知这些区别，对于团队效率经常都有很好的影响。理解这四种团队类型的划分、并且明确自己所在的团队和打交道的团队类型是非常重要的。 三种团队交互模型Collaboration（协作）即两个团队直接紧密合作。不过虽然这种方式往往能带来快速的思想交流，同时它也需要付出更大的代价：比如更多的交流，需要说服更多的人，两个团队之间要有更多的协调，两个团队之间产生互相的依赖等等。所以一般建议一个团队在同一个时间最多只和另一个团队以collaboration的方式合作；同时最好提前明确collaboration的时长和要达成的结果。 X-as-a-service（XaaS）将团队产生的价值通过（内部）产品、服务的方式推广出去；接受方同理。这里的服务指自助服务，可以是API，可以是library，可以是一套工具，可以是文档等等。上面提到的platform team和complicated system team一般情况下最终目的都是以这样的方式去服务stream-aligned team。 Facilitating（赋能）帮助另一个团队扫清障碍、建立能力；接受方同理。这种方式的直接代价就是提供facilitation的团队的工程师需要占用自己用在维护或产出新功能的时间，不过好处是可以进行宣传和教育、增强公司内对相应技术、工具等的认知。一般建议一个团队同时不要facilitate很多个团队；提前协调好时长；并且以被facilitate的团队最终可以独立运行为目的（自主掌握、可以自己解决这方面的问题，或者说不用再考虑这方面的问题）。 "},{"title":"如何进行产品需求/项目立项","date":"2021-06-15T06:32:05.000Z","url":"/2021/06/15/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%BA%A7%E5%93%81%E9%9C%80%E6%B1%82-%E9%A1%B9%E7%9B%AE%E7%AB%8B%E9%A1%B9/","tags":["产品"],"content":"需求分析的三重境界第一层次：用户的观点和行为第二层次：用户的目标和动机第三层次：用户的人性价值观 用户场景分析 谁遇到了问题[WHO] 什么环节遇到了问题[WHEN] 在哪里遇到了问题 [WHERE] 问题是什么[WHAT] 问题产生原因[WHY] 如何解决[HOW] 解决成本[HOW MUCH] 商户 售后 因为 xxx，不得不退款 造成经营损失 平台出于成本考量，不能对此进行赔付 通过 新建 xxx 产品能力，提供补充能力 待思考，也许是中 需求背景要讲场景，讲数字，有定性 项目评估 项目收益：某项指标会上升、某项指标会下降。 项目目标：上线时间。 涉及资源：涉及几个部门和团队？ 具体产品设计方案产品到底有几个维度的细节，要建设的细节分别是什么。"},{"title":"机器学习的几个概念","date":"2021-06-11T06:06:05.000Z","url":"/2021/06/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%87%A0%E4%B8%AA%E6%A6%82%E5%BF%B5/","tags":["机器学习"],"content":"混淆矩阵混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。 * * True Class True Class * * p n Hypothesized Class Y True Positive False Positive Hypothesized Class N False Negative False Positive 精准、召回与打扰率precision 精准策略识别真实 bad case True Positive/策略识别的 bad case True Positive + False Positive 风控识别出 100 个案子，实际上有 20 个是真的，精准率为 20%。 recall 召回策略识别真实 bad case True Positive /所有真实的 bad case True Positive + False Negative 总共发生了 200 个案子，有 20 个被识别出来了，召回率为 10%。 打扰率总共有 10000 个案子，风控拦截了 200 个，打扰率为 2%。"},{"title":"管理的几个问题","date":"2021-06-08T03:00:22.000Z","url":"/2021/06/08/%E7%AE%A1%E7%90%86%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98/","tags":["管理"],"content":"管理者的几个问题和解法在管理者里面，有几种逃避的现象，第一种：不愿意做判断，进而就不愿意做决策。要突破心理障碍，要敢于做决策，敢于做判断，敢于输出。 第二个逃避的症状：不愿意用比自己强的人。不单在于初级管理者，高级管理者也是一样。喜欢用听话的人，听话的人管理成本低。 正如《领导梯队》里面讲，管理者不断往上走，需要关注三个方面——领导技能、时间管理、工作理念。看古论今，我们要敢于组建团队，里面要有各种角色的人，在早期管理的时候，比如你开始刚毕业前几年，你很容易是团队里专业性最强的人，但是很快你就没办法做到，因为你的精力你的时间开始分散，各方面不足以让你在专业上始终碾压你的团队其他成员，这点大家不要担心，你做的是综合判断，有观点输出了，你的价值就是做相对最优的决策。 大家要敢于用比自己强的人，组建一个多元的团队，这很重要。第三条我觉得大家比较喜欢逃避的是在时间管理上做逃避。初级管理者特别容易犯的一个错误——跟下属抢活干，喜欢解决一个特别具体的问题，表现出在团队里面好像有比较强的解决问题的能力。当解决一个具体问题的时候，你感觉树立了威信。跟下属抢活干，本质上我认为是一种逃避的表现，因为你不愿意去干该干的活，然后用另外一种你擅长的，或者是能让你产生成就感的事情，把你时间都占满。高级管理人员喜欢用一些不太重要的会，尤其是外部的会或者 social 的场合，把自己的时间占满，然后享受在会上输出的成就感。 焦虑的本质，对策略的思考不足所谓焦虑，就是你对所做的事情到底怎么做不太适应。表现在时间管理上，就是不知道到底应该投入多少精力去做事。这是很正常的，在之前的岗位上做得很成功，但到了新的岗位上面对一些新的情况，之前的经验可能会变成了一种负担。时间管理和角色转化焦虑背后的本质是策略思考不足。当你从个人贡献者变成团队管理者，之前的策略肯定不能直接搬过来，而是需要针对实际情况制定新的策略。在面对业务时，相信在座各位对策略打法都很清楚了。但是在带团队的时候，其实也同样需要策略——用什么样的策略来带团队。时间管理和角色转化的背后，其实是策略到底怎么定的问题。 订立个人目标是最难的相对个人目标，团队目标还算好制定，结合团队现状、业务目标、业务对你的要求、上级对你的要求，周边团队对你的要求，大概可以做一个对标，行业比较好的团队是什么样子，然后经过分析，可以定出你的团队目标。最难的问题是你的个人目标到底是什么？ 要理解格局，提升格局大家不要把“格局”作为一个贬义词去理解，而要作为一个褒义词，避免说某个人格局不高，而是尽量让自己格局变高，为什么这么说？因为“格局”这个词通常代表个人的目标以及利益观——你的成就动机到底是什么？动机是个人理解，没有对错之分。但是，只有自己格局变高了，才能站在更高的视野看现在的位置。 要做任何技术规划、甚至业务规划，都要跳出你所在的岗位来看。特别是一线管理者，作为某个职能的负责人，如果只看到自己的职责范围的话，思考问题会狭隘化，得不到全局最优解。假设现在业务研发的瓶颈在前端，你作为后端负责人是不是应该主动去考虑怎么帮助整个研发团队解决问题，设计一个整体效率更高的架构，甚至短期破坏一些架构帮前端提效。所以感受最深的就是跳出自己的职责范围来看，站在更高的层面上来看。 从领导梯队开始搭建团队首先从个人贡献者到一线管理者MO，要求他能知道业务目标，并且针对该目标制定策略、达成业务目标。再往上一级，当你是MM也就是管理一群管理者的时候，需要培养他们，除了把事情做完还有能够把人才培养出来。更高一级的管理者FM，需要能独立定目标、定策略。通常情况下站在BM（业务负责人）的角度，不是对每个职能方向都特别专业，这时候就需要各职能负责人能够结合自己的专业能力以及整个业务目标，拆解自己的目标。总结下来有三层，第一层是把事情做好，第二层是把人带好，第三层是能够把职能方向的目标和策略定好。 何谓借假修真 所以真正好的管理，就像父母养孩子一样，一个菜鸟、新人，一个什么都不懂的人，到我这里来，一开始我说你听、我做你看、你说我听、你做我看，手把手的教你——所谓的把屎把尿，但是你真正的目的是为了让他将来成长的比你更优秀。这是管理的杠杆，也是管理的价值。为什么说好的管理人员能带出一支好的队伍，好的公司能够不断的培养人才。 对在座诸位这么多年轻人来讲，有比你们今天拿的工资和股票期权更值钱的事情，就是你们的能力。这个组织在你身上的品牌背书，这才是你一辈子真正行走江湖的饭碗，而这都是依赖于这个组织能不能把人培养起来，所以管理借假修真就是这个意思。 差的管理人员只是在布置任务，把下属看成是干活的工具，或者是自己实现目标的一种手段。有的时候还耍耍威风和心眼，搞搞办公室政治。其实这些都很常见，但都不是高明的做法。好的管理是有复利的，是能把人培养出来的，这样组织才能壮大。所以借假修真讲的就是这一点，只有组织的成长才是真理。要做正确的事，做长期有积累的事，培养人就是其中非常重要的一件事。 没有使命必达 探索业务哪有那么多的使命必达。如果真的有了必达的使命，那经营企业就容易多了。不管是经营一个企业，管一块业务或者创业，很多时候我们看到的听到的更多的是成功之后的回过头，各种天降祥瑞、一道红光的演绎。其实当时充满了迷茫，并不知道这事有没有机会。既然是探索业务，对于中基层来讲，在我这一段里可以进行拆解，然后朝着目标去努力。不是说目标没完成，就觉得这个事不靠谱。探索业务领域练的就是在大量的机会里筛选出相对靠谱的，或者说你的价值就是把99个不靠谱的排除掉。最怕的是你走过的时候没炸，别人走过去炸了，那你就麻烦了，说明你没好好的走。练的是不一样的功夫，明确大规模扩张的时候是另外一种优化迭代、优化升级。不同的事要分开看待。 述职述职是一种群体性的工作总结、自我剖析、对标学习、互相反馈的会议机制。在述职会上，团队成员对上一阶段的工作情况进行汇报、共同讨论，并互相给予反馈。 述职可以： 帮助管理者了解团队成员阶段性的工作情况，提供辅导的重要渠道。 是团队成员相互了解、相互学习、对齐信息、增进交流的沟通平台。 是述职者复盘、自省、收集反馈、发现盲点的机会。 模板： 个人 总结过去： 目标与结果 分析与总结 个人成长/炼心志 展望未来： 下阶段的工作方向或思路 下阶段的个人成长目标 需要的支持和帮助 团队 总结过去： 定战略/策略 建团队 拿结果 炼心志 结合领导梯队的个人思考 展望未来： 下阶段的工作目标和策略 团队建设的思路 个人成长目标 需要的支持和帮助 个人述职的常见问题 没有框架，要应用 STAR。 要体现思考。不要领导让做什么就做什么，要体现自己的价值。 不要有低级错误，反复阅读。以读者为中心，符合写作四要求。 不管是述职还是给反馈，不唯上只唯真最好。备心态、备北荣。 听清问题再回应。不要急于防御、不要急于表达，有时候先复述会更好。 对话的双方要完整地了解背景和逻辑。接受反馈重反思，给予反馈重有效。 知行合一，设定 todo 和完成时间。 要借着反馈迭代你自己。 绩效管理绩效管理旨在帮助同学成长，促进目标达成，激发组织活力。 绩效考核是绩效管理的一部分，一定要做到客观公正。 沟通绩效结果，要让大家清晰地了解自己的绩效结果及原因，未来的发展计划及工作规划，帮助大家持续成长。 自评自评是回顾工作进展和个人成长的好机会。可以帮助主管更全面、准确地了解一个人的工作成果，让绩效评价更加客观。客观真实的自评，为考核后的绩效沟通提供依据，为个人发展讨论提供基础。价值观虽然不能直接对业绩产生巨大影响，但从长远看会对公司产生持续、缓慢的正面作用，是非常重要、非常值得做的事情。 Good Case业绩自评 (S/T) 公司需要在2月底前，开办线下活动M。活动M需要将D系统做二次开发，时间紧，任务重。 (A)我快速地组建了项目团队，明确职责分工，并制定了项目计划。因为时间紧任务重，我要求项目组成员对进度报告精准到天，并为保证系统顺利上线采取了2个措施：1……2……。 (R)中间的人力风险，技术攻关风险，都被提前发现并解决。D系统的二次开发在早于活动两周的时间完成，预留了更多的用户验证时间。最终活动M顺利举办。 价值观自评 (S) 背景：收银对接 xx 项目，与订单侧、系统侧、代理商侧、服务商侧协同开发。 (T) 目标：倒排期项目，保证 11 月 7 号前上线。 (A) 行动：1. 多方合作，讨论接口、解决问题积极行动。 (R) 结果：项目顺利上线，与各个团队的参与者保持较好的合作关系。 绩效沟通理念 坚持高标准、严要求 ：今天的最佳表现，作为明天的最低要求 。 双向沟通，持续对齐 ：上下级间持续共识目标，阶段性辅导和反馈 。 既要结果，也要过程：业绩产出要好，还要苦练基本功，践行好公司价值观 。 客观公正，奖优汰劣 ：坚持客观公正，合理分布，激发组织活力。 导师从成就自我到成就他人的角色转换。 建立良好的沟通关系。 同理心特别重要，首先是要肯定他们，每一个人都是有着无限潜力的。 “学习不但应该把我们带往某处，而且还应该让我们日后在继续前行时更为容易。”教育只是启发别人，别人的能力是自己构筑的。 保持空杯心态，教育别人的时候，也是在通过输出的方式重建自己。 常见误区误区一：缺乏关注——校招生觉得导师很忙，不管我；校招生没有导师误区二：关注过度误区三：过分说教、缺乏倾听误区四：授之以鱼而非授之以渔误区五：布置任务不说背景、不考虑校招生实际情况误区六：导师要求很高，有时候太着急，误区七：对比式、打击式教育误区八：负面价值观传递 如何对校招生进行辅导反馈 开启对话 澄清事实 交换看法 达成共识 总结对话 开启对话 塑造良好的沟通氛围（以轻松的话题开场，周末去哪啦？最近过得怎么样？） 关注对方的情绪状态（先处理情绪，再谈事情）。 展开正式沟通 谈什么？ 为什么要谈这个（对个人、团队、公司的影响/利益）？ 如对方提议沟通，即可通过询问确定对方的目的。 澄清事实 描述事实，不掺杂自己的观点（我观察到，我看到 XX 进展到……）。 确认对方也知晓/承认这个事实。 如果对方描述事件不完整，则可以通过询问将事件还原完整。注：先别进行评论，基于客观事实先进行澄清和说明。 交换看法 探寻对方的想法： 对于这件事，你怎么看？ 为什么这么想呢？ 你当时想到了什么菜这么做的？ 是不是遇到什么问题了才会这样？ 陈述自己的观点、分享经验： 对于这件事情，我的看法是……原因是…… 类似的情况我也遇到过……当时…… 我的意思是……而不是 说一个我的想法，供你参考…… 达成共识 明确共识-确认我们有哪些看法一致了。 商讨改变-哪些行为/观念需要改变。 行动促进-接下来干什么，双方的 todo。 需要支持-要完成行动需要我提供哪些支持和帮助。 跟进计划-有必要的话，预约下一次沟通时间。 总结对话 对取得的一致表示肯定：我们这次沟通达成了几点一致，我觉得特别开心。 承认仍然存在不同的看法：可能在 XX 上我们看法不一致，但也特别能理解，在这件事上处于以客户为中心的共同目标，我们先按照刚才共识的方式推进，XX 事情我们之后可以再找机会沟通。 给予对方积极的信号：你在这次对话中表现出了……，相信你之后可以…… 确认对方也满意这样的对话方式：咱们这样的对话方式和频次 ok 吗？有什么建议？ 如何帮校招生融入专业技能 第一阶段：0-1 个月，确定目标&amp;制定 roadmap。 第二阶段：2-3 个月，夯实基础：学习 git、maven。 第三阶段：6 个月，适配工作的难易程度：适度有挑战性的工作、小型项目的主 R、小范围的分享。 工作理念 学生思维 职场思维 兴趣出发 结果导向 自由散漫 严谨规范 单打独斗 合作共赢 科研理论 动手实践 专业深井 客户为中心 团队融入 环境不熟悉 团队不熟悉 文化不了解 缺乏归属感 时间管理要有管理观念 如何传播文化传道受业，先传道，再授业。 如何规划校招生成长发展IDP（个人成长规划）： 确定目标 找到策略 做好计划 确定目标通用目标参考： 融入期（0-6 个月）：初做者，基础支持工作。 成长期（7-12 个月）：独立者，独立完成需求。 找到策略通过 721 学习法制定个人发展策略： 事上练：70%，岗位实际锻炼。 聊高人：20%，向他人学习。 读好书、学好课：10%，培训和阅读。 做好计划 1. 待发展项 2. 现状 3. 成功的指标 4. 学习行动计划 5. 资源/支持 6. 时间 能力 1：解决问题的能力 问题列举 OKR 721 要采取哪些抓手 需要谁当导师、参加什么项目 2022上半年 能力 2：跨团队沟通能力 PDCA循环PDCA循环是一个持续改进模型， 它包括持续改进与不断学习的四个循环反复的步骤， 即计划（Plan）、执行（Do）、检查（Check）、处理（Act）。 P（Plan）–计划，通过集体讨论或个人思考确定某一行动或某一系列行动的方案，包括5W1H； D（Do）–执行人执行，按照计划去做，落实计划； C（Check）–检查或学习执行人的执行情况，比如到计划执行过程中的“控制点”“管理点”去收集信息，“计划执行的怎么样？有没有达到预期的效果或要求？”，找出问题； A（Act）–效果，对检查的结果进行处理，认可或否定。成功的经验要加以肯定，或着模式化或者标准化以适当推广；失败的教训要加以总结，以免重现；这一轮未解决的问题放到下一个PDCA循环。为了避免Act与Do的混淆，也有很多人将A解释为Adjust。 SMART原则所谓SMART原则，即是： 目标必须是具体的（Specific）stresses the need for a specific goal over and against a more general one. 目标必须是可以衡量的（Measurable）stresses the need for concrete criteria for measuring progress toward the attainment of the goal. 目标必须是可以达到的（Attainable）stresses the importance of goals that are realistic and attainable. 目标必须和总体目标具有相关性（Relevant）stresses the importance of choosing goals that matter. 目标必须具有明确的截止期限（Time-bound）stresses the importance of grounding goals within a time frame, giving them a target date. 根本原因分析（Root Cause Analysis）根本原因分析（Root Cause Analysis）是一项结构化的问题处理法，用以逐步找出问题的根本原因并加以解决， 而不是仅仅关注问题的表征。根本原因分析是一个系统化的问题处理过程，包括确定和分析问题原因，找出问题解决办法，并制定问题预防措施。在组织管理领域内，根本原因分析能够帮助利益相关者发现组织问题的症结，并找出根本性的解决方案。 根本原因分析法的目标是找出： 问题（发生了什么）；原因（为什么发生）；措施（什么办法能够阻止问题再次发生）。 所谓根本原因，就是导致我们所关注的问题发生的最基本的原因。 丰田的 5Why 方法其实是一种根因分析法。 如何高效开会按照MBALib的规则[参考1]：不管哪种会议，主持者要想利用好它，提高会议效率，就必须做到以下“八不”： 不开无目的的会议，必须事先确定本次会议目的，否则宁可不开； 不开多议题的会议，每次会议只解决一个中心议题； 不开无准备的会议，会前必须有充分的准备； 可开可不开的会议就不开，只召开非开不可的会议； 不要无关的人参加会议，会议参加者必须与会议议题有关； 不做离题的讨论，开会时必须围绕会议的中心议题发言； 不能重复别人已经讲过的观点，表达观点应简洁明了； 不开议而不决的会议，会而有议，议而有决。多次会议才能解决的问题，应当明确宣布是暂时休会，并应宣布下次会议的进一步要求，提醒大家早作准备。 另外，Google的Larry Page在公司内部要求，讨论性会议需要遵循下面四个原则（英文是原文，中文我自己翻译的）： 每个会议都有明确的可以拍板的人参加。Every meeting must have one clear decision maker. If there’s no decision maker – or no decision to be made – the meeting shouldn’t happen. 参加会议的人不超过10个。No more than 10 people should attend. 每个参会的人都应该给出意见，否则他就不必参会。Every person should give input, otherwise they shouldn’t be there. 不是每个决定都需要开会才能做，如果真的需要，那就应该立即开会。No decision should ever wait for a meeting. If a meeting absolutely has to happen before a decision should be made, then the meeting should be scheduled immediately. 其中第三条也是黑石的要求。 周会模板轮值人职责 在哪里开会，怎么通知同事。 询问 todo 完成情况，汇总项目进度。 记录会议纪要 wiki。 提前收集议题，提前发出。 周会轮值顺序。 参与人要提前请假 周会信息 会议时间 会议地点 周会主持人 参会人员 请假人员 下次周会组织人 2022年01月13日 xx 会议室 @张三 团队列表 @李四 @王五 SRE 指标需求总览迭代内容需求池链接：新进入排期需求？个，在途需求数量？个，进度异常需求？个，整体正常。 交付效率当前组织有多少个在途需求： 需求吞吐量 开发周期正确率（对标几周交付？） 交付周期正确率 单周开发达成率 x周交付达成率 千行代码缺陷率 缺陷数 线上故障数 指标总览业务指标环节 1各种单据数量，按周罗列要有数据解读 环节 2各种时效数据，按周罗列要有数据解读 环节 3各种体验数据，按周罗列要有数据解读 技术指标 编号 系统名称+责任人 关键指标： 峰值 qps 服务可用性（只标识可用性不达标） 慢查询 告警：分类 告警处理：处理比例 db 容量 qa 指标周会纪要本周 todo 本周todo 责任人 需求链接 上周 todo 上周todo 责任人 需求链接 完成时间点 效果 分享1 on 1 你所在部门的最大问题是什么？为什么？ 在这里的工作中，哪一点令你感到不愉快？ 公司里谁最优秀？你最佩服谁？ 假如你是我，你会做何调整？ 你这个产品的哪个方而不尽如人意？ 你觉得我们错失的最大机遇是什么？ 哪些是我们该做而没有做的？ 你对这里的工作满意么？ 你对于近期的工作满意吗？为什么？ 你最困扰的事情是什么？ 你认为自己的价值和能力被低估了吗？为什么？ 你觉得在工作中能学到东西吗？你最近学到了什么？你还希望在哪些领域进行学习？ 作为你的 manager，我需要做什么能帮助你更顺利地工作？ 我应该更多还是更少地参与到你的日常工作当中？ 在工作中你更希望我给你多一点还是少一点的指导？ 每周浪费你时间最多的事是什么 作为一个团队我们应该着手做什么 你认为你应该开始做什么，应该停止做什么，应该继续做什么 在工作中你更希望我给你多一点还是少一点的指导 你觉得你在工作上的得到的成效够吗？如果不够，你想从哪里获得更多的成效呢？ 有什么方面能让我帮你在工作中更得心应手？ 在你的工作中，你想要更多的帮助或指导吗? 你觉得你已经得到足够多的工作成效了吗 如何提升我们的团队协作能力 1到10分，给你的工作幸福感打几分？ 在公司战略和目标方面，你最不清楚的是什么? "},{"title":"STARR 法则","date":"2021-06-07T03:49:13.000Z","url":"/2021/06/07/STARR-%E6%B3%95%E5%88%99/","tags":["管理"],"content":" STAR 法则最早用于面试，后来演变为 STARR，最后一个 R 是反思/Reflection。 但 STARR 不仅适用于面试，也适用于工作小结，项目报告等各种场景。 什么是STARR行为面试法？所谓 STARR原则，即 Situation（情景）、Task（任务）、Action（行动）、Result（结果）、Reflection（反思）五个英文单词的首字母组合。 S - Situation - 情景：描述候选人过去经历中某件重要事件背景状况，了解候选人行为背后的动机。我们需要特别关注的是过去行动的背景情况与未来岗位场景之间的相似性。 T - Task - 任务：了解候选人在其背景环境中所执行的任务与角色，从而考察该候选人是否做过其描述的职位及其是否具备该岗位的相应能力。 A - Action - 行动：是考察候选人所担任的角色与执行任务的方式。行动是行为事例（STAR）的核心，因为多个STAR的行为串在一起就能说明候选人是否有某种行为模式。 R - Result - 结果：即该项任务在行动后所达到的效果，我们要关注行为和结果的因果关系，需要特别注意区分和行为无关的结果。有时候结果是环境造成的，不是行为造成的，不要只看结果的好坏直接判断候选人的能力。 R - Reflection - 反思：即候选人在重点任务完成后的总结与收获，侧重于评估候选人是否具有思考、迭代的意识和能力。 为什么要采用STARR方法？行为法面试的底层逻辑是候选人过去连贯性的行为可以直接影响未来的行为，未来的行为将直接影响未来绩效；因此，面试官需要重点关注候选人过去工作的复杂程度，确认候选人过去面临的场景和现在岗位具有相似性，通过候选人过去一贯的行为模式判断候选人是否具备岗位所需核心能力，以全面了解该候选人的知识、经验、技能的掌握程度以及他的工作风格、性格特点等方面。 全面了解：候选人通常没有意识补充完整信息，面试官要予以引导： 了解候选人所处的背景与面对的任务，可以更好地了解候选人行为背后的动机和思维方式。 候选人通常侧重强调成果，但对自身的贡献和具体任务语焉不详，或较为简单和宽泛，从而无法判断候选人的实际贡献和能力。 识别水分：候选者很难完全捏造完整STARR，但是通常会夸大自己所做的贡献，可以通过完整的STARR信息进行甄别。 如何应用STARR方法？ 引导候选人补充不完整的STARR 面试官收集到了完整STAR后，需要判断STAR各部分的信息是不是有必要继续追问更详细的内容，特别是A的部分。 面试官追问策略：围绕STARR，缺哪儿补哪儿。 Situation / Task Action Result Reflection - 能说说当时的背景吗？ - 当时出于什么原因发起的该项目？ - 你当时面临的任务是什么？ - 当时期待的产出是什么？ - 这件事的难点在哪里？ - 当时有哪些人参与？如何分工？你承担什么角色？ - 你当时的应对措施是什么？ - 采取了什么样的行动步骤？ - 你是怎么做的呢？能不能举个例子？ - 当时这么做的原因是什么？你是如何考虑的？ - 后来呢？ 你得到了怎样的反馈？ - 请列举一些采取这样举措之后的数据和效果。 - 你在这件事中最大的收获是什么？对你有什么启示？ - （负面问题）这件事对你最深刻的教训是什么？ 识别假的STARR 面试官追问策略：识别+追问具体STARR。 假的STARR是指候选人的回答并不是一个STARR事例，可能是自己的观点、也可能是表达习惯导致的模糊描述，需要面试官用心识别并追问出真实的STAR事例，候选人提供假的STARR并不能代表其不诚实。 从完整的STARR中全面识别能力的一致性 面试官追问策略：确认正负问题相结合+至少有两个充实的STARR。 通过负面问题考察候选人的逆境应对能力，评估行为的稳定性和质量，从而预测绩效风险。 举例：“让你觉得最失败/有遗憾的经历” 提问技巧：负面问题要放在正面问题之后。通过自黑等方式泛化负面问题，避免让候选人感到有攻击性。 收集足够的STARR事例：根据本次面试的考察目标，面试官还需要判断是否有足够、全面的STARR能判断出候选人的行为惯性。一般而言，正负问题相结合下的3个STARR事例才能看出行为惯性，有时候选人的项目比较复杂或者重大，这种情况下我们也要收集到两个充实的STARR。"},{"title":" leadership 的境界","date":"2021-06-04T12:02:58.000Z","url":"/2021/06/04/leadership-%E7%9A%84%E5%A2%83%E7%95%8C/","tags":["管理"],"content":" 修身：以身作则 齐家：relugate 自己的部署 治国：governance 自己的公司 平天下：occupy 占领自己的目标市场 世界上最好的商业模式是，建立一个国家。社会主义和资本主义的区别有很多，其中有一种区别是，不同的治理方式。"},{"title":"插件化架构","date":"2021-05-27T08:11:08.000Z","url":"/2021/05/27/%E6%8F%92%E4%BB%B6%E5%8C%96%E6%9E%B6%E6%9E%84/","tags":["系统架构","未完成","领域驱动设计","插件化"],"content":"为什么要实现插件化架构业务和平台要解耦。业务和平台都是多对多的关系。全链路里既有业务，也有平台。大家应该如何 talk by interface。我们看待复杂组织的业务流程，要线性看，看到很多节点；也要分层看，看到复合的层次。在这种情况下，上层架构域和下层架构域之间怎么实现复杂度的管理？ 如果我们需要构建大规模的泛交易平台，我们需要靠插件化架构把我们的系统组装起来。 插件化架构通常需要一个 runtime 层（或者 boot 层）、core 层。 从业务视角来看，要解决多团队协同的问题因为多个业务域/团队没有把能力用统一的方式透出，所以没有人能够知道统一的技术能力应该怎么串联。进行全链路沟通需要大量的沟通对齐工作。 从业务视角来看，复杂性业务要素包含本业务用例里的各种模型。 从平台视角来看，要解决复杂性管理问题平台要支撑多种业务，业务的复杂性、差异性，以及众多业务需求不确定性，在各平台内部如何管理和支撑？简单的 if-else 不易于管理，确保对业务的支撑能力不相互影响。隔离是最好的管理手法。 从平台视角来看，复杂性业务要素包含本域内标准系统用例里的各种模型。 同一个模型，在业务场景里看到的是具体的模型-如外卖；而在平台层想到的是商品。业务层看到的是外卖的成交、制作、配送，而平台层看到的是商品的上单、供给、交易、退款、履约。 如何实现插件化架构通过插件化技术架构，使业务与平台隔离，解决业务差异性和不确定性。让业务可以扩展平台能力-通过回调来实现架构上的反向依赖，但主流程大部分时候是跑在平台里的。 我的额外总结： 平台首先定义领域：领域活动、领域服务、领域能力（商业能力），平台实现一部分领域能力（通过扩展点实现）。 平台把领域包装成商业能力、平台产品。 业务拥有自己的业务流程（有自己的 bizActivity、和 bizService），使用平台产品，实现业务扩展领域能力（既是最顶层用户，也是底层能力提供方之一）。业务只理解商业 sdk，只理解商业能力。 具体原则 平台提供经过业务抽象的、标准化业务能力；同时提供可扩展的扩展点（extension 或者 slot），开放给业务进行个性化定制。 业务基于可扩展扩展点，进行业务个性化定制开发，实现自己的业务。 平台与业务是共建、共享、反哺的关系。平台深入到业务，抽象建模出通用的标准业务能力，同时设计供业务进行个性定制的扩展点。 通过 sdk 进行通信和解耦统一业务语言和概念，把控业务全貌。 从各平台提供的平台产品/商业能力视角出发，构建全平台统一SDK，分门别类设计能力扩展点，统一透出给业务方进行个性化定制，提供缺省的扩展点封装实现。 统一业务身份，一个业务扩展包、一个业务身份贯穿所有业务平台。 构建业务运营支撑发布平台，业务可视、可管、可运营。 通过业务能力SDK + 运营支撑发布平台，把商业能力、需求结构化和服务代码建立映射，做到需求即PRD-&gt; PRD即代码 -&gt; 代码即部署 -&gt; 部署即监控。 插件化架构.drawio 常见的业务子域：订单、支付、结算、营销、价格、库存、商品、售后。 什么是业务：拥有 bizIdentity，也叫垂直业务，每个业务都有自己独立的 bizCode。 什么是产品：提前准备好的、跨多个域、横向提供给多业务方使用的可复用的组件，所以产品也可以认为是 平台能力。本质上就是对平台中已有扩展点（可以是多个域、多个能力）的定制的一个集合。这里的产品应该特指的是终态的平台产品-对应业务用例和系统用例。 业务与产品的区别：业务之间是互斥的，一个商品固定场景只能属于一个业务。但是一个商品固定场景可以属于（或者说使用了）多个产品，如： 聚划算+分期购+货到付款。 简单说产品就是为了给大家复用的系统能力。 业务身份：某一具体业务在系统流程的身份象征。通过业务身份，系统流程能唯一识别出该业务，执行业务对应的扩展点定制逻辑，以及产出运行态业务数据（gmv、订单量等）。 冲突：本质上来讲产品和业务都是对扩展点的定制，业务和产品、或产品和产品之间会存在对同一个扩展点定制的场景这时候就产生了冲突，冲突分两种情况：a. 所有业务和产品定制点都执行。这种情况理论上不需要解决冲突的，因为业务和产品之间本身的代码需要做到相互隔离，不应该相互依赖。b. 只选择第一个定制点的返回结果。这个时候就需要为多个定制点调整优先级。 业务流程：描述一个业务生命周期，由业务活动编排而成（此处可以引入编排框架）。比如保险批改流程，报价-&gt;创建批单 -&gt; 核价 -&gt; 核保 -&gt; 支付 -&gt; 出单。 业务活动：由特定角色触发的一段业务语义完整的业务功能，对应我们平时说的业务用例，比如用户下单、用户支付、商家发货等。业务活动的执行流，由域服务节点编排而成。 域：类似DDD中的业务子域，一个域包含一到多个域服务，一到多个域能力。比如阿里的buy2，全交易链路上有多少个业务子域，我们就需要建立多少个这样的设计： 域服务：功能域对外提供的可供业务活动编排的服务接口，比如拆单接口、生单接口、库存扣减接口、风控接口等。 域能力：功能域对外能提供的可扩展能⼒，是一组扩展点的组合，用于更好的组织系统。可以被看作调用一组特定扩展点的模板方法集合-从另一个视角来看，如果没有模板方法的结构，这也可以是一个双层的策略，通过扩展点动态绑定的策略。举例: 减库策略策略能力（扩展点举例： 库存策略、是否回补、是否强减付减、预扣超时时间 等） 普通收货方式策略能力（扩展点举例：是否使用UIC地址、是否过滤赠品、默认选中收货地址、是否展示地址 等） 淘金币策略能力（扩展点举例：可用淘金币数量、是否使用淘金币、是否要禁用淘金币 等） 买家评价策略能力（扩展点举例：是否允许卖家评价、直营评价计分类型、是否允许买家评价） 能力实例：继承自域能力，是域能力的扩展和增强。 扩展点：对整个流程中需要被不同的业务定制的一个功能点。a. 库存策略选择（拍减、预扣、付减）、是否回补库存、是否调用优惠b. 是否支持货到付款、是否支持分期购、是否默认选中匿名购买、是否强制匿名购买。 核心服务层（core 层）交易框架核心域绝对抽象，是交易核心领域层的抽象定义。它定义了交易规范，交易做了什么、应该怎么做、哪些是可以扩展的。 主要按领域进行建模和划分，定义了领域服务接口、领域模型、领域能力模型以及可扩展点。基础域输出的是基于对电商业务的理解，制定的交易模型标准。 域服务描述每个子域应该做什么，如拆单、创建订单、创建支付单等 能力描述每个子域应该包含什么，如下单风控能力、库存扣减能力、优惠校验能力的 扩展点描述每个子域的行为是什么，是否支持分级库存扣减、是否支持、库存扣减策略（分级扣减、普通扣减）等 Repo描述下游服务依赖是什么，比如潘多拉、商品中心、库存中心等 解决方案层（biz-service-impl 层）对核心服务层定义的域、域服务、能力、repo的具体实现，是对交易规范的实际实现和解释。核心领域层定规范、解决方案层负责在特定场景下解释实现。 开放SDK：业务方在业务定制时可以使用的SDK，允许业务方在SDK规定的范围内做业务扩展和定制。里边是一堆分门别类组织好的扩展点 业务活动：由域服务接口编排成一个个执行流程（如下单、支付、发货、收货等），只能通过域服务接口进行编排，不允许硬编码业务逻辑，后续通过运营平台配置 业务流程：由业务活动编排成一个个业务流程（如团购交付流程、预订交付流程、货到付款交付流程等），只能通过业务活动进行编排，不允许硬编码业务逻辑，后续通过运营平台配置 能力实例：对Ability进行具体实现。 扩展点实现：提供一份默认的扩展点实现。如是否支持折扣优惠的扩展点，默认实现为false，只有需要折扣优惠的业务方才定制该扩展点返回true TMF（Trade Modularized Framework）同理还有 BPF。 COLAtodo"},{"title":"故障演练平台设计","date":"2021-05-27T06:33:43.000Z","url":"/2021/05/27/%E6%95%85%E9%9A%9C%E6%BC%94%E7%BB%83%E5%B9%B3%E5%8F%B0%E8%AE%BE%E8%AE%A1/","tags":["云计算"],"content":"目的 验证故障应急处理能力 验证服务降级及止损能力 验证中间件、存储和服务的稳定性 发现隐患，提升服务可用率 要具备的功能 有环境恢复的能力。 准备演练场景。 感知监控。 权限管理、时间管理。 "},{"title":"监控与告警","date":"2021-05-25T12:58:50.000Z","url":"/2021/05/25/%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%91%8A%E8%AD%A6/","tags":["监控"],"content":"如何设计监控系统监控系统设计得好，我们就能够用图表说话。最通常意义上的指标，是 Metric 系统。 日志收集和指标收集不一样我们的监控系统需要监控整个技术栈。指标是由技术栈决定的，我们有多少技术层次，就有多少类指标。 多套监控系统是有问题的，需要尽量考虑技术体系的融合。然而，基于“一切可监控”的技术原则，移动端、浏览器端、应用层、系统层以及网络层的指标采集、计算、存储、展示以及告警可以集中在一个系统里。但应用层的日志需要 Kafka、ELK 等日志中心的支持。但某些错误日志、慢事务日志，是可以以 logview 的形式被抽样保留下来的。在 logview 里，L代表最新一条请求（L for Latest）的 Log，S代表耗时最久请求（S for Slowest）的 Log。 这样可以： 1、让系统在配置监控时只有一个入口和一套配置，降低学习成本和使用成本，也会消除设计上的概念不完整。实现产品上的融合。2、整合需要整合的存储空间，实现技术上的融合。 正常指标和异常指标是不一样的。异常指标的上报可能包含上下文（在某些场景下叫 NameValuePairs），需要单独设计。 不同端上的指标 移动端：端到端网络质量、Crash错误、代码级日志、性能等。 Web端：JS错误、Ajax接口监控、性能等。 应用层：异常、接口性能、依赖拓扑，堆栈等。 系统层：CPU、Memory。 网络层：流量，丢包等。 作为业务团队的研发人员，应当关注应用层、系统层和网络层的指标、监控和告警。 有多少种方法可以获取监控数据 小规模在线场景，只能支持简单的应用：提供标准的数据 API，下游业务可以基于 API 做一些定制的报表，比如汇总监控数据作为团队周报、问题看板的数据补充等场景。 大规模在线场景，需要利用消息中间件的堆积能力：提供监控数据MQ的下游消费能力，满足吞吐量较高的下游系统实时消费需求，比如说下游业务系统数据分析诊断。 大规模离线场景，如果需要支持复杂计算，如机器学习，则需要建立另一个 L1 层：建立自己的离线数仓，把关键业务数据导入离线计算平台，这数据用于一些大规模机器学习等任务，比如说智能预测计算。（直接让这些大规模机器学习任务访问实时系统存储，会影响在线系统的SLA）。 监控采样问题大 qps 的场景下大量的请求生成会导致生产端网卡超载，所以 api 自己要有高负载的时候把全量采样转成部分采样的策略（采样率低的时候甚至可以低到 0.03%），同样，消费端自己要有流控抛弃请求的策略。但，所有的系统异常的消息是不能因为采样而被丢弃的。 采样率最好做成不可调节，服务自己计算自适应调节。 可以把监控指标做个转换：监控数据是全量统计，客户端预计算；链路数据是采样计算，大约有5%的项目链路是采样统计。这样只要保证客户端或者近端的负载可控即可-这是一个类似 log4j2 的 logger 怎样炒高性能响应的问题。 基础模型设计所有的模型都有 type 和 name，理论上 messageTree 可以支持好几层的细分的 messageTree。Transaction 和 Event 都有的 data 的参数（addData），这里面的数据主要用于在查看请求的logview里面用到，这个参数一般传入一些参数值等。 Transaction 和 Event 都记录成功和失败，可以存储抽样的 logview。Transaction 可以嵌套，Event 是不能嵌套的。 Metric 就不记录 logview，纯粹记打点，可以被用来记录 count 和 duration。 建议埋点 Transaction、Event、Metric 等的 type 和 name，都是用英文小写（免得各个环节出现奇奇怪怪的问题），然后分隔符用.表示。比如如下的例子jvm.gc.count，jvm.memory.used 这类表达方式。 通常能够表达成功和失败的节点的 status 都是 0 为成功，非 0 为失败。 Transaction事务是一种： 可嵌套 有时间 有成败 可聚合 的监控指标。 缺点是： 状态只有成败两种。 有 type、name、success 和 time，因此可以算出 avg、max、min、tp50、tp99、tp999、tp9999、qps。 主要记录一些边界信息（跨项目、跨模块的调用），记录一些复杂的比较耗时代码统计。 建议如果是本地代码的 Transaction，建议平均执行时间要相对比较长，比如至少超过5ms。错误的用法：不少业务方用了 Transaction，基本平均耗时基本都是1ms都不到，可能仅仅只是用统计功能，这个可以用 Event 来代替，Event 相比 Transaction 开销要很低，并且埋点的代码也更加精简。 Transaction 支持服务 key、IP、Type、Name 四个维度的聚合，统计指标有总数、失败数、成功率、TP90、TP95、TP99等丰富的性能指标。注意 Transaction 有 IP 维度的聚合，这样可以根据单台机器看性能指标，很多场景下，机器维度数据是非常有用的。 Transaction 的 Show 图表 统计表格： Total Failure Failure% LogView Max Avg TP50 TP90 TP95 TP99 TP999 TP9999 QPS 23,450 33 0.1407% Latest Logview 的链接、Slowest Logview 的链接 97.0 15.5 15.4 18.3 19.3 33.0 58.5 59.4 6.5 耗时分布直方图：x 轴耗时分布区间，y 轴请求 count。 请求个数直方图（Hits Over time）：x 轴分钟分布，y 轴请求 count。 平均耗时直方图：x 轴分钟时分布，y 轴平均耗时。 成功率曲线图：x 轴分钟时分布，y 轴成功率。 最大耗时直方图：x 轴分钟时分布，y 轴最大耗时。 失败次数直方图（Failures Over Time）：x 轴耗时分布区间，y 轴失败次数 count。 50/90/95/99/99.9/99.99 Line Over Time 曲线图：x 轴分钟分布，y 轴每条分位线的分位点。 机器分布统计：|序号|HostName|IP| + 上方统计表格 总量统计分布饼图 错误统计分布饼图 Status Code 饼图 Event “需要计时用 Transaction，仅需要计数用 Event。” Event 性能更好。 Event 和 Transaction 有个固有的缺点，就是不能很好地支持多分支的指标监控。只能通过一个 name - show 的“错误分布统计”和“status code 分布统计”来做一些小时级的饼图监控。 主要记录用于记录事件。最常见的场景就是当埋 Transaction 时候，需要 event作为补充（如Monitor.logEvent(&quot;Config1&quot;, &quot;Value1&quot;);），比如记录当时访问参数等、代码一些特殊诡异路径的分析（branch 分析），还有异常信息记录。Event 可以解决一些业务统计问题，它更加侧重于业务一些简单统计。Event 埋点支持 Appkey、IP、Type、Name 四个维度的聚合，统计指标相比 Transaction 少一些，只有总数、失败、以及成功率，Event也支持机器维度的统计。 每个 event 都包含 type 和 name，可以被认为是不带执行时间的 Transaction。 event 可以当做 metric 用，记录分布的 tag 值，也可以记录配置（配置也可以是一种 tag），他们记录值的方法有：把值写进 type 的名称路径里，把 type 写成 name 的一部分，或者直接写成 name-这是中间件使用 Event 的主要思路！。常见的 event type 有： 数据库相关，包括： rows、length、method（insert 等语句的统计）（有时候需要理解事务，需要去看 transaction，这个特别重要，可以看到各种的实际 sql）、database（实际的物理 jdbc url，从这里可以看到实际负载均衡和读写分离的分布）。分库分表模式下的逻辑数据源、物理数据源、实际的工作权重。 ShardSQL.xxx 分布式 sql 的请求路由和结果归并是它们的 name，如：物理数据源的名称、操作的事件。 对下游的 rpc call：下游的服务名称、上下游 ip 地址、是否同异步调用。 rpc 类型：是否已经 mesh 化。 泳道/Cell/环境：环境标记。 请求类型、协议类型、请求响应的 size。 是否使用鉴权、是否灰度了鉴权。 限流/熔断相关的配置：到底多少个请求被命中了限流。限流组件.限流模式.log。 缓存：缓存集群、缓存连接、缓存配置、缓存事件、缓存的超时事件。 kms：是否正确地使用了 kms。 是否存在特定的异常。 内部服务调用：这通常需要 aop 来做普遍拦截。 有些设计里面，单独的 event 埋点不会生成消息树（消息树等于 LogView），event埋点本身不包含耗时等指标。可以直接使用 transaction埋点。 有非常多的 Event 比 Error 更适合拿来做告警，但专门的异常情况还是适合使用 Problem。 Event 的 Show 图表Event 是没有时间的 Transaction，所以没有任何 top percentiles 统计数据。 统计表格： Total Failure Failure% LogView QPS 79,712,728 354,372 0.4446% 最新请求的 LogView 的采样（因为谈不上 Slowest） 6.5 请求个数直方图（Hits Over time）：x 轴分钟分布，y 轴请求 count。 失败次数直方图（Failures Over Time）：x 轴耗时分布区间，y 轴失败次数 count。 Metric/Tag主要用于记录了一些实际的业务指标，用于运维监控，比如订单量，支付等这类case： metric侧重于实时监控，侧重于非常重要关键业务指标，不做统计分析。所以不适合看跨很长时间的图表，不容易产生分级聚合（只适合按照 tagName 下钻）。 metric 不适合记录失败，应该想办法把它变成 problem 的指标。 Metric 通常有乘积限制，有的 metric 实现允许的多维度的 tag 乘积总数限制是一万（比如一个 metric name 名字叫 pay，有一个 tag 叫 channel，一个 tag 叫 status，如果 channel 有 500 个，status 最多有 20 个，笛卡尔积不能超过一万个）。 通常 metric 实现有两个 API，logMetricForCount 以及 logMetricForDuration，logMetricForCount 主要用于 counter 类的业务指标，logMetricForDuration 主要用于 timer 类的业务指标。 另一种简化版本： Metric 和 Transaction/Event 的区别是： Metric 一开始就是一个个 Graph，Transaction/Event 一开始就是一个 Type、Name 聚合的 Table，下钻到单一指标上才能看到 graph。 Metric 可以按照单独的 Tag 维度再下钻，但 Transaction/Event 只能按照 status 维度再分类一下。 Problem通常异常的 Problem type 是 error，但又可以不只是 error。程序内部的 error 打点是一种 error，exception 是另一种。 Problem 的 Show 图表 统计表格： Type Category Name Count error（一般是 error、long-call、long-service、long-sql、long-cache、long-mq、long-url，也可以有中间件/业务自定义的 type，每种介质一种 type） 未分类（一般都不分类） java.lang.InterruptedException（通常是异常名） 最新请求的 LogView 的采样（因为谈不上 Slowest） 可移动的时间轴：调节时间轴会导致统计数据变更 Minutely Distribution 直方图：x 轴分钟分布，y 轴 problem count。 Machine Distribution 饼图：机器和本 Problem 的分布。 Machine Group 饼图：机房和本 Problem 的分布。 如何选择打点 如果要做 profiling，优先选 Transaction。因为带有成功失败和百分位分布。 如果仅看配置或者操作成败，优先选 Event。业务监控首选 Event。 选 Event 的时候，可以在 Type 上做文章，如果一种业务有好几种结果，可以产生好几个 name。但这种情况下，基于不同 Name 的比例做告警很不合适。 如果选一个 Event 的 Type 和 Name 表达一种业务，则只能选一种 status 作为 success，其他 status 为失败。则可以针对这种 status 的比例设置告警。 如果一个业务产出好几个维度的结果，只能只用一个 metric name 配上多个 tag kv 对的解法了。这种解法的缺点是，不容易配置基于 tagValue 这种【可枚举值】的告警。 告警策略设计 可选的主题：Transaction、Event、Problem、Business。 机器：All、或者指定机器 ip、指定正则表达式匹配、枚举若干个机器标签。 指标：qps、请求次数（这里就是单个点的 count 的意思）、失败次数、失败率。有时间的指标还可以看最大耗时、最小耗时、平均耗时、执行总耗时、tp50、tp99、tp999、tp9999。 Type：可以枚举若干个 Type 标签。 Name：All 或者枚举若干个 Name 标签。 GroupBy：All（全集群的意思）、ip、type、name。 图表设计此处专指 Graph，而不是 Show 的基本图表。 任何一个指标都有单独的统一的 name、type、发生时间加上环境指标（机器、机房、单元、线程、traceId），所以总可以做总聚合，也可以下钻以后再局部聚合。 所以总能进行 sum，进而得到时间维度的曲线图，然后可以按照某一个环境维度再聚合出饼图，或者对时间进行聚合得到柱状图。这一层的分布主要是进行统计分析用。 除此之外，图表应该还能提供相关的 legend，让我们提供足够好的洞察。 常见的图表折线图最有用 主轴（y 轴）：单个点的 count/sum/avg/max/min 副轴（右侧 y 轴） 同环比： 周同比有一条折线 日环比有一条折线 饼图 主环、周同比环、日环比环 采样方法：单个点的 count/sum/avg/max/min 排名图纵轴：排名顺序，可以由大到小，也可以由小到大。横轴：采样方法：单个点的 count/sum/avg/max/mintopN：可以定制 N 统计文本 同环比：周同环、日环比 采样方法：单个点的 count/sum/avg/max/min 固定列数：N 漏斗图一层一层 同环比：周同比半梯形、日环比半梯形 采样方法：sum/avg/max/min 排序方法：指标顺序、数值大小 时序表格 第一列：时间 第二列：采样方法：单个点的 count/sum/avg/max/min 大盘大盘是一个监控系统核心可视化模块，是向用户展示度量信息和关键指标现状的工具。Dashboard中文称“仪表盘”或“大盘”，一般由多个图表组成，以满足特定监控主题或场景下，展示整体情况的需求（多个指标数据在时间序列上的展示工具）。 大盘要具有以下特点： 汇总多端数据。 用户个性化定义报表 基础大盘基础的指标关注大盘。 关键步骤： 选择空间和目录（如果有必要就新建）。 新建大盘。 新建指标-新增图表（选择折线图、曲线图等类型）。 选择需要 theme、监控的项目（或者服务 key）、目标指标、显示名称、维度、分组（基础 group by 选项）。 新增子指标以后，可以产生聚合指标大盘（指标经过四则运算可以产生比例指标监控）。 核心大盘从基础大盘相关指标衍生出的大盘。很多公司的核心大盘是由 SRE 配置的。 生成核心指标的过程是一个指标提炼上报的过程： 页面型业务的指标应该访问成功率和 PV。 查询型服务的指标应该是 qps，交易型服务的指标应该是单量（要对单据产生深刻的理解）和金额。 风控型服务的指标应该是拦截率。 供应链型的服务的指标应该是吞吐量。 核心大盘往往可以引入智能告警，智能告警受波动影响，要么限制时间，要么限制阈值。 告警条件 什么指标（count、value） 多少个上报周期（3 分钟、5 分钟、1 小时） 聚合方法（avg、sum、max） 运算符 阈值 条件执行时间 条件间与或非关系 监控系统的缺陷通常 APM 系统因为结构复杂，流量大，能保证 99.9% 的可用性就很不容易了。基于监控发出的 mq 可以做事件驱动架构，实现告警驱动的自动降级。但如果告警 db 有自动清零机制，自动清零的错误可能导致自动降级出巨大故障。"},{"title":"CRM 平台化的思路","date":"2021-05-25T08:56:50.000Z","url":"/2021/05/25/CRM-%E5%B9%B3%E5%8F%B0%E5%8C%96%E7%9A%84%E6%80%9D%E8%B7%AF/","tags":["系统架构"],"content":"从外到内对企业来讲，获客、维护客户关系是很重要。每个企业都有自己的 CRM 平台。 数据建模业务流程划分流程，从流程获得各种域。 通用语言制作数据字典。 划分领域不同的域有不同的实体。 客户管理域 工具管理域 过程管理域 数据策略域 数据模型共性抽象统一，差异元数据扩展支持。 流程逻辑通用设计 抽象核心标准流程 非核心流程异步后处理 适配不同的业务流程 差异 标准流程抽象扩展点。 基于业务/租户的扩展点实现，解耦业务代码。 扩展点注解标识，降低代码侵入。 规则设计规则配置（表达式配置、脚本配置）=因子配置（因子标识、取数方式、入参、返回值定义）+ 关系运算（到底有多少种运算符） + 值域配置（手动配置、接口配置 DSL） 业务身份设计服务端引用业务身份 sdk，通过 sdk 的标准接口进行解耦和扩展。 架构支撑可以考虑业务之间通过单元化/轻量级单元化进行相互隔离，考虑单元内多租户设计。 注意 fallback 到主干上还要留一手 failfast，避免主干被打死。"},{"title":"投资分类","date":"2021-05-25T06:08:50.000Z","url":"/2021/05/25/%E6%8A%95%E8%B5%84%E5%88%86%E7%B1%BB/","tags":["投资"],"content":"分类 股票 债券 期权 期指 股票期权 互惠基金 衍生权证 衍生品认识 "},{"title":"规划结构化","date":"2021-05-24T06:53:51.000Z","url":"/2021/05/24/%E8%A7%84%E5%88%92%E7%BB%93%E6%9E%84%E5%8C%96/","tags":["团队管理"],"content":"基础结构![Long Range Plan.png](Long Range Plan.png)[Long Range Plan.xmind](Long Range Plan.xmind)"},{"title":"操作系统导论 Three Easy Pieces","date":"2021-05-22T03:16:54.000Z","url":"/2021/05/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%BC%E8%AE%BA-Three-Easy-Pieces/","tags":["操作系统"],"content":"前言本书的目的是厘清操作系统的发展脉络。有助于学生了解过去是什么、现在是什么、将来是什么。 无论如何，在试图解决问题时，我们首先要说明最重要的问题是什么。我们在书中明确提出关键问题（crux of the problem），并通过本书其余部分提出的技术、算法和思想来解决。 在许多地方，我们将通过显示一段时间内的行为来解释系统的工作原理。这些时间线（timeline）是理解的本质。例如，从页故障出发，我们可以理解虚拟内存的工作方式。 本书采用最古老的教学方法之一-对话（dialogue）。 我们应当首先呈现抽象，然后介绍具体。抽象是计算机科学各个方面的基础，因此它在操作系统中也是必不可少的。 作业模拟程序具有以下特点，通过提供不同的随机种子，产生近乎无限的问题。 本书使用 xv6 操作系统来编程。 学生很难理解并发问题是如何产生的，也很难理解人们试图解决它的原因。"},{"title":"数据中心","date":"2021-05-20T05:55:56.000Z","url":"/2021/05/20/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83/","tags":["存储","数据"],"content":"如何分层按照在线-离线、对时延的要求，可以把数据存储分为： L0：T+0L1：T+0L2：T+1 其中 L1 是 L0 的穿透防御层，但延时会稍微更高。L0 是 10ms 查询层，不是全量数据。L1 是 100ms 查询层，是全量数据，L0 和 L1 都支持轻度分析操作。 L2 是全量数据，可以支持复杂大型查询。 设计 L 的分层要考虑数据的： 是否全量：数据量大小，这要求我们关注我们技术选型的 scale 能力，特别是数据线性增长以后，性能是否线性增长。 是否全维度：这要求我们关注我们技术选型的 schema 建模能力。 延时要求：这要求我们关注我们技术选型的查询执行模型。 查询复杂程度要求：这需要关注我们的技术选型支持的查询语言。 如何迁移数据数据迁移问题 = 制造新从库问题 + 读写切换的问题 寻找一个时间点，使用备份进行冷启动，然后通过类似 binlog 制造新从库的机制进行追踪（对于 update 和 delete，都可以设置简单的幂等机制，insert 的幂等要防异常）。 框架进行数据校验：主键范围查询，md5 查询。因为数据迁移总是非事务性的最终一致性方案，只能通过校验来确保最终一致性。 业务层自行根据 binlog 事件进行消息驱动的校验。 可以参考《MySQL 与数据迁移》。"},{"title":"ElasticSearch 总结","date":"2021-05-10T07:57:39.000Z","url":"/2021/05/10/ElasticSearch-%E6%80%BB%E7%BB%93/","tags":["JVM","Java","ElasticSearch"],"content":"ES 思维导图ElasticSearch总结.xmind ES 的定位 ES 是 build on top of Lucene 建立的可以集群化部署的搜素引擎。 ES 可以是 document store，可以结构化解决数据仓库存储的问题。在 es 中一切皆对象，使用对象对数据建模可以很好地处理万事万物的关系。 ES 是海量数据的分析工具能够支持：搜索、分析和实时统计。 ES 的架构有优越的地方： 自己使用 pacifica 协议，写入完成就达成共识。 节点对内对外都可以使用 RESTful API（or json over http）来通信，易于调试。 因为它有很多很好的默认值，所以开箱即用。 它天生就是分布式的，可以自己管理多节点。 ES 的架构ES 是基于 Lucene 的，集群上的每个 node 都有一个 Lucene 的实例。而 Lucene 本身是没有 type 的，所以 ES 最终也去掉了 type。 ES 中每个节点自己都能充当其他节点的 proxy，每个节点都可以成为 primary。用户需要设计拓扑的时候只需要关注种子节点和 initial master 即可。 ES 中的搜索全文搜索按照《全文搜索》中的例子，使用 match 总会触发全文搜索。因为在Elasticsearch中，每一个字段的数据都是默认被索引的。也就是说，每个字段专门有一个反向索引用于快速检索。想不要做索引需要对任意的 properties 使用 &quot;index&quot;: &quot;not_analyzed&quot;。 精确（短语）搜索精确查询的方法有： 短语查询： term 查询（这种查询是客户端查询里最常用的）： 另一种 phrase 查询： 精确和不精确查询有好几种方法，详见《elasticsearch 查询（match和term）》 和《finding_exact_values》。 search api 的搜索参考《空查询》。 倒排索引简析倒排索引的 key 是 term，value 是文档的指针，可以参考这个《倒排索引》文档。 过滤机制头机制x-packversion 机制 容量与分片为何分片不宜过大？ 增加索引读压力-不利于并行查询。 不利于集群扩缩容（分片迁移耗费较长时间） 集群发生故障时，恢复时间较长 类似的问题也会发生在 Redis 之类的架构方案里。 解决大分片的方法 索引按月、日进行分割 delete_by_query方法对索引进行缩容 模板增加主分片数量 扩容数据节点 减小单位分片大小 一个可实操的方案： 修改写入逻辑和 mapping，让新写入的 doc 的 field 变少。 对老的索引进行 delete_by_query。 "},{"title":"如何画架构图","date":"2021-05-07T12:39:55.000Z","url":"/2021/05/07/%E5%A6%82%E4%BD%95%E7%94%BB%E6%9E%B6%E6%9E%84%E5%9B%BE/","tags":["系统架构"],"content":"前言 有意义且具备一致性（coherence）的架构图有助于为不同的利益相关者（stakeholder）澄清（illustrate）事实，并达成共识-反之，图表杂乱无章。 有意义的图表胜过建模（建模指的是With modelling, you&#39;re building up a non-visual model of something (e.g. the software architecture of a software system), and then creating different views (e.g. diagrams) on top of that model. ），在架构沟通上，visualization 胜过千言万语。 一致性要求我们有足够好的指导原则，让我们知道标准的图元是什么。 “架构是一项复杂的工作，只使用单个图表来表示架构很容易造成莫名其妙的语义混乱”。 在同一个架构图里添加不同层级的抽象可能会导致冲突的出现，因为它们是从不同的角度描述问题的。 应该在架构图旁边加上图例（legend），沟通者应该懂得图元（key）是什么。key 和 legend 都是一种 explicit notion。 架构图越多就越难以理解，而且维护起来也很费劲。最直接的后果就是有可能出现碎片化（比如，通过两到三个架构图来描述同样的质量属性——性能、伸缩性等等——但每一个架构图都无法完整地描述它们）。在这种情况下，建议移除不能反映相关质量属性的架构图，或者把它们合并起来。 两类架构师规范TOGAFThe Open Group Architecture Framework ArchiMateArchiMate，是一种整合多种架构的一种可视化业务分析模型语言，属于架构描述语言（ADL）它从业务、应用和技术三个层次（Layer），物件、行为和主体三个方面（Aspect）和产品、组织、流程、资讯、资料、应用、技术领域（Domain）来进行描述。ArchiMate是 The Open Group 发布的企业级标准。它是一种图形化描述语言，正好可以作为 TOGAF 图形工件的建模工具。 一个比较好的实现是 Archi，其文档见这里。 C4为什么会有 C4？因为每个团队都有自己的 confused mess of box and lines。 我们当然可以使用 UML 来体现包、组件和其他 stereotypes，但UML 不适合加上描述性文本（descriptive text）。 The C4 model was created as a way to help software development teamsdescribe and communicate software architecture, both during up-frontdesign sessions and when retrospectively documenting an existingcodebase. It’s a way to create maps of your code, at various levels ofdetail, in the same way you would use something like Google Maps tozoom in and out of an area you are interested in. Although primarily aimed at software architects and developers, the C4model provides a way for software development teams to efficiently andeffectively communicate their software architecture, at differentlevels of detail, telling different stories to different types ofaudience, when doing up front design or retrospectively documenting anexisting codebase. The C4 model consists of a hierarchical set of software architecturediagrams for context, containers, components, and code. 创建 C4 模型是为了帮助软件开发团队在前期设计会议和回顾性记录现有代码库时描述和交流软件架构。这是一种创建代码地图的方法，具有不同的详细程度，就像您使用 Google Maps 之类的工具放大和缩小您感兴趣的区域一样。尽管主要针对软件架构师和开发人员，但 C4 模型为软件开发团队提供了一种有效地交流他们的软件架构的方法，在进行前期设计或回顾时，以不同的细节级别，向不同类型的受众讲述不同的故事记录现有的代码库。C4 模型由一组分层的软件架构图组成，用于上下文、容器、组件和代码。 C4 提倡“抽象为先”，由一系列抽象引出架构决策。它的设计模仿了谷歌地图，认为应该通过不同级别的 zoom-in 和 zoom-out 来获取不同层次的信息量。 Context -&gt; Container -&gt; Component -&gt; Code Context 是把价值交付给用户（stakeholder）的最高级抽象。Context 里有多个 System。Container 指的是应用程序或者数据存储（这个词在软件工业里被滥用了）。代码在 Container 的边界里执行，数据在 Container 里存储。一个 Container 图就是把一个 System 展开，看到里面的多个 Container（每个 container 是一个 deployable 或者 runnable unit）。Component 指的是interface 背后被组织起来的一系列相关功能。代码是 Code Elements。 值得注意的是 context 中的图元总共有 5 种，灰色的盒子是已存在系统的意思。 Context Diagram 系统上下文图是绘制和记录软件系统的良好起点，允许您退后一步并查看大图。画一个图表，将您的系统显示为中心的一个盒子，周围是它的用户和与之交互的其他系统。 细节在这里并不重要，因为这是显示系统景观大图的缩小视图。重点应该放在人（演员、角色、画像等）和软件系统上，而不是技术、协议和其他低级细节。这是您可以向非技术人员展示的那种图表。 范围：单个软件系统。 主要元素：范围内的软件系统。支持元素：在范围内直接连接到软件系统的人员（例如用户、参与者、角色或角色）和软件系统（外部依赖项）。通常，这些其他软件系统位于您自己的软件系统的范围或边界之外，您对它们没有责任或所有权。 目标受众：软件开发团队内外的每个人，包括技术人员和非技术人员。 推荐给大多数团队：是的。 Container Diagram 一旦您了解您的系统如何适应整个 IT 环境，下一步非常有用的是使用容器图放大系统边界。 “容器”类似于服务器端 Web应用程序、单页应用程序、桌面应用程序、移动应用程序、数据库架构、文件系统等。本质上，容器是一个可单独运行/可部署的单元（例如一个单独的进程空间)执行代码或存储数据。 容器图显示了软件架构的高级形状以及如何在其中分配职责。它还显示了主要的技术选择以及容器如何相互通信。这是一个简单的、专注于技术的高级图表，对软件开发人员和支持/运营人员都很有用。 范围：单个软件系统。 主要元素：软件系统范围内的容器。支持元素：直接连接到容器的人员和软件系统。 目标受众：软件开发团队内外的技术人员；包括软件架构师、开发人员和运营/支持人员。 推荐给大多数团队：是的。 注意：此图没有说明部署方案、集群、复制、故障转移等。 注意，container 相比 context 是把企业边界内的系统进行了下钻（drill down）。 接下来，您可以进一步放大和分解每个容器，以确定主要的结构构建块及其相互作用。 Component Diagram组件图显示了容器是如何由多个“组件”组成的，每个组件是什么，它们的职责以及技术/实现细节。 范围：单个容器。 主要元素：范围内容器内的组件。支持元素：容器（在范围内的软件系统内）加上直接连接到组件的人员和软件系统。 目标受众：软件架构师和开发人员。 推荐给大多数团队：不，仅在您认为组件图增加价值时才创建组件图，并考虑自动创建长期文档。 Code Diagram 最后，您可以放大每个组件以显示它是如何作为代码实现的；使用 UML 类图、实体关系图或类似的。 这是一个可选的详细级别，通常可以通过 IDE 等工具按需提供。理想情况下，该图将使用工具（例如 IDE 或 UML建模工具）自动生成，您应该考虑仅显示那些允许您讲述想要讲述的故事的属性和方法。除了最重要或最复杂的组件外，不建议将这种详细程度用于任何其他组件。 范围：单个组件。 主要元素：范围内组件的代码元素（例如类、接口、对象、函数、数据库表等）。 目标受众：软件架构师和开发人员。 推荐给大多数团队：不，对于长期存在的文档，大多数 IDE 可以按需生成这种级别的详细信息。 我们画 c4 的视图的时候，重点关注 container 和 component 即可。很多时候我们甚至不需要画出component。 c4 意味着 4 个层次的架构图，自顶向下。 C4 模型没有预定义任何特定的符号，你在这些示例图中看到的是一个个简单的符号，适用于白板、纸张、便签、索引卡片和各种图表工具。你也可以使用 UML 作为符号，并适当使用包、组件和原型。无论你使用哪种符号，我都会建议让每个元素都包含名称、元素类型（即“人”、“软件系统”，“容器”或“组件”）、技术选型（如果有的话），以及一些描述性文字。在图表中包含如此多的文本可能看起来很不寻常，但这些附加文本有助于消除软件架构图中通常会出现的不明确的表示。 图元素里至少要包括：名称、类型、描述和其他属性。线头至少包括：方向、多对多关系、动作（有时候包含宾语）。 System Landscape diagram 系统景观图的特点是，可以总览企业边界内的系统。注意企业边界给我们带来的各个系统的关联。 Dynamic diagram 动态视图让我们看到在一个功能/用例/用户故事视角下，系统的组件和容器之间是如何交互的。画图时，不必拘泥于颗粒度在抽象上层次的统一。 Deployment diagram 部署视图在视觉上突出了 IaaS 和 Paas 的存在，各种 boundaries 本质上就是划定 containers and deployment nodes。 一些友善的建议Diagrams 每个图都应该有一个描述图类型和范围的标题（例如“我的软件系统的系统上下文图”）。 每个图表都应该有一个键/图例来解释所使用的符号（例如形状、颜色、边框样式、线型、箭头等）。 首字母缩略词和缩写词（业务/领域或技术）应为所有受众都能理解，或在图表键/图例中进行解释。 Elements 应明确指定每个元素的类型（例如人员、软件系统、容器或组件）。 每个元素都应该有一个简短的描述，以提供关键职责的“概览”视图。 每个容器和组件都应该有明确指定的技术。 Relationships 每条线都应该代表一种单向关系。 每一行都应该有标签，标签与关系的方向和意图一致（例如依赖或数据流）。尝试使用标签尽可能具体，最好避免使用诸如“使用”之类的单词。 容器之间的关系（通常代表进程间通信）应该有明确标记的技术/协议。 4 + 1 视图![4+1 view of software architecture](4+1 view of software architecture.png)[4+1 view of software architecture.xmind](4+1 view of software architecture.xmind) 漏斗图Plant UMLReal World PlantUMLPlant UML本地使用扩展名 .puml。 使用 Web Server 来绘制自己的 C4 图，相应的 icons。 注意边界： Boundary(alias, label, ?type, ?tags, $link) Enterprise_Boundary(alias, label, ?tags, $link) System_Boundary Container_Boundary(alias, label, ?tags, $link) component 图应该使用这种边界 tags 参考 github 例子，link 是真的让这个图表可以被点击的 link（只在 plantUml 的矢量图上可以点，没什么实际用处），所以这两个 attribute 一般是空白的。 一个风险landscape的例子： 场景分层架构图这种架构图能够表达用例、场景、context、container 和 component，像 landscape view。 场景分层架构图.drawio Runtime 图Runtime图.drawio 数据处理系统 保险架构图 大数据架构图 服务治理架构图 Visual Paradigm 的时序图Sequence Diagram Tutorial DB 架构olap和oltp.drawiodb对比.drawio ELKlog-data-warehouse-arch.drawio 订单系统 内存布局 关于常量池的变化，可以参考：《面试题系列第5篇：JDK的运行时常量池、字符串常量池、静态常量池，还傻傻分不清？》。总而言之，常量池理论上都会被实现在方法区内，但方法区有时候在 JVM的内存区域里，有时候不在。字符串常量池有时候在方法区内实现，有时候在 managed heap 里实现，这些实现都遵循 JVM 规范。"},{"title":"结算问题","date":"2021-04-12T12:23:12.000Z","url":"/2021/04/12/%E7%BB%93%E7%AE%97%E9%97%AE%E9%A2%98/","tags":["金融"],"content":"基本用例 结算 分润 收费 返佣 结算的业务场景支持费用结算、佣金和分润。 尽量在结算周期里实现自动结算，提高资金效率。 有结算平台可以实现结算单据。 100%线上化，支持财务运营线上化，符合监管要求。 规则分类财务平台的规则 计费规则 出账规则 结款规则 逾期规则 结算平台的规则 结算周期 佣金费率 分润费率 内部结算账号 逾期规则 如何设计计费单据按照结算规则，计费事件至少包括（几种佣金率、结算涉及的主体、业务线、相关公司、周期、商品品类、基本事件金额）。 结算规则要包括：周期、费率、账号、预期规则。不同的结算会产生不同的单据： 分润 分佣 各种业务单据：保费、理赔 如果有可能，在一个事务里面生成这些单据，正逆向流程都批量处理。 常见单据： 理赔款单 xxx主体保费单 xxx主体保费单 1 类佣金单 2 类佣金单 分润单 颠覆单 规则规则要可配，可审批，要能够根据时间生效，自动切换。 计费量切换注意按照时间、业务类型进行切换。 工作流程 结算事实获取 规则配置和获取 根据规则拆分计费项（清分计费） 按周期生成结算单：如果需要线上付款，需要确认是否需要审批后发出结算指令，不同的计费项要有不同的汇总维度，汇总出结算单-账单的一种。 在财务运营平台对账审批后打款-这要关注这个单据的这些状态，和使用的。审批可以分不同的流程，还可以打通对账的平台，在对账后再打款。 有必要的话，打款要触发开发票（开发票不一定可逆，这是结算的一个风险点）。 结算 组装基础流水数据 确认是否需要汇总-需要汇总需要在事务里另产生汇总流水。 由下游支付还是本地支付-注意打标。 按照标记确认是否推送下游支付平台。 流水入库-推送和入库实际上是个事务性消息问题，如果没有事务性消息支持，先发送再入库也可以，否则入库可以自己做个任务表驱动发送消息。 一般的结算流水类型 支付 消费-特指出单，也就是出保单 未消费退-特指售中退款 已消费退-特指售后退款 "},{"title":"MySQL 存储引擎- InnoDB 技术内幕","date":"2021-03-28T08:22:25.000Z","url":"/2021/03/28/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E-InnoDB-%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95/","tags":["数据库","MySQL"],"content":"前言MySQL 是处理海量数据（尤其 是OLTP 写入）时仍能获得最佳性能的最佳选择之一，它的 CPU 效率可能其他任何基于磁盘的关系型数据库所不能匹敌的-但它应该能够匹敌 Redis。 Think Different 而不是 Think Differently，这意味着要思考不同的东西，而不只是思考不同的方式。 不要相信网上的传言，去做测试，根据自己的实践做决定。 change buffer 是 inert buffer 的升级版本。 MySQL 体系结构和存储引擎定义数据库和实例 数据库：物理操作系统文件或其他形式文件类型的集合。 实例：操作系统后台进程（线程和一堆共享内存）。 存储引擎：基于表而不是基于库的，所以一个库可以有不同的表使用不同的存储引擎。 InnoDB 将数据存储在逻辑的表空间中，这个表空间就像黑盒一样。 存储引擎不一定需要事务。比如没有 ETL 的操作，单纯的查询操作不需要考虑并发控制问题，不需要产生一致性视图。 NDB 存储引擎是一个集群存储引擎，类似 RAC 集群。不过与 Oracle RAC share everything 不同，NDB share nothing，而且把数据放在内存中。 如果不需要事务，文件系统就可以当做数据库。数据库区别于文件系统的地方就是，数据库可以支持事务（不代表必然使用事务）。 用户可以按照文档 16 章自己写自己的存储引擎。 InnoDB 的存储引擎InnoDB 是 transactional-safe 的 MySQL 存储引擎。 InnoDB 存储引擎概述InnoDB 当前支持每秒 800 次的写入，也可以存储 1tb 以上的数据。 InnoDB 的体系结构可以大体包括： 后台线程 + 内存池 + 文件 后台线程包括master thread负责异步地将缓冲池中的数据异步地刷新到磁盘，dirty page refresh、merging insert buffer。 IO thread在 InnoDB 中大量使用 AIO 来处理 IO 写请求。 purge threadpurge 操作是从 master thread 里单独分离出来的一部分职能，专门处理 undo log。 page cleaner thread定时将之前版本中的 dirty page refresh 的职责分离出来。 内存缓冲池为了弥合 cpu 和磁盘的性能鸿沟，基于磁盘的数据库必然引入内存缓冲池。 主要的内存缓冲池有： innodb_buffer_pool redo_log_buffer innodb_additional_mem_pool_size 有了内存缓冲池，就允许出现脏页。把脏页刷新到磁盘上，是通过 checkpoint 机制实现的。 LRU list、free list 和 Flush listinnodb 使用这三种 list，来调度不同的脏页。 所有的数据页，调度进内存，都要调度进 lru list 里（调度进某个 midpoint）。所以，有时候查询数据会导致新页加载进内存，脏页刷盘，引发 checkpoint。 redo log buffer这个 buffer 是 wal 写入磁盘之前的 buffer。注意 wal 的 buffer 刷新到磁盘，不是脏页的刷新到磁盘（checkpoint 实际上就是 dirty page refresh）。 通常情况下，每一秒钟这个 buffer 会被刷新到磁盘上（通过 page cleaner thread），只要用户每秒产生的事务量在这个缓冲大小之内即可。 总共有三种情况下会发生内容刷新： 一秒定时 事务提交 buffer 的大小小于 1/2时 这代表了三种策略： 时间 空间阈值 持久化事件 additional mem pool管理一些 buffer controll block。 checkpoint 技术checkpoint 保证，在灾难恢复时，过了 checkpoint 的 redo 日志才需要关注。这样可以减少宕机恢复时间。 重做日志不可能无限被使用，所以一旦要重用重做日志，必然带来强制的 checkpoint，导致脏页至少被刷新到 redolog 当前的位置。 标记 redolog 的位置方法是 LSN（log sequence number）。 有以下几种情况会触发 checkpoint： Master Thread 定时刷新脏页 LRU 脏页列表大小不够 redo log 大小不够 脏页数量太多 innodb 关键特性insert bufferInsert Buffer 既是内存缓冲池的一部分，也是物理页的一部分。 对于非唯一的辅助索引，为了减少随机插入，InnoDB 在插入更新数据页的时候，会想办法校验缓冲池里有没有该数据页。如果有，则先处理缓冲池里的数据；否则，在插入缓冲里插入一页，欺骗（mock）全流程，然后继续剩下的 buffer pool 操作。 change bufferchange buffer 可以缓冲 dml 了，insert、delete 和 purge 都可以缓冲。 insert buffer 的实现全局有一个 insert buffer b+树，存放在 ibdata 中。 非唯一的辅助索引在插入到数据库中时，会构造一条记录，然后插入到这棵树中。当读写发生的是，只要需要读最终数据，都要触发 merging。这种索引的性能提升借助于不做唯一性检查。 doublewrite写入一个数据页不一定能够原子成功。有可能发生部分写失效（partial page write）。因为 redo log 是物理日志，所以强依赖于页的状态。 doublewrite 的意思是，重做发生时，需要先把页副本还原出特定的页，然后再 apply redo log。 innodb 在刷新脏页时，会先写入 double write buffer，然后双写到表空间里的 double write extent 里，最后再用 fsync 把脏页刷新到 ibd 数据文件里。 自适应哈希索引innodb 会自动根据访问的频率和模式来自动地某些热点页建立哈希索引。 异步 ionative aio 需要操作系统的支持。 刷新邻接页（flush neighbor page）机械硬盘需要这个功能，固态硬盘不怎么需要。 启动、关闭与恢复默认的情况下，MySQL 会在关闭和重启时，把脏页刷新回磁盘。所以有时候 MySQL 重启的速度可能非常慢。 文件现在默认的 binlog 格式是 row。 redolog 使用的是 ib_logfile1、ib_logfile2，循环使用。 表tablespace 下分为 段 segment、区 extent 和页 page。 默认的行格式是 compact。 锁注意意向锁之间的兼容性。 事务redo 保证持久性。它的地址空间需要用来重用。 undo 保证原子性和 mvcc。它的地址空间需要被 purge 线程消除。"},{"title":"数据库容灾体系的演变","date":"2021-03-24T11:21:00.000Z","url":"/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%B9%E7%81%BE%E4%BD%93%E7%B3%BB%E7%9A%84%E6%BC%94%E5%8F%98/","tags":["数据库"],"content":"什么是容灾 备份的分类 备份方式 说明 逻辑备份 数据库对象级备份，备份内容是表、索引、存储过程等数据库对象，如MySQL mysqldump、Oracle exp/imp。 物理备份 数据库文件级备份，备份内容是操作系统上数据库文件，如MySQL XtraBackup、Oracle RMAN。 快照备份 基于快照技术获取指定数据集合的一个完全可用拷贝，随后可以选择仅在本机上维护快照，或者对快照进行数据跨机备份，如文件系统Veritas File System，卷管理器Linux LVM，存储子系统NetApp NAS。 规划要结合业务，产生多维立体的解决方案。"},{"title":"从美元周期看大国经济战","date":"2021-03-18T11:57:18.000Z","url":"/2021/03/18/%E4%BB%8E%E7%BE%8E%E5%85%83%E5%91%A8%E6%9C%9F%E7%9C%8B%E5%A4%A7%E5%9B%BD%E7%BB%8F%E6%B5%8E%E6%88%98/","tags":["经济"],"content":"FROM：   一个新的世界秩序通常在国家内部（通过革命）和国家之间（通过战争）发生根本变化之后开始。通常在爆发战争（热战）之前，通常会有一场经济战争。 严重的经济衰退、巨大的贫富差距、巨额债务以及无效的货币政策，构成了一种易燃的组合，通常会导致国家内部的重大冲突和革命性变革。 在大冲突时期有一种趋势，即走向更专制的领导，导致原有世界秩序混乱。 典型的萧条期现象 专制、民粹主义和民族主义：在经济极度紧张的时期，转向更加专制、民粹主义和民族主义的领导人和政策是很典型的，因为人们希望强有力的领导能给混乱带来秩序，并强有力地对付外部敌人。 扩张的货币政策：通货紧缩或者萧条是由于债务人手中没有足够的钱来偿还债务而导致的危机。这不可避免地导致印钞、债务重组以及增加货币和信贷供应、降低货币和信贷价值。 大规模财富再分配：在严重的经济困境和巨大的财富差距时期，通常会有革命性的大规模财富再分配。如果和平进行，这些目标可以通过对富人大幅增税和大幅增加货币供应量(这会使债务人的债权贬值)来实现，如果是暴力进行，则可以通过强制没收资产来实现。 最常见的经济战术 资产冻结/扣押：防止敌人/竞争对手使用或出售他们所依赖的外国资产。这些措施的范围可以从对目标群体的国家资产冻结，到更严重的措施（如单方面不偿还债务或直接没收一个国家的资产）。 阻碍资本市场准入：阻止一个国家进入自己或其他国家的资本市场。 禁运/封锁：为了削弱目标国家或阻止其获得必需品，或阻止目标国家向其他国家出口从而切断其收入。 01 1930至1939/41：经济战争世界秩序更迭的规律 在爆发战争之前，通常会有一场经济战争。 严重的经济衰退、巨大的贫富差距、巨额债务以及无效的货币政策，构成了一种易燃的组合，通常会导致国家内部的重大冲突和革命性变革。 在大冲突时期有一种趋势，即走向更专制的领导，导致秩序的混乱。 Dalio称，美国和中国现在正处于一场经济战争，很可能会演变成一场热战，将上世纪30年代（二战期间）与当今进行比较（尤其是在经济制裁方面），可以更好的理解当前的经济战争。 经济战争开始于热战的10年前。大萧条给几乎所有国家都带来了经济灾难，导致国家内部和国家之间争夺财富的斗争，并导致十年后的热战。 当美联储在1929年收紧货币政策以抑制投机时，泡沫破裂，全球大萧条开始。 美国的债务问题对美国银行来说是毁灭性的，它们减少了在世界各地放贷，伤害了国际借款者。与此同时，大萧条造成了需求疲软，导致美国进口和其他国家对美国出口的崩溃。随着收入的减少，在自我强化的经济下行螺旋中出现了更多的信贷问题。与此同时，美国转向保护主义以保护就业，于是在1930年提高了关税(通过《斯穆特-霍利关税法》)，这进一步恶化了其他国家的经济状况。 在经济不景气时期，转向保护主义和提高关税以保护国内企业和就业是很常见的。提高关税虽然会导致效率降低、出口疲软，然而，这确实有利于那些受关税保护的实体，并可以为征收关税的领导人创造政治支持。 当大萧条开始时，德国、日本、苏联和中国已经在受苦了。 德国在第一次世界大战的债务和外国军队占领莱茵兰地区的沉重负担下挣扎。 日本在1927年经历了一场经典的大债务危机，随后在1930-31年经历了严重的经济萧条，然后是典型的大规模货币贬值、财政刺激和债务货币化，这些都几乎摧毁了日本的金融财富。 苏联经历了1917-22年的革命和内战，败给了德国，一场代价高昂的波兰战争，1921年的饥荒，以及整个1930年代的政治清洗和经济困难。 中国在1928-30年经历了内战、贫困和饥荒。 因此，当1930年情况恶化时，这些国家的糟糕状况变成了令人绝望的状况，引发了随后的经济和军事冲突。 更糟糕的是，美国和苏联很快也发生了旱灾。苏联的干旱/饥荒，加上极端的政府政策，造成了数百万人死亡。自然灾害(例如，干旱、洪水和灾害)常常导致严重的经济困难，再加上其他不利条件，就会导致严重的冲突。 典型的萧条期现象 专制、民粹主义和民族主义：在经济极度紧张的时期，转向更加专制、民粹主义和民族主义的领导人和政策是很典型的，因为人们希望强有力的领导能给混乱带来秩序，并强有力地对付外部敌人。 扩张的货币政策：通货紧缩或者萧条是由于债务人手中没有足够的钱来偿还债务而导致的危机。这不可避免地导致印钞、债务重组以及增加货币和信贷供应、降低货币和信贷价值。唯一的问题是，政府官员要多长时间才能采取这一行动。 以大萧条为例，从1929年10月的顶峰到1933年3月罗斯福采取行动。从那时起，直到1936年底——这一年美联储收紧了货币政策导致了1937-38年的衰退——股市恢复了200%以上，经济以大约9%的平均实际速度增长！ 大规模财富再分配：在严重的经济困境和巨大的财富差距时期，通常会有革命性的大规模财富再分配。如果和平进行，这些目标可以通过对富人大幅增税和大幅增加货币供应量(这会使债务人的债权贬值)来实现，如果是暴力进行，则可以通过强制没收资产来实现。 在1932年的美国总统选举中，富兰克林·D·罗斯福(Franklin D.Roosevelt)当选，许多人认为他是左翼的民粹主义者。1933年3月/4月就职后，他立即违背将美元兑换成黄金的承诺，向所有银行提供资金以便储户可以取钱，允许所有价值大于100美元的黄金以每盎司$20.67的价格换成纸钞，并使美元相对于其他货币贬值。还有一些大的财政支出计划导致巨额预算赤字和巨额债务，这些债务是美联储印钞购买的。 在罗斯福执政的头100天里，他创造了一系列庞大的政府支出计划，这些计划都是通过大幅增税和巨额预算赤字来支付的，这些赤字是由美联储货币化的债务提供的。他提供了就业计划、失业保险、社会保障支持以及有利于劳工和工会的项目。在他1935年的税单（当时被广泛称为“富人税”）之后，针对个人的最高边际所得税税率升至75%(而在1930年仅为25%)。到1941年，最高个人税率为81%，最高公司税为31%，他还征收了一些其他的税。尽管提高税率和经济好转也帮助提高了税收收入，但预算赤字却从GDP的1%左右上升到GDP的4%左右，因为支出的增长过大。 1936年至1937年，美联储收紧了货币和信贷，以对抗通胀，减缓过热的经济，导致脆弱的美国经济陷入衰退，其他主要经济体也随之走弱，进一步加剧了国家内部和国家之间的紧张关系。 事实上，1940年11月，罗斯福第三次连任是因为他承诺让美国置身战争之外，尽管美国已经采取行动保护自己的利益，尤其是在太平洋地区的利益。尽管如此，美国还是开始对它同情的国家给予经济支持，对它不同情的国家实行经济制裁。早在1940年，美国战争部长史汀生(HenryStimson)就对日本实施了积极的经济制裁，并最终通过了1940年的《出口管制法》(Export Control Act of1940)。1940年年中，美国将太平洋舰队迁至夏威夷。10月，美国加大了禁运力度，限制“所有钢铁运往英国和西半球国家以外的目的地”。他们的计划是切断日本所需的资源，以迫使日本屈服，并迫使日本从他们占领的大部分地区撤退。 在1941年3月，美国仍希望避免战争，国会通过了《租借法案》，允许它贷款或租赁战争物资给其他国家。这对美国在地缘政治和经济上都是有利的，因为美国向其在战争中青睐的国家出售武器、食品和其他物品，赚了很多钱。这些即将结盟的国家在发动战争时无法生产核武器，而且他们(最重要的是英国)的资金耗尽(也就是说，他们在制造核武器的过程中遇到了困难)。因此，美国决定给予更多支持，并将付款推迟到战后(在某些情况下完全避免付款)。租借政策，虽然不是一个直接宣战，但它结束了美国的中立。 与此同时，在德国，希特勒继续推行民族主义政策，拒绝向债权国支付赔款债务。他还退出了国际联盟(League ofNations)，并在1934年实行独裁统治。通过兼任总理和总统的职位，他成为了德国的最高领导人。 第一次世界大战之后，德国曾背负着巨额赔款债务。1929年，德国开始通过“青年计划”(YoungPlan)摆脱这些债务的束缚。然而，全球大萧条重创了德国，导致25%的失业率、大量破产和广泛的贫困。典型例子是，左翼民粹主义者(共产主义者)和右翼民粹主义者(法西斯主义者)之间的斗争出现了。为了应对内部斗争和恢复秩序，希特勒于1933年1月被任命为总理，他的纳粹党得到了害怕共产党的实业家的大力支持。两个月后，纳粹党赢得了最多的支持和席位。 在民主国家，总是有一些法律允许国家领导人攫取特殊权力。他援引“第48条”终止了许多公民权利，镇压来自共产党的政治反对，并迫使通过了“授权法案”，该法案允许他在没有议会和总统批准的情况下通过法律。他推行“雅利安人种族”的独裁统治，对任何反对派都毫不留情。在德国，他控制或审查了报纸和广播公司，创建了秘密警察部队（盖世太保）来搜寻和打击所有的反对派，剥夺犹太人的所有公民权，控制新教教会的财政，逮捕反对他的教会官员。 希特勒也采取了同样的独裁/法西斯主义的方法来建设经济，同时还实施了大规模的财政和货币刺激计划。为了创造一个强大的经济，希特勒迅速将国有企业私有化，并鼓励通过借贷来进行企业投资。 他大力支持提高人民的生活水平。例如，他创立了大众汽车，让大多数人买得起汽车，他还指导了高速公路的建设。他迫使银行购买政府债券，从而为大幅增加的政府支出提供资金。所产生的债务通过公司盈利和央行(德国国家银行)的债务货币化来偿还。 这些政策总体上很有效。这个例子说明，用自己的货币借款，增加自己的债务和赤字，如果把借来的钱投入到提高生产力的投资中，从而产生足够的现金流来偿还债务，即使它不能100%偿还债务，在实现国家的经济目标方面，它也是非常划算的。 至于这些政策的经济影响，希特勒1933年上台时，失业率是25%，到1938年降到零。在他上台的五年后，即1938年，人均收入增长了22%，而在1934年至1938年期间，年均实际增长率超过了8%。如下图所示，德国股市在1933年至1938年间稳步上涨了近70%，直到热战爆发。 与此同时，在德国，希特勒继续推行民族主义政策，拒绝向债权国支付赔款债务。他还退出了国际联盟(League ofNations)，并在1934年实行独裁统治。通过兼任总理和总统的职位，他成为了德国的最高领导人。 第一次世界大战之后，德国曾背负着巨额赔款债务。1929年，德国开始通过“青年计划”(YoungPlan)摆脱这些债务的束缚。然而，全球大萧条重创了德国，导致25%的失业率、大量破产和广泛的贫困。典型例子是，左翼民粹主义者(共产主义者)和右翼民粹主义者(法西斯主义者)之间的斗争出现了。为了应对内部斗争和恢复秩序，希特勒于1933年1月被任命为总理，他的纳粹党得到了害怕共产党的实业家的大力支持。两个月后，纳粹党赢得了最多的支持和席位。 在民主国家，总是有一些法律允许国家领导人攫取特殊权力。他援引“第48条”终止了许多公民权利，镇压来自共产党的政治反对，并迫使通过了“授权法案”，该法案允许他在没有议会和总统批准的情况下通过法律。他推行“雅利安人种族”的独裁统治，对任何反对派都毫不留情。在德国，他控制或审查了报纸和广播公司，创建了秘密警察部队（盖世太保）来搜寻和打击所有的反对派，剥夺犹太人的所有公民权，控制新教教会的财政，逮捕反对他的教会官员。 希特勒也采取了同样的独裁/法西斯主义的方法来建设经济，同时还实施了大规模的财政和货币刺激计划。为了创造一个强大的经济，希特勒迅速将国有企业私有化，并鼓励通过借贷来进行企业投资。 他大力支持提高人民的生活水平。例如，他创立了大众汽车，让大多数人买得起汽车，他还指导了高速公路的建设。他迫使银行购买政府债券，从而为大幅增加的政府支出提供资金。所产生的债务通过公司盈利和央行(德国国家银行)的债务货币化来偿还。 这些政策总体上很有效。这个例子说明，用自己的货币借款，增加自己的债务和赤字，如果把借来的钱投入到提高生产力的投资中，从而产生足够的现金流来偿还债务，即使它不能100%偿还债务，在实现国家的经济目标方面，它也是非常划算的。 至于这些政策的经济影响，希特勒1933年上台时，失业率是25%，到1938年降到零。在他上台的五年后，即1938年，人均收入增长了22%，而在1934年至1938年期间，年均实际增长率超过了8%。如下图所示，德国股市在1933年至1938年间稳步上涨了近70%，直到热战爆发。 和德国一样，日本也在大萧条中遭受了格外沉重的打击，并因此变得更加专制。 日本在大萧条中尤其脆弱，因为作为一个没有足够自然资源的岛国，它依靠出口来获得收入，进口必需品。当它的出口在1929年到1931年间下降了大约50%时，它的经济遭到了重创。 1931年，日本经济大萧条严重到整个国家都崩溃了，它被迫减少黄金储备，放弃金本位，并让其汇率自由浮动，这使得日元大幅贬值，导致日本的购买力耗尽。 这些糟糕的状况和巨大的贫富差距导致了左翼和右翼之间的斗争。1932年，右翼民族主义和军国主义大规模增加，强力恢复秩序，恢复经济稳定。为此，日本军队掌握了控制权，并采取军事手段从其他国家夺取日本所需的资源。日本在1931年入侵满洲，后来扩张到中国和亚洲，以获取自然资源(如石油、铁、煤、橡胶)和人力资源。 就像德国的情况一样，可以认为这种通过军事侵略获取所需资源的途径是日本的最佳途径，因为依靠传统的贸易和经济手段无法得到他们需要的东西。 1934年，日本部分地区发生严重饥荒，政治动荡加剧，右翼军国主义、民族主义和扩张主义运动进一步加强。 在接下来的几年里，自上而下的法西斯主义指挥经济的发展，逐渐强大起来，建立了军事工业联合体，动用军队来保护其在东亚和中国北部的现有基地并向其他地区扩张。与德国的情况一样，在这段时间里，虽然大多数日本公司仍不属于政府所有，但它们的生产由政府控制。 最常见的经济战术 资产冻结/扣押：防止敌人/竞争对手使用或出售他们所依赖的外国资产。这些措施的范围可以从对目标群体的国家资产冻结，如当前美国制裁伊朗革命卫队或二战时美国对日本的资产冻结，到更严重的措施，如单方面不偿还债务或直接没收一个国家的资产（一些美国高层决策者现在正讨论不偿还对中国的债务）。 阻碍资本市场准入：阻止一个国家进入自己或其他国家的资本市场，例如，1887年德国禁止购买俄罗斯证券和债券，以阻碍俄罗斯的军事建设，现在美国对中国发出同样的威胁。 禁运/封锁：为了削弱目标国家或阻止其获得必需品，如美国对日本的石油禁运和禁止其通过巴拿马运河，或阻止目标国家向其他国家出口从而切断其收入，如法国在拿破仑战争中对英国的封锁。 02 1939/41至1945：热战热战中的未知数太多： 第一，因为敌对国家只有在它们的实力大致相当的情况下才会发动战争，因为明显较弱的国家发动战争是愚蠢的自杀行为； 第二，因为战争的可能性太多，聪明的领导者通常只有在别无选择的情况下才会卷入热战。 当国家弱小时，对立的国家会利用他们的弱点来获取利益。当时，欧洲盟国(法国、荷兰、英国)在亚洲都有殖民地，在欧洲的战争使它们不堪重负，因此它们无法保护这些殖民地不受日本的接管。从1940年9月开始，日本为了获得更多的资源，利用欧洲对其大陆战争的关注，入侵了几个东南亚殖民地，首先是法属印度支那。1941年，日本通过夺取荷属东印度群岛的石油储备，将“南部资源区”纳入其“大东亚共荣圈”。“南部资源区是东南亚的欧洲殖民地的集合，征服他们将使日本获得关键的自然资源(最重要的是石油、橡胶和大米)。大东亚共荣圈是由日本控制的亚洲国家集团。自此德国和日本法西斯政府蒸蒸日上。 与此同时，日本的领土扩张对美国自身的太平洋野心构成了威胁，并继续加剧了与日本的紧张关系。1941年7月和8月，罗斯福作出回应，下令冻结日本在美国的所有资产，不允许日本通过巴拿马运河，并禁止向日本出口石油和天然气。这切断了该国四分之三的贸易和80%的石油供给。预计日本将在两年内耗尽石油。这使得日本不得不在退让和进攻之间做出选择。 1940年，在欧洲战争开始后至美国加入战争前，德国和日本一样，看起来势不可挡，德国占领了丹麦、挪威、荷兰、比利时、卢森堡和法国，并与有共同敌人且意识形态一致的日本和意大利结成了更强大的联盟。通过迅速占领领土，希特勒的军队得以保存石油并迅速获得资源(例如，通过吞并罗马尼亚获得石油)。德国对自然资源的渴求仍然是纳粹向俄罗斯和中东发动战争的主要动力。德国对西欧的征服使这两个意识形态上对立的大国走上了冲突的道路，与共产主义苏联的战争是不可避免的。1941年6月，德国入侵俄罗斯，这使德国陷入一场对西欧和苏俄双方都代价高昂的战争。 珍珠港事件后，美国加入欧洲和太平洋战争，大多数国家实行的是经典的战时经济政策，领导人变得更加专制，其专制方式得到了反对邪恶敌人的民众的广泛支持。 经典的战时经济政策经典的战时经济政策包括政府对几乎所有事物的控制，比如国家将资源的使用从盈利转向战争制造。政府决定了： 什么物品被允许生产， 什么物品可以以何种数量(定量配给)被买卖， 什么物品可以进出口， 价格、工资和利润， 获得金融资产的机会， 把钱转移到国外的能力， 政府发行大量货币化的债务， 依靠非信贷货币，如黄金进行国际交易， 政府更加专制， 对敌人施加各种经济制裁，包括切断他们获得资本的途径， 对敌人施加这些制裁。 下表显示了在战争年代在每个主要国家实施的经济控制，以及战时各国对市场和资本流动的控制。 战时的资本市场在许多国家，股市关闭是常见现象，导致股票投资者无法获得资金。因为战争的失败通常会导致财富和权力的完全丧失，那些在战争年代保持开放的股票市场的变动，很大程度上是由国家在关键战役中的表现所驱动的。 例如，二战伊始，德国占领了领土并确立了军事统治地位，德国股市表现优于其他国家，而在美国和英国等盟军扭转战局后，德国股市表现不佳。1942年中途岛战役(Battle of Midway)之后，盟军的股票几乎持续上涨，直到战争结束，而轴心国的股票则持平或下跌。 如图所示，德国和日本的股票市场在战争结束后都关闭了，大约有五年没有重新开放，而美国股市却异常强劲。 在战争时期保护自己的财富是困难的，因为正常的经济活动受到限制，传统上安全的投资不安全，资本流动性有限，当人民和国家为生存而战时征收高额税收。在冲突的困难时期，保护那些拥有财富的人的财富，相对于重新分配财富、把财富送到最需要的地方，并不是优先事项。 战争是代价极其高昂的财富和权力转移的手段战争年代就是如此。 1945年盟军的胜利带来了巨大的财富和权力转移。 第二次世界大战是一场在生命和金钱方面代价极其高昂的战争。这些数字是巨大的，而且极其不精确。 据估计，有4000-7500万人因此丧生，占世界人口的3%，这是迄今为止最致命的战争。其中超过一半的死亡来自俄罗斯(约2500万)和中国(约2000万)。德国的死亡人数约为700万人，其中一半以上是军人，剩下的是平民，其中大部分是大屠杀造成的(还有数百万的非德国人也是受害者)。英国和美国各自损失了约40万人。 根据大多数专家的说法，这场战争的财政成本是巨大且不可估量的。根据Dalio的研究，以当前美元计算，大约在4-7万亿美元左右。 之后，Dalio将探讨以美国为主导力量的新世界秩序，并在之后将视角转向中国。 之后，Dalio将探讨以美国为主导力量的新世界秩序，并在之后将视角转向中国。 03 1945年至今的新世界秩序正如战后的典型情况一样，第二次世界大战最重要的战胜国——美国，英国和苏联（当时称为“三巨头”）召开了会议，以建立新的世界秩序，其中包括全球势力范围的划分和建立新的货币信贷体系。 尽管法国、中国和其他几个国家技术层面上和这些战胜国平起平坐，但它们不是主要的参与者。 由于德国，日本和意大利在战争中被打败和破坏，它们既不是领导国也不是独立大国，从属于美国并与美国保持一致。 本质上已经破产的英国也与美国结盟。 苏联作为不与美国结盟的主要竞争对手，与自己的盟友组成了自己的阵营。 战后两个阵营之间虽然有相对良好的合作，但不久之后世界就被美国领导的资本主义/民主阵营和苏联控制的共产主义/专制阵营划分开来，各自拥有自己的货币/经济体系，尽管少数不重要的国家不结盟。 下图显示了战后以来美国，英国，俄罗斯和中国的综合国力指数，传达了这一总体情况。 现在，我们将更深入地研究这个故事。 战后地缘政治与军事体系三大强国和其他大国在一起召开了多次会议，雅尔塔会议，波茨坦会议和布雷顿森林会议是最著名的几次会议，世界因此被分为以美国控制的资本主义/民主国家和苏联控制共产主义/专制主义两大阵营，每个阵营都有自己的货币体系。 从意识形态上讲，以美国为首的世界信奉资本主义和民主主义，而以苏联为首的世界信奉共产主义和专制主义。美国主导的国家的美国主导的货币体系将美元与黄金挂钩，其他大多数国家的货币与美元挂钩。40多个国家采用了该系统。由于当时美国拥有全球约三分之二的黄金，并且由于美国在经济和军事上比任何其他国家都强大得多，因此这种货币体系运作得最好，一直持续到现在。苏联和那些被带入苏联集团的国家的富裕程度则要低得多，其基础也薄得多。 这种分裂一开始就显现了。杜鲁门总统在1947年3月的演讲中概述了现在称为“杜鲁门主义”的内容： “在世界历史的当下，几乎每个国家都必须在不同的生活方式之间做出选择。选择往往不是没有代价的。 一种生活方式以多数人的意志为基础，其特征是自由机构，代议制政府，自由选举，对个人自由的保障，言论和宗教自由以及不受政治压迫的自由。 第二种生活方式是基于少数人强加于多数人的意愿。它依靠恐怖和压迫，受控的新闻和广播，固定的选举以及对人身自由的压制。 我认为，支持那些反抗少数武装上层集团和外部压力蓄意压迫的自由人民必须成为美国的政策。 国际关系的管理与国家内部的治理差距甚远。这是因为在国家内部存在着规范行为的法律和行为标准，而在国家之间，原始力量最为重要，而法律，规则，甚至是国际商定的条约和仲裁组织，例如国际联盟，联合国和世界贸易组织，实际上并无多大的意义。国际事务的运作就像在一个适者生存的丛林中，几乎所有事情都会发生。这就是使一支强大的军队如此重要的原因。 军事联盟是沿着相同的思想和地缘政治思路建立的。1949年，由12个军事同盟国组成了北大西洋公约组织（NATO）。1954年，美国，英国，澳大利亚，法国，新西兰，菲律宾，泰国和巴基斯坦建立了东南亚条约组织，以防止共产主义在东南亚传播。1955年，苏联阵营的七个军事盟国成立了《华沙条约》。 如下图所示，美苏及其追随者为制造核武器投入了大量资金。由于拥有互相摧毁的威慑力，这些武器从未被使用过，但有几次接近被使用的边缘（例如1962年的古巴导弹危机）。如今，有11个国家拥有不同数量和不同程度的核能力，或者即将拥有核武器。拥有核武器显然是世界权力游戏中的一个重要谈判筹码，因此可以理解为什么某些国家想要拥有核武器而其他国家却不想其他国家拥有核武器。 当然，自冷战以来，军事力量不仅包含核武器，而且发生了许多变化。现在的情况如何？虽然我不是军事专家，但通过一些交谈使我确信，尽管美国总体上仍然是最强大的军事强国，但它并非在世界所有地区都处于绝对优势，来自其它地区的挑战正在升级。有人告诉我，如果美国在中俄的地理势力范围内与其发生冲突，美国大概率会输，或者至少会收到难以承受的损失，而且可能个别二线国家也会给美国造成难以接受的损失。现在已经不是1945年后世界秩序开始时美国军力独步天下的美好时光。尽管当前有很多高风险点，但最令人担忧的风险点是中国强行采取行动控制台湾。 下一场军事冲突是什么样的？显然，随着新技术的运用，未来的战争和过去的战争将会截然不同，同样，离我们越近的战争所运用的技术也与之前不一样。传统上，赢得战争的国家在支出、投入方面远超对手。因为在军事上的花费使政府抽走了本可用于社会福利项目上的资金，并且由于军事技术与私营部门技术齐头并进，所以大国的最大风险是它们输掉经济和技术竞赛。 战后货币和经济体系不管是过去还是现在，国家之间的货币和交易与国家内部的货币和交易有很大不同。这是因为在国家内部，政府可以控制货币和交易的关键要素（例如，使用了什么货币，有多少货币，它的成本是多少，由谁处理以及如何使用等），而在国家之间的交易中金钱和交易的关键要素必须达成共识。在国家之间，只有那些进行交易的人都认可的货币才可以被接受。这就是为什么黄金和储备货币在国家间交易中如此重要，而国家内部，人们通常用本国发行的纸币与其他人进行交换，他们并没有意识到本国货币在国外价值不高的事实。 在国家内部，个人不得拥有和交易黄金，因为政府希望能够控制货币供应和货币价值以及人们的财富分配。民众拥有黄金可能会威胁到该系统，因为黄金是一种替代货币，不受政府控制，民众可以用它代替政府的金钱。 至于战后新的特殊货币和经济体系，有一个是美国领导的阵营，一个是苏联领导的阵营。 《布雷顿森林协定》使美元成为世界主要的储备货币。这很自然，因为两次世界大战使美国成为迄今为止最富有，最强大的国家，它通过大量出口获得了这笔资本。相比之下，其他国家基本破产，这使得他们很难从美国和其他国家购买他们需要的东西。 为了解决共产主义的蔓延，美国向西欧和日本提供了大规模的一揽子援助计划（称为“马歇尔计划”和“道奇计划”），这些计划 对于遭受重创的国家有利； 经济上对美国有利，因为这些国家用这些钱购买了美国商品； 有利于美国在海外的地缘政治影响力； 有利于加强美元作为世界主要储备货币的地位，因为它们增加了对美元的使用。 历史上所有主要的中央银行都在延续这种进程。最近，中国的“一带一路”倡议为中国提供了类似的优势。 至于货币政策，从1933年到1951年，货币数量，货币成本（即利率）以及货币去向由美联储（Federal Reserve）控制，以服务该国的更大的战略目标，而不是让自由市场分配货币和信贷。更具体地说，它印刷了很多钱来购买债务，设定了放贷人可以收取的利率上限，并控制了允许放什么钱，所以高通胀并没有将利率推高到无法接受的高度，并且人们发现，没有什么投资比购买政府债券更有吸引力（政府希望通过发债吸收公众的储蓄）。 战后短暂的衰退是由于政府的战争支出减少而引起的，由于新的相互促进的大周期的到来，美国进入了长期和平与繁荣的时期。最重要的是，新的债务周期始于新的货币体系，财富和价值的差距缩小了，因此这是一个追求和平和繁荣的大环境，一个不可逆转的主流趋势。另外，股票价格非常便宜。结果就是，美国的经济和市场在未来很多年都非常强劲。 失业率：在1945年中期至1947年中期的战后调整时期，有超过2,000万人从武装部队和相关工作中解雇，因此失业率从1.9％上升至3.9％。营利活动重新出现，这增加了对劳动力的需求，因此就业非常旺盛。 消费：同时，之前挤压的需求和积累的储蓄在战时配给法（限制人们购买消费品的能力）取消后，点燃了消费者的购买热情。 投资：退伍军人还可以使用廉价抵押贷款，这导致了住房繁荣，从而推动了扩张。从1945年到1970年代，美国私营部门也走向全球并进行了海外投资。 出口：出口强劲是因为美国政府通过马歇尔计划和道奇计划帮助建立了美国在海外的商品市场。 资本市场：这种环境对商业，利润和股票都很有利，因为战后美国公司的获利极高，而股票相对于债券而言却非常便宜（例如，股票收益和股息收益率远高于债券收益率）。股票之所以便宜，是因为经历了萧条和战争年代的那些人非常厌恶风险，因此，他们明显偏爱安全的收入来源而不是风险。这一系列条件创造了数十年来的繁荣和牛市，这增强了纽约作为世界金融中心的主导地位，带来了更多的投资并进一步增强了美元作为储备货币的地位。 教育：这种和平与繁荣也为改善教育，发明出惊人惊讶的技术（例如登月）和实现更多的事情提供了资金。换句话说，战后美国正处于相互扶持和自我强化的循环的上升期。 在整个繁荣的1960年代，美国的典型行为使世界变得更加美元化。美国银行向全球提供的美元贷款蓬勃发展。但同之前一样，a）这是通过不明智的经营造成的过度繁荣，而b）全球竞争，尤其是来自德国和日本的竞争加剧。结果，美国人的贷款和财务状况开始恶化，同时贸易顺差消失了。 20世纪60年代末，布雷顿森林货币体系的终结1945年以后，外国央行可以选择持有付息债券或无付息的黄金。以美元计价的债务和黄金一样好，可以转换成黄金，并且更高回报，因为它提供利息（黄金不能提供利息）。从1945年到1971年，各国央行相对于美元计价的债务而言都减少了黄金持有量。 正如在第二章“不断变化的货币价值”附录中所解释的那样，投资者做出这样的举动是一种典型行为，并且在 对真实货币（比如黄金）的索取权数量远远超过真实货币的数量，和 人们看到，在银行真实货币的数量（比如，黄金储备）正在下降。也就是说利率没有高到持有债务（比如，真实货币的索取权）而不是把纸币兑换为黄金的程度。 正如我在第二章中所叙述的，我对美元的贬值记忆犹新。当时我在纽约证券交易所的柜台做职员。我在电视上看到尼克松总统向全世界宣布美元将不再与黄金挂钩。我想，“天哪，我们所熟知的货币体系就要结束了。”事实的确如此。第二天是星期一。当我开始工作时，我预料会有一场混乱，并且股票将下跌。事实上，虽然是一片混乱，但股市仍在上涨。因为我以前从未见过货币贬值，所以我不明白它们是如何运作的。然后我研究了历史，发现1933年3月5日晚，也是一个周日，美国总统富兰克林•罗斯福给了实质上相同的演讲，做了实质上同样的事情，在接下来的几个月里产生了实质上相同的结果（货币贬值，股市大涨，黄金价格大幅上涨）。 当我进一步观察时，我发现这种情况以前在许多国家发生过很多次，原因都是相同的——债务太多，需要资金来减轻债务负担——政府高级官员发表了基本相同的声明。你可能还记得，最近的例子包括美联储在2008年11月25日宣布的量化宽松政策，当时国会批准了财政部长汉克·保尔森(Hank Paulson)要求联邦政府提供7000亿美元用于资产购买的计划；马里奥·德拉吉(Mario Draghi)在2012年7月表示，欧洲央行将“不惜一切代价”，随后大量印钞和购买政府债券；2020年3月15日，特朗普总统和国会两院的领导人同意一项超过2万亿美元的刺激计划，美联储主席鲍威尔宣布大幅降息至0%以及7000亿美元的量化宽松计划和其他大量的支持，之后，刺激政策的力度还在加大。"},{"title":"MySQL 压缩","date":"2021-03-18T08:52:47.000Z","url":"/2021/03/18/MySQL-%E5%8E%8B%E7%BC%A9/","tags":["数据库","MySQL"],"content":"压缩算法Table CompressionInnoDB存储引擎是按照索引组织表（index-organized table）的方式组织数据的，数据存储在B-tree索引（clustered index/primary key &amp; secondary index）中。Table Compression是针对整个表，和相关索引进行的，而不是单独的数据行。 B-tree页经常被更新，InnoDB会尽量减少B-tree节点的分裂（split），减少不必要的压缩和解压页。为此，InnoDB在每个B-tree页中都预留了未压缩的“modification log”空间，记录页的变更。对于update和insert的数据量较小时，会先写入“modification log”，不用立刻重构整个页。当“modification log”空间用完了，InnoDB解压该页，应用变更（apply），然后重新压缩。如果压缩失败，该B-tree叶节点就要进行分裂了。在写入量比较大的场景，比如某些OLTP应用，为了避免频繁压缩失败，InnoDB会在页中保留一些额外空间（padding），在“modification log”用完，页重构时，仍有足够的空间避免分裂。 在压缩表中，每个压缩的页（1K, 2K, 4K 或 8K）都对应着没被压缩的16K的页。当检索该页中的数据时，若不在内存中（Buffer Pool），MySQL会将其从存储中读取到内存，解压。为了降低I/O和减少解压次数，有时内存中会同时存在压缩的页，和非压缩的页。为了维持可用的内存，MySQL会将非压缩的页回收掉，只保留压缩的页在内存中，又或一个页较长时间没被访问，压缩页会被写回磁盘，以释放内存。对于Table Compression，数据会被压缩变小，在存储中读写数据时，能有效减少I/O次数，提升吞吐量。压缩的数据读入到内存中，会进行解压；写入存储时，会进行压缩。压缩解压过程会消耗CPU资源。在内存中，会同时存在压缩的页，和非压缩的页，内存空间使用比正常要大。 可见使用Table Compression，会大幅提升I/O效率，消耗更多CPU资源，消耗更多内存资源。在生产负载下，Table Compression特性能否在有效降低存储空间的前提下，还保持一个不错的性能，往往就取决于该三个因素的相互作用结果。 Page CompressionPage Compression需要借助PUNCH HOLE特性，该特性要操作系统和文件系统的支持（Centos7的ext4和xfs文件系统都是支持PUNCH HOLE的）。在Linux操作系统上，存储的最小单元是一个块的大小（Block size ），Page Compression压缩成功的条件是page compressed size ≤ page size - N*Block size（N≥1，且整数）。比如innodb_page_size=16K，Block size=4K，该页被压缩为12K，这样在磁盘上就占用3个Block size，从而节省了一个Block size。整个过程比较简单，利用数据压缩 + PUNCH HOLE来实现，数据页在内存中表现是一个正常的页，只在读写到磁盘时，才进行数据压缩、解压处理。 可见使用Page Compression，会大幅提升I/O效率，消耗更多CPU资源，但相比Table Compression不会消耗那么多的内存资源，在生产负载下，Page Compression特性能否在有效降低存储空间的前提下，提供一个良好的性能，取决于该两个因素的相互作用，以及设备对于PUNCH HOLE特性的支持程度。 压缩比normal-16k，innodb_page_size = 16384。 tabcmp-8k，Table Compression，ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8。 tabcmp-4k，Table Compression，ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=4。 pcmp，Page Compression/Transparent Page Compression，COMPRESSION=’zlib’（有zlib和lz4两种压缩算法，选择取决于业务对存储空间的诉求，一般zlib压缩比高于lz4，所以zlib。）。 压缩比 = 压缩后数据大小/压缩前数据大小。 对于压缩，tabcmp-8k压缩比为22%，tabcmp-4k压缩比为32%，pcmp压缩比为44%。 性能比性能比 = 压缩后QPS/压缩前QPS。 性能比，各OLTP场景tabcmp-8k在70%左右，tabcmp-4k和pcmp不稳定。对于线上业务实际负载，相对极限压测，根本不会达到这么高，那么70%的性能比，还是不错的。 什么业务适合开启压缩数据特点影响压缩成功率的一个关键因素是数据本身的属性，对于字符串的压缩效果一般都比较好，比如数据类型是CHAR，VARCHAR，TEXT或BLOB这样的字段。相反对于二进制数据的压缩效果一般都不是太好，比如数据类型是int或float这样的字段。 负载特点负载类型是开启压缩要考虑的另一个关键因素。根据Table Compression和Page Compression工作原理示意图可见，开启压缩后的性能情况，是I/O能力的提升，与CPU使用率上升，内存使用效率下降，多方因素相互作用的一个结果。经此也不难看出，对于I/O bound，而不是CPU-bound的，读多写少的负载特点，压缩对于性能提升是有帮助的，退而求其次不至于性能下降太多，业务无法接受，而此时我们已经多收获了40%~60%的存储空间。 硬件特点数据库服务器的硬件配置也是一个关键因素，强劲多核心的CPU，充足的内存等，对开启压缩后的性能是非常有帮助的。对于Page Compression，Fusion-io NVMFS可以充分的利用PUNCH HOLE特性，让开启压缩后的性能表现更出色。 做压力测试的时候需要关注的点 tp999 线 cpu 和内存的涨幅 qps 的降低 实际的压缩比 "},{"title":"分库分表","date":"2021-03-17T12:44:18.000Z","url":"/2021/03/17/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/","tags":["数据库"],"content":"业界方案问题垂直拆分优点：降低负载，提高可用性 缺点： 无法降低单表数据量 不能无限扩容 存在单点故障 join 等多表操作受限 存在跨库事务 水平拆分优点： 降低单表数据量 理论上可无限扩容（NoSQL 通常采取这种方案） 不存在单点故障 缺点： join 等多表操作进一步受限 存在跨库事务 扩容成本高 如何分hash 分表常见的分表方案。 range 分表建立时间 range，按 range 分表。 混合分表先 hash，再 range。 怎么查 SQL 路由（route）和结果合并（merge） 多表 join 多维度查询 跨库事务 路由要定义 dsl，用语言解析表达式。 做广播表的查询的结果就是一张逻辑表查询转成多张表查询。 如果要做无分表键的查询，不如做影子表做侧维度。但影子表依赖于数据迁移服务。数据迁移服务的存在在日常的数据库运维中非常重要，它可以支持任意的 etl 的形式来同步异构数据。但这会带来成本上的坑。"},{"title":"MySQL大表平滑迁移与拆分实战","date":"2021-03-17T11:58:11.000Z","url":"/2021/03/17/MySQL%E5%A4%A7%E8%A1%A8%E5%B9%B3%E6%BB%91%E8%BF%81%E7%A7%BB%E4%B8%8E%E6%8B%86%E5%88%86%E5%AE%9E%E6%88%98/","tags":["数据库"],"content":"向外看 数据量变化 业务形态变化：我们要不断重构数据存储层 趋势变化 向内看 数据增长，某项指标超过某个阈值 数据量太大，隐患很高 如何消除，支撑业务健康发展我们可能有各种方案来解决这个问题。只要我们肯侵入代码，数据迁移、校验、流量灰度都可以做同异步切换来实现。 读写旧 -&gt; 读写旧，写新 -&gt; 读旧，读写新 -&gt; 追数据，校验，读写新 Scale Up Vs Scale Out要实现弹性伸缩，伸缩以后，数据要重新打散。 设计全流程可以分成组件： 备份重建 增量同步 校验 这里有不同的组件，可以通过编排来满足差异化的需求。 在数据库里面，扩展是一个比较核心的问题。 要注意校验中锁表的颗粒度，有时候要引入区间锁，不要全锁表。"},{"title":"货币价值的变迁","date":"2021-03-15T12:19:12.000Z","url":"/2021/03/15/%E8%B4%A7%E5%B8%81%E4%BB%B7%E5%80%BC%E7%9A%84%E5%8F%98%E8%BF%81/","tags":["经济"],"content":"FROM： 1. 摆脱债务危机最简单的做法就是印钱并使其贬值决策者可以利用以下四种杠杆来使得债务和偿债水平相对于偿债所需要的收入和现金流水平显著下降： 紧缩（减少支出） 债务违约和重组 将资金和信贷从富余方转移到短缺方（例如提高税收） 印钱并引发贬值 紧缩会造成通缩，同时由于其过于痛苦，所以不可能持久。债务违约和重组也是一个通缩和痛苦的过程，因为被抹去或贬值的债务是另一个人原本的资产。结果，违约和重组对破产债务人、和资产被剥夺债权人以及本来富有却不得不减记资产的债权人来说都是痛苦的。将资金和信贷从富余方转移到短缺方（例如：提高税收以重新分配财富）在政治上具有挑战性，但比前两种方法都更容易被接受，这通常也是解决方案的一部分。与上面其他几项措施相比，印钞是最方便，最不被大众理解，也是最普遍的债务重组方式。实际上，它看上去对大多数人其实是利大于弊，因为它有助于缓冲债务挤兑的局面，那些财富被通胀掠夺的受害方也难以分辨（尽管他们是货币和债务资产的所有者）在大多数情况下，它会导致以贬值货币计价资产的价值上升，这会让人们从表面上看起来越来越富有。 2. 所有的货币要么贬值、要么完全消失自1700年以来存在的大约750种货币中，只有20%的货币保留了下来，而且所有保留下来的货币都贬值了。回到1850年，世界上的主要货币都与今天的完全不同。虽然美元、英镑以及瑞士法郎当时就存在，但其他大多数货币都是不同的且已消失。 在1850年的德国，你可能会使用基尔德（荷兰货币单位Gulden）或者泰勒（德国的旧银币Thaler）。 那时候还没有日元，所以在当时的日本你可能会用Koban或者ryo 来代替。 在意大利，你可能使用六种货币中的一种或者多种。 在西班牙、中国、和大多数其他国家，你会使用不同的货币。 有的货币已经完全消失（大多数情况下，这些货币都属于那些极度通货膨胀以及/或者战争失败、债台高筑的国家），取而代之的是全新的货币。有些被取代它们的货币所合并（例如，一些欧洲国家的货币被欧元合并）。有些货币仍然存在，但已经大幅贬值了，比如英镑以及美元。 3. 货币贬值代表着什么？ 货币贬值最主要的主要目的就是减轻债务。这是因为印钞的目标就是减轻债务负担。 增加货币和信贷的供应既会降低其价值（这对持有者不利），但同时也减轻了债务负担。 如果债务减记促进这些货币和信贷流入企业，提升了企业的生产率以及利润，那么实际的股价（经通货膨胀调整后的股票价值）就会上涨。 但当信贷严重损害“现金”和债务资产的实际和预期回报，并且导致资金流出这些资产，流入能够对冲通胀的资产以及流入其他的货币时，就会导致该货币价值自我强化式的下跌。 中央银行通常有以下选择： 允许实际利率（即名义利率减去通货膨胀率）上升并对经济造成损害，或者 通过印钞和购买现金及债务资产，防止实际利率上升 而通常，在面对短期债务危机时，央行都会选择第二种。这进一步降低了持有“现金”和债务资产的回报率，进而为长期债务周期埋下包袱。 两种货币贬值 对系统有益的贬值：尽管对货币和债务持有人来说，贬值的代价总是高昂的 对系统有害的贬值：这种贬值是创建新的货币秩序，消除债务所必须的，但它破坏了信贷/资本的配置体系。 4. 货币价值与黄金的关系货币通常在债务危机期间突然贬值，而在繁荣时期保持相对稳定。1600年以来，三大储备货币相对于黄金的即期汇率回报率 货币大幅贬值往往更具有偶发性，而非渐进性在过去170年中，主要货币（虽然还有更多的次要货币）出现了六次大幅的贬值。 在19世纪60年代，美国内战的巨额融资需求促使美国暂停黄金兑换，同时印刷纸币（称之为“绿钞”），以货币化战争债务。 a. 在19世纪70年代中期，美国恢复了之前的金本位制度后，许多其他的国家加入了金本位制； b. 直到第一次世界大战之前，大多数货币对黄金的汇率都是固定不变的。 主要例外是日本（在19世纪90年代之前采用的银本位制，这期间银价下跌，导致其汇率对黄金贬值），以及意大利和西班牙，这两个国家常常暂停黄金兑换，以解决巨额的财政赤字。 随后到了第一次世界大战时代，战争中的国家出现了由央行印钞和借贷造成的巨额赤字。在战争年代，因为缺乏信任，国际信用缺失，黄金成了国际通用货币。当战争结束的时候，一个以黄金和战胜国家货币所主导的新的货币秩序诞生了。 a. 尽管如此，在1919年到1922年间，印钞以及许多欧洲国家货币的贬值，仍然是债务危机在那些负债累累国家内延续所必须的，尤其是那些战败国。这导致了1920年至1923年，德国马克和德国马克债的彻底消失，以及其他依然有大量债务的国家包括战胜国货币的大幅贬值，以求一个新的开始。 b. 随着债务、国内政治、以及国际地缘政治完成重建，20世纪20年代出现了一段繁荣的时期，并最终发展成为了一个巨大的泡沫，于1929年，泡沫开始破灭。 在1930年到1945年间，1）债务泡沫破裂使得央行印钞并将货币贬值， 然后2）当战争债务必须增加以支撑战争时，就需要印更多的钞票以及让货币更多的贬值。 a. 1930年至1933年间，发生了一场全球的债务危机，引发了经济紧缩，进而导致了印钞以及几乎所有国家竞相贬值，这侵蚀了货币的价值，引发了第二次世界大战。国家内部和国家之间的财富冲突导致了国家内部和国家之间更大的冲突。 b. 当战争末期，在1944年至1945年间，建立了将美元与黄金挂钩，其他货币与美元挂钩的新的国际货币体系 c. 德国、日本、意大利和中国（以及其他一些国家）的货币和债务被迅速且彻底地消灭 d. 而大多数战胜国的货币和债务也仍然在缓慢的贬值中。这种货币体系一直维持到20世纪60年代末。 在1968年到1973年间（其中最重要的是1971年），过度的支出和债务的产生——特别是美国要求美元与黄金脱钩，因为此时黄金的兑换权正在被要求兑换为真正的黄金，且兑换权所对应的黄金数量远远大于实际可供兑现的实体黄金数量，这导致了以美元为基础的法定货币体系的出现，此体系允许以美元计价的货币和信贷的大幅增加，这加剧了20世纪70年代的通胀，并导致了上世纪80年代的债务危机。 自2000年以来，由于大量货币以及信贷的创造，再加上利率相对于通货膨胀率较低，货币价值相对于黄金已经下降。因为是自由浮动的货币体系，所以没有出现像过去那样突然的断裂；低利率甚至负利率并不能为不断增加的货币和信贷以及由此造成的通货膨胀（尽管是较低的）提供补偿，货币的贬值是持续和渐进式的。 自1850年至今，相对于持有黄金，持有货币的收益（即获取短期债务的利息）反而是更有利可图的。在超过60年的债务/货币周期期间，大多数货币相对于黄金或者白银都能够保持固定的汇率。 持有货币的投资者都可以获得不错的收益，因为一般在繁荣阶段，债权人和债务人都能获得较高的回报。这一繁荣时期，就是著名的第二次工业革命时代，借款人将借入的资金转化为收益，使得债务得以偿清。 尽管在此期间依然有债务危机发生（像是在美国发生的“1873恐慌”、“1893年恐慌”、以及“1907年恐慌”），并造成了市场动荡，但其规模都不大，不足以使得货币和信贷贬值。 同时，巨大的贫富差距和其他的一些社会问题（比如：妇女的选举权）引起了政治局势的紧张，资本主义受到挑战，税收开始上升，从而为财富的再分配过程提供了资金。 然而我们要注意到，在不同国家持有货币的回报具有极大差异 自1850年以来，在大约一半的国家里，持有国债都会得到正向的实际回报，另一半则会得到负回报，而在德国这样的国家里，你的资产会被彻底的消灭两次。 当持有生息货币可以取得实际回报时，大部分这样的时期都是国家实行金本位体制的时期。这些国家之所以坚持金本位制，是因为它们当时都处于繁荣期（比如：第二次工业革命和1945年后的繁荣期，这期间，债务水平和偿债成本相对较低，收入增长几乎等同于债务增长），直到这一长周期的结束。 自1912年（现代法定货币时代）以来，持有国债的实际回报率（调整过通货膨胀率以后的）为-0.2%。而持有黄金的实际回报率为2.2%。 在此期间，你只有在大约一半的国家里持有生息现金货币，才能获得正收益 而在其余的国家则会遭受不小的损失（在法国，意大利和日本，每年的损失超过2%，而在恶性通货膨胀的德国，会损失超过15%）。 5. 货币价值与商品&amp;服务价格的关系如图所示，在两次世界大战期间是非常糟糕的，自那以后，有起有落。大约一半的生息现金货币能提供高于通货膨胀率的回报，而另外的一半则表现糟糕。在所有的案例中，在平均值附近都有大约10年的周期波动。 换句话说，历史已经说明了持有生息现金货币作为财富储备存在很大的风险，尤其是在债务周期的末期。 6. 货币贬值与储备货币地位的丧失货币贬值不一定意味着失去其储备货币的地位，但两者同样是由债务危机引起的，而货币失去其储备货币地位则是由于其货币长期和大规模的贬值所造成的。 当处于长期债务周期末期时，发生货币和货币体系崩溃的可能性大大增加，这个时候重要的事情是要区分什么是系统性的良性贬值和系统性的破坏性贬值。 7. 货币贬值有无相似之处所有的经济体都经历了一种典型的“挤兑”动态，因为市场上存在货币兑换权的数量，高于中央银行能够实际以硬通货/储备货币兑付的数量。 货币挤兑和货币贬值通常都伴随着与战时开销相关的重大的债务问题例如，荷兰人的第四次英荷战争、世界大战中的英国，布雷顿森林体系下越南与美国的越战） 最糟糕的情况是那些战败的国家，这常常会导致这些国家的货币和经济彻底的崩溃和重组。 然而，战胜国最终的债务也是远远大于他们的资产，这降低了他们的国际竞争力（比如：大不列颠帝国），他们也失去了其储备货币的地位，虽然这一过程是缓慢和渐进的。 同样是为了应对战时债务进行信贷扩张，不同国家的结局取决于该国家在贬值时所具有的经济实力以及军事实力 荷兰盾（Guilder）的崩溃是惨烈的，而且在不到十年的时间内迅速崩塌，同时在第四次英荷战争结束时，荷兰盾（Guilder）的实际流通量已经大大减少了。这一崩溃伴随着荷兰作为一个世界强国的地位迅速下降，它首先输掉了跟英国的战争，随后又要面对来自法国的侵略。 英镑的地位下降是渐进式的：在完全的失去其储备货币地位之前，它经历了两次贬值。在此期间，英国经历了周期性的收支紧张。许多持有英镑储备的人都是因为政治压力而持有的，而他们的资产表现在同一时期，明显远逊于美元资产表现。 美元出现了两次大型剧烈贬值（1933年和1971年），以及2000年以来相对于黄金的缓慢贬值，但这并没有使美元失去其储备货币的地位。 什么情况下国家失去其储备货币的地位——崛起的对手、不断增加的债务以及货币价值不断贬值 有一个正在崛起的对手挑战了其已确立的政治和经济的主导地位，造成其国家实力上的脆弱性（例如：荷兰落后于英国，以及英国落后于美国） 存在庞大及不断增加的债务，只能通过中央银行不断的印钱和购买政府债券以货币化的形式解决，这导致了 货币价值的不断弱化，强化了货币挤兑的可能性，并且这种趋势无法阻止，因为财政和收支赤字太大，无法靠削减开支的方式平衡。 "},{"title":"货币、信贷与债务","date":"2021-03-15T09:21:12.000Z","url":"/2021/03/15/%E8%B4%A7%E5%B8%81%E3%80%81%E4%BF%A1%E8%B4%B7%E4%B8%8E%E5%80%BA%E5%8A%A1/","tags":["经济"],"content":"FROM： 货币系统：大多数货币和信贷（尤其是现存的法币）并无内在价值。所有货币要么被摧毁，要么贬值。而当这发生时，财富就会以一种浩荡的方式转移，从而在经济和市场中产生巨大的反响。然而，拥有储备货币的国家更容易摆脱大量借贷（即创造信贷和债务）或者发行巨额货币的窘境，因为储备货币可用于世界各地的支出，所以其他国家倾向于持有这些债务。 经济周期由短期债务周期和长期债务周期构成 短期债务周期：通常持续8年左右，或多或少。时机取决于“兴奋剂”将需求提高到实体经济生产能力极限所需的时间。与短期债务周期相比，长债务周期需花费我们一生时间才会完成，因此大部分经济学家在内的大众根本没有意识到长期债务周期的存在。 长期债务周期：通常持续约50至75年。 拥有储备货币地位对国家意义重大，相对于美国经济规模而言，其规模是巨大的。 2008年以来，央行在MP2（QE）的基础上开启了MP3的新范式 ，这意味着具有储备货币的中央银行创造货币和信贷的能力几乎没有或没有限制。 当一个国家拥有储备货币时，它可以按照自己的意愿印刷货币并借钱支出，就像美国现在的做法一样；而那些没有储备货币的人必须得到他们需要的资金和信贷（以世界储备货币计价）来进行交易和储蓄。 硬通货（Hard Money）、纸币（Paper Money）和法币（Fiat Money）的区别和内涵： 硬通货（Hard Money）：最早的货币形式，通常指金银等贵金属货币，是人们为了交易便捷、保存财富而发明。硬通货因为其供给的有限和实用价值（首饰等），本身具有内生价值（intrinsic value），通常也具有可分割、携带方便的特点。 纸币（Paper Money）：特点是可以兑换硬通货。如宋代交子、金本位时期的美元。纸币依托于受到公众认可的信贷实体而诞生，信贷实体（通常是银行）以硬通货作为基础来发放纸币，并向持币人承诺可随时以一定比例使用纸币兑换硬通货。因此纸币的供给量受限于信贷实体的硬通货储备量，对于央行而言硬通货储备量则取决于国家挣取硬通货的能力。因而在纸币体系下，信贷机构仅具有有限的信贷调节能力（以其持有的硬通货数量为限），否则容易发生挤兑。 法币（Fiat Money）：不和硬通货挂钩，仅仅是由某个政府的信誉担保，例如今天绝大部分法币。政府可以自由创造货币和信贷，只要人们继续对货币充满信心，平衡可以一直持续。如果人们对货币丧失信心，则会通过各种手段将该国法币兑换成储备货币（通常是美元），造成货币贬值、资本外流。 恒久的货币与信贷的基础原则如果一个实体拥有大量的净资产（即资产远多于负债），它可以在收入之上支出，直到钱用完，这时必须削减开支；如果它有大量的负债，并且没有足够的收入支付费用和债务，债务就会被拖欠。由于一个实体的债务是另一个实体的资产，债务拖欠会减少其他实体的资产，这就要求债权实体削减开支，愈演愈烈的下行债务和经济紧缩随之而来。 这种货币和信用体系有一个重大的例外：所有国家都可以印钱给人们消费或借出，然而并非所有政府印制的货币都具有同等价值。 储备货币在世界范围内广泛流通的货币称为储备货币。目前，美元在储备货币中独占鳌头，由美国的中央银行（美联储）发行，约占所有国际交易的55％。次之是欧元，由欧元区国家的中央银行（欧洲中央银行）发行；它约占所有国际交易的25％。尽管人民币的影响力与日俱增，日元，人民币和英镑目前仍是势力相对较弱的储备货币。 拥有储备货币的国家更容易摆脱大量借贷（即创造信贷和债务）或者发行巨额货币的窘境，因为储备货币可用于世界各地的支出，所以其他国家倾向于持有这些债务。 发行储备货币的国家可以发行大量以它们计价的货币和信贷，尤其是货币短缺的情况下。 相反，非储备货币国家没有这种选择。当非储备货币国迫切需要储备货币来偿还以之计价的债务，或从接受储备货币支付的卖家那里购买商品时，这些国家将无法获得足够的储备货币来满足需求，最终走向破产。 什么是货币货币是一种交易媒介，同时可以作为财富储备。 大多数货币和信贷（尤其是现存的法币）并无内在价值； 会计系统中的日记账分录很容易更改； 该系统的目的是帮助有效地分配资源，从而提高生产力，奖励贷款人和借款人， 这个系统会定期崩溃。 因此从一开始，所有货币要么被摧毁，要么贬值。当货币被摧毁或贬值时，财富就会以一种浩荡的方式转移，从而在经济和市场中产生巨大的反响。 更具体地说，货币和信贷体系并没有发挥完美的作用，而是在一个周期内改变货币的供给、需求和价值，这个周期在上升时产生令人愉悦的富足，在下降时释出过程惨痛的重组。 经济周期的基本构成虽然货币和信贷与财富息息相关，但它们不是财富。因为要创造财富就必须提高生产力，一个人不能只通过创造更多的资金和信贷来获得财富，原因有二： 人们在通过信贷推高价格和生产的同时，必须偿还这些信贷，偿还信贷的时候会对经济产生相反的效果； 事物的内在价值不会因为它们的价格上涨而增加。 货币和信贷在发放时是一针强心剂，但偿还时就变成了一盆冷水。这就是货币、信贷和经济增长颇具周期性的原因。 为了控制市场和经济，掌握货币和信贷的主体（即央行）通过不断调整和改变二者的成本与获取难易度，来保证经济不会失控，但是政府的弹药是有限的。 政府的举措导致货币、信贷、商品、服务和金融资产数量和价格的周期性涨跌，并通常以短期和长期两个债务周期的形式出现。 短期债务周期短期的涨跌周期通常持续8年左右，或多或少。时机取决于“兴奋剂”将需求提高到实体经济生产能力极限所需的时间。大多数人已经见证了不少短期债务周期，以至于他们错误地认为，人们将永远以这种方式继续下去。它们通常被称为“商业周期”，不过我把称之为“短债务周期”，以区别于“长债务周期”。但不同于我们所有人都经历过且了解的短债务周期，长债务周期需花费我们一生时间才会完成。而谈及长期债务周期时，包括大部分经济学家在内的大众，根本没有意识到或不承认债务存在。要搞清楚长周期运作方式，我们必须研究众多国家数百年来经历，以获得充足样本。 长期债务周期长期来看，这些短期债务周期加起来就是长债务周期，通常持续约50至75年。 因为大多数人一生中只经历一次，所以人们意识不到长期债务周期的存在。因此，人们一次次地为之震惊，也被它伤害。 上一个大的长债务周期，即我们现在所处的周期，是1944年在新罕布什尔州的布雷顿森林设计的，1945年二战结束后，美元/美国主导的世界秩序拉开了帷幕。 长期债务周期开始时，早前的超额债务透过某种形式完成重组，债务维持低水平的同时，中央银行瓶中也充满着兴奋剂。但当债务水平攀升，中央银行瓶中的兴奋剂所剩无几时，长债务危机便结束了。更具体的说，当中央银行无法透过增发货币和债务水平，促成实质经济增长时，央行的刺激能力便走到了尽头。央行失能通常发生在债务水平高企、而利率无法继续降低的时候，此时增发的货币将推高资产价格，而非助推经济活动；那时，手握债权者都想将其转化为其他财富。当人们普遍认为：金钱和可换取金钱的债务资产，不再是良好的财富储备时，长期债务周期便将结束，货币体系必然面临重组。 换而言之，长期债务周期始于： 债务水平低（令控制货币和贷款增长者有足够空间制造债务，为借款人创造购买力，而贷方极大可能获得良好收益），直到社会来到了。 高债务水平和债务负担的阶段，此时银行不再有能力为借款人推高购买力，获得高回报可能性也很小。长期债务周期结束时，银行瓶中几乎没有兴奋剂（中央银行不再有延长债务周期的能力），因此需要进行债务重组，或债务贬值，减轻负担，令周期重启。 01 它往往始于无债务/低债务的“硬通货”时期（”Hard Money”）It Begins with No or Low Debt and “Hard Money” 02 而后，硬通货的代换物出现了（也就是支票和纸币）Then Come Claims on “Hard Money” (aka, “Notes” or “Paper Money”) 信贷实体应运而生（后来被称为银行，但早期涵盖各种获得人们信任的机构，例如中国的寺庙）。 03 随之而来的是不断增加的债务 Then Comes Increased Debt 然而随着债务资产相比于实际存在的商品和服务不再平衡，两个不切实际的问题便会同时出现: 1.人们的收入不足以偿还债务：债务是一种“负收益“的资产（negative earnings / negative asset that eats up earning），但其拥有更高的优先级（seniority） 如果不足以偿还债务的话，那么债务人只有两条路可以走： a）债务重组，以减少债务和债务负担。当然这对债务人和债权人都是难以接受的，因为一个人的债务，会是另一人的资产； b）央行印钞、中央政府发放货币和信贷，来填补收入和资产负债表的漏洞，这种情况就是目前面对疫情对经济的冲击下，正在发生的。 2.人们寄希望于出售不断贬值的债务资产偿还债务：当债务人不相信他们将从中获得足够的回报时，他们便寄希望于出售不断贬值的债务资产偿还债务。 挤兑很容易出现，无论是商业银行还是央行都将面临抉择 要不允许大量的资金流出债务资产，利率随之上升，使债务问题进一步恶化； 要不开启印钞机，将那些被出售的债务资产都购买下来，防止利率上升，寄希望于此安抚市场情绪，使挤兑不再继续。 因受到生产能力的限制，商品和服务的数量是有限的，银行里的“硬通货”（即黄金储备）也是有限的，然而“硬通货”对应的纸质货币却是不断增长的。我们需要注意两点： a）债务和金钱和银行里的“硬通货”（黄金储备）是否平衡； b）现有商品和服务的数量。 04 紧随其后的便是债务危机、违约和贬值 Then Come Debt Crises, Defaults, and Devaluations 商业银行只能选择违约或者依靠政府援助，央行也可以选择货币贬值，如果债务是以本国货币计价的话，其最终可能只需偿还原本债务的50%-70%左右，但面对以外币计价的债务，违约是唯一的选择了。 05 之后，便是法定货币的出现 Then Comes Fiat Money 中央银行希望尽可能延长货币和信贷周期，因为这要比其他替代方案要好得多。但这种“金本位”的制度是有局限性的，其后法定货币站上了山头。 当信贷周期达到极限时，最合乎逻辑的又比较常用的政策是让中央政府和央行增加大量债务并印钞，将其用于商品，服务和投资资产，以保持经济发展。 中央银行“印钞”以鼓励支出的优点。 债务必须被偿还，因此容易引发各种各样的问题 而只要货币用于提高生产，单纯的货币增长是不容易带来各种各样问题的。 中央银行“印钞”的风险： a）市场参与者将无法仔细分析货币是否已投入生产性使用 b）消除了偿还货币的需要 一次次的历史实践证明，我们不应当依靠政府的财务担保。 政府将比任何个人、公司和其他金融实体更容易陷入债务漩涡。在几乎所有情况下，政府都会通过举债成为最大的债务人。当债务泡沫破裂时，政府会通过印钞和贬值来救助自己和其他债务人。 印钞购买债务的方式被称为债务货币化。在政治层面上，这种方式相比于征税更容易令大多数人接受。 纵观整个历史，统治者积累的债务直到统治结束很久才显现出问题，而留给其继任者收拾残局。 当央行印钞并购买债券时，资金流入金融市场，推高金融资产价值，当然这进一步加剧了贫富差距的扩大。 最终，法定货币制度不得不回归到“硬通货”Then Comes the Flight Back into Hard Mone 法定货币的过度印刷终会导致债务资产的出售，以及先前描述的银行挤兑，最终会降低货币和信贷的价值，从而促使人们逃离货币和债务去选择其他储蓄财富的方式。 巨大的贫富差距也会造成经济压力 从而导致更高的税收，富人们更希望转向更保值的资产，甚至转移到其他国家。 自然而然的，面对资本外逃的政府会想方设法制止其发生。往往政府会取缔黄金交易、禁止外币交易、建立外汇管制机制。 当这种情况变得极端，以致货币和信贷系统崩溃，债务被贬值甚至被拖欠时，通常就必须迫使各国政府重新使用某种形式的“硬通货”，以重建人们对于储备货币的信念。 在过去的近一个世纪中，许多国家都将自己的本国货币和美元挂钩，变相地将美元作为交换的媒介和财富的储备。 06 最终，法定货币制度不得不回归到“硬通货”Then Comes the Flight Back into Hard Mone 法定货币的过度印刷终会导致债务资产的出售，以及先前描述的银行挤兑，最终会降低货币和信贷的价值，从而促使人们逃离货币和债务去选择其他储蓄财富的方式。 巨大的贫富差距也会造成经济压力 从而导致更高的税收，富人们更希望转向更保值的资产，甚至转移到其他国家。 自然而然的，面对资本外逃的政府会想方设法制止其发生。往往政府会取缔黄金交易、禁止外币交易、建立外汇管制机制。 当这种情况变得极端，以致货币和信贷系统崩溃，债务被贬值甚至被拖欠时，通常就必须迫使各国政府重新使用某种形式的“硬通货”，以重建人们对于储备货币的信念。 在过去的近一个世纪中，许多国家都将自己的本国货币和美元挂钩，变相地将美元作为交换的媒介和财富的储备。 长期债务周期持续时间长（大约50到75年），其特征是债务和货币体系的重组。但债务和货币危机时期通常发生得极为迅速，仅持续数月或长达三年，通常都会发生两到四次重大债务危机。 储备货币地位对国家的意义回顾美国货币体系发展历史布雷顿森林协定使美元在1944年成为世界领先的储备货币。美国和美元自然可以适应其中之所以发挥作用，是因为在战争结束时，美国拥有的政府黄金约占世界的2/3（当时是世界的货币），占世界经济生产的50％，并且是主要的军事力量。 布雷顿森林体系的货币体系于1971年8月15日崩溃原因：美国政府在随后的几年花费了超过税收的收入，因此不得不借钱，这增加了以美元计价的债务。 结果： 美元对黄金和其他货币贬值。从那一刻开始，美国和所有国家进入第三类货币体系（即无兑现实际的资产义务法定货币）的时候。 美联储和其他中央银行从实物兑付压力中解放，创造了大量以美元计价的货币和信贷，从而导致了1970年代通货膨胀，其特征是商品， 服务和对冲资产（如黄金）的价格上涨。 1979-82年的货币和信贷危机以美元计价的债务迅速增长，导致了债务周期中经典的债务泡沫。 美元和以美元计价的债务面临着不再成为公认财富储备物的风险。 影响 抛售美元/美元计价的资产，买入通胀对冲资产； 迅速借入美元转变为实际债务。 保罗·沃尔克（Paul Volcker）债务重组为应对这场货币通胀危机并打破通货膨胀，沃尔克收紧了货币供应。 债务人必须在收入和资产价值下降的同时，支付更多的债务。这给债务人造成了巨大的压力，并迫使他们出售资产以偿还债务。 那时的市场对美元的需求还很巨大，所以美元体系整体保持了稳定。 后续影响 美国通货膨胀率下降了 这使美联储可以降低利率，并为美国人放松货币和信贷。 通货膨胀率下降也使得在1980年代的债券和其他通缩资产表现出色。 许多贬值的债务人和相应资产的持有人的破产 因此，在20世纪80年代，这些破产的债务人（大多数是外国债务人，尤其是新兴国家的债务人），经历了长达十年的萧条和债务重组期。 债务管理和重组过程一直持续到1991年，当时该债务通过布雷迪债券协议完成，该协议以当时的美国财政部长尼古拉斯·布雷迪（Nicholas Brady）的名字命名。 若干短期债务周期自新的以美元计价的货币体系以来，利率和通胀率的整个大周期都在剧烈波动。 2000互联网泡沫：20世纪90年代全球货币，信贷和债务的新一波增长又开始了。这再次推动经济走向繁荣期，并导致通过债务融资购买的投机性投资大幅增加，最终变成了互联网泡沫，并在2000年破裂。 07-08年债务泡沫：2000-01年的经济衰退，刺激美联储放松了货币和信贷，这将债务水平推到了新高，并创造了另一种繁荣，这种繁荣在2007年变成了另一个更大的债务泡沫，并在2008年破裂，导致了美联储和其他储备货币国家的中央银行再次放松，导致了最近破裂的下一个泡沫。 但是，2008年为应对经济低迷而需要的货币和信贷创造的设计却有所不同。 利率失去下降空间：短期利率在2008年达到了0％，而且下降幅度不足以创造市场所需要的货币和信贷规模。 央行转而QE：降低利率是央行的首选头牌货币政策。由于这种政策不再有效，中央银行转向了第二选择印钞和购买金融资产，主要是政府债券和一些优质债务。 这种情形上一次出现在1933年出现0%利率的时候开始，一直持续到世界大战爆发。 QE导致新的货币/信贷/经济范式一直持续至今，由新冠疫情引发的经济衰退时期。 2008年以来的新范式QE的传导机制 央行通过印刷货币和购买债务，抬高债券价格，并向这些债券的卖方提供现金，从而促使他们购买其他资产。 随着资产价格的上涨，拉低了未来的预期收益。由于利率低于其他投资的预期回报率和债券收益率，投资者越来越多地借钱购买他们期望比借贷成本回报更高的资产。 这两者都推高了这些资产的价格，又造成了新的债务泡沫。 无论如何，在此期间，债务和非债务（例如养老金和医保）相对于收入继续上升，而中央银行设法降低了偿债成本。这将利率推至零，并使债务长期化，以至于本金支付将很低——这意味着中央银行创造货币和信贷的能力几乎没有或没有限制。 拥有世界储备货币可能是最重要的力量，甚至比军事力量还要强大。这是因为 当一个国家拥有储备货币时，它可以按照自己的意愿印刷货币并借钱支出，就像美国现在的做法一样； 在1944年美元是世界上主要的储备货币时，美国政府持有的黄金约占世界黄金的2/3（在当时被认为是货币），约占世界GDP的一半。 如今，美国仅占世界GDP的20％左右，但仍占全球储备的60％和国际交易的约一半，相对于美国经济规模而言，其规模是巨大的。 而那些没有储备货币的人必须得到他们需要的资金和信贷（以世界储备货币计价）来进行交易和储蓄。 美联储以对美国人有利的方式实施其货币政策（如直升机撒钱），但对依赖美元的世界其他国家却可能不利。世界上大多数国家都无法像美国人那样获得他们需要的金钱和信贷来填补损益表和资产负债表的空缺。 非美国人（即新兴市场，欧洲国家和中国）所欠的债务约为20万亿美元（比2008年高约50％），其中不到一半是短期的。这些美元债务人不得不拿出美元来偿还这些债务。 重大周期始于新的世界秩序，即一种新的国内和国际运作方式，其中包括新的货币制度和新的政治制度。上一次的大周期始于1945年，按照50-75年的长周期运算，我们已经接近了这个周期的尾声。"},{"title":"世界财富与权力大转移背后的规律","date":"2021-03-15T09:02:32.000Z","url":"/2021/03/15/%E4%B8%96%E7%95%8C%E8%B4%A2%E5%AF%8C%E4%B8%8E%E6%9D%83%E5%8A%9B%E5%A4%A7%E8%BD%AC%E7%A7%BB%E8%83%8C%E5%90%8E%E7%9A%84%E8%A7%84%E5%BE%8B/","tags":["经济"],"content":"FROM： 财富和权力的大幅波动是由多达17种主要因素引起的，最重要的是货币和信贷周期，贫富差距周期和全球地缘政治周期。这些强大的力量通常以经典的周期汇聚在一起，这些经典的周期以相互补充的方式趋向于形成一个非常大的起伏周期，并在整个历史中反复出现。这个庞大的周期范式（archetypical cycle）控制着帝国的兴衰。 在多种因素引导着历史更迭和全球周期起伏，暗中发生着国家间财富和权力转移。这种转移往往会被人忽略，因为虽然财富和权力的转移在历史长河中属于白驹过隙，但对个体有限的寿命而言是长达十余年潜移默化的改变。我们如今正在经历相对财富和权力的范式迁移（archetypical big shift in relative wealth and power），并且随着这种变化，我们将见证世界秩序的深刻变化给所有国家造成的影响。 历史上，几乎所有大国都经历了崛起期、全盛期和衰弱期。而在每一个国家的周期中，不同因素的影响总是相辅相成，其中教育永远是领先指标，而储备货币地位的变化则姗姗来迟。这种国力上下摆动的”大循环“通常具有三个阶段： 崛起阶段，特征是获得竞争优势； 全盛阶段，国家保持强大实力，但逐渐为失去竞争优势埋下苦果； 衰弱阶段，国家各方面的自我强化机制均告衰退。 萧条，革命和战争造成的破坏重组很大程度上摧毁了旧系统并为新系统的出现奠定了基础，这些大萧条往往每10到20年会发生一次。而新系统的诞生将有可能触动储备货币拥有国转移，历史上从荷兰盾&gt;英镑&gt;美元的变迁皆为如此。 研究国家的筛选标准研究国家范围：三个储备货币国家：荷兰，英国和美国，和其他六个重要大国：德国，法国，俄罗斯，印度，日本和中国 大国不一定是生活水平最好的国家。两个原因： 第一，尽管财富和权力是大多数人追求的，但并不是所有国家认为这些事情是最重要的，也不会考虑为之奋斗。 其次，研究的国家不包括所谓的“精品国家”（”boutique countries”，例如瑞士和新加坡），这些国家的财富和生活水平很高，但规模不足以成为大国。 财富和权力的大幅波动是由多达17种主要因素引起的，最重要的是货币和信贷周期，贫富差距周期和全球地缘政治周期。 这些强大的力量通常以经典的周期汇聚在一起，这些经典的周期以相互补充的方式趋向于形成一个非常大的起伏周期，并在整个历史中反复出现。这个庞大的周期范式（archetypical cycle）控制着帝国的兴衰。 通俗来讲，下图中的17个特征指标是驱动国家兴衰的主要力量。 对于任何国家而言，各个特征向左偏移得越多，崛起的可能性就越大；向右偏移得越多，衰弱的可能性就越大。世界强国往往越发地显示出更偏左的特征，良性循环下，不断变得更加强大；然而如若管理不善，各个特征指标向右偏移，国家便走向衰弱。这时新竞争者便能趁机崛起，针对各个特征指标妥善管理，渐渐的强弱的形势便发生了转变。 我们最近在经济低迷时期将利率降至0％，同时背负了大量债务。这导致大量政府债务的产生，各国央行正在印制货币进行货币化，同时国家之间存在巨大的政治和价值观差距，而且新兴世界大国（中国）正在挑战当前的世界大国（美国）。虽然这种情形在我们的一生中都没有发生过，但它在历史上已经发生过很多次了（最近一次发生在1930-45年）。我们现在正在经历相对财富和权力的范式迁移（archetypical big shift in relative wealth and power），并且随着这种变化，我们将见证世界秩序的深刻变化给所有国家造成的影响。之所以国家间财富和权力的转移往往会被人忽略，是因为尽管它在快速形成，但没有突然出现。 不同国家（countries）、王国（kingdoms）、民族（nations）、邦国（states）、部落（tribes）、帝国（empires）和王朝（dynasties）间的区别曾令我纠结。众所周知，主权国家直到欧洲三十年战中后的17世纪才出现。笼统的说，在那之前并没有现代国家，只能见到王国。一般来说，王国是最小的，国家居次，而帝国最大，他们间的关系并不明确。每种类型的政治实体（如国家、王国、部落、帝国）以不同方式控制人口。在某些情况下，帝国指被统治力量占领的地区；有时指那些透过威胁和利诱被统治力量影响的地区。 英国最早是个王国，而后演变为主权国家，最后成为边界扩张到英格兰以外的帝国，以便其领导人控制广阔地区，和众多非盎格鲁-萨克逊人民。 大英帝国大体上占领了帝国中的领土，而美国则依靠”胡罗卜+大棒“策略控制了更多国家。 历史更迭与如影随形的周期教育带来生产力上升早期全球人均产出增速十分缓慢，但到1800年左右增长曲线斜率骤然变陡，反应出生产效率快速提升。这样的变化得益于全民教育水平提升，以及将教育成果转化为生产力。这种变化由许多因素导致，最早可追溯至15世纪中叶欧洲印刷机的发明（中国很早便使用过），这提升了更多人的知识和教育水平，并为文艺复兴、科学革命、启蒙运动和英国第一次工业革命作出贡献。 教育普及也令财富和权力从农业经济转向工业经济。 在农业经济中，君主、贵族和教会共同拥有土地并借此牟利； 在工业经济中，资本家创造并拥有生产资料，并同（世俗）政府共同维护一套令他们可持久牟利及掌权的制度。 在这种体制中，财富和权力来自教育资源、创新能力和资本主义制度的结合，并由当权者和那些控制资本和教育资源的人把持。尽管这套制度曾被共产主义（过去尝试均告失利）和社会主义 (人们正辩论这种结合财富和机会平等的社会制度之优劣)挑战。但先由受教育者发明创新，随后转化为生产 ，最后借资本主义制度及其共生政府体系分配利益，一直是成功的模式。 动荡时期大萧条期间人均GDP下降了约10%，随后又得以恢复，同时美国股市下跌了85%。紧接着大萧条的是二次大战，提高了军需品产量。但由于大量生产资料被毁，称这段时期为“大生产时代”是不准确的，即使因人均计亦是如此。战争尾声时，全球人均GDP下降了约12%，一大部分因战败国经济崩溃所致。 国家间发生的财富和权力转移下图显示了过去500年间11个世界大国的相对财富和国力。这一财富和权力指数由八个指标计算而得。即使这些数据因年代久远未尽准确，但仍完美反应宏观趋势。如你所见，几乎所有大国都经历了崛起和衰弱期。粗线是四个最重要的大国：荷兰、英国、美国和中国，他们分别掌握历史上最近的三种储备货币。对美国来说是现在时，英国是过去式，而荷兰则更早一些。我之所以提到中国，因其已成长为第二强大的国家，并且在1850年前大部分时间一直如此强大。 尽管中国地位在19世纪后急剧下降，但它几个世纪以来一直处于统治地位（在商品贸易上始终超过欧洲）； 荷兰作为一个相对较小的国家，在17世纪成为世界上最伟大的帝国； 英国循荷兰模式，在19世纪达到国力巅峰； 最终，美国超越数者，并保持世界强权长达150年，其地位在二战和战后尤为明显。如今，中国正迎头赶上。 长周期演变如图所示，在1500年前，中国几乎总是最强大的，尽管阿拉伯帝国、法国、蒙古、西班牙和奥斯曼帝国也曾崛起。 我们在以后的章节中将着重探讨中国，尽管它作为几个世纪以来的大国，但其货币从来没有成为全球储备货币，这背后的原因值得我们深究。 衡量综合国力我在前两张图表中衡量各国财富和国力的指数，基本由八个指标平均而得。他们是1.教育；2.（国际）竞争力；3.科技水平；4.经济产出；5.贸易份额；6.军事实力；7.金融中心实力和8.储备货币。稍后我们将进一步探讨权力的衡量标准，但让我们先关注这八个关键要素。 范式规律我们以国家成为全球头号大国年份为原点，列出前后各120年各项指标的变化。下表为多国平均数据，但大部分权重被赋予三个拥有储备货币的国家（即美国，英国和荷兰）。 所有这些指标在大国崛起前后都呈弧形，是因为这些指标总是相辅相成。即在教育、竞争力、经济产出、世界贸易份额等方面的优势和劣势,可合乎逻辑地转化为其他优势或劣势。例如，受过良好教育的人们会创造出缔造出更具创新性，竞争力和生产力高的社会。 教育永远是领先指标，而储备货币地位的变化则姗姗来迟。这是因为强大的教育会为大多数领域带来优势，包括创造世界上最广为流通的货币。如同世上的通用语言一样，习惯将放大货币本身的实力，令其更持久地流通。 大循环我称呼这种国力的上下摆动为”大循环“。广义而言，我们可把大国（empire）的崛起和衰弱分为三个阶段： 崛起阶段，特征是获得竞争优势； 全盛阶段，国家保持强大实力，但逐渐为失去竞争优势埋下苦果； 衰弱阶段，国家各方面的自我强化机制均告衰退。 崛起阶段 强而有为的领导：是一切成功要素的前提，包括…… 良好的教育：不止包括教授知识和技能，还包括…… 坚如磐石的美德、公民素养和强烈的职业道德：它们借学校和家庭教育传承，并助力公民社会达成如下成就诸如： 低腐败率和对法治等社会规则的高度尊重 人民不仅能够团结，还具有为何需要团结的共识：当一群拥有充沛知识、先进技能、善良美德、良好公民素养人团结一致，便会创造出： 一个良好的资源分配体系，而且能够… 吸引全球最优秀人才，这是国家成功的最重要条件，紧接着，这个国家就会… 获得在国际市场中的强大竞争力，令国家收益远大于支出，促成 强劲的收入增长，助力于… 增加基础设施、教育、研发投资，从而获得 更高的生产效率： 生产效率的提升意味着生产力和财富水平的同步提升，当国家的生产效率足够高时，他们可投资并发展出： 新科技：这些新技术将具备商用或军用价值；随着这些国家借如上因素更具竞争力，他们会在 国家贸易体系中占据更多份额：这令他们必须建立： 强大的军事力量：保护贸易路线，并借此扩大对他国的影响力。藉由经济上的优势，他们发展成为世界领先的…… 金融中心，能够汇聚和融通资本：（在荷兰帝国称霸世界时，阿姆斯特丹是世界金融中心；英国取而代之后，伦敦成为金融中心；而纽约如今地位亦由美国霸主地位而来。但中国也正以上海为中心，发展其金融体系）这些不断扩展的帝国在全球范围内 强大的股票、货币和信贷市场：那些在贸易和资本流动中占主导地位的国家，其货币自然成为交易媒介和财富储备首选，并发展为储备货币。循此逻辑，荷兰帝国称霸时，荷兰盾是全球储备货币；大英帝国时期，英镑继承这一地位。1944年美元成为全球储备货币时，美国离赢得二战只有一步之遥，显然在经济、财政和军事上都处于领先地位。将某国货币作为储备货币，自然令该国获得更强大借贷和购买力。如上图所示，一国获得或丧失全球储备货币地位的时机，要比它其他各项实力增强/衰退要晚许多。 帝国缔造者协调经济、政治和军事实力，建成了在国际社会中不断得利的经济-政治-军事体系。荷兰人创建了荷兰东印度公司，英国创建了英属东印度公司，美国有了军工联合体。事实证明，这种经济、政治和军事的协同配合，对帝国扩张攫利是必不可少的。 全盛阶段 繁荣时期，人们的收入增加，令劳动力变得更加昂贵；比起同等工作下薪资水平更低的国家，竞争力自然下降。 那些最成功国家的发展模式会被新兴竞争者模仿，时常青出于蓝胜于蓝，令领先者失去竞争优势。英荷争霸时期，英国造船厂人工成本低于荷兰；前者因此选择雇佣荷兰工程师，设计出比荷兰性价比更高的船舶。由于复制所需时间和金钱成本少于发明创造，在其他条件相同时，新兴帝国透过复制，搭了成熟国家的便车。 在那些生来富裕的国家，人们会减少工作量，从事更多休闲和低生产力的活动；极端情况下，变得颓废无能。尤其当社会中坚从必须艰苦奋斗才能获得成功的一代人，变成继承财富的一代时，年轻一代往往脆弱且缺乏历练，遭遇挑战更易败阵。随时间流逝，这些繁荣社会中的人们更渴望追求闲适且奢华的生活，为此不惜自损实力，制造泡沫，最终更不堪一击。 最富裕和强大国家拥有全球储备货币地位，并借此获得大量借贷的特权，以致深陷债务陷阱。大量借贷短期内增强了霸权国的消费能力，但长远却恰恰相反。换而言之，当借贷和消费强劲时，霸权国看似强大，但财政实力却被侵蚀。这种借贷模式令国内民众得以过度消费，并为扩军和发动战争提供资金，以提升基本国力以外的力量。这样的模式可维持一段时间，甚至自我强化，全因此举增加了债权国的利息回报，从而增强了储备货币的地位。 但富国向发展中国家借钱，也是财富转移的早期标志之一。1980年代时，美国的人均收入是中国的40倍，但当时中国已开始购买美国国债，只因美元是全球储备货币；同时，那也成为中国赶超美国格局的起点。同样的，二战时期英国从穷得多的殖民地大量借贷；荷兰在国力走下坡路前也做了类似的事，但当债权人不愿再持有并抛售荷兰盾时，荷兰债务结构瞬间崩塌，货币地位和经济情况一落千丈。美国如今也借贷一大笔钱，并透过增发货币削减债务，但这暂时没能撼动美元和美债地位。 当头号大国不断“扩张版图”，直至维持它变得不再值得时，维护体系的成本变得高于收益。而全球大国体系无利可图，将进一步重创其财政状况，如今的美国正是如此。 因分配不平等，经济发展的成功自然扩大了贫富差距。那些拥有财富和权力的人（如在商业活动中获利或政府中人）相互照应，维持对他们有利的体制，普通人则远远落在后边，直至贫富分化已形成无法容忍的不公平。如今的美国也是如此。 衰弱阶段衰落的伏笔总是埋在黄金时代，鼎盛的国家会在倾泻的颓势中逐渐式微。这种衰落是因为国家在走下坡路时，能与之抗衡的力量已然在上文所述的领域中发展得相对壮大。 当国家债台高筑、央行面对疲软的经济只能寅支卯粮、下行状态又导致更多债务和经济问题时，国家不得不大量印钞，货币贬值。 如果贫富差距无限扩大、社会价值观两极分化、经济压力（无论者压力来自何处）无从释放，富人和穷人之间就很容易大动干戈，最初的几起冲突到后来会愈演愈烈。这通常会助长政治极端主义的气焰，也就是改革派（力图重新分配财富的人）和保守派（希望财富掌握在资本家等富人手中的人）的民粹主义。无论是民主还是集权国家都有可能成为民粹主义的土壤。比如20世纪30年代时，左翼极端民粹主义者成为斯大林主义者，而右翼则成为法西斯分子。民粹主义者往往更热衷于斗争、更尊崇权力而不是法律。 当富人们担心财富会被掳走，或者自己会成为众矢之的时，他们就会把万贯家财和身家性命都转移到自认为更安全的地方、资产和/或货币上。如果这种转移没被明令禁止，将会蚕食资产转出地的税收和收入，使其经历一个典型的恶性循环的资产空心化过程。税收的缩水更是雪上加霜，加剧了紧绷的局势，又加大了税收力度，迫使更多的富人一走了之，以及其他更糟的后果。比如我们现在观察到，某些社会问题的根源是富人逃离了税收较高的州，因为他们不想面对财政压力和贫富群体之间的鸿沟。资产空心化过于严重时，政府会出面制止——禁止资金从流失地源源不断地汇集到它们新落脚的地方、资产和/或货币，而想要明哲保身的人们会因此倍感恐慌。 发生撼动根基的事件会侵吞国家的生产力。财富蛋糕的尺寸小了一圈，人们为了抢夺萎缩中的资源而斗争；蛋糕日渐干瘪，人们又为了如何分配而斗争。不同阵营的民粹主义领导人在角力中卖力地呼号着，希望控制局势以重整秩序，这时民主和集权相比，尤为岌岌可危。这也是为什么在20世纪20年代和30年代，德国、日本、意大利和西班牙（以及一些小国）都被集权拔了民主阵营的旗子，而主要的民主国家（美国、英国和法国）也有了集权的影子。人们普遍认为，在混乱时期，集中而快速的决策比基于讨论的民主决策更可取，因此，当不服管教、诉诸暴力的群众斗争出现时，这场运动并非一无是处。 假如一个国家具备足够强大的经济、地缘政治和军事力量去挑战现有的主导力量，那么这些相互竞争的大国之间就有许多潜在的冲突隐患。因为和平裁决此类争端的体系并不存在，所以冲突总得通过一场硬碰硬的较量来解决。 当大国在外维持形象的成本大于其带来的收入时，国家的经济实力就被掏空了。与此同时，其他国家正在崛起，已经外强中干的大国又不想把手中的利益拱手送人。这种状态会使强撑着的大国在经济和军事上面临威胁，为了守住大国地位，军费开支一再扩大，国内经济却已然凋敝，让领导人更难征到税，也让他们更需要投入国内的支持。看到这一困境，敌国纷纷选择在大国衰落的迹象初显时出手。紧接着，大国将面临着在经济和军事方面迎战或撤退的艰难抉择。 如果其他外部冲击，比如自然灾害（瘟疫、干旱或洪水），在大国疲于应付内忧外患的脆弱时期发生，无异于在国家衰落的进程中注入了另一股摧枯拉朽的力量。 当一个国家中尸位素餐的人居多，不足以让该国在这个循环的阶段获胜时，也是一个问题。当然，由于每一位领导人只负责这个循环中的一小段，他们只能在前人留下的基础上解决问题，这意味着国运比领袖更能掌控一切。 当盛极而衰时，国家就走向了解构和重组时期。国家兴旺的原因走向了反面，变成了致命的弱点: 高负债 巨大的财富、价值和政治观点差距 国民之间合作破裂，转而互相攻讦 落后的教育和基础设施 为了维持过度扩张的状态，大国在新崛起力量的挑战下经历了煎熬的斗争、破坏和重组时期，孕育了新秩序，为新时代的来临奠定了基础。 储备货币大周期面这张图把每个大国的兴衰史都勾勒得十分清晰。如下图阴影区域所示，萧条，革命和战争造成的破坏重组很大程度上摧毁了旧系统并为新系统的出现奠定了基础，这些大萧条往往每10到20年会发生一次，但这个时间段可能存在更大的变数。紧接其后的就是美好新世界了，没有国家愿意和世界霸主去竞争头把交椅，学乖的人们开始和谐地工作发展。通常这些美好的时期持续的可以长达40至80年，但会有很大的波动。在上述的两个大周期中，同时也伴随着一些诸如短期债务危机/商业周期等持续7至10年的小周期。 荷兰大国衰败让位于英国大国，亦或是英国让位于美国，这个过程中都会发生以下大部分事情： 债务重组与债务危机 国家内部冲突，冲突最终导致财富重新分配 外部战争 储备货币地位崩溃 新一代的国内与国际秩序 上一次大萧条发生在1930-45年，从而推动了始于1945年的重建期。 货币和信贷系统的崩溃和重组导致了1930-45年的萧条，从而使得在1944年建立了以美元为基础的新全球货币体系（布雷顿森林体系）。 喧闹激荡的1920年代（Roaring 20s’）所产生的巨大贫富差距因萧条和战争而缩小，从而导致了财富和权利分配的根本性改变，全球性的战乱也改变了世界格局。 1945年后，一切都发生了翻天覆地的变化，美国成为世界霸主，金本位移位，以美元为基础的全球货币和信贷体系得以建立。 "},{"title":"Ray Dalio - 变化的世界格局与宏观周期","date":"2021-03-15T07:53:23.000Z","url":"/2021/03/15/Ray-Dalio-%E5%8F%98%E5%8C%96%E7%9A%84%E4%B8%96%E7%95%8C%E6%A0%BC%E5%B1%80%E4%B8%8E%E5%AE%8F%E8%A7%82%E5%91%A8%E6%9C%9F/","tags":["经济"],"content":"FROM： 为什么要关注全球历史的大趋势：每个人一生都只能够经历宏观周期中一小部分，因此时而会对长达50-70年大周期视而不见。而通常人生中最大机遇和失误，往往来自于错过了“人生中没有发生过，但在历史当中反复重演”的市场信号。 历史上重要事件由三大力量所驱动：长期货币和债务周期、国内财富与权力周期、国际财富与权力周期。三种力量往往相互融合、相互促进，共同决定了国家和全球的经济政治走势。 本系列重点关注世界舞台上长袖善舞的大国：主要包括3个储备货币国家：荷兰，英国和美国，以及其他6个重要大国：德国，法国，俄罗斯，印度，日本和中国。这些具体个例将提炼出历史反复发生的典型范例。 回看历史，有3个对经济整体趋势至关重要的事件： 经济增长困局：全球经济体的高负债率（high level of indebtedness）+低利率，将会极大程度限制全球各大央行刺激经济增长的能力； 内部冲突：各国家内部巨大的贫富差距与相应的政治分歧，带来了不断恶化的内部社会与政治冲突； 外部冲突：中国作为一个不断发展且冉冉上升的世界强国（world power），正在挑战过分扩张后显得力不从心的美国，这个过程中产生了很多地缘冲突与贸易冲突。 历史通常呈现为一长一短两种典型周期的吻合与交叉，分别是10-20年左右的“过渡性”周期，与随之而来的50-100年的经济政治大周期。 这些经济政治大周期又由两种元素组成： 安乐繁荣发展期：决策者（people with power）在一起和谐共处并携手并进，以合适可持续的方式追求创造财富； 痛苦下行震荡期：各方为争夺权力和财富不断摩擦产生冲突，打乱了经济的和谐发展与生产力的不断提升，有时甚至会导致战争和社会动荡（revolution）。 为什么要关注过去100年历史中的重要经济、市场事件 人们往往会错过生命中重要的“进化时刻”的原因是，我们每个人都只能够经历宏观周期中一小部分、且发生在现在的事情。 我的职业生涯当中最大的那些错误，往往来自于错过了那些“在我的人生中没有发生过，但在历史当中反复重演”的市场信号（market moves）。这些错误教会了我需要从历史和全球的角度来看经济和市场的发展历程，来去学习那些宝贵的市场运作方式（mechanics），更重要的是在这其中提炼出一些普适的原则（timeless and universal principles）。 我的工作方式是研究尽可能多的特定事件，并在此过程中抽象形成一个典型事件，我称之为典型范例（archetype）。 相对于中国和印度等新兴大国，美国的这些10年经济指标（例如教育质量和负债水平）正在不断恶化。 在2016年特朗普当选后不久，随着发达国家民粹主义的日益明显，突显了当下的深刻社会和政治冲突背后的财富差距和价值观分歧，这跟1930年代经济大萧条时的财富、价值观分歧非常相似。 我发现美国人们正经历着巨大的经济状况差距；而这些差距，往往被【经济平均水平】的烟雾弹所掩盖。 三大力量驱动重要事件发生1) 长期货币和债务周期在当下正常人的一生中，利率都没有低到今天这样的水平，乃至出现了负利率的情况。在2020年初，超过10万亿美元的债务处于负利率状态，并且为了再融资和满足财务赤字的需求，我们很快将需要发行数量庞大的新债务。雪上加霜的是，巨额养老金和医疗保险也同时快要到期亟待支付了。如此低的利率下债务所用的结算货币贬值会发生什么？如果投资者逃离以世界常见储备货币（即美元，欧元和日元）结算的债券，那么央行将采取什么措施应对？ 储备货币（reserve currency）是全世界公认的交易和储蓄货币。能够印制世界主要货币的国家（现在是美国）享有特权且处于非常强大的地位，而以世界储备货币计价的债务（即以美元计价的债务）是实现世界资本市场平稳运转、经济稳定发展这一目标的最基本构成要素。 在过去的历史当中，基本上所有的“世界储备货币”的地位最终都不可避免的被终结了；而对于享有这种特殊特权（印发“世界储备货币”）的国家而言，这种终结往往会导致非常糟糕的结局。 因此我也开始怀疑和思考，美元会否、何时、为什么会在成为世界领先的储备货币的过程中走向下降和终结，以及这将如何改变当下的世界格局与经济形势。 2) 国内财富和权力周期当财富和价值观差距巨大并且经济不景气时，关于如何分配产出和收入的冲突将会大幅增多。 除了这些传统工具（削减利率）已经无效之外，印刷额外的钞票和购买金融资产（现在称为“量化宽松”）也扩大了贫富差距，因为购买金融资产将会推高这些资产的价格，而往往能够购买金融资产的，是富人而不是穷人。 3) 国际财富与权力周期在国际角度上来看，美国在我这一代人的一生中，第一次碰到了旗鼓相当的对手。 中国已经以多个方面比美国更具有竞争力，并且以比美国更快的速度实现经济增长。 现在我看到了冲突在迅速增加，尤其是在贸易、技术、地缘政治、资本领域，以及经济/政治/社会形态等。我忍不住想知道，这些冲突以及由此产生的世界秩序变化将如何在未来几年里不断发展，并对我们所有人产生什么样的影响。 三种力量的融合这三股力量的融合意味着，如果不了解其中任何因素的重叠影响，就不可能理解其中任何一股力量。 为了了解这三股力量本身、及三者的融合可能意味着什么，我查看了过去500年来所有主要帝国（empires）及其货币的兴衰，其中最密切地关注了三个体量最大的：美国和现在最重要的美元，之前最重要的大英帝国和英镑，以及更久远的荷兰帝国和荷兰盾。我也关注了德国，法国，俄罗斯，日本，中国和印度这六个非常重要但统治程度相对小一些的帝国（empires）。在这六个国家中，我给予了中国最多的关注，并回顾了其600年以前的历史。 技术创新和自然灾害在推动这些帝国兴衰的过程中发挥了重要作用。通过考察不同帝国和不同时期的案例，我发现地位重要的帝国周期通常持续大约150-250年，在这个周期中，巨大的经济，债务和政治周期持续大约50-100年。"},{"title":"MySQL 的 MGR","date":"2021-03-11T07:38:44.000Z","url":"/2021/03/11/MySQL-%E7%9A%84-MGR/","tags":["数据库","MySQL"],"content":"MySQL 高可用架构的历史MySQL 自带的主从复制机制，本身并不能实现自动高可用。 早期使用开源组件来搭 MySQL 集群的方案，使用 MMHA。当代 MySQL 官方自己主推的方案是 MySQL cluster。这些老的方案，优先保证MySQL服务的持续可用，在异常切换情况下，可能出现主机上部分数据未能及时同步到从库，造成主从切换后数据丢失。但是包括金融支付在内的一些业务，对于数据库服务既要求持续可用、也要求数据强一致（可以在性能上做出一些让步）。 因此，当代的 MySQL 官方提供了组复制（MySQL Group Replication）的方案，构建了新一代的 MySQL 高可用强一致服务。 Master-Slave（MS）架构高可用概述MS架构高可用基础高可用MySQL是依赖复制（Replication）技术实现的，复制解决的基本问题就是，让一台数据库服务器的数据同步到其它服务器上。MySQL数据库的复制有如下三个步骤。 在主库上把数据更改记录到二进制日志（Binary Log）中（这些记录被称为二进制日志事件）。 备库将主库上的日志复制到自己的中继日志（Relay Log）中。 备库读取中继日志中的事件（Event），将其回放到备库数据之上。 以上只是概述，实际上每一步都很复杂，更详细的描述了复制的细节。 MS架构高可用痛点MS架构围绕着复制方式实现高可用，复制的痛点主要围绕着数据一致性。如果第一个节点的数据进行了更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是老数据，这就是典型的数据不一致的问题。 在高可用数据库进行Failover时，可能数据还没有复制完毕，这样就出现了数据不一致的风险，反应在实际业务上可能是数据丢失了，或错乱了。MySQL在数据复制上进行了旷日持久的改进，由异步复制（Asynchronous Replication）到半同步复制（Semisynchronous Replication），再到增强半同步复制（Enhanced Semisynchronous Replication），几近使RPO趋于0，直至组复制（Group Replication）的出现。 异步复制MySQL默认的复制就是异步复制，主库在执行完用户提交的事务后，将事务事件写入到Binlog文件中，这时主库只会通知Dump线程发送这些新的Binlog，然后主库就会继续处理用户的提交，而不会保证Binlog传送到任何一个备库上。 若主库发生Crash，其上已经提交的事务可能并没有传送到备库上，此时Failover，可能就会导致新主库上的数据不完整，出现了数据不一致性的问题。 半同步复制半同步复制与异步复制不同的是，其在主库执行完用户提交的事务后，等待至少一个备库将接收到的Binlog写入Relay Log后，并返回给主库ACK，主库才会继续处理用户的提交。这里主库等待备库返回ACK的时间点，由参数rpl_semi_sync_master_wait_point=AFTER_COMMIT设置；等待几个备库返回ACK，由参数rpl_semi_sync_master_wait_for_slave_count=1设置。其中还有一个半同步超时的设置，由参数rpl_semi_sync_master_timeout=100控制，超时后半同步复制退化为异步复制。 半同步复制提高了数据的安全性，同时也会造成一定程度的延迟，该延迟至少是一个RTT（Round Trip Time）。 从这个方案起，就一定会带来一个写入抬升，很容易导致业务对时延的容忍要翻倍，业务能够逐步容忍超过 30ms -80 ms 的写入抬升（写入性能会下降超过 50%），才能逐步实现同城/异地的多活。 增强半同步复制增强半同步复制与半同步复制的不同之处是，其等待备库返回ACK的时间点不同。在MySQL中一个Commit过程由三个步骤组成：第一，Prepare the transaction in the storage engine (InnoDB)；第二，Write the transaction to the binary logs；第三，Complete the transaction in the storage engine。增强半同步复制等待备库ACK的时间点，由参数rpl_semi_sync_master_wait_point=AFTER_SYNC配置，是在Commit的第二，和第三步骤之间。不同于半同步复制等待备库ACK的时间点，是在Commit的第三步骤之后。试想对于增强半同步复制，在主库等待备库返回ACK时发生了Crash，由于该Commit还没最终结束，用户在主库上不会看到变更。当Failover后，用户在新主库上也不会看到变更，不存在数据不一致的问题。而对于半同步复制，由于该Commit已结束，用户在主库上会看到变更。当Failover后，用户在新主库上反而看不到变更，出现了数据不一致的情况。可见增强半同步复制，比半同步复制，在保证数据一致性上又前进了一步。 证明同步写远端的部分应该总是在 commit 之前，而不是 commit 之后。这是一个简单，但不易察觉的问题。 MGR跨越MySQL Group Replication（后简称MGR）的出现让大家眼前一亮，其建设性的以插件（Plugin）的方式添加到MySQL现有体系架构中，基于原生复制技术，使用了Binary Log，Row-based logging，和GTID等特性，使用了Paxos一致性协议的数据复制逻辑，保证了数据的一致性。 下图展示了Group Replication插件的层次体系，逐步了解下每个模块的大致作用。 APIs - Capture/Apply/Lifecycle：插件设置的一组API，用于和MySQL Server交互通信。 Capture/Applier/Recovery：插件设置的一组组件，Capture组件负责追踪事务执行时的上下文消息；Applier组件负责执行异地事务；Recovery组件管理全局恢复，如节点加入Group时，选择Donor，又或连接Donor失败重连。 Replication Protocol Logics：该模块实现了复制协议的逻辑，负责处理事务冲突检测，接收和发送事务消息到Group中。 Group Communication System（GCS）：该层属于高层API，其抽象了构建复制状态机的属性，将插件下层通信层的实现和上层进行了解耦。 Group Communication Engine（XCom）：通信引擎，Paxos协议的核心实现，负责Group中成员的通信。 组复制下图显示了MGR与普通MySQL复制模式的区别，在MGR中提交事务时，事务在引擎层完成Prepare，写Binlog之前会被MySQL预设的钩子（Hook）before_commit拦截，进入到MGR层，其将事务执行相关的信息打包，通过Paxos一致性协议（Consensus）进行全局排序后发送给MGR各个节点，当超过半数（N/2+1）的节点（包括它自己）回应后，发送消息告诉所有节点，这个数据包同步成功。各节点独自进行认证（Certify）。若认证通过，本地节点写Binlog完成提交。异地节点写Relay Log，由建立的复制通道（Replication Channel）group_replication_applier完成事务并行回放。若认证不通过，就会进行回滚（Rollback）。 认证类似 Paxos 里面对于 proposal 的 accept，也类似 2PC 里面的 update 后的 canCommit，不然会触发回滚，是一个收集 ballot 的过程。 When a read-write transaction is ready to commit at the originatingserver, the server atomically broadcasts the write values (the rowsthat were changed) and the corresponding write set (the uniqueidentifiers of the rows that were updated). Because the transaction issent through an atomic broadcast, either all servers in the groupreceive the transaction or none do. If they receive it, then they allreceive it in the same order with respect to other transactions thatwere sent before. All servers therefore receive the same set oftransactions in the same order, and a global total order isestablished for the transactions. However, there may be conflicts between transactions that executeconcurrently on different servers. Such conflicts are detected byinspecting and comparing the write sets of two different andconcurrent transactions, in a process called certification. Duringcertification, conflict detection is carried out at row level: if twoconcurrent transactions, that executed on different servers, updatethe same row, then there is a conflict. The conflict resolutionprocedure states that the transaction that was ordered first commitson all servers, and the transaction ordered second aborts, and istherefore rolled back on the originating server and dropped by theother servers in the group. 当代版本的 MGR 先不支持多主模式，虽然上图支持自动冲突检测，但不支持自动冲突解决。 MGR 的写入性能最差，但读写性能非常好。"},{"title":"秒杀通用解决方案","date":"2021-03-10T14:30:13.000Z","url":"/2021/03/10/%E7%A7%92%E6%9D%80%E9%80%9A%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","tags":["数据库"],"content":"秒杀的实质秒杀的实质，是围绕库存管理展开的并发读写如果架构设计里面包含商品系统，包含库存，秒杀就要解决库存热点行高并发读写问题。 秒杀的底线是：不能超卖。qty库存 ≥ qty卖出 &amp;&amp; qty库存 - qty卖出 ≈ 0。秒杀能够容忍的一些思路：渐进趋于一致，允许漏卖。 秒杀架构的特性 高性能：秒杀架构要承载的访问流量比平时高出许多倍，涉及大量的并发读和并发写，因此支持高并发访问非常关键。 一致性：秒杀活动中有限数量的商品在同一时刻被很多倍的请求同时扣减库存，在大并发更新的过程中要保证数据准确，不能发生超卖的问题（超卖，本来应该卖完下架的商品，在前台展示依然有库存，依然不停的被卖出），即库存是多少，理应卖出多少（qty库存 ≥ qty卖出 &amp;&amp; qty库存 - qty卖出 ≈ 0）。 高可用：秒杀架构虽经多次打磨优化，但现实中总难免出现一些考虑不到的情况，要保证系统的高可用，还要设计一个兜底预案，以便在最坏的情况发生时仍能从容应对。 秒杀技术难点 在有限的资源下，秒杀链路承载合理的最大流量。 大并发下扣减库存准确，“一致性”中说到的“超卖”往往发生在该环节，减库存一般有下面几个方案： 下单减库存，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样基本不会出现超卖的情况。但是，有些人下完单可能并不会付款。 付款减库存，即买家下单后，并不立即减库存，而是等到用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为商品可能已经被其他人买走了。 预扣库存，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如10分钟），超过这个时间，库存将会自动释放，释放后其他买家可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款购买成功。 秒杀典型时序 查询库存 创建订单 扣减库存（2 和 3 应该在一个事务里） 更新订单 付款 秒杀的 3 大挑战超卖2012 年的双11 产生了大量的超卖。事后复盘，大家发现系统中出现了未知的热点。 热点问题缓存雪崩、缓存击穿，进而导致服务雪崩。 吞吐瓶颈在高并发的情况下，整体吞吐水平会低于正常水平。 准则热点发现 根据业务场景，提前摸清热点数据。 智能识别、动态散列，能够根据基线，自动识别热点，并扩容对应分片。 做好隔离链路、机器、系统都要做好隔离、缓存和限流。不止考虑业务系统层面的限流和熔断，如果有必要，秒杀的资源要单独做好隔离。 动静分离把用户请求的数据分为静态和动态数据。 基于时间分片削峰 答题 排队，同步变异步，从紧耦合变松耦合 读缓存（舍 c 得 a） 最终实现漏斗状的写，实现有效写入的数量足够小。 数据库的相关配置说到数据库层秒杀优化，我们到底在做什么：加速事务执行的每个关键环节，降低事务耗时。 库存分片，分而治之，提升热点行变更TPS，需要业务配合改造。 降低行锁（row lock）持有时间，持锁时间长的SQL放在最后，提升并发。 降低事务耗时，关闭deadlock detect、binlog group commit，和双1，加速事务。 减少线程间切换，使用线程池Threadpool，提升并发效率，正在测试中。 现实案例分析现实案例分析 1热点商品的 sku，同步select for update 的锁定，在秒杀多个商品时冲突很严重，一种解决方案是使用 lua 的原子脚本来实现分布式锁，再异步锁定 sku 行，然后要加上对热点商品的限流，在前端撞限流来减轻 db 的压力，提前让漏斗变小。 乐观锁不适合高并发场景，因为重试很容易让系统过载。 悲观锁适合高并发场景-扣减库存的关键还是要排队，要看业务流程中是否允许异步化，允许就用 mq 排队，不允许就用悲观锁排队。 现实案例分析 2用 nowait 或者 skip locked 来减少锁等待，避免阻塞和死锁。 每个 sql 的执行时间是 1.25ms，这一行被更新的 tps 就是 800。但实际上单行事务非常少，所以大事务晚释放锁会让行的并发性降低。 方法： 合并 update，把热点 key 的更新语句在内存里 merge 一下。 组提交：把双一写关掉，让 fsync 慢一点。 删除多余的索引：需要考虑数据库的自治系统的建设。 秒杀是一种系统工程，需要业务理解数据库，关键还是在业务系统中做优化。 阿里和美团的解决方案阿里使用 alisql 的内部排队和组提交事务的功能，大秒系统可以达到 8 万的 tps。其中排队指的是让请求的事务按照求锁顺序【使用信号量排队】获取锁，而不是将事务异步化，这可以让 MySQL 内核的死锁检测时间复杂度从 O(N*N)下降到 O(N)。 美团的解决有：架设一个 Redis 集群，通过 lua 脚本，实现一个在 redis 里的事务，扣减库存在 Redis 里实现，然后解析 aof 文件异步地真扣减库存，同时加上一个 mq（先写 redis 再写 mq），防止 Redis 丢失数据。mq 和 redis 对写操作做了建模，写操作带有版本，这样可以防止分布式环境下消息乱序和错漏重的问题。我猜这个版本可以是 seqNum，也可以是 行 version。这个方案被称作双通道冗余，在保证高可用的前提下逐步区域一致。aof 文件是一个纯异步复制的模式。这里使用的架构方案有点在本地做服务编排和 saga 的感觉。"},{"title":"数据库选型","date":"2021-03-10T11:59:56.000Z","url":"/2021/03/10/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%80%89%E5%9E%8B/","tags":["数据库"],"content":"业务场景分类讨论 OLTP 类 金融账务类：账务、信用 交易流水类：订单、运单、交易、支付、物流 库存类：库存中心 IOT 控制类：取餐柜、单车、电单车 商品类：商品中心 用户/商户信息类：用户商户信息、优惠券、游戏 ugc：点评评论、弹幕、用户消息 近线型 近（离线写）-在线读 数据中台类：MySQL 多集群汇总存储 日志流水类：IOT 上报流水 归档存储类：交易流水冷热分离 计算辅助类：ETL 过程的中间存储 高可用与强一致MGR 是 Paxos 的一种变种，可以强一致不丢数据。 RPO Recovery Point Objective：数据恢复点目标，业务能够容忍的数据丢失量。除了强一致性的共识算法，不能保证 RPO 变 0（半同步还是可能丢失数据）。RTO Recovery Time Objective：恢复时间目标。业务能够容忍的停止服务的最长时间，即从灾难发生到业务系统恢复服务功能所需要的最短时间周期。 不要用冷冰冰的 SLA 来理解数据库的高可用。 基于 dts 的方案，是异步写入，不可能等远端的 ack，所以 rpo 为 0。能不能选用强一致的方案，要看业务的容忍程度。 Aurora 应该使用数据卷和数据库实例分离的设计，所以不是 shared-nothing 的架构： Aurora 共享存储架构使您的数据独立于集群中的数据库实例。例如，您可以快速添加数据库实例，因为 Aurora不会创建表数据的新副本。相反，数据库实例连接到已包含所有数据的共享卷。您可以从集群中删除数据库实例，而无需从集群中删除任何基础数据。仅当您删除整个集群时，Aurora才会删除数据。 可扩展性 原生分布式的架构扩展最简单。 架构没有银弹，一定会牺牲掉一些完整的 ACID 的特性，比如没有全局二级索引，或者没有全局事务。 事务特性要关注事务的内外一致性。 预聚合的 OLAP 的性能会很好。 表结构变更 在线实时分析 结论不同的数据结构和工作模式适应不同的业务场景，不同业务场景的选型意味着要根据领域模型和领域流程做出合理的选择。平衡性最好的选择还是 RDBMS。"},{"title":"MySQL实战45讲","date":"2021-03-10T06:53:58.000Z","url":"/2021/03/10/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2/","tags":["数据库","MySQL","存储"],"content":"01 | 基础架构：一条SQL查询语句是如何执行的？连接器管 tcp 连接。全局的权限、配置的修改不会直接在存量 session 里生效。 show processlist 可以显示 Sleep status 的空闲连接。这个命令看起来是管理 process，其实是管理 session。 默认的连接断开时间是 8 小时，是由参数 wait_timeout 控制的。 建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 长连接会把本连接临时使用的内存管理在连接对象里（类似 ThreadLocal 之于线程），这些资源在连接断开的时候才释放，解决方案就是： 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 MySQL 8.0 以后不会再有查询缓存了。 02 | 日志系统：一条SQL更新语句是如何执行的？重要的日志模块：redo logredo log 是 WAL 日志模块。一个事务会把变更写入内存 + Redo log，然后后台线程再把变更更新到磁盘中。 redo log 通常 4 个 1gb 的文件，在写入一个文件满，或者到达 checkpoint 以后，会 flush 数据到磁盘。checkpoint 的意思是，过了这个点，数据的原地变更已经完成（之前的 redo log 不需要再 apply）。 有了 redo log，就有 crash-safe。 重要的日志模块：binlog两种日志有以下不同： redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 redo log 的两阶段提交： 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。 prepare 和 commit 的两阶段提交在 MySQL 的本地事务上也有，不独分布式事务上有。但 MySQL 内部自己也有分布式事务。 两阶段提交binlog 本身意味着可以配合备份恢复丢失的记录-这和 redo log 的功能有些像。 由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。 仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？ 先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。 先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。 可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 小结我还跟你介绍了与MySQL日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。 近端 prepare -&gt; 远端写 -&gt; 成功后近端 commit 数据库一天一备好，还是一周一备好？一天一备，需要一天的 binlog；一周一备，需要一周的 binlog。binlog 越多 RTO（恢复目标时间）越长，binlog 越少，要存储备份需要的空间越多。 03 | 事务隔离：为什么你改了我还看不见？提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。最经典的例子就是转账，你要给朋友小王转100块钱，而此时你的银行卡只有100块钱。 转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这100块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。 简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。 而且在全部成功和失败以前，不能读到中间状态，要模拟并发编程的原子性。 事务隔离的实现按照阿里数据库月报的分析，可见性的 readview 的数据来源是： 由于在修改聚集索引记录时，总是存储了回滚段指针和事务id，可以通过该指针找到对应的undo记录，通过事务Id来判断记录的可见性。当旧版本记录中的事务id对当前事务而言是不可见时，则继续向前构建，直到找到一个可见的记录或者到达版本链尾部。（关于事务可见性及readview，可以参阅我们之前的月报） 当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在MySQL5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。 事务的启动方式 如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL的事务启动方式有以下几种： 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。 setautocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit或 rollback 语句，或者断开连接。 有些客户端连接框架会默认连接成功后先执行一个setautocommit=0的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。 因此，我会建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。 但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次“begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用commit work and chain语法。 在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work andchain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 5 04 | 深入浅出索引（上） 哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。 有序数组索引只适用于静态存储引擎，在等值查询和范围查询场景中的性能就都非常优秀。 不管是哈希还是有序数组，或者N叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM树等数据结构也被用于引擎设计中，这里我就不再一一展开了。你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。 基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的： 只有一个索引； 该索引必须是唯一索引。 你一定看出来了，这就是典型的KV场景。 6 05 | 深入浅出索引（下） 这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 所以现在你知道了，这段开头的问题里，我们要为高频请求创建(身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。 那么，如果既有联合查询，又有基于a、b各自的查询呢？查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。 这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。 而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断（所以当代的 where 语句，只要能够在索引里过滤，就不会在 server 层过滤），直接过滤掉不满足条件的记录，减少回表次数。 可以使用alter table T engine=InnoDB来重建主键，不必先删除主键再重建主键（理论上可以重建任意主键）。 7 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？ 顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with readlock(FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都select出来存成文本。 官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 你一定在疑惑，有了这个功能，为什么还需要FTWRL呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。 所以，single-transaction方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。 你也许会问，既然要全库只读，为什么不使用set globalreadonly=true的方式呢？确实readonly方式也可以让全库进入只读状态，但我还是会建议你用FTWRL方式，主要有两个原因： 一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。 但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。 FTWRL 也可以用来做主从切换。 MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlocktables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，locktables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write;这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlocktables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用locktables命令来控制并发，毕竟锁住整个表的影响面还是太大。 另一类表级的锁是MDL（metadatalock)。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。这也是高负载的服务器很难发生备份的原因，备份连接一直都求不到 MDL 锁 基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？ 首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。 但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？ 这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在altertable语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。 MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT/WAIT n这个语法。 ALTER TABLE tbl_name NOWAIT add column … ALTER TABLE tbl_name WAIT Nadd column … 非阻塞等待、计时等待很重要 8 07 | 行锁功过：怎么减少行锁对性能的影响？MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。 从两阶段锁说起 这个问题的结论取决于事务A在执行完两条update语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。 知道了这个答案，你一定知道了事务A持有的两个记录的行锁，都是在commit的时候才释放的。 也就是说，在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。 假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到以下操作： 从顾客A账户余额中扣除电影票价； 给影院B的账户余额增加这张电影票价； 记录一条交易日志。 也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？ 试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。 根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。 好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。 MySQL 处理死锁的方式有 2： 看哪个事务先达到 innodb_lock_wait_timeout 定义的超时，自己回滚。 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。 你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。 这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成0的时候，代码要有特殊处理。 但这需要处理类似负载均衡的问题，对于单一数据的分片更新是一个复杂问题。 9 08 | 事务到底是隔离的还是不隔离的？ begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用starttransaction with consistent snapshot 这个命令。 在MySQL里，有两个“视图”的概念： 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。 “快照”在MVCC里是怎么工作的？ 实际上，我们并不需要拷贝出这100G的数据。我们先来看看这个快照是怎么实现的。 InnoDB里面每个事务有一个唯一的事务ID，叫作transactionid。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transactionid赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。 如图2所示，就是一个记录被多个事务连续更新后的状态。 图中虚线框里是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的rowtrx_id也是25。 你可能会问，前面的文章不是说，语句更新会生成undo log（回滚日志）吗？那么，undo log在哪呢？ 实际上，图2中的三个虚线箭头，就是undo log；而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undolog计算出来的。比如，需要V2的时候，就是通过V4依次执行U3、U2算出来。 明白了多版本和row trx_id的概念后，我们再来想一下，InnoDB是怎么定义那个“100G”的快照的。 按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。 因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。 当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。 在实现上，InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。 数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。 而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。 这个视图数组把所有的row trx_id 分成了几种不同的情况。 这样，对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。 比如，对于图2中的数据来说，如果有一个事务，它的低水位是18，那么当它访问这一行数据时，就会从V4通过U3计算出V3，所以在它看来，这一行的值是11。 你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的2或者3(a)的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。 所以你现在知道了，InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 接下来，我们继续看一下图1中的三个事务，分析下事务A的语句返回的结果，为什么是k=1。 这里，我们不妨做如下假设： 事务A开始前，系统里面只有一个活跃事务ID是99； 事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务； 三个事务开始前，(1,1）这一行数据的row trx_id是90。 这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101],事务C的视图数组是[99,100,101,102]。 从图中可以看到，第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。这时候，这个数据的最新版本的rowtrx_id是102，而90这个版本已经成为了历史版本。 第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。这时候，这个数据的最新版本（即rowtrx_id）是101，而102又成为了历史版本。 你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。 好，现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的： 找到(1,3)的时候，判断出row trx_id=101，比高水位大，处于红色区域，不可见； 接着，找到上一个历史版本，一看row trx_id=102，比高水位大，处于红色区域，不可见； 再往前找，终于找到了（1,1)，它的row trx_id=90，比低水位小，处于绿色区域，可见。这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。 这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。 所以，我来给你翻译一下。一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 现在，我们用这个规则来判断图4中的查询结果，事务A的查询语句的视图数组是在事务A启动的时候生成的，这时候： (1,3)还没提交，属于情况1，不可见； (1,2)虽然提交了，但是是在视图数组创建之后提交的，属于情况2，不可见； (1,1)是在视图数组创建之前提交的，可见。 你看，去掉数字对比后，只用时间先后顺序来判断，分析起来是不是轻松多了。所以，后面我们就都用这个规则来分析。 只有已提交事务会产生（可见的）新版本，否则不会有。 更新逻辑 细心的同学可能有疑问了：事务B的update语句，如果按照一致性读，好像结果不对哦？ 你看图5中，事务B的视图数组是先生成的，之后事务C才提交，不是应该看不见(1,2)吗，怎么能算出(1,3)来？ 是的，如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。 但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的setk=k+1是在（1,2）的基础上进行的操作。 所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。 所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。 这里我们提到了一个概念，叫作当前读。其实，除了update语句外，select语句如果加锁，也是当前读。 所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或forupdate，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。 update 一定会触发当前读，update 成功一定会导致行视图的版本的 row trx_id 成为本事务，不管提不提交都可见。 所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或forupdate，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。 mysql&gt; select k from t where id=1 lock in share mode; mysql&gt; select kfrom t where id=1 for update; 再往前一步，假设事务C不是马上提交的，而是变成了下面的事务C’，会怎么样呢？ 事务C’的不同是，更新后并没有马上提交，在它提交前，事务B的更新语句先发起了。前面说过了，虽然事务C’还没提交，但是(1,2)这个版本也已经生成了，并且是当前的最新版本。那么，事务B的更新语句会怎么处理呢？ 这时候，我们在上一篇文章中提到的“两阶段锁协议”就要上场了。事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。 ![事务B更新逻辑图（配合事务 C）.png](事务B更新逻辑图（配合事务 C）.png) 到这里，我们把一致性读、当前读和行锁就串起来了。 现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？ 可重复读的核心就是一致性读（consistentread）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 小结InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。 对于可重复读，查询只承认在事务启动前就已经提交完成的数据； 对于读提交，查询只承认在语句启动前就已经提交完成的数据； 上期问题时间我在上一篇文章最后，留给你的问题是：怎么删除表的前10000行。比较多的留言都选择了第二种方式，即：在一个连接中循环执行20次 delete from T limit 500。 确实是这样的，第二种方式是相对较好的。 第一种方式（即：直接执行delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。 除此之外，还会造成 binlog 过大。大事务是万恶之源。 第三种方式（即：在20个连接中同时执行delete from T limit 500），会人为造成锁冲突。 10 09 | 普通索引和唯一索引，应该怎么选择？现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？ 查询过程对于 select id from T where k=5。如果 k 实际上是唯一的。则普通索引和唯一索引在性能上的差别微乎其微。因为通常查询都可以（也必须）在一个数据页里完成，在内存数据页里面做线性搜索的成本微乎其微。 更新过程 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在changebuffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行changebuffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，changebuffer在内存中有拷贝，也会被写入到磁盘上。 将changebuffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。 显然，如果能够将更新操作先记录在changebuffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用bufferpool的，所以这种方式还能够避免占用内存，提高内存利用率。 那么，什么条件下可以使用change buffer呢？ 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用changebuffer了。 因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。 change buffer用的是buffer pool里的内存，因此不能无限增大。changebuffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示changebuffer的大小最多只能占用buffer pool的50%。 现在，你已经理解了changebuffer的机制，那么我们再一起来看看如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。 第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下： 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。 但，这不是我们关注的重点。 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在changebuffer，语句执行就结束了。 将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。changebuffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 之前我就碰到过一件事儿，有个DBA的同学跟我反馈说，他负责的某个业务的库内存命中率突然从99%降低到了75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。 所以结论是唯一索引带来的检查成本会导致 buffer pool 的频繁 swapping 调度。 change buffer的使用场景 通过上面的分析，你已经清楚了使用change buffer对更新过程的加速作用，也清楚了changebuffer只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用changebuffer都可以起到加速作用吗？ 因为merge的时候是真正进行数据更新的时刻，而changebuffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，changebuffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时changebuffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在changebuffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了changebuffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。 简而言之：change buffer 只适用于非唯一二级索引（也就是本文说的普通索引）的旁路修改，唯一索引的插入/更新需要内存里做检查和维护工作，需要额外的性能开销。 简单地把数据分为： 日志型：写多读少。change buffer 是有用的。 交易型：写不如读多。change buffer 不太有用，因为读需要频繁触发 merging。这种时候如果我们增加了唯一索引，则写性能会下降。 通常，除了业务要求，明确保证全局唯一或者确保幂等性，我们应当优先使用非唯一索引，否则不如把 change buffer 关掉。 索引选择和实践 回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，changebuffer都能提升更新性能。 在实际使用中，你会发现，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。 特别地，在使用机械硬盘时，changebuffer这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把changebuffer 尽量开大，以确保这个“历史数据”表的数据写入速度。 change buffer 和 redo log 所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而changebuffer主要节省的则是随机读磁盘的IO消耗。 11 10 | MySQL为什么有时候会选错索引？对于由于索引统计信息不准确导致的问题，你可以用analyze table来解决。 而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。 上期问题时间我在上一篇文章最后留给你的问题是，如果某次写入使用了change buffer机制，之后主机异常重启，是否会丢失change buffer和数据。 这个问题的答案是不会丢失，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。 12 11 | 怎么给字符串字段加索引？ 同时，MySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。 通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。 但是，对于这个查询语句来说，如果你定义的index2不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。 也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。 实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。 前缀索引对覆盖索引的影响 也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。 其他方式 对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？ 比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前6位一般会是相同的。 假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。 按照我们前面说的方法，可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。 但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。 那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。 答案是，有的。 第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写： mysql&gt; select field_list from t where id_card =reverse(‘input_id_card_string’);由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用count(distinct)方法去做个验证。 第二种方式是使用hash字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。 mysql&gt; alter table t add id_card_crc int unsigned, addindex(id_card_crc);然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。 mysql&gt; select field_list from t whereid_card_crc=crc32(‘input_id_card_string’) andid_card=’input_id_card_string’ 这样，索引的长度变成了4个字节，比原来小了很多。 接下来，我们再一起看看使用倒序存储和使用hash字段这两种方法的异同点。 首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X,ID_Y]的所有市民了。同样地，hash字段的方式也只能支持等值查询。 它们的区别，主要体现在以下三个方面： 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段。当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段也差不多抵消了。 在CPU消耗方面，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数。如果只从这两个函数的计算复杂度来看的话，reverse函数额外消耗的CPU资源会更小些。 从查询效率上看，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。 上期问题时间事务 a 的存在，会导致事务 b 删除的数据不能真的被删除。 查询优化器的优化结果可能需要 analyze table 做校正。 13 12 | 为什么我的MySQL会“抖”一下？ 回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。 导致脏页刷盘（到数据页）的情况大概有四种： 1、redolog（logfile） 用完，引发 checkpoint。2、lru list 和 free list 不够用，需要新页，导致旧页淘汰，旧页引发了 checkpoint。3、cleaner 线程定时工作。4、MySQL 重启。 MySQL 会尽量保证，如果内存里能读到数据页，内存里的数据页的状态就是最新的（哪怕是脏页，但数据实际上已经进入 redolog，只是没有写入磁盘数据页而已）；如果内存里没有相关数据页，那么磁盘上的数据页就是最新的（除非发生灾难恢复，需要从 redo log 里面 apply 出最新的数据）。 InnoDB刷脏页的控制策略innodb_max_dirty_pages_pct + lsn + checkpoint 的位移 + innodb_io_capacity 综合运算，可以得出刷新脏页的速度。 一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。 在InnoDB中，innodb_flush_neighbors参数就是用来控制这个行为的，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。 找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。机械硬盘的随机IOPS一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。 而如果使用的是SSD这类IOPS比较高的设备的话，我就建议你把innodb_flush_neighbors的值设置成0。因为这时候IOPS往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。 在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。 已知会造成查询阻塞的原因： 1、查询触发了锁-mdl 锁、读锁不兼容写锁。2、iops 打满。3、存储引擎正在刷新脏页-这时候即使 iops 不满，checkpoint 的存在也会导致 tps 下降。 上期问题时间存学号的问题，最佳解是增加一个转化列，把字符串转化为数字，单独给这列加索引，用这个索引来加速查询。给字符串加索引其实关注的是怎么把有信息量的数据从字符串中截取出来。 14 13 | 为什么表数据删掉一半，表文件大小不变？将innodb_file_per_table设置为ON，是推荐做法。通过drop table命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。 删除记录，页空间不一定可以复用，所以数据文件不会变小。 删除整页，页空间可以被复用，但数据文件也不会变小。 插入数据，造成分裂的话，数据文件也会产生空洞。 重建表 这里，你可以使用alter table A engine=InnoDB命令来重建表。在MySQL5.5版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自动完成转存数据、交换表名、删除旧表的操作。 显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会造成数据丢失。因此，在整个DDL过程中，表A中不能有更新。也就是说，这个DDL不是Online的。 而在MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。 我给你简单描述一下引入了Online DDL之后，重建表的流程： 建立一个临时文件，扫描表A主键的所有数据页； 用数据页中表A的记录生成B+树，存储到临时文件中； 生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态； 用临时文件替换表A的数据文件。 临界区： 可以看到，与图3过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表A做增删改操作。这也就是OnlineDDL名字的来源。 我记得有同学在第6篇讲表锁的文章《全局锁和表锁：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL之前是要拿MDL写锁的，这样还能叫Online DDL吗？ 确实，图4的流程中，alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。 为什么要退化呢？为了实现Online，MDL读锁不会阻塞增删改操作。 那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做DDL。 而对于一个大表来说，OnlineDDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个DDL过程来说，锁的时间非常短。对业务来说，就可以认为是Online的。 需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗IO和CPU资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用GitHub开源的gh-ost来做。 这个过程是inplace的，但会阻塞增删改操作，是非Online的。 如果说这两个逻辑之间的关系是什么的话，可以概括为： DDL过程如果是Online的，就一定是inplace的； 反过来未必，也就是说inplace的DDL，有可能不是Online的。截止到MySQL 8.0，添加全文索引（FULLTEXTindex）和空间索引(SPATIAL index)就属于这种情况。 最后，我们再延伸一下。 在第10篇文章《MySQL为什么有时候会选错索引》的评论区中，有同学问到使用optimize table、analyzetable和alter table这三种方式重建表的区别。这里，我顺便再简单和你解释一下。 从MySQL 5.6版本开始，alter table t engine =InnoDB（也就是recreate）默认的就是上面图4的流程了； analyze table t其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁； optimize table t等于recreate+analyze。 上期问题时间如果 redolog 设计得太小，checkpoint 会频繁地往前推，则：磁盘压力很小，但是数据库出现间歇性的性能下跌。 15 14 | count(*)这么慢，我该怎么办？因为 mvcc 存在，所以 innodb 的 count(*) 只会一条一条读可见的数据。 普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 所以 count(id) 不一定是最快的，因为扫描完它全部的页，需要花太多时间了。 你可能还记得在第10篇文章《MySQL为什么有时候会选错索引？》中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到40%到50%。所以，showtable status命令显示的行数也不能直接使用。 如何得到一个精确的 count？这是一个类似秒杀的问题。 如果使用 Redis 之类的缓存系统，有如下缺点： 1、写 redis 不是原子的，不能保证异常时的精确性。2、写 redis 不是隔离的，不能保证并发读的精确性。3、redis 的灾难恢复并不好，duration 实现得不好，发生灾难恢复会出现不精确的数据。 改进方案是引入一个计数表 C，在事务里变更这个数据表。因为事务隔离，每个事务读取的 C 的数据和实际的记录行数总是在数据库里一致的。 当然，MySQL专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且MySQL已经优化过count(*)了，你直接使用这种用法就可以了。 其实，把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在MySQL中，就解决了一致性视图的问题。 16 15 | 答疑文章（一）：日志和索引相关问题 如果在图中时刻A的地方，也就是写入redo log处于prepare阶段之后、写binlog之前，发生了崩溃（crash），由于此时binlog还没写，redolog也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog还没写，所以也不会传到备库。到这里，大家都可以理解。 我们先来看一下崩溃恢复时的判断规则。 如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交； 如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整： a. 如果是，则提交事务； b. 否则，回滚事务。 追问1：MySQL怎么知道binlog是完整的? 回答：一个事务的binlog是有完整格式的： statement格式的binlog，最后会有COMMIT； row格式的binlog，最后会有一个XID event。 另外，在MySQL5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验checksum的结果来发现。所以，MySQL还是有办法验证事务binlog的完整性的。 追问2：redo log 和 binlog是怎么关联起来的? 回答：它们有一个共同的数据字段，叫XID。崩溃恢复的时候，会按顺序扫描redolog： 如果碰到既有prepare、又有commit的redo log，就直接提交； 如果碰到只有parepare、而没有commit的redolog，就拿着XID去binlog找对应的事务。 追问3：处于prepare阶段的redolog加上完整binlog，重启就能恢复，MySQL为什么要这么设计?回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻B，也就是binlog写完以后MySQL发生崩溃，这时候binlog已经写入了，之后就会被从库（或者用这个binlog恢复出来的库）使用。 所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。 追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redolog写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？回答：其实，两阶段提交是经典的分布式系统问题，并不是MySQL独有的。 如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。 对于InnoDB引擎来说，如果redo log提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果redolog直接提交，然后binlog写入的时候失败，InnoDB又回滚不了，数据和binlog日志又不一致了。 两阶段提交就是为了给所有人一个机会，当每个人都说“我ok”的时候，再一起提交。 追问5：不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？回答：这位同学的意思是，只保留binlog，然后可以把提交流程改成这样：… -&gt; “数据更新到内存” -&gt; “写 binlog” -&gt;“提交事务”，是不是也可以提供崩溃恢复的能力？ 答案是不可以。 如果说历史原因的话，那就是InnoDB并不是MySQL的原生存储引擎。MySQL的原生引擎是MyISAM，设计之初就有没有支持崩溃恢复。 InnoDB在作为MySQL的插件加入MySQL引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。 InnoDB接入了MySQL后，发现既然binlog没有崩溃恢复的能力，那就用InnoDB原有的redo log好了。 而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用binlog来实现崩溃恢复的流程，我画了一张示意图，这里就没有redolog了。 图2 只用binlog支持崩溃恢复这样的流程下，binlog还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog没有能力恢复“数据页”。 如果在图中标的位置，也就是binlog2写完了，但是整个事务还没有commit的时候，MySQL发生了crash。 重启后，引擎内部事务2会回滚，然后应用binlog2可以补回来；但是对于事务1来说，系统已经认为提交完成了，不会再应用一次binlog1。 但是，InnoDB引擎使用的是WAL技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。 也就是说在图中这个位置发生崩溃的话，事务1也是可能丢失了的，而且是数据页级的丢失。此时，binlog里面并没有记录数据页的更新细节，是补不回来的。 你如果要说，那我优化一下binlog的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个redo log出来。 所以，至少现在的binlog能力，还不能支持崩溃恢复。 追问6：那能不能反过来，只用redo log，不要binlog？回答：如果只从崩溃恢复的角度来讲是可以的。你可以把binlog关掉，这样就没有两阶段提交了，但系统依然是crash-safe的。 但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog都是开着的。因为binlog有着redolog无法替代的功能。 一个是归档。redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log也就起不到归档的作用。 一个就是MySQL系统依赖于binlog。binlog作为MySQL一开始就有的功能，被用在了很多地方。其中，MySQL系统高可用的基础，就是binlog复制。 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费MySQL的binlog来更新自己的数据。关掉binlog的话，这些下游系统就没法输入了。 总之，由于现在包括MySQL高可用在内的很多系统机制都依赖于binlog，所以“鸠占鹊巢”redolog还做不到。你看，发展生态是多么重要。 追问7：redo log一般设置多大？ 回答：redo log太小的话，会导致很快就被写满，然后不得不强行刷redolog，这样WAL机制的能力就发挥不出来了。 所以，如果是现在常见的几个TB的磁盘的话，就不要太小气了，直接将redo log设置为4个文件、每个文件1GB吧。 追问8：正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？回答：这个问题其实问得非常好。这里涉及到了，“redo log里面到底是什么”的问题。 实际上，redo log并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由redolog更新过去”的情况。 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与redolog毫无关系。 在崩溃恢复场景中，InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让redolog更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。 追问9：redo log buffer是什么？是先修改内存，还是先写redo log文件？ 回答：这两个问题可以一起回答。 在一个事务的更新过程中，日志是要写多次的。比如下面这个事务： begin; insert into t1 … insert into t2 … commit;这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没commit的时候就直接写到redo log文件里。 所以，redo logbuffer就是一块内存，用来先存redo日志的。也就是说，在执行第一个insert的时候，数据的内存被修改了，redo logbuffer也写入了日志。 但是，真正把日志写到redo log文件（文件名是 ib_logfile+数字），是在执行commit语句的时候做的。 （这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的IO消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。这个问题我们会在后面第22篇文章《MySQL有哪些“饮鸩止渴”的提高性能的方法？》中再详细展开）。 单独执行一个更新语句的时候，InnoDB会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。 以上这些问题，就是把大家提过的关于redo log和binlog的问题串起来，做的一次集中回答。如果你还有问题，可以在评论区继续留言补充。 17 16 | “order by”是怎么工作的？全字段排序 初始化 sort_buffer，确定放入所有列。 在索引中找出第一个满足条件的行，回表，把所有的 select和 id放入 sort_buffer 中。 重复查找索引，直到找不到下一条记录为止（所有的非唯一索引都有这个特点，要找到所有记录）。 对 sort_buffer 进行快排。排序动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。 内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。 这种外排序是 MySQL 默认使用的工程手段，实际上也应该被广泛运用于其他工程上的去重/排序问题。排序文件的大小不会大于 sort_buffer 本身的大小。 rowid排序 初始化 sort_buffer，确定放入排序列和主键。 在索引中找出第一个满足条件的行，回表，只把排序列和 id放入 sort_buffer 中。 重复查找索引，直到找不到下一条记录为止（所有的非唯一索引都有这个特点，要找到所有记录）。 对 sort_buffer 进行快排。 按照排序结果取 row id，再次回表查询所有行的原始数据。 也就是说，回表两次。 全字段排序 VS rowid排序 如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。 如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。 这也就体现了MySQL的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。 对于InnoDB表来说，rowid排序会要求回表多造成磁盘读，因此不会被优先选择。 如果有得选，我们应该在待排序字段上也加索引，这样某些时候排序（非复合排序条件索引里的所有排序列恰好有序，而且也是被搜索列）就不需要使用到 sort_buffer（这也是为什么时间排序经常要加上时间索引的原因）。如果查询列能够命中覆盖索引就更好-这样就达到三星索引的水平了。 大部分需要使用 filesort 的查询，都可能触发生成临时表，explain 里这两个标志经常搭配出现。只要涉及到排序的列，不能在索引上简单排序，都会用到 sort buffer。 我们平时做设计，进行搜索，也可以利用这种宽搜索、窄搜索和本地有序思路，进行时间、空间上的优化。 上期问题时间Rows matched：1，Changed：0 MySQL 依然会加锁，比对值。 18 17 | 如何正确地显示随机消息？ 那么，是不是所有的临时表都是内存表呢？ 其实不是的。tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。 好的随机查找算法，一定要解决算法均匀的问题。如果 id 不均匀，可以这样： 1、算出总数，然后找出总数里面的若干个随机数。2、用 min id +加上若干个随机数得到若干个起点，limit 1 查找。这样可以避免 id 不均匀。 上期问题时间 我在上一篇文章最后留给你的问题是，select * from t where city in (“杭州”,” 苏州 “) order byname limit 100;这个SQL语句是否需要排序？有什么方案可以避免排序？ 虽然有(city,name)联合索引，对于单个city内部，name是递增的。但是由于这条SQL语句不是要单独地查一个city的值，而是同时查了”杭州”和”苏州 “两个城市，因此所有满足条件的name就不是递增的了。也就是说，这条SQL语句需要排序。 那怎么避免排序呢？ 这里，我们要用到(city,name)联合索引的特性，把这一条语句拆成两条语句，执行流程如下： 执行select * from t where city=“杭州” order by name limit 100;这个语句是不需要排序的，客户端用一个长度为100的内存数组A保存结果。 执行select * from t where city=“苏州” order by name limit 100;用相同的方法，假设结果被存进了内存数组B。 现在A和B是两个有序数组，然后你可以用归并排序的思想，得到name最小的前100值，就是我们需要的结果了。 如果把这条SQL语句里“limit 100”改成“limit 10000,100”的话，处理方式其实也差不多，即：要把上面的两条语句改成写： select * from t where city=”杭州” order by name limit 10100; 和 select * from t where city=”苏州” order by name limit 10100。这时候数据量较大，可以同时起两个连接一行行读结果，用归并排序算法拿到这两个结果集里，按顺序取第10001~10100的name值，就是需要的结果了。 当然这个方案有一个明显的损失，就是从数据库返回给客户端的数据量变大了。 所以，如果数据的单行比较大的话，可以考虑把这两条SQL语句改成下面这种写法： select id,name from t where city=”杭州” order by name limit 10100; 和 select id,name from t where city=”苏州” order by name limit 10100。然后，再用归并排序的方法取得按name顺序第10001~10100的name、id的值，然后拿着这100个id到数据库中去查出所有记录。 上面这些方法，需要你根据性能需求和开发的复杂度做出权衡。 先做深搜索。 再做外排序。 "},{"title":"计算的本质","date":"2021-03-09T11:03:09.000Z","url":"/2021/03/09/%E8%AE%A1%E7%AE%97%E7%9A%84%E6%9C%AC%E8%B4%A8/","tags":["计算理论"],"content":"语义小步语义小步语义类似对代数式迭代求值。 大步语义大步语义的意思是，对于大的表达式，先求它的小表达式，然后把结果结合起来得到最终的答案。这通常意味着递归 操作语义（operational semantic）想象一个理想、抽象的计算机，操作语义为程序在某些机器上的执行定义一些规则。 指称语义（denotional semantic）用一种低级、更形式化的语言来解释当前的语言。 状态机的分类确定性有限自动机finite state machine -&gt; finite automaton deterministic finite automaton 是确定性有限自动机的意思 我们的领域模型的状态机最好是这种状态机。 非确定性有限自动机NFA能被一台特定机器接受的字符串集合称为一种语言：我们说这台机器识别了这种语言。 任何 NFA 等价于 DFA 确定性下推自动机PushDown Automaton pda。 这种状态机可以处理无限多的中间状态。 确定型图灵机Deterministic Turing Machine DTM 可以解决所有可判定/可计算问题 停机问题不可解，即任意问题都可能是不可终止的。"},{"title":" 关于编程语言的typing(一些基本概念) ","date":"2021-03-09T11:01:24.000Z","url":"/2021/03/09/%E5%85%B3%E4%BA%8E%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84typing-%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","tags":["编程语言"],"content":"from： 最近围观一本JavaScript的书籍引发的争论，一不小心碰到一篇讲编程语言类型系统划分的帖子，回想起当年还在公司内部的Tech Session上主讲过这个话题，不过只涉及到静态/动态、强类型/弱类型，远没有这位仁兄总结的那么全面。 原文链接 不多废话，直入正题： [维度一] Static vs Dynamic Typing静态类型和动态类型，区分的关键点为编译期或运行期确定类型：静态类型在编译期确定，动态类型在运行期确定。静态类型代表 Java、Scala、Haskell动态类型代表 Ruby、Python、Erlang [维度二] Strong vs Weak Typing强类型和弱类型，区分的关键点为运行时是否自动转换到与实际类型不符的类型：强类型要求手工类型转换，弱类型自动转换。强类型代表 Java、Scala、Python弱类型代表 C、Assembly、JavaScript [维度三] Latent (Implicit) vs Manifest (Explicit) Typing隐式类型和显式类型，区分的关键点为是否要在源码中声明类型：隐式类型不需要，显式类型需要。隐式类型代表 Haskell、Erlang、Python显式类型代表 C、C++、Java [维度四] Nominal vs Structural Typing名义类型和结构类型，区分的关键点为类型判定是根据标称还是根据内容：名义类型根据标称，结构类型根据内容。名义类型代表 C、C++、Java结构类型代表 Haskell、Erlang、Python 关于JavaScript书籍的争论，请移步如下网址：1- 网友Hax的”炮轰”帖  周爱民(aimingoo)的MSN空间  火星常驻JE办事处相关帖 "},{"title":"纪要","date":"2021-03-04T12:16:45.000Z","url":"/2021/03/04/%E7%BA%AA%E8%A6%81/","tags":["会议"],"content":"无人区所有伟大的创新、公司和企业家都不是在既有经验、已有成果之上取得的成绩，而是在毫无经验、毫无基础、毫无积累的状态下取得成功。 所有伟大的机会都来自于未来、来自于未知，而非来自于既有。 什么叫逆向思维？在大家恐惧的时候，你需要乐观，在大家都是乐观的时候，你可能要恐惧，类似于古人曾提及的“乐极生悲，否极泰来”，其实讲的就是这个道理。大众的一个惯性思维是“追涨杀跌”，在大家都认为情况乐观的时候，会引发人们跟风模仿。曾有人以投资为例，大部分老百姓并不懂得投资规律，当看见一堆人跟风投资的时候，你就要非常谨慎，这时候可能正是风险来临的时候。 所以，对我们来讲，在遇到困难时，我们要去思考这件事为什么困难，这困难会持续多久？它是在正确轨迹上的一个困难；还是说这个业务面临一些根本性的挑战，需要一个巨大的变革；还是这条路本身就是一个死胡同？当处于乐观状态时，我们要思考这种乐观状态是否可持续，未来需要做什么才能让这种增长得以保持。历史的无数经验表明，所有的发展都是一种波浪式的发展。可以看到，我们有时候处在一个波浪的波谷，有时候处在一个波浪的波峰，更重要的是，我们要去识别这种波浪是否在逐步升高，而不是在逐渐下降。 很多时候我们需要把所做的工作标准化并复制，最终实现规模化的效果。要想规模化达到更好的效果，还要考虑一个很重要的元素，就是准确识别业务的问题。 挑战是存在的，通过成就他人来成就自己，很多时候是反人性的，难免会认为为什么要这样，我直接成功不是更好吗？但要获得长期的成功，必须是看你帮助到了多少人。对公司来讲取得最长久的成功，是帮到了多少用户、多少合作伙伴，帮助社会做了什么事情，而非自己利益的最大化。对团队也是一样，对个人也是一样，要先实现帮助别人，自身才能获得长久的成功。我认为也是长期有耐心的一种具体行动——通过成就他人，同时成就自己，这也是协同的内在价值。 持续保持高标准要求，可以维持我们整个公司为每个团队的客户提供更好的服务，获得更多的用户认可。更重要的，这也非常有助于我们去吸引并且保留人才。大家都想做有成就感的事、做有价值的人，因此会非常愿意跟更有价值感的人在一起。 其次，如何更好地理解高标准。一方面，高标准、好的标准，并不是完全通用的，它是跟领域有关的。每个领域有其内在的逻辑，过往期间的积累，才形成今天约定俗成的惯例。我们面对不同领域的最高标准，需要更加谦逊并保持开放。尤其是当我们做到更大范围的团队leader时，领导管理的可能是实体的，也可能是虚拟的，你是否知道你最擅长的领域是什么？你们多年来工作的沉淀及专长是什么？你的高标准体现在哪里？所有leader包括我也要试图去理解每个领域，及其高标准要求在哪里？另一方面，我们同时要理解高标准是不太容易实现的，需要一个足够长的时间去积累和训练的。比如写一篇好的文章，这是非常非常困难的，需要训练很长时间，而且还需要在本身专业能力不错的基础上。我们很难指望说花一夜的时间写一个明天要去给客户、给领导汇报的的完整材料，可能需要整理好几版，准备两周、甚至一个月的时间。所以，这也是我们说在重要的、热爱的事情上花最长的时间，是长期有耐心的一种正确做法。 要有面对问题的心境。有时候“出点事情”或许也是好的，老不出事儿，总有一天可能会变成一个重大危机，正如偶尔一次感冒，如果长期不生病，那可能某一天就要来一场大病了。当问题出现时，可以坦然一点，如果问题发生了两次以上，我们就要进行自我总结和复盘了。 公司能够取得一个重大的进展，或者说未来能有更大的发展，它可能来源于两类事情：第一，是抓住了行业的、重大的、战略性、规模性以及历史性的机遇。如果说错过这个机遇，就算我们把事情做得非常完美，也不足以支撑公司走向未来；第二，认准一个高山和远处的目标，在前进的路上要走正确的方向或者说少走一些弯路，保证我们走在通往最终目标的道路上。 供需关系“供给和需求相互促进”这样的说法基本都是没想清楚。如果觉得都重要，很有可能会导致资源投错方向，资源消耗太快、ROI也跟不上。 要按照供需关系来分配资源花时间投入。盲目扩张等于种蘑菇。 Insight &amp; Operation的区别：人们因为常常会因为一件事的Operation比重太大，反而认为这件事重要，但实则不然。 零售行业的老大之所以会有这样的错觉，正是因为通常老大必须亲自了解需求的insight，不能假他人之手。而下属只能搞供给，也只能执行供给的策略。 某零售老大亲自完成了1,000家店的选址，但是选址是需求洞察的集合。而一旦选完址之后，剩下的都是供给的事情了，因此常常会让老板觉得供给更重要。 《零售的哲学》：绝大部分在讲需求，讲供给的部分也在讲如何服务好需求。 稀缺的环节、难的事情才是商业的核心。这通常是一家公司只有一个人知道怎么做、一个行业只有几个人会做的事情，而不是全公司花最多精力去干的事情。 需求更重要，服务好需求更重要。 变化慢但是一直在变的行业是值得警惕的，尤其是变化周期和团队懈怠速度一样的行业。 理论家很重要的一点是通过自身的理论去预测未来，而不是仅仅能解释过去的历史。 线上和线下市场通常会拥有不同的供需关系，甚至多次反转。 打车平台为什么在低谷期将take rate调高，在高峰期将take rate调低，而不是调节价格？高价通常都能抑制需求，但是低价并不能有效刺激需求。动态定价既能平滑平台利润（将低谷期的高take rate换成在高峰期对司机的补贴）。动态调价的市场平台必须要保证自己手头有调节供需的筹码-所以 take rate 决不能丢。 零售行业是一个长期供过于求的市场（竞争过饱和了），而且供需变化太慢了，所以可以维持很低的take rate。Costco的商业模式（会员费+0后端毛利）是非常符合零售行业的供需变化特征的，用商业模式实现了消费者和经营者的利益一致，确保了价值观的实现。 没有后端利润：避免了渠道商为了拿后端返利扭曲了行为，利用消费者的信息不对称来赚钱，例如把差产品放在好的位置卖以获取更高额的返利。 通过会员费卡住前端利润率：激励员工依靠商品品质、性价比来选择商品，为了单品能卖更多来选品，与消费者利益一致。 缩减经营中的各种变量，聚焦于将商品搞好 在单一产品不允许调价的时候，通过推出产品来实现调价。 拼多多今天之所以做得这么好，本质上是因为阿里犯了错误。阿里不是没有做拼团的事情（聚划算），不是没有做下沉市场的生意（农村淘宝）。因此拼多多今天做的事情，阿里原本的战略都是cover的，但是最后还是让拼多多跑出来了。因此，这意味着某些战略一定需要整个运营、组织、产品的配合，而不是有战略就完了。 互联网行业需要额外警醒，亏损经营会导致原本不成立的供需在短期内看起来成立，补贴一定要减少对供需的扭曲。 在极其动态的市场中，锁定运力、锁定供给通常是失败的策略。如此动态的市场，我们不可能提前锁定好合适的价格、并对供需状态进行预判，这件事的复杂程度超过了系统的预判能力。 获取流量也不一定要补贴，需要补贴才能换来的流量不可能赚钱。正是因为我们没有补贴就有供需失衡，所以我们才要进行补贴-反向证明补贴是有效的，需求是存在的。"},{"title":"HATP 问题","date":"2021-03-01T05:32:07.000Z","url":"/2021/03/01/HATP-%E9%97%AE%E9%A2%98/","tags":["系统架构","数据库"],"content":"问题定义AP 的出现在互联网浪潮出现之前，企业的数据量普遍不大。通常一个单机的数据库就可以保存核心的业务数据。那时候的存储并不需要复杂的架构，所有的线上请求(OLTP, Online Transactional Processing) 和后台分析 (OLAP, Online Analytical Processing) 都跑在同一个数据库实例上。后来业务越来越复杂，数据量越来越大，产生了一个显著问题：单机数据库支持线上的 TP 请求已经非常吃力，没办法再跑比较重的 AP 分析型任务，在这样的大背景下，于是AP开始从TP系统分离，某种程度上，AP是TP的一个分支。 这等于是在存储层做 CQRS 架构设计-另一种方案是在应用层也设计读写分离的架构。 AP的玩法在这样的背景下，以 Hadoop 为代表的大数据技术开始蓬勃发展，它用许多相对廉价的 x86 机器构建了一个数据分析平台，用并行的能力破解大数据集的计算问题。 TP和AP的联系虽然 TP 和 AP 开始往独立的方向演进，但是他们的核心都是需要处理数据，所以需要将数据打通。业内普遍玩法将 TP 数据通过 ETL 工具抽取出来，导入独立的 AP 分析系统。业务数据库专注提供 TP 能力，分析平台提供 AP 能力，各施其职。AP 为什么需要HTAP挑战根据现在的架构，通过ETL桥接TP和AP，数据基本可以做到T+1（小时、天、周等）要求，解决了TP系统处理AP的性能及隔离难题，但也带了一些问题： a）复杂性，TP和AP本身是非常独立的系统，中间搭建ETL的过程实际上是比较复杂的数据集成，业内比较知名的工具如sqoop、DataX、datapipeline，需要对数据二次开发； b）实时性，ETL是周期性过程，一般按T+1时间来做数据同步，无法满足部分实时分析和统计需求（需要 OLAP 的在线业务越来越多）； c）一致性，TP系统数据错乱，往往会导致AP系统在回溯数据时无法幂等，导致数据不一致； 由于以上局限性，HTAP（Hybrid Transactional/Analytical Processing）融合型数据库解决方案既能满足 OLTP 类需求，也满足 OLAP 类需求是非常有必要的。 定义2014 年，Gartner 对 HTAP 数据库给出了明确的定义，HTAP 数据库需要同时支持 OLTP 和OLAP 场景。基于创新的计算存储框架，在同一份数据上保证事务的同时支持实时分析，省去了费时的 ETL 过程。从定义上可以看出他是希望一份数据不同引擎，但往往在实现时会百花齐放。 行业分析业内头部公司已经针对HTAP开发单独解决方案，实现上各不相同，但有一个共同特点TP&amp;AP隔离，要么计算&amp;存储完全隔离，要么同一份数据，计算层隔离，总之隔离是趋势。 阿里架构PolarDB-X 2.0（原DRDS）实现了在线高并发OLTP联机事务处理以及OLAP海量数据分析，即HTAP。存储层扩展读节点，流量接入层统一调度，做到对用户基本透明。 特性 功能 方案 说明 复杂性 TP和AP请求提供了统一接入层 TP&amp;AP统一入口，业务使用简单 隔离性 计算&amp;存储独立的AP节点 TP&amp;AP完全隔离，不会互相影响 实时性 实时 基本完全实时 一致性 待确定 扩展性 扩展性 扩展读节点 理论上可以无限扩展 优点：实现复杂度可控； 缺点：虽然对用户使用非常友好，同时业务层TP&amp;AP也完全隔离，但是因为AP节点还是行存，所以性能方面有一定缺陷（如压缩、速度等）； PingCapTIDB在4.0 支持了HTAP， TiSpark（计算层，同一份数据两个引擎），它可以直接读取 TiKV 的数据，利用 Spark 强大的计算能力来加强 AP 端的能力，然而由于 TiKV 毕竟是为 TP 场景设计的存储层，对于大批量数据的提取、分析能力有限，所以TiDB 引入了以新的 TiFlash 组件（存储层），从而完成存储和计算的完全隔离。 TiKV 是的 kv 是基于 map 的，map 又是按照 sstable 组织的，所以存在写放大的问题。 架构： 功能 方案 说明 数据复制 通过 Raft Learner 协议，从 TiKV 同步过来的 取消ETL过程，减少数据开发过程 复杂性 TiSpark 和 TiDB均可以访问TiFlash数据 TP&amp;AP统一入口，业务使用简单 隔离性 计算&amp;存储独立的AP节点 TP&amp;AP完全隔离，不会互相影响 实时性 实时 基本完全实时 一致性 强一致 有一定阻塞影响，并非走强一致同步 扩展性 TiSpark 和TiFlash可以扩展 理论上可以无限扩展 优点：TiFlash 列式存储，TiSpark 和 TiFlash 扩展性较好，性能有较大优势； 缺点：实现复杂度较高； 总结 多节点复制，基于日志的方案是基础方案，业界现有的方案大致上有： 自带主从复制的日志方案，以 MySQL 主从复制为方案 基于方案 1 的自动选主的集群方案，以 Paxos 类实现为主 自己搭建桥接通道，把 tp 系统的数据，通过 mq 之类的数据通道引导到另一个异构系统，异构系统可以： 可以引入不同的计算层 可以引入不同的存储层（如把行存储转换为列存储） 使用 RDBMS 的 AP 节点最好可以无限扩展，方案进阶的方案有： 在线业务只（RO）读从库 离线业务统计从库 混合离在线的从库 传统的 OLAP 方案，是从 RDBMS 方案转入大数据生态套件的方案。但 HTAP 的出现，让数据库领域出现技术融合的现象。这种技术融合，可以让上层应用使用统一的 portal，使用 OLAP 和 OLTP 来解决自己的问题，不再有接入异构存储层的体验不一致的痛感。 读写的分离，产生的架构隔离，是工程上不可避免的-非这样无法保证 OLTP 侧的 SAL。但在抽象层次上抹去这种差异，又是一种 hybrid 方案 nice to have 的，所以存储支持基础的 JDBC 协议又是必然的，只有这样才能实现平滑升级。 "},{"title":"中高层领导力","date":"2021-02-20T03:07:00.000Z","url":"/2021/02/20/%E4%B8%AD%E9%AB%98%E5%B1%82%E9%A2%86%E5%AF%BC%E5%8A%9B/","tags":["管理"],"content":"商业思维 建立商业思维 建立远见（forsight）：知道自己的行业和企业的终局是怎样的。 洞见（insight）：对行业的定律有自己的理解，“我的网页打开速度，每变慢一秒钟，我的转化率会下降X个百分点”。 管理者 建设团队： 直接产出 管理其他人 管理管理者 管理部门 三高三低 战略卡片-房子图房子图要分平台房子图和业务房子图。 商业模式三要素 客户价值：谁是客户？有多少客户？你提供什么价值？ 核心能力：确保业务能赢的关键能力是什么？我们为什么具备或者有可能具备？ 收费模式：分为哪几种收费模式？比如，一次性收入，附加长期维护收入。 商业分析方法论：三层四面 三层：市场总量、互联网化率、公司占有率 四面：用户量、订单量、收入、利润 【观测、解释、预测、影响/创造】方法论【观测】：知道发生了什么事情，要对情况很了解，包含了观察和测量。【解释】：解释这个事情，可以用理论自恰说明。【预测】：预测将来会发生什么事情。如果你观测的数据很全面很准确，解释是很有信心的，你就能预测将来会发生什么情况。如果一个理论可以解释现在，还能预测未来，那么这个理论比较靠谱，认知比较深入。【影响/创造】：知道什么输入能导致什么输出，如何改变输入从而改变输出。 什么是战略战略是做少数艰难而正确的决定。“上兵伐谋，其次伐交，其次伐兵，其下攻城”。战略讨论清楚很重要，战略决定了你用什么方式赢这个事情，以及这个战略路径下什么是重要的。你的战略路径决定了你的资源分配。先确定什么是值得争取的，再看从什么路径来达成。 SWOT《营销管理》（第14版） ，菲利普•科特勒、凯文•莱恩•凯勒著，王永贵等译 波特五力模型《竞争战略》，迈克尔·波特著，陈丽芳译 波特竞争战略《竞争战略》，迈克尔·波特著，陈丽芳译，中信出版社 杨三角《组织能力的杨三角》，杨国安著，机械工业出版社"},{"title":"《恰如其分的软件架构》","date":"2021-02-10T06:56:27.000Z","url":"/2021/02/10/%E3%80%8A%E6%81%B0%E5%A6%82%E5%85%B6%E5%88%86%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E3%80%8B/","tags":["系统架构"],"content":"前言这两周集中时间间歇性读完了《恰如其分的软件架构》这本书。这本书讲的是架构方法，架构方法是一种思维模型（mind set），这种思维模型叫作“风险驱动模型”。 这本书经我们团队的架构师推荐，列在我们团队的集体书目里很久了。但真正去读它、读完它的人又很少。究其原因，还是这本书的内容以谈概念为主，虽然书中举的例子非常生动，仍然始终无法摆脱“为了谈概念而举玩具例子”的问题-这几乎是所有架构书的通病。似乎正统的架构书籍都不可避免地举一些传统行业或者经典软件（比如很多书籍都会反复出现在“xxx 播放器”）的例子。这些软件架构非常经典，可以只用一些小的组件、场景，就讲清楚典型的组件、模式和架构风格的用处。但没有很深的工程/架构经验的读者读这些书的时候，仿佛重新回到了抄书和念书的大学课堂，对于脱离现实的例子只会产生“左耳进右耳出”的感觉。能够温故而知新，是一本书经典化的特征。而能够阅读非入门级的纯理论书籍，则是一个程序员的认知能力和经验达到了一定程度的特征。我读这本书里很多细节还是很痛苦，证明我还是对于形式化的符号（symbol）、记法（notion）还不是很熟悉，而且对于书中运用的问题解析方式、高细节设计具体化的方式，不具有很好的辨析能力。证明我还不是一个已经搭建起来足够成熟的思维框架的架构师。 本文不同于之前我读架构书的总结文，不再是简单地抄书，而是尽量用框架式的方式来重新谈论架构问题，有时候使用书中的论述，有时候使用自己的论述。 另外，这本书的内容很繁复，在现实中应该是给 CMU 的研究生在讲习班上讨论研究的参考教程，可能需要一个学期来专门研究。 架构师的时代背景这个时代的软件规模和复杂度增长得非常迅速，开发者与软件复杂度的战争也随之升级。我们能够使用的武器从汇编到高级编程语言，从子例程到子对象，但这些东西都不是银弹（没有银弹）。真正能够让我们破解这个“永久的软件工程问题”的，只有化繁为简的思维方式。按照 Fred Brooks 的观点，只有运用各种“武器”，分割系统（1 partitioning），提供知识（2 knowledge），并利用抽象来揭示问题的本质（3 abstract），我们才能应对我们现实中的挑战。 接下来本书作者举了一个现实中的例子，“rackspace 公司的日志文件系统”： rackspace 公司是一间现实中存在的企业，它的数据库经历了本地日志文件-中央数据库（基础的 ETL）-索引簇（使用大数据的 ETL）。 作者观察这个案例，得出了以下结论： 相对于大相径庭的架构，每一代系统的功能大致相同，这证明了正交的设计能够保证功能和业务的延续性。 有以下几种质量属性特别值得关注（这些质量属性接下来还会在下文中反复出现）： 可修改性（modifiability） 可伸缩性（scalability） 延迟时间（latency） 我们需要建立概念模型，以帮助推理。这个例子说明了 C/S 和 map-reduce 这两种架构风格在性能上的差别如此之大。如前文中 alan kay 所说，洞察到领域里的问题，是开始推理的关键。 我们不能直接陷入细节里难以自拔，这样会阻碍我们推理问题。比较合适的方法是引入一个具有约束的概念，约束帮我们减少了可能性，这样让我们在解空间里搜索解决方案变得简单。比如本例子中我们使用了 job 来专门描述在系统之间传递、执行的子程序，这样我们可以不必把“小程序是如何在大程序里执行”这种大得没边的问题引入我们的思考。 时代在变化，在旧的时代，人们习惯用现成技术（通常就是一门编程语言）里的抽象方式（通常就是这门编程语言里的逻辑单元：类、模块、例程）。在现代，我们要主动做出观念转变（perspective shift），使用架构抽象（architecture abstract）来思考问题，按照本文的观点，要使用组件和连接器来思考问题。 我们历史上已经出现了太多的软件过程（process）了，敏捷过程、瀑布过程和螺旋（spiral）过程，都强调设计。但本书提到了风险驱动模型（risk-driven model），是一种推陈出新的模型，它强调：设计的度，要和风险的度相匹配。接下来作者举了非常多很细节的例子，要理解、认同和记住这些全部细节是不可能的；要对这些观点完全弃之不顾，也无法建立正确的工作方式。一个好的架构师，应该在实战中用最精华的方式，来解决最紧要的问题，而不要导致求全之毁。 这也意味着，我们可能在现实中遇到这样的一些情况： 对于流程很复杂，对功能和质量的要求很 critical，我们可能需要做很严格的复杂设计。我们要求从顶层开始推导我们的系统的全貌，建立领域模型、设计模型和代码模型，借助系统的主模型，把系统的视图导出来，关注单一维度的质量属性。然后我们的系统的每一个子问题足够小，让每一个独立工作的工程师都可以单打独斗解决问题。进行架构提升（architecture-hoisting design），得到一个参考架构（reference architecture）。 只做一些初步的设计，把关键的问题定义好，把解决方案勾勒出来。进行架构无关（architecture-indifferent design）的设计，构建推定架构（presumptive architecture 适用于大多数场景的架构）。 这两种情况都是正常的，都是恰如其分的架构。事实上，大部分的复杂架构只适用于大型项目，而大部分的项目实际上是小项目（现实总是与架构师的雄心壮志相反）。敏捷之所以流行起来，就是因为众多工作者对重型工作流程心怀不满，做出反击。我们不要浪费我们最重要的资源（时间）和次重要的资源（其他人的工作成果）。不要纠结于无法流畅使用的东西，那不是适合我们的解决方案。 大型系统之所以要做恰如其分的架构，是因为如果出现问题，架构重构的风险极大。本身讲的“风险驱动的模型”大体上仍然是一种敏捷过程（所以这是一本关于敏捷架构的书），这种敏捷过程至少让我们关注： 恰如其分的软件架构（just good enough architecture） 概念模型（conceptual model） 这些东西并非敏捷过程所独创，但敏捷过程需要将他们阐发得足够简单易行，让只有一些工程经验的工程师只要读过此书就能看碟下菜，也是一种对于工程学的改进。 市面上有如此多的架构书籍，讲述的架构方法，有的简单，有的复杂，对于自有软件流程的工程师而言，无法分辨哪些方法是高阶的，哪些方法是低阶的，哪些东西是已经过去了的无需学习的，哪些是未来的尚未达到的，真是一个令人苦恼的问题。这也反映了软件工程界百家争鸣，观念混乱。有时候一个读者读完一本书觉得自己能够理解架构和流程，读到第二本书的时候反而发现自己不会了。这本书看待问题的基本观点是“任何一本书，如果只对某种技术只知道一味颂扬，而缺乏批判精神，都是不值得信任的”，值得称道。但这本书高谈阔论的东西对于现实互联网公司的流程而言，又过于理想化，大部分人都无法仔细看待架构问题，所以无法做出很漂亮的架构设计。 何谓软件架构架构的定义破这个题非常难。 软件中存在架构，架构决定了软件的基本形态和性质，这是软件工程师的朴素认识，如何导出这种基本基本形态和性质？这就是架构这类学问要探讨的问题了。 有无数本书大谈特谈架构的宏大之处及其种种细节，仿佛架构是一套概念堆积起来的体系大厦。但很少有人能够对谈论的内容进行进行很好的总结，把架构收敛为一个简单的概念。 本书列举了业界关于架构的定义，解释了定义的清晰之处和模糊之处。 清晰的定义包括： 架构这个词实际上是 nasa 发明的。 架构是系统的骨架。 架构与功能（基本上）是正交的-这意味着它们可以单独抽象。这又应了国内某些架构师说的话，架构应该是架子，上面放一些业务。因此架构和功能可以独立升级。 CMU 的定义是被普遍接受的：架构是元素和元素之间的一种结构。这衍生出一种新口号（architecture-as-artifact）。 Martin Fowler 与 Ralpha Johnson 之间的讨论则告诉我们：架构是项目早期必须做出的一组设计决策（design decision）。 架构的模糊之处在于：我们无法把架构和详细设计区分出来。有时候我们要做很细很细的设计，但我们仍然是在做架构设计-比如决定某些关键流程里面性能、安全性相关的流程。架构要传达很关键的决策和意图。 所以如果要去面试架构师，要阐述什么是架构，一个折中的答案是：架构是必须早期做出的，关于组件和交互的宏观设计。 架构为什么重要软件架构太重要了，它影响系统的： 质量属性 功能的实现 约束（约束是用“专制”带来自由的权衡，是导轨 guiding rail） 概念的完整性（这条特别容易被忽略） 架构何时重要 小的解空间。这点很反直觉，在我们没有多少好的选择，只能做差强人意的设计的时候，架构反而特别特别重要。因为这时候我们已经没有质量下降的空间了。 高的失败风险。 难以实现的质量属性。 全新的领域。这时候进行架构设计有助于借助流程帮我们看清楚问题。 产品线。当我们有一类产品时，我们需要通用架构-如，对于保险而言，架构的通用性很重要。 在现实中，金融系统的架构需要特别关注质量属性，因此往往不能采取简单的推定架构，而需要复杂的参考架构。 推定架构与参考架构推定架构（presumptive architecture）是在特定领域中占据主导地位的架构族。参考架构（reference architecture）描述了针对某一问题在架构层面的解决方案。参考架构意味着着那种雄心勃勃的架构（如 OSI 七层架构），而推定架构意味着（该领域）事实上的标准（如 TCP/IP 五层架构）。 传统的 3-tier 架构至少能够实现了这种封装： 一层处理用户界面。 一层处理业务逻辑。 一层处理数据存储。 事实上，采用推定的 N 层架构的开发者几乎总能做得不错，他们真正的架构决策往往是使用哪些 COTS 现成商业软件，如使用哪种数据库-这也是外包解决方案能够解决一揽子问题的简单解释，这也是很多技术团队能够快速构建业务系统的原因。"},{"title":"Journal 与 EBS","date":"2021-01-29T09:55:34.000Z","url":"/2021/01/29/Journal-%E4%B8%8E-EBS/","tags":["存储"],"content":"EBS 的定义EBS — Elastic Block Storage，简言之就是高可用、高性能、弹性可扩展的分布式块存储服务。对于业务来说，它就是一块磁盘，只不过将业务数据存储于远端网络节点，但是使用方法和体验与访问本地磁盘一样。 EBS 可以作为容器的存储盘，可以解决： 有状态容器的状态存储问题 海量存储问题：邮件系统、监控平台、数据库、用户录音、集成测试平台、MySQL 备份（需要测试 OLTP/OLAP 的交互操作和在线交易性能） EBS 的文件系统结构在EBS分布式块存储系统中，最终存储业务写入数据的服务是ChunkServer。 单机存储引擎位于每个ChunkServer上，业务的数据读写请求到达ChunkServer后，最终通过单机存储引擎与操作系统文件系统交互来写入或读取数据。 业务申请的每一块ebs网络盘在我们的系统里都对应一个Volume。Volume本身是一个逻辑概念，每个Volume被切分成多个Chunk，Chunk最终对应到ChunkSever上文件系统中的一个真实文件，因此我们的单机存储引擎最终会管理这一系列Chunk文件的创建，读写，删除等操作。 Journal就是在ChunkServer上的单机存储引擎这一层引入的，上图中最左侧的“big-journal dir”就是用来存储journal的目录。 其他 Journal 的实现Linux 中的日志文件系统文件系统要解决的一个关键问题是防止掉电或系统崩溃造成数据损坏。 我们知道一个文件既包括元数据，又包括真正的用户数据。文件有写入时这两部分数据都需要被写入。因此导致文件系统损坏的根本原因就在于写文件不是原子操作，写操作无法一步完成，如果其中任何一个步骤被打断，就会造成数据的不一致或损坏。 为解决上面说到的问题，日志文件系统(Journal File System)应运而生。 日志文件系统的原理是在进行写操作之前，把即将进行的各个步骤（称为transaction）事先记录下来，保存在文件系统上单独开辟的一块空间上，这就是所谓的日志(journal)，也被称为write-ahead logging(WAL)。日志保存成功之后才进行真正的写操作，把文件系统的元数据和用户数据写进硬盘（称为checkpoint），这样万一写操作的过程中掉电，下次挂载文件系统之前把保存好的日志重新执行一遍就行了（称为replay），避免了前述的数据损坏场景。 结论：所以到达 checkpoint 意味着它之前的 log 不需要 replay 了 MySQL InnoDB引擎的redo logInnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下图所示： write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。 checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的是还空闲的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，这时候不能再执行新的更新，得停下来先把 checkpoint 推进一下。 EBS 中的 journalEBS的ChunkServer可能会同时处理大量的写请求，这样写请求最终会转化为大量的磁盘随机写操作，随机写磁盘性能是很差的。有了journal后，可以将这些大量的随机写请求，转化为对journal文件的基本上是顺序的写请求，从面提升写性能，降低写延迟。 同时，如果没有journal，那么用户数据将被直接写chunk文件，这会导致在chunkserver挂掉时chunk文件里出现脏数据，从而使得chunk不同副本出现不一致的问题。 所以日志总有个基本的用处： 优化随机写 处理并发写 "},{"title":"TiDB 与 bbb","date":"2021-01-26T03:02:16.000Z","url":"/2021/01/26/TiDB-%E4%B8%8E-bbb/","tags":["系统架构","数据库","存储"],"content":"两种业务场景和相应的架构模式偏重事务处理（online transactional processin, OLTP）：此类数据库将不同属性连续存储，也即按行存储。按行存储可以使得插入/更新/删除更快，毕竟一条数据的所有属性是连续存储的。这种存储模型也叫做 N-Ary Storage Model (NSM)。 偏重数据分析（online analytical processing, OLAP）：此类数据库将不同数据的同一属性连续存储，也即列存储。这种存储可以使得查询操作只读关心的数据属性，而不是一整条数据，减少浪费；按列储存可以更好地支持复杂查询。这种存储模型也叫做 Decomposition Storage Model (DSM)。 TiDB 的基础架构Log-Structured Merge-tree (LSM-tree)是一种存储结构，由于其优越的写性能被很多大型分布式存储系统采用，包括Google 的 BigTable, Amazon的 Dynamo, Apache 的 HBase 和Cassandra等；MongoDB的WiredTiger引擎则支持B-tree 和 LSM-tree 两种模式；TiDB 则使用了著名的RocksDB。 Balde 2.0 是基于社区TiDB版本，独立重构存储层（改动较大，下面会介绍），深度定制SQL层（改动较小，复用较多的功能）的分布式数据库。bbb 2.0 主要结构如图所示： TiSQL 又叫 TiDB Server，基本实现了 parser、optimizer、executor、cache，是无状态可以无限扩展。但 TiDB 本身并不是 monolithic deployment 部署的，而是和底层的 tikv 分离部署的-这和 MySQL 的架构不一样。 在最初版本的实现里面，TiSQL 的接口层稳定以后，就能接入 HBase，这点和 Tair 是很像的。 bbb-root 是一个 pd（placement driver） server 的分布式集群，彼此之间也使用 raft 靠 leader 来维护元数据，元数据是负载均衡至关重要的信息。 采用类似于Google F1/Spanner 的分布式KV存储 (即bbb-kv) + 无状态计算节点 (即bbbSQL) 模型； 用户表中每一行数据，对应一个 Data K/V（Key: tablePrefix{TableID}_recordPrefixSep{RowID}Value: [col1, col2, col3, col4]） + N个Index K/V（Key: tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValue Value: RowID），N是二级索引的个数(N&gt;=0)；这些 kv 是以 map 的形式组成了 sstable，由 Rocksdb 支持（基于谷歌的 LevelDB，由 facebook 出品）。 -bbb-kv 以Ranged Partition的方式将整个key空间分为多个Region(Partition/Shard)，每个Region对应一段连续范围的key；这点很类似 HBase。 每个Region都有多个副本，副本间通过共识协议 Raft 来达到CAP的平衡；多个 region 组成一个 raft-group。 每个Region的数据，以一棵独立LSM-tree的形式存储； Region在容量超出水位线时，会进行分裂，变成两个独立的Region； bbb-root 管理集群元数据信息，提供Region的路由服务以及全局授时服务； bbb-sql处理SQL解析、优化和执行，将SQL请求转化为一系列的K/V请求，再根据路由信息，发送对应的bbb-kv 节点； 提供乐观/悲观锁模型，支持分布式事务，支持Read Committed隔离级别。默认使用乐观事务模型，对于写写冲突，只有事务提交时才检测冲突。支持完整的 ACID 语义（TiKV 是个 Transactional Storage Engine）。 多节点同步都依赖于 Raft，批量事务处理则依赖于谷歌的 Percolator 事务处理模型。 tidb 本身不能很好地支持自增主键（这会导致单一的写流量集中到一个节点上），改造的方法是引入唯一索引。 LSM-tree 和一些典型实现LSM-tree模型LSM-tree [1] 是一种out-of-place（相对于原地更新，暂且译作外地更新） update的结构，它的特点是把新数据写到新的位置，在后台做merge，而不是原地更新。 所谓out-of-place，是相对B-tree等in-place update的结构而言的，in-place的结构只保持一个最新版本，查询效率更高。但是因为有了随机写，in-place update牺牲了写性能。 Out-of-place 没有随机写，但是也带来了一些其他开销，尤其是读可能需要查询多个层级。 注意，C0是内存中的，而C1及其他更大的层级，都是需要持久化存储，且越靠近内存的层数据量越小。 Tree的含义：每一层是一颗树。事实上最原始的paper [1]中，每一层都是一个B-tree，只是后来的很多实现中，已经不用B-tree了，但是名称保留了。 层与层间的增量关系：C0实际上是C1的增量，C1是C2的增量。增量数据可以是Insert/Update/Delete等不同操作产生的。 Log-Structured 的含义： 像写log一样去顺序磁盘，避免随机写，因为随机写性能太差。 Merge 是指把上层的增量数据，合并到其基线版本（所以基线版本是 Ck）中去的过程。例如，C0的数据被merge到C1中。这个过程也称为 Compaction，不过现在已经有跨层compaction等变体。 FAQ: 为什么要Compaction/Merge: 提高查询效率：虽然每一层是个有序的集合，但是层级多了后，查询可能要依次查询每一个层级。通过merge，让数据从较多个有序集合，变成较少个有序集合，提高效率。 释放空间：重复写的数据，其旧版本可以在Compaction时删除；用户Delete的数据，需要做物理删除。 一些开源的LSM-tree 实现LSM-Tree 因为优秀的性能被广泛采用，其中著名的开源产品包括Google的 Jeff Dean的杰作 LevelDB，Facebook 基于LevelDB开发的 RocksDB 等。 FaceBook 还开发了 MyRocks，在部分业务场景下用 RocksDB 替 InnoDB 作为 mysql 的引擎。下表列出了一些原始的 LSM-tree 概念与LevelDB中概念的对应关系。 LSM-tree概念 LevelDB/RocksDB对应 C0 Mem Table (分为Mutable/Immutable) C1 Level-0 (Tiered) C2 Level-1 (Leveled） Ck Level-(k-1) (Leveled) LSM-tree 的一些问题和 bbbKV 的设计取舍bbbKV的存储也是采用LSM-tree的方式。LSM-tree本身是灵活的，自身也存在一些问题，在设计和工程实现方面需要进行取舍。 这些问题可以用“三个放大”来描述。 三个放大LSM-tree 存储系统在设计实现时需要考虑写放大、读放大和空间放大三个因素，这三个因素都是比率： 写放大： 磁盘数据的写入量 / 用户写入的数据量 读放大： 磁盘数据的读入量 / 用户实际要读取的数据量 空间放大：磁盘空间占用 / 有效的用户数据量 其中写放大往往是最严重的，对它的计算和分析也相对较多。 写放大的计算及最优化在LSM的原文中，作者提到层与层之间的扇出系数(size ratio)是常量时，写放大最优。但是具体取什么常量是最优的，并没有明确。 Size Ratio是指相邻两层之间大小的比率，比如，C0层大小是1GB, C1层大小是10GB，那么 Size Ratio 就是10。 FaceBook的文档中有获得最优写放大倍数具体的计算方式，详细推导参见[2] [3]。这里大致列下推导过程： 假定LSM-tree 每一层的扇出系数相同，都是f，即f=sizeof(Cl+1​ )/sizeof(Cl​ )，而总的持久化层数为n。 考虑到数据最终会落到最底层，那么最终写放大倍数为： wa=n∗f 假设磁盘容量是内存容量的 t 倍，或者说内存/磁盘容量比是1/t，那么t=fn ,即f=t1/n 。写放大系数wa变为： wa=n∗t1/n t 是已知常量，把wa 对n求导数，经过一些变换，可以得到式子： n′ (wa)′ ​ =t1/n −n1​ ×ln(t)×t1/n =t1/n ×(1−nln(t)​ ) 当n=ln(t)时，导数为0，得到最小的写放大倍数。 在这种情况下，每层的扇出系数是f=t1/n =t1/ln(t) =e。注意，虽然rocksdb的默认扇出系数是10，但是数学上最佳值是自然对数e。 如果 t = 1024，则对应层数 n 的最佳值是ln(1024)=6.93，取整为7层。 注意上面假设的1024是个较大的比值，即磁盘容量为内存容量的1024倍。 读放大假设LSM-tree有n层。由于每一层的文件都是有序的且有元数据。对于一个点查， 在每层最多打开一个文件，因此读放大是O(n)。 常见的缓解读放大方法包括： Cache： 尽量缓存容量较小层级的数据在内存中，因为它们访问频率较高。 Bloom Filter: 可以根据hash值提前确定一些key不存在，从而缓解一部分点查的读放大；但是解决不了Scan类型的范围查询的读放大。（这个结论非常重要，做读放大的优化，一定要先把问题分成两类问题）。 Range Filter: 例如SuRF等，可以优化查询范围查询的性能。 总的来说，层级越少，对读越友好。Hash 对单一 key 查找有极强的优化作用，但 range 查找可能要借助一些空间局部性优化手段。 空间放大空间放大主要有两个因素： 不同 Level 有同一key的多个版本; 用户已经删除的数据没有做物理删除，只是记录了log或者在做了删除标记。 空间放大一般相对有限。对于第一个因素，层级越少则重复的key越少，相应地，它导致的空间放大越低。 对于第二个因素，用户已删除的数据何时在物理上被删除，主要依赖于Compaction机制。 bbbKV：每分片独立的LSM-tree有些分布式存储系统选择使用一个 LSM-tree存储整个节点的所有分片的数据，比如 TiKV（架构上简单）；也有些选择一个 LSM 实例只管理节点上的某个分片，例如 Hbase。（架构上复杂） bbb 选择了后者，即一个表有多个分片，每个分片对应一个 LSM-tree，理由是： 表（索引）的迁移、删除效率更高，可以直接通过物理文件的传输、删除实现，无需进行数据遍历，性能优势明显。 不同的表物理上就完全分开，隔离性更好，可以做更细粒度的控制，比如表级的缓存预热。 限定单个 LSM 的大小后可以进行深度定制，在几乎不影响读放大、空间放大的前提下可以大大降低写放大 付出的代价主要是实现上的复杂性，比如全局元数据管理和跨分片操作（分裂、合并）相对单实例管理所有分片需要更精心的设计。 bbbKV：大 Memtable、少层级bbbKV选择了较大的Memtable(即前图中的C0)，大部分时候只有一个持久化层(称之为Level-1)。取舍 1。主要原因如下： 服务器能够为bbbKV分配的内存、磁盘容量比较确定，可以算出内存/磁盘容量比。 典型的内存/存储的容量比：按照2.9TB NVME磁盘， 256GB内存计算，内存与存储容量比接近 1/10，即 t 接近于 10。 由于对schema的感知，Memtable 中可以只保存修改的列，而不是整行，所以相当于获得了更高的内存/磁盘容量比。这一点leveldb/rocksdb 这种纯K/V接口的引擎是做不到的。取舍2。 写流量有明显的局部性，更新的 key 较为集中，不会出现 major compaction 关联大量 L1 文件，每个文件只关联少量数据的情况。取舍 3。 每个分片一个 LSM 实例，限定了单个实例的大小（目前暂定2G，可能根据实际运行情况调优），也就限制了总的文件数量（千级别），不会对读造成太大的影响。取舍 4。而 leveldb/rocksdb 原生设计需要支持单实例数百上千G的容量，不分级读会很慢。 在此前提下，与 TiDB(TiKV) 相比，这样设计有如下取舍： 写放大大幅降低：每次 compaction 涉及的 SST 文件中实际不需要合并的数据减少；每个 key 经过一次 compaction 就达到了“最终”层。 空间放大略微降低：bbb 没有空间放大，比 TiDB(rocksdb) 的 1.1 要好些。 读放大相当：考虑在数据量 1T 的进程上查询一个不在 memtable/immutable 的 key 由于 region 已经确定，假定是满 region，bbb 需要从 1000 个(2G/2M) FileMeta 中找到目标 SST，共要 10 次逻辑查询和 1 次物理查询（ps: SST 文件没有多 level 重叠，bloom filter 的必要性下降了）-这证明了 bloom filter 能够优化 leveling i/o，不适合优化单 i/o。 TiDB 所有 region 共用一个 rocksdb，导致潜在的候选文件更多(1T*1.1/8M ~ 144,000)，但由于 Level 和 fractional cascading 机制，逻辑查询较少。物理查询大部分情况下也只需要 1 次，但 bloom filter 误报或范围查询时，需要每层做一次物理查询。 bbb 查询耗时较稳定，TiDB 受 key 所在层级和查询方式影响较大。 层级较低的“温” key TiDB 占优，能以较少的逻辑查询和相同的物理查询次数获得数据； 范围查询 balde 需要的物理查询较少，优势明显； 考虑到点查较多，且 bbb memtable 远大于 TiDB，读放大两者大致相当。 总体上 bbb 优势明显，关键在于充分利用已知要查询的数据属于哪个 region 的特性，重新调整了底层存储引擎；TiDB(TiKV) 整个进程用一个 rocksdb 的方式无法利用这点。 上面有了定性分析，下面我们定量地计算一下写放大。按照t= 10和前面的最优扇出系数 e 计算，最优的持久化层级n=ln(10)=2.3层，取整则是2层。相应地，可以把e向上取整 f=3，最终取整的写放大倍数是3*3=9倍。 如果BaldeKV 只使用一个持久化层： 扇出系数f=10，写放大倍数是10倍； 空间放大较小，没有各层间保存重复key导致的空间浪费； 读放大是1； 所以，bbbKV选择了只有一个持久化层Level-1。 应急处理： 如果出现大量的突发写，导致内存压力过大，而将 memtable 与磁盘上的 Level-1 做Compaction太慢，bbb-kv会临时启用Level-0，作为Level-1的增量。 Level-0 是个特殊的层，它允许同层的不同文件间key的重叠。所以写 Level-0 不需要任何Compaction，可以快速缓解内存压力。在高峰过后，可恢复正常的单个持久化层。 comment 老牌的数据库产品oraclemysql使用的是B-tree加undo的方式实现存储mvcc，而LSM相对来说实现更简单，对于很多热点相对集中的业务，内存使用效率更高，可以借鉴B+tree引擎的思路去优化compaction 长期来看，并不是非此即彼，它们的融合架构是比较好的方向，比如bbb中的SST存储结构，整体来看已经是支持快照的B+tree结构了；而优化了compaction影响后的架构可以支持更频繁的fullcompaction，跟oracle/mysql的checkpoint也就很像了。 1）关于先进和落后（打开链接只看到一点点评论，不知作者怎么论证落后和先进的），LSM在关系数据库领域应用并不少，只是发展的没那么早，不知道说落后是啥理由。例如，单机数据库：FaceBook的MyRocks(MySQL的底座换RocksDB，有对比测试，性能比较强悍)；分布式数据库领域：GoogleSpanner和阿里的OceanBase。 2）相比之下，LSM-tree的设计更倾向于写优化，B-Tree则倾向于读优化。为什么近年来LSM-Tree受关注多，跟存储系统的变化也有关。我们逐渐从机械盘过渡到了SSD盘，SSD有几个机械盘所没有的特性，更需要优化写：1)读写性能不均衡(写比读差很多，网上后数据); 2)写需要做擦除(擦除的单位远大于磁盘扇区)，本身又是一次写放大；3)写寿命/擦除次数非常有限。事实上，我知道的做SSD固件的人，基本都是在优化写性能和寿命。 "},{"title":"构建 spring-framework","date":"2021-01-09T06:39:58.000Z","url":"/2021/01/09/%E6%9E%84%E5%BB%BA-spring-framework/","tags":["Spring","gradle"],"content":"介绍下使用到的 Gradle 工具《一篇文章讲清楚Gradle与Gradle Wrapper的区别》 comments： Gradle Wrapper 提供了一种“在本地构建中，使用特定版本的 Gradle 进行构建”的功能。 换言之，对于大多数敏捷迭代的项目而言，应该选择 ./gradlew clean build，而不是 gradle clean build。这样不会遇到 pluginManagement 之类的问题，这样说来，每个项目都是自构建的。 要么 IDE（像 Android Studio）自带 gradle wrapper，要么项目自带一个 gradle/wrapper 文件夹，这个文件夹里指定了 gradle-wrapper.properties。 这个命令专门指定了特定版本的 gradle。-all.jar、-bin.jar、-src.jar 分别代表不同的包。 gradlew是在linux,mac下使用的，gradlew.bat是在window下使用的，提供在命令行下执行gradle命令的功能。-这种 w 的中间层策略，值得我们学习。 每个项目本身都带有特定的 plugin（可能在下一版本失效），所以 gradle 专门写了针对 gradle project 的 upgrade 指南​。 .gradle文件夹，就是那个跟项目第一个文件夹，带点的那个。那个对我们没什么用，他是gradle运行的时候产生的一些记录性的文件。我们不需要关注。 实际构建的过程./gradlew -a :spring-webmvc:test 这里面蕴藏一个模式./gradlew -a :项目名:task名。 代码风格Spring 使用 tab 而不是空格（和很多其他项目恰恰相反），替换空格的方法是find . -type f -name &quot;*.java&quot; -exec perl -p -i -e &quot;s/[ \\t]$//g&quot; &#123;&#125; \\;。 Spring 的代码不提倡使用静态引用： Static imports should not be used in production code. They should beused in test code, especially for things like import staticorg.assertj.core.api.Assertions.assertThat;. 成员的顺序： static fields normal fields constructors (private) methods called from constructors static factory methods JavaBean properties (i.e., getters and setters) method implementations coming from interfaces private or protected templates that get called from method implementations coming from interfaces other methods equals, hashCode, and toString Spring 使用埃及括号。Braces mostly follow the Kernighan and Ritchie style (a.k.a., “Egyptian brackets”) for nonempty blocks and block-like constructs。"},{"title":"云原生应用","date":"2020-12-16T14:01:05.000Z","url":"/2020/12/16/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8/","tags":["云原生","分布式系统"],"content":"弹性问题 弹性服务最好和监控服务、限流服务配合。 弹性服务的监控最好低于限流服务的阈值，否则不会被触发。 要注意扩容阈值和缩容阈值。如果有必要，设置阶梯阈值，离正常值越远的阶梯越不敏感，离正常值越近的阶梯越敏感。阶梯越远，弹性的量应该越大。 注意弹性有静默期，注意发布和弹性静默期之间是相互矛盾的，要相互关闭。 如果有压测标记，注意让弹性扩容监控包括/排除压测流量。 任务调度或者特殊的有状态的中间件依赖的分布式节点应该尽量避免弹入和弹出。 慢预热服务-扩容机器服务可用性差问题极少部分依赖缓存预热的业务在接入弹性的过程中，在业务代码配置不合理的情况下，可能出现服务节点启动时服务不可用或性能较差的情况。 出现这种问题可以产生如下情况: 服务节点启动后尚未完全预热，大量流量打入导致服务不可用（TP耗时飙升）。 服务依赖数据源尚未初始化完成，服务节点就已注册至服务治理的命名服务器，开始承担流量，但此时服务处于不可用状态（请求异常）。 机器刚刚扩容出来时cpu.busy指标较高，承接流量后影响服务可用性。 此类问题的根本原因是：服务自身预热工作未完成时，处于服务不可用状态，此时不应该将服务节点注册至服务治理的命名服务器承接流量。 为什么服务预热未完成的情况下，服务节点仍会注册至服务治理的命名服务器？ 业务自身代码中没有进行强保障，一般是由于没有指定bean加载顺序，导致在预热未完成的情况下，服务端口已启动，此时服务节点会自动注册至服务治理的命名服务器 直接由弹性服务启动的容器容易遇到这个问题，但使用发布服务发布的容器不容易遇到这个问题。 解决方案： 业务调整服务启动类加载顺序，确保服务warmup完成后，启动服务节点端：如使用 xml 配置的 bean 标签的 depends-on 属性。 开启服务慢启动配置，逐步调整新注册节点的权重比例，避免流量突增。通过服务节点权重变化实现对服务节点调用流量的控制，达成服务预热的效果。 服务慢启动的触发条件：当服务状态由未启动变为正常时，都会触发慢启动 以默认权重10为例：060s权重为1，60120s权重自动改为3，120s之后权重为10，慢启动结束 假如发布前权重为100：060s权重为1，60120s权重自动改为3，120s之后权重为100，慢启动结束 假如发布前权重为8：060s权重为1，60120s权重自动改为3，120s之后权重为8，慢启动结束 假如发布前权重为2：060s权重为1，60120s权重自动改为2，慢启动结束 "},{"title":"去屑洗发水","date":"2020-12-12T05:44:14.000Z","url":"/2020/12/12/%E5%8E%BB%E5%B1%91%E6%B4%97%E5%8F%91%E6%B0%B4/","tags":["生活"],"content":" maro 摩隆 17 艾凡达男士头皮净化洗发露 sp 清爽男士劲能洁发乳 欧莱雅维他强韧（经常缺货） ryo 男士参澈控油洗发水 selsun 黄 养元青 "},{"title":"活动保障性体系建设和实践的总结","date":"2020-12-08T05:50:58.000Z","url":"/2020/12/08/%E6%B4%BB%E5%8A%A8%E4%BF%9D%E9%9A%9C%E6%80%A7%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE%E5%92%8C%E5%AE%9E%E8%B7%B5%E7%9A%84%E6%80%BB%E7%BB%93/","tags":["系统架构","高可用"],"content":"活动的定义和特点活动具有大并发、高流量的特点，前期充足的准备是活动顺利完成的必要条件。 准备好完备的保证流程，可以为相关人员提供指引。 基本的保障方案 事前：严格按照保障步骤分工执行，活动要报备，核心链路要梳理，梳理完要评估容量和准备，要治理风险，要准备预案，要建设大盘，准备压测和演练预案，要安排值班。 事中：相关责任方（要分技术负责人和运维负责人，召集相关人员，组成稳定性保障小组）监控线上数据，以线上/线下会议、群聊和电话等多个方式参与值班并及时响应异常事件。 事后：组织复盘，总结亮点，指出不足，沉淀经验。 活动报备要理清活动信息：活动背景、活动时间、用户参与路径、活动链接、活动 玩法、预计UV数、负责人。 核心链路的设计与梳理核心链路的梳理、设计需和活动保障的几个核心要素相结合，核心要素分为：隔离、限流、容量。 隔离：域名隔离、Nginx集群隔离、核心服务隔离、以及其他一些重要服务的隔离。 限流：前端活动业务限流、Nginx限流（HTTP限流）、服务限流（RPC）等。特别要关注接入层的限流能力和方案。 容量：从域名解析到后端存储的系列容量评估和准备，容量无法保障的时候需做到对应的预案。特别要关注网关、存储和其他有状态或者单点服务的容量问题。 评估方案 评估基础资源：按照已知的链路图梳理相关的资源准备是否充足。 核心服务评估：根据核心链路，进行容量评估，并完成服务扩容，或接入弹性扩缩容。 依赖服务评估：核心链路服务依赖的下游服务，进行容量评估，并完成服务扩容，或接入弹性扩缩容-要熟悉弹性扩容的策略，精确设计弹性扩容的流程。 其他关联服务评估： 前置行为：用户在进入活动页面之前的一些行为，会对某些服务造成一定压力，比如首页推荐； 后置行为：用户参加完活动之后的一些行为，比如去我的券包去查看券信息，或者查看订单信息，此时会对app中“我的”部分服务造成压力，比如红包卡券服务、订单查询服务、个人资源位服务、动态布局服务。 风险治理 评估服务是否有限流、服务是否有熔断机制、服务是否隔离（服务仅支持本次活动）等方案上的风险。这每一种机制，都应对一类风险。 评估是否有安全风险。 对运营策略、文案、账户等做整体评估，避免出现歧义客诉、法律纠纷、活动效果大打折扣等问题。 大盘建设要把监控告警放到统一的大盘中，以便高效精准地定位问题。 核心指标应包括交易数据、客诉数据、核心接口成功率、流量等。 活动后复盘 目标回顾：目标拆分，达成情况回顾 case study 复盘：沉淀经验，总结教训，TODO 落地与完成。 峰值与容量回顾：对比实际峰值与预估差异，实际容量下，稳定性是否得到保障，及容量是否高估太多而造成成本浪费。 预案回顾：预案是否到位、完备，有无预案待补充和完善。 亮点与不足：肯定亮点和回顾不足。 后续改进：输出正确的做法及未来规划。 "},{"title":"服务治理组件笔记","date":"2020-12-02T09:54:32.000Z","url":"/2020/12/02/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E7%BB%84%E4%BB%B6%E7%AC%94%E8%AE%B0/","tags":["系统架构"],"content":"背景service-centric architecture 以服务为中心的架构，和 SOA 的区别是？ 服务治理的模式server-side pattern：容易集中管控，易单点失败。client-side pattern：不容易集中管控，不易单点失败。 演化流程 基础治理能力：通信协议统一、命名服务的统一、监控预警、运营平台 高性能/易用性：通信框架高性能/通信框架轻量化/分布式链路追踪/测试工具可视化 全方位的治理能力：全链路压测平台/深度服务化 SOA/链路级流量治理/易用化平台构建 业界前言探索：SET 化高扩展架构/云原生架构治理 治理体系该有的治理能力都要有。 注册中心 服务注册 服务概要 提供者 消费者 监控报警 节点监控 性能监控 业务监控 异常监控 服务运营 配置管理 服务分组 节点管理 服务鉴权 数据分析 性能指标 来源去向 主机分析 数据报表 调用链路 关键组件-本地代理比如 LocalAgent，能够做到：策略下沉，解耦功能，对业务服务侵入性低。 但 Provider/Consumer 还需要使用自己的 sdk，它和远端的 naming service 服务，管理本地服务列表缓存、配置列表。 这样可以让通信简单化。 健康检查服务Scanner 是专门的服务，负责检查和更新服务节点状态。这也可以有中心化和去中心化的设计。中心化的设计简单一点。 由健康检查服务可以实现平滑发布： 先修改服务为不可用，kill 掉服务。 发布成功，修改服务为启动中。 然后进行健康检查。 健康检查成功-服务修改为正常。 逐步导入流量。 这种发布要近端和远端协同，涉及状态机涉及，在关闭流程中，先改服务治理远端状态，再处理本服务器问题；在启动流程中，先处理本服务器问题，再改服务治理远端状态。 Mesh 化完全 sidecar 化的 agent，完全独立的 agent 进程，这样所有服务治理的功能都用治理流量的方式来做。之前的 agent 只治理服务治理流量，sidecar 化以后也治理业务流量。 SRE 可以自主升级。业务可以更加聚焦业务核心逻辑。 单元化/基础设施set 只是逻辑机房（数据中心）的一种称呼。 使用 set（或者其他方式）可以实现全链路流量隔离。这种全链路流量隔离，可以提供： 全链路灰度验证 全链路服务压测 全链路故障演练 服务治理平台 事件运营平台基本结构.xmind"},{"title":"《罪與罰》出場人物筆記","date":"2020-11-29T14:12:51.000Z","url":"/2020/11/29/%E3%80%8A%E7%BD%AA%E8%88%87%E7%BD%B0%E3%80%8B%E5%87%BA%E5%A0%B4%E4%BA%BA%E7%89%A9%E7%AD%86%E8%A8%98/","tags":["文学"],"content":"版权归作者所有，任何形式转载请联系作者。作者：二阶导（来自豆瓣）来源： 這篇筆記按照目前小說的兩位主線人物，即 拉斯柯爾尼科夫 和 馬爾梅拉多夫 兩家人作爲主軸進行區分，隨着劇情的推進，此結構可能會進行調整。 拉斯柯爾尼科夫 相關1 羅季昂 · 羅曼諾維奇 · 拉斯柯爾尼科夫 Rodion Romanovich Raskolnikov (Родиóн Ромáнович Раскóльников)小名叫做羅佳 (Rodya)，或是叫做羅季昂，羅季卡 (Rodka)，窮困潦倒的法律系大學生，男主角 拉斯科爾尼科夫 Raskolnikov 中的 Roskol 意為「分裂」①，指俄罗斯正教会的教派分裂事件②2 阿芙多季婭 · 羅曼諾芙娜 · 拉斯科爾尼科娃 Avdotya Romanovna Raskolnikova (Авдотья Романовна Раскольникова)小名叫做杜尼婭 (Dounia)，或是叫做杜涅奇卡 (Dunechka)，拉斯科爾尼科夫的親妹妹 3 普利赫利婭 · 亞歷山大羅夫娜 · 拉斯科爾尼科娃 Pulkheria Alexandrovna Raskolnikova拉斯科爾尼科夫的母親 4 德米特里 · 普羅科菲伊奇 · 弗拉祖米欣 Dmitry Prokofyich Vrazumikhin, or Razumikhin常被叫做拉祖米欣，拉斯科爾尼科夫的大學同學，善良忠厚 拉祖米欣 Razumikhin 中的 Razum 意為「理性、思維、智力」5 阿廖娜 · 伊萬諾芙娜 Alyona Ivanovna給拉斯柯爾尼科夫放高利貸的老婦人，冷漠刻薄 6 莉扎薇塔 · 伊萬諾芙娜 Lizaveta Ivanovna十四等文官夫人、放高利貸的老太婆阿廖娜·伊萬諾芙娜的妹妹，高個子、反應遲鈍、膽小怕事、性格柔順，常被姐姐毆打 7 娜斯塔西婭 · 彼得羅芙娜 Nastasya Petrovna (Настасья Петровна)又叫做娜斯塔西尤什卡，或是娜斯金卡，拉斯科爾尼科夫所住公寓的女僕人，來自鄉下 8 普拉斯科維婭 · 帕甫羅芙娜 · 扎尔尼岑娜 Praskovya Pavlovna Zarnitsyna又叫做帕申卡，拉斯科爾尼科夫的女房東，有一個女兒，叫做娜塔莉婭·葉戈羅芙娜 9 阿爾卡季 · 伊萬諾維奇 · 斯維德里蓋洛夫 Arkady Ivanovich Svidrigaïlov阿芙多季婭去做家庭教師時的雇主，對阿芙多季婭粗暴無禮，實際上暗戀她，借暴力宣洩情感，酒鬼 斯維德里蓋洛夫 Svidrigaylov 中的 -gail- 與德語 geil（好色的）近似10 瑪爾法 · 彼得羅芙娜 · 斯維德里蓋洛娃 Marfa Petrovna Svidrigaïlova斯維德里蓋洛夫的妻子，宅心仁厚，在花園偷聽到丈夫向阿芙多季婭求婚，誤以為是她勾引丈夫，故將她趕走 11 彼得 · 彼得羅維奇 · 盧仁 Pyotr Petrovich Luzhin斯維德里蓋洛妻子的遠房親戚，七等文官，未婚男子，向阿芙多季婭求婚，體面可靠，但陰沈傲慢，愛慕虛榮 盧仁 Luzhin 即 Luzha，意為「水塘」12 安德烈 · 謝苗諾維奇 · 列別賈特尼科夫 Andrey Semyonovich Lebezyatnikov目前暫時和盧仁住在一起 列別賈特尼科夫 Lebezyatnikov 中的 Lebezit 意為「巴結、討好」13 佐西莫夫 Zosimov (Зосимов)拉斯科爾尼科夫的醫生，和拉祖米欣一起討論殺人事件 馬爾梅拉多夫 相關1 謝苗 · 扎哈羅維奇 · 馬爾梅拉多夫 Semyon Zakharovich Marmeladov又叫做謝苗 · 扎哈羅維奇，文縐縐、迂腐的九等文官，將金錢揮霍一空的酒鬼，對家人有種病態的愛 2 卡捷琳娜 · 伊萬諾芙娜 · 馬爾梅拉多娃 Katerina Ivanovna Marmeladova馬爾梅拉多夫妻子，曾是軍官的千金小姐，受過教育，但是性格暴躁易怒，高傲刻薄 3 索菲婭 · 謝苗諾芙娜 · 馬爾梅拉多娃 Sofya Semyonovna Marmeladova馬爾梅拉多夫的親女兒，也叫做索涅奇卡 (Sonechka) ，索尼婭 (Sonya) 馬爾梅拉多娃 Marmeladova 中的 Marmelad 意為「軟糖、柑橘果醬」4 阿瑪莉婭 · 費奧多羅芙娜 · 利佩韋赫澤爾 馬爾梅拉多夫的房東 案件相关1 尼科季姆 · 弗米奇 Nikodim Fomich (Никодим Фомич)警察局长 2 伊利亚 · 彼得羅維奇 Ilya Petrovich (Илья Петрович)警察分局副局长，中尉，性格火爆 3 亞历山大 · 格里戈里耶維奇 · 扎苗托夫 Alexander Grigorievich Zamyotov (Александр Григорьевич Заметов)警局办事员 扎苗托夫 Zamyotov 中的 Zametit 意為「注意、意識」4 米科拉·傑緬季耶夫 Nikolai Dementiev (Николай Дементьев)又叫做尼古拉，或是尼科拉什卡，和他的朋友米特莱一样是油漆匠，事发当天恰好在楼下做工，被屈打成招承认杀人 參考資料①：Rodion Raskolnikov: ②：Raskol: ③：Crime and Punishment: "},{"title":"《今日简史》","date":"2020-11-23T09:40:16.000Z","url":"/2020/11/23/%E3%80%8A%E4%BB%8A%E6%97%A5%E7%AE%80%E5%8F%B2%E3%80%8B/","tags":["历史"],"content":" 本书不同于《人类简史》和《未来简史》，是探讨当下的重要议题和全球化的议题。其实顶层的议题，和每个人的切身命运，是息息相关的。这本书其实是 21 世纪的 21 堂课，有内部重复的内容。 在自由主义的故事已经失去解释现实的能力的时代，知识分子的头脑已经对现实产生了无力感。自由主义作为灵丹妙药，曾经成为历史唯一正确的一边，但现在已经没有了正确的一边。甚至有些人认为特朗普的当选是人类文明的终结，自由化和全球化是一个巨大的骗局。 当今的信息技术革命和生物技术革命，使得自由主义政治体系无从招架。因为现在的技术革命拥有的爆炸性潜力难以规范。算法的存在可能使得金融体系难以被理解，而区块链的存在可能使货币改革，税制失效（当代法币能够存在的经济学基础之一就是：政府强制征税，而且强制税收用货币缴纳）。未来，信息可能成为经济体系里面最重要的资产，也是在大量交易中唯一交付的东西。 信息技术和生物技术的发展，可以帮助我们改造我们的身体和思想。 人类发明工具很简单，使用工具却很复杂-困难。人类在无意之中获得改造地球的能力的同时，也在无意地破坏地球的生态。 特朗普当选和英国脱欧，意味着身处世界自由主义中心地带的选民，对自由主义的故事和民主进程失去了信心。1938 年，自由主义社会方兴未艾的时候，老百姓认为自己是生活中的英雄。但如今，一般人会觉得自己无足轻重。在 20 世纪，群众反抗剥削，把自己在经济中的重要作用转化成为在政治上的权力；在如今，群众担心自己以后变得无足轻重，于是急着发挥目前仍有的政治力量。这种现象展现出与传统社会主义革命相反的轨迹：过去推动俄国、中国和古巴革命的，是一群对经济至关重要但对政治缺乏权力的人；而在 2016 年，支持特朗普当选和英国脱欧的，却是一群享有政治权力却担心失去经济价值的人。在 21 世纪，populist 反抗的不是经济精英剥削人民，而是经济精英不再需要人民。 反抗“无足轻重”比“反抗剥削”困难许多。 自由主义和全球化第一次失败是在第一次世界大战。第一次世界大战以前，帝国主义者认为武力征服，优于自由与和平商业活动带来的统一。第一次世界大战是终结一切战争的战争。接下来到了 40 年代，自由主义在与法西斯主义的战斗中幸存下来。切格拉瓦的年代（50 年代），看起来自由主义仅一息尚存，但最终又取胜。自由主义从共产主义吸取长处，在自由之外，也重视平等。 西方人的自由主义只针对中产阶级男性，很少涉及女性、少数族裔和工人阶级。所以，欧洲的殖民地的民族解放运动所寄望的是苏联和中国，而不是西方国家。西方国家在战后建立起了共产式福利计划的社会安全网，提供社会福利。 到 90 年代末期，思想家和政治家高谈“历史的终结”，信心满满地认为过去所有重大的政治和经济问题都已获得解决，认为自由主义经过翻新，成为包含民主、人权和自由市场和政府福利组合的组合，是人民的唯一组合，统一世界。 裴迪南时期、希特勒时期、格瓦拉时期过后，人们来到特朗普的时期，特朗普时期的特点是历史虚无主义，不再推动全球化，认为自由主义在本地流通即可。相比之下，中国更开放，也更拥抱自由主义。俄罗斯实行寡头统治。伊斯兰主义吸引土生土长的人。以色列希望恢复古以色列的领土（多数国家把大使馆设在特拉维夫，巴勒斯坦和以色列都认为它们对耶路撒冷有主权）。一神教侍奉对好怜悯、行公义的上帝，以“天不变道亦不变”的态度来面对变革。大家心中还是不愿意放弃自由主义的故事-大部分的人愿意移民到西方国家。 自由主义幻灭后形成思想空缺，暂时由地方的怀旧幻想来填补。虽然自由主义还有诸多缺陷，但自由主义仍远胜其他方案。人类历史上第一次，大多数人无疾而终，而非死于非命。 现在我们面临的最大问题是：生态破坏和科技颠覆。传统的自由主义是通过经济增长，使饼变得更大，来平息棘手的社会和政治冲突。但现在增长，则是以破坏性创新为基础。当代由于科技颠覆和生态崩溃，年青一代只是维持现状，已经算是幸运。 我们是回头去谈旧神祇，还是超越当今，制造新的价值观？我们处于虚无主义时期，意味着我们幻灭和愤怒。如何处理这种幻灭和愤怒，就是本书的议题。我们只有能够正确理解这两种革命带来的挑战，才能重新形成新时代的叙事-我们应当如何看待我们的世界，哪些是未来世界里正确的价值观。 机器学习和机器人一定会改变工作的形态。卢德注意会反抗这种潮流。人有两种能力：身体能力和认知能力。机器的出现使得依靠身体能力的工作逐渐消失，人工智能的出现会使人在认知能力方面失去优势。人类没有第三项能力能够永远胜过机器。传统观念认为，“心灵”是神圣创造物，实际上并非如此。 未来，一群人会被一个网络取代。两辆汽车如果由人来驾驶，就是两位司机，两辆汽车如果由机器来驾驶，则只有一位司机-一个同时具有连接性和可更新性优点的网络。 在未来，无用之人就是没有受到足够教育之人。 19 世纪工业革命兴起之后，当时的社会、经济和政治模式都无法应对相关的新情况和新问题，所以出现了新的社会制度。技术革命带来的新挑战，一样可能带来类似的挑战。如果应对这种挑战失败，人类付出的代价可能会比第一次世界大战大得多。现行的社会制度不足以保护劳工（而不是保护工作）。 机器可能不只是生产者，还可能是消费者。证券交易所的算法就是一个好例子，谷歌的搜索算法是另一个例子。 政府可以采取两种方法：提供全民基本收入，提供全民基本服务。 脱欧展示了选举制度的一个弊端：它只提供了人人的感受平等表达的机制，并不能平均地分配权力，创造最大的价值。所以丘吉尔说，民主是最坏的制度里面最好的制度。 自由主义对人的自由，奉若神明，就好像宗教对人的灵魂的伟大奉若神明一样。权威的来源的变化：神明-内心-算法。最初不信任算法的人，最终也会相信算法。 自动驾驶的汽车也可能破除哲学难题，人即使懂得哲学也会受情绪驱使。机器的算法可以把哲学问题转化为工程问题。算法即使正确而精确，也可能被背后的人误用-使用算法的人可能是坏人。 21 世纪可能是人类最不平等的时代。有财产才有不平等。人工智能的兴起，可能让大多数人不再拥有经济价值和政治力量。 在古代，土地是世界上最重要的资产，政治斗争是为了控制土地，社会因此分裂为平民和规则；到了现代，机器和工厂的重要性超过土地，于是政治斗争转化为争夺这些重要生产工具的控制权，社会分裂成资本家和无产阶级；等到数据成为最重要的东西，人类还是会被分化成不同的物种。要警惕大企业和政府占有、垄断用户的基础大数据。 传统并不足以解释当代的政治现实，犹太教正统派是错的。伊斯兰国的士兵、墨西哥毒枭都信奉美元的价值，大家信奉的是同一个资本主义。伊朗和朝鲜对物理学的看法，和以色列和美国完全一样。20 世纪的德国，经过了 6 个不同的政体-霍亨索伦王朝、魏玛共和国、第三帝国、西德、东德、当代德国。 对小群体亲近是动物的本性，但对千万人亲近是几千年才有的事情，而且需要社会建设的巨大努力。国家这个虚幻共同体是为了公共事务而刻意建立起来的。 近代民族主义国家主义，可以用国家体制和福利来换取公民对国家的热爱，也可能导致战争。在核的时代，要用一个更大的社群，像尼罗河边的部落结成王国治理尼罗河一样，治理核问题。 约翰逊的《雏菊》广告，是电视历史上最重要的一个广告之一。在冷战时代，大家觉得冷战升温，核毁灭是必然的，但事实上各个大国在没有流血的情况下结束了冷战，建立了新的国际主义世界秩序。 使用国际组织来解决国际间问题是一种国际大势，搞垮欧盟是不负责任的赌博行为，无视英法德意联合起来的欧盟对和平和秩序的贡献。 当前的时代对于地质学而言是全新世（Holocene），21 世纪以来的生态崩溃程度远超之前的历史进程其他阶段。当代的智人，是化石燃料成瘾者。核战争带来的威胁对全球各国是均等的，所以各国会不遗余力地消除这种威胁。但气候变化对不同国家的影响是不一样的（比如对俄罗斯而言，是个好事），所以要大工业国拿出决心出来，很困难。所以基里巴斯这样的国家，无法逃脱被海水淹没的命运。 过快的颠覆性技术进步可能导致社会的崩溃，但如果人类社会遇到巨大危机，则各个国家可能会刻意追求技术爆炸，进而引发更快的技术进步。 宗教之所以能够介入一切事务，是因为他们的主要技能是诠释。但有用的东西，最终会变得人人都用。在现代社会，人们决定事务的时候，首选现代理论，然后想办法把他们用宗教经典加以包装。伊朗经济学知识的来源是马克思、弗里德曼和哈耶克，而不是宗教经典。宗教里总是能够找到各式各样的依据，支持互相对立的观点。但宗教带来传统，传统决定了意识形态，意识形态决定了我们的身份认同。 移民问题既是文化保守主义的问题，也是私有制问题。种族主义从生物学立论，则易于破产，但如果诉诸文化主义，则问题会复杂化。 恐怖主义的力量实在太小，不足以发动战争，所以需要刺激对手，让对手过度反应，破坏社会的平衡。恐怖主义就好像手中只有烂牌的赌徒，只有希望对手乱洗牌来翻盘。在古代，暴力随处可见，大家习以为常，恐怖主义没有现代那么强的声音；但对现代国民而言，和平习以为常，恐怖主义对情感的伤害特别大，就好像有回音板，或者往空瓶子里扔了一个硬币，回声作响。国民往往无法客观看待恐怖主义带来的损害（超过对其他暴力犯罪的观感），甚至对国家的合法性和合理性产生怀疑。 在早期农业社会，15%的人口死于暴力；在 20 世纪，5%的人口死于暴力；在 21 世纪，1%的人口死于暴力。 两次世界大战之前，发动成功的战争能够带来征服，进而可以给国家带来巨大的利益，如美国击败墨西哥，获取了好几个州。但在二战后，发动战争能取得成功而促进国家繁荣的例子凤毛麟角，大家都竭力避免军事冲突。失败的例子多不胜数，而成功的例子恐怕只有俄罗斯联邦在无抵抗的情况下吞并克里米亚。但俄罗斯的崛起，既不带有强大的苏联时代的国力，也没有能够放之四海皆准的意识形态，所以不能进一步扩张下去。造成这种差异的根本原因在于，财富的形态/经济的逻辑发生了变化，在古代与近代，财富以实体的形式存在；而在现代，财富存在于金融体系与知识里。因为军事科技的发展，21 世纪很难出现战争消灭对手，进而调整经济秩序的方法-英国击败拿破仑、美国击败希特勒。 即使在当代，发动战争是一个高耗损，低收益的事情，也不要低估人类自身的愚蠢。这种愚蠢是推动历史进步的巨大力量之一。 避免愚蠢的方法是，谦逊。不要认为自己的文化是人类历史最关键的部分，不要认为自己的国家是人类世界的中心。以犹太人为例，犹太人认为自己的民族是宇宙中最重要的民族，塑造自己的孩童的世界观和历史叙事的时候，都是以犹太人的观点为中心，这样自然而然会培养出带有偏见，而没有广阔视野的观点。对犹太人而言，不止有《旧约》，还有《塔木德》，总体而言，是一种部落文化，而不是适用于全人类的文化。在正统犹太教派的语境里，上帝的选民专指犹太人，爱人如己的人也专指犹太人，如果犹太人不研习经典，宇宙会崩溃。而孔子、佛陀和马哈维拉虽然对迦南地的先知一无所知，却建立了所有人共通的伦理道德。虽然犹太人获得了特别多的诺贝尔奖，但这应该是因为犹太人重视教育，经常处于逆境，而不是因为犹太经典里蕴含了问题的答案，世俗犹太人比正统犹太人容易取得成功。犹太教带来的一神论，从伦理道德的角度来看，也是人类历史上最糟糕的概念，因为它导致了人类在道德上更不宽容。-如此说来，一国论又当如何？ 如果神是掌管宇宙奥秘的存在，宗教经典也与这样的神无关，只与社会规范和政治结构的合法化/合理化有关。经典上说，不要妄称神名，但宗教的正统主义者却经常说，神讨厌同性恋。神在俗世中变成了一种名义，名义又变成了一种借口。但坚信这种神与宗教的信徒总坚称，如果脱离了这种社会轨迹，人类会退化回无文明状态。这个观点并不正确，因为如果我们必须依赖于某些超自然的存在才能拥有道德，那么道德就并不自然。自然的道德实际上是关乎“如何减少人世间的痛苦”的戒条。 与有神论相反，世俗主义看重真相（truth）、同情（compassion）、平等（equality）和责任（responsibility）。世俗主义也并不完美，但需要确立一种原则，可以承认自己的学说、观点里的阴影。 每个人都知道得很少，因为我们有一种错觉，把别人脑海里的知识当作了自己的。很难用真相说服茶党（不是一个政党，而是政治运动），因为知识不一定能战胜无知。 现代社会的正义问题之所以难以回答，是因为因果关系高度复杂，很多人幸福而无知地活着 ，也不想真的求知。因此我们实际上生活在一个后真相时代。人类生活在后真相时代里已经几万年了，只有活在虚构叙事里，才能发挥特殊的能力。如果只有 1000 人相信某个编造的故事，相信了一个月，这就是假新闻；如果是 10 亿人相信某个编造的故事，相信了1000 年，这就成了宗教信仰。人类要能合作，需要在虚构和真实之间保持平衡。而人类能够追寻的真相是有限的，所以对虚构的金钱、宗教和国家都熟视无睹了。 追寻真相仍然有意义，有几个原则可以帮助追寻真相：1、如果想要得到可靠的信息，必然要付出昂贵的代价。如果人总是得到免费的信息，有可能你才是整个商业世界的产品。如果觉得某些问题似乎对你特别重要，就该真正努力阅读相关的科学文献。 在 21 世纪，艺术的重要性仍然特别高。人们对于高科技的基本看法，来自于文艺作品。这类文艺作品有个基本的叙事结构，就是人是一个更大的母体的一部分，逃离母体之外，还得逃离自我。《头脑特工队》具有颠覆性的内涵。 仪式可以带来真实感，仪式所消耗的牺牲，会更加让人深信不疑。大部分的宗教戒律和理想，对人类而言都遥不可及。所以人在做不到宗教的要求的时候，可以使用牺牲来替代。牺牲可以替代人应该对宗教尽的义务。 人有很多种不同的身份，谁能说生活不复杂。 要理解死亡，要首先理解生命。死亡所发生的变化，不会超过人在此刻和彼刻呼吸之间发生的事。作者参加了 10 天的内观课程，对人的心智的理解，超过之前的人生所学。“不要讨论理论或哲学，请把问题集中在与你实际修行相关的事情上”。人的心智看起来是灵魂主导的，暗地里还是由神经元加算法驱动的。我们常常了解事实，但缺乏穿透性地顿悟，了解事实背后的真相。 "},{"title":"《未来简史》","date":"2020-11-23T09:36:37.000Z","url":"/2020/11/23/%E3%80%8A%E6%9C%AA%E6%9D%A5%E7%AE%80%E5%8F%B2%E3%80%8B/","tags":["历史"],"content":" 这本书厉害就厉害在，15%以上的内容都是引述的资料，可谓旁征博引。 人类历史上有过以下几个危机：饥荒、瘟疫和战争，都已经被现代文明部分战胜了（或者，至少已经在正确的道路上取得可观胜利了）。 人类已经可以追求长生。现代文明的特点是让人追求快乐。人虽然没有必然享受快乐的权利，但有追求快乐的权利。（智）人类可以通过生物工程、半机械人工程和非有机生物工程，往神迈进。我们得到了神的创造力和破坏力，就可以成为神。神并不全知全能，也不是某种形而上的特质，神意味着超生物的能力。 伊壁鸠鲁告诫自己的门徒，过度追求快乐是危险的。佛教徒认为，追求快乐是痛苦的。快乐本身是来去不定的东西。 21 世纪，人类作为一个整体，将追求长生不死、快乐和神性。 知识很容易过时，它只要一改变行动，就会立刻过时。所以用知识指导和预测未来是徒劳的。马克思透彻地研究了资本主义的历史，但他的理论被资本家研究，于是工人引发的革命没有如预期般出现。 在俾斯麦的时代，设计国家福利是为了让国民忠于国家。 研究过去的目的，是为了从过去中解放出来。 草坪是中世纪晚期英法贵族在自家城堡门口养成的习惯。草坪毫无实用价值，却有维护成本，因此成了身份的象征。 人类追求自身价值的念头，来自于贯穿于文化中的人文主义哲学。这种哲学在人类世界兴起了三百年，推动人类追求成神之路，也最终因此而消亡。 历史已经见证了太多的文化、宗教、帝国的起起落落。法老王统治埃及三千年，教皇统治欧洲一千年，浪花淘尽英雄，千古风流人物。 最近七万年可以被称作人类世。地球从来不是单一的生态系统，而是由许多彼此松散连接的小生态系统组成的。人类是这七万年来改变地球的生态系统的单一因素。 人类是狩猎采集社会，是有泛灵论的-即与万物交谈。但进入农业革命的社会以后，人类诞生了我们现在的“传统文化”。 进化论认为，所有的本能、冲动、情感的存在和进化都只有一个目的：生存和繁衍。因此农业革命对家畜而言是一种灾难。 情感是所有哺乳动物都有的生物算法。 所有的哺乳动物都有母婴连结。 根据《民数记》，烧烤大会比较接近犹太的原始祭祀的仪式。这证明最早的宗教，就是和牧人农人的活动息息相关的。 有神论的宗教，用一种新的宇宙神话来合理化农业经济体制。过去的泛灵论宗教，是将宇宙描绘成如同一场盛大的京剧，有无穷无尽，五彩华丽的角色上场。但有神论的宗教改写了剧本，把宇宙变成易卜生荒凉的喜剧场景，只有两个主要角色：人和神。 世界上第一个洪水神话记载在《吉尔伽美什》里，比《旧约》早了一千年。 现代科学和工业的兴起，带来了人与动物关系的第二次革命，神的角色被删去，只剩下人自己。人得到了无上的权力，免去了所有（对外界的）义务，在物理、化学和生物学领域，为所欲为。 现代科学抄袭了知识树和伊甸园的传说，开启了用人取代神作为宇宙中心地位的人文主义思潮，神在舞台上退场了。 传统一神论认为，只有人类有永恒的灵魂，这是人类高于动物的伦理依据之一-只是这一依据是人类凭空编造的。科学研究无法证明人有灵魂而动物没有，所以一神论者对达尔文进化论恨之入骨。因为，进化无法产生永恒不变的实体，无法解释灵魂是怎么出现在进化中的。 什么是心灵？心灵是运行在大脑里 800 个神经元发出的生物电信号里的算法。 因为人无法解释自己的身体，所以总是用最先进的科技成果对人体进行类比：在弗洛伊德的时代，使用压力来类比情绪，因为那个时代最先进的科技成果是蒸汽机；在当代则使用就计算机的算法，因为计算机是机械/结构上最先进、最精密的产物。其实这些类比都未必正确，因为人体有独一无二的架构。 “他心问题”（Problem of Other Minds）：因为只会有一个真实的世界，而可能的虚拟世界无穷无尽，所以你所在的这个世界碰巧是真实的可能性实际上接近于零。 阿兰图灵提出的图灵测试，是检验计算机是否有心灵的方法之一。其实它复制了那个时代每个英国同性恋必须通过的日常测试：你能装成一个异性恋吗？ 因为动物有意识的生理结构基础，有相应的化学物质基础，所以动物有意识逐渐成为普遍共识。在欧美国家，动物福利已经开始成为普世价值的一部分。 智人之所以能够在地球的生物圈里登顶，是因为我们有大规模灵活协同的能力。这点对于历史的发展而言，至为重要。 人的行事不仅依赖于简单的数理逻辑，还依赖于有温度的社交逻辑。 人和人之间只要相信一样的故事，他们就可以一起合作。这包括文化、宗教、制度。对这种故事的信念，就是“意义之网”。意义之网被不断地消解，又被不断编织，历史就是这样沧海桑田地变迁。苏联就因为一支笔签署的一纸条约，立刻就烟消云散了。 人和人的关系有互为主体性（Intersubjective），所以可以携手创造。 在苏美尔人生活的城邦里面，神的存在和现在谷歌和微软的存在一样真实。但祭司们在没有发明货币和文字这对双胞胎以前，没有能力管理太大的业务-因为没有贸易网络。 在尼罗河谷，法老是有生物身体的神。他神的一面在百万国民里口口相传。 人类有了文字，就有社会管制的算法。当然，早期的古埃及的算法，是运行在莎草纸和黏土板上的。这套算法拥有真实的权力，所以法老依靠几千名能写会算的官吏替他管理国家，而他自己不必亲手做任何具体事务。垄断了这套算法就垄断了权力，所以进入现代社会以前，大部分人不识字。 文字有时候会造成破坏，但对行政管理而言，整体上利大于弊。对于官僚系统而言，文字代表的才是客观真实，如果现实与文字相抵触，要修改的是现实。因为很多时候官僚系统拒绝承认并修改自己的错误。1884 年欧洲的官员共聚柏林，在一张白纸上，凭着自己对非洲一知半解的理解（欧洲人当时只能理解非洲的海岸线，和几条河流的地理水文情况），就划定了许多势力边界，完全无视宗教、部落和文化情况。在欧洲殖民者殖民欧洲时，即使发现了原先规划的势力边界有违事实，也只能硬着头皮，继续按照协议划分势力范围。日后非洲的众殖民地独立，为了避免引起新的纷争，也继承了不合理的边界划分。 人类直到工业时代出现大众教育系统以后，才开始固定使用精确的分数。因为文字拥有的巨大的描述现实的能力，学校也不再只是利用分数来衡量和评估教育的结果，而转而追求分数。 因为文字有巨大的威力，宗教也使用文字来制造经文。尽管经文里描述的东西并非现实，但只要维持着真实和虚构的微妙平衡，宗教就能大权在握几千年。《圣经》里的历史观将万物的因果，归结于人的行为在神的眼中的对错，充满谬误，并不如希罗多德的《历史》对现实的认识精确。然而并不是犹太人学习了希腊人的历史观，而是希腊人皈依了犹太人的宗教。可见虚构的力量巨大，而且能够构成大规模合作的基础。但虚构叙事的能力太强了，人类甚至会为它感到痛苦、牺牲性命。 历史的文本往往的单一叙事，关注经济产量、社会和谐、政治举措，但历史的现实恐怕是千万种叙事混合在一起。很难简单评价历史的功过是非。 只要坚信只有自己的信仰是真理，其他信仰是迷信，就是一种宗教。因此，科学也是一种宗教。与宗教相对的是，源于古希腊哲学的灵性之旅。灵性要逃离世俗秩序，挑战信仰和惯例（遇佛杀佛）。 现代科学、自由主义诞生的地方，是宗教最不宽容的地方。 现代历史的准确看法是，科学与特定宗教（也就是人文主义）达成协议的过程。 现代性是每个现代人出生的时候就自动签署的社会契约。现代性的意思是：人类同意放弃意义，换取力量。前现代的人认为生活是宇宙的一个伟大计划的一部分，人类的力量受到意义的限制。遵循意义会带来不变，等于放弃了力量。现代文化则不再相信宇宙计划的存在，转而认为整个宇宙就是个盲目而没有目的的过程。现代生活就是在以往一个没有意义的宇宙里不断追求更多的力量。现代文化的力量是史上最强的力量，同时，现代文化也比以往任何文化感受到了更大的存在性焦虑。 古代的社会，经济增长相对停滞不前。因为万物平衡、进化压力和零和博弈使得增长似乎不可能，人类已经习惯于把世界看作一个静态的大饼（如何分这张大饼，会带来许多困难的选择，也会带来伦理问题）。现代性的理念则认为：经济增长不仅有可能，而且还绝对必要。解决饥荒、瘟疫和战争等问题，唯一的方法就是增长。“如果解决问题，可能就需要更多；为了拥有更多，要交生产更多。” 现代的经济（主要是资本主义）给人类社会的增长找到了合适的道路，对促进社会和谐，解决社会问题提供了比宗教更多的现实帮助。 现代经济是否能够无限增长下去？原材料和能源是有限的，但知识是无限的。拥有知识，我们可以克服资源短缺的问题。 然而现代经济增长并不是没有副作用。现代经济增长对环境的破坏很深远，对穷人的影响远比富人要大。但如果经济增长停滞，对穷人的影响仍然远大于富人。在大事上，决不可相信有“方舟综合征”的人。 无休止的增长会让人感到焦虑，现代社会已然抛弃了宗教-上帝已死，靠什么来维护现代社会的秩序呢？人文主义。传统认为，是伟大的宇宙计划为宇宙赋予了意义；而人文主义认为，人必须从自己的体验赋予意义，为无意义的世界创造意义。对宗教失去信心，但对人要有信心。 人文主义认为，现实的政治权威，不是宗教里上帝制定的道德信条，而是人群对事务的集体判断。中世纪的人认为艺术的灵感来源于上帝和宇宙星辰；但人本主义认为艺术的灵感就来源于人的感受。一个著名的例子是，杜尚买了一个小便池，命名为喷泉。中世纪时商品的优劣由行业协会把持，而现代社会则交由消费者选择决定。中世纪的教育的内容是研读经典；而当代的教育的内容是，让学生形成自己的看法。 人文主义在19-20 世纪产生了分裂，分裂出三个分支：正统的自由人文主义、主张建立集体制度的社会主义人文主义和认为冲突是福不是祸的进化人文主义。 从 1919-1989，三种人文主义流派掀起了凶残的信仰之战。1949 年的第二次世界大战，在后期来看是属于自由主义的巨大胜利，在当时看来，可能是社会主义人文主义的胜利。社会主义苏联承担了冲突的主要力道，付出了巨大伤亡的代价。胜利的大半功劳应该归功于社会主义，使得参战前孤立的、不受重视的社会主义苏联，成为全球两个超级大国之一。而自由主义却与种族主义画上等号，但凡旧欧洲帝国崩溃，取而代之的不是军事独裁，就是社会主义政权。接下来的多米诺效应掀起一波又一波的政治浪潮，华沙公约的军事力量超过北约。北约不得不奉行 MAD（Mutual Assured Destruction），对任何常规武器的攻击以饱和核武攻击应对。 自由人文主义之所以能够取胜，和他们适应了新科技发展有关。科技和宗教要和谐发展，才能取得时代的胜利。现代社会里，各种老宗教都没有拿得出手的创造，徒留老经典的权威耳。当代的历史学家应该承认马克思和列宁对历史的解读，但他们的解读是基于那个时代的科技发展状况的。如果马克思生在当世，他会让自己的信徒去研究计算机和基因工程。 古代哲学/神学一直在探讨灵魂和自由意志之间的关系。现代科学认为，不存在真正的自由意志。自由意志只不过是几十亿的神经元依照特定算法瞬间进行模式运算的结果而已。 人的内心并不是不可分割的灵魂，至少可以分为紧密相连的叙事自我和体验自我。很多时候人关注和追求叙事自我，但却受体验自我主宰和驱动。有时候太执着于叙事自我，会产生一种“不能徒劳纵横征”。 人类十分擅长应付认知上的矛盾，能允许自己在实验室里信一套，到了法庭或国会又信完全不同的一套。 当代的计算机对比上世纪的计算机原型，并未有增强的意识。但现在人们认识到，意识不重要，智能很重要。有了智能算法，人类在所有熟悉的领域，都可能变得没有用处。 纵观历史，就业市场可以被分为三个部门：农业、工业和服务业。这些部门，没有一个一个不能被算法所控制。算法完全可能成为控制地球上层的非人类实体（如同王国和公司一样）。 在当代社会，要理解自己的内心，与其研究哲学、心理学，不如研究自己的生理指标。 从古至今，富人并未真正与穷人因为医学产生根本差距，但未来的科技进步可能造成不同状况-产生超人类。人类如果从生物定义上分裂成不同的阶级，就会摧毁自由主义意识形态的根基。自由主义面对社会不平等的解药，不是让每个人都有同样的体验，而是对于不同的人类体验赋予相同的价值。 如果人类的社会被分为普通人和超人类，或者由算法决定社会运作，自由主义都将崩溃。 现代人文主义走到尽头，硅谷的科技大师们诞生了新的宗教-科技人文主义和数据主义。七万年前，认知革命带来了第一代的智人；而当代的第二次认知革命，带来了神人。科技人文主义不再确定，人的意志是意义的权威，转而可以随意操弄意志。数据主义则认为，宇宙由数据流组成，任何现象或实体的价值就在于对数据处理的贡献。 人文主义革命之后，现代西方文化不再想了解高级心理状态（无上的宁静、极端的敏锐、无可比拟的感性），认为一般人的俗世体验就是神圣。 大部分的科学机构都已经改信了数据主义。我们把数据转化为信息，把信息转化为知识，最后把知识转化为智能。数据主义来源于生物学和计算机科学，将现实的各种机制（甚至是不同的意识形态）视为不同的数据处理系统，资本主义和共产主义之间，实际上是不同的数据处理系统之间的竞争。苏联的中央委员会是集中式数据处理，而纽约的证交所则是分布式数据处理。鉴于资本主义的成功，政治科学家也逐渐把人类政治结构理解成数据处理系统。 因为科技进步太快，产生太多了数据。国家和政客都很难及时提高自己的数据处理速度，无法看清长期愿景，只能拥有狭窄的视野。有时候狭窄的视野反而能够帮助协助人们保持专注，而取得优势。 依照数据主义，人类可以被认为数据处理系统的处理器芯片。人类的历史实际上是增加处理器的数量、种类、连接度和流通度的过程。当万物互联（Internet of All Things）的网络构成，智人就在历史上功成身退了-智人和智人的宗教、人文主义，通通都是该淘汰的算法。 人类很少能够真正发明新的思想。18 世纪以来宣称的人类自由、博爱、平等的思想，是相对于之前几千年的人服从于神的思想的创造。 新的时代，要求有数据自由。自由被赋予的对象不再是人（言论自由赋予的对象是人），而是数据，数据应该自由流动。 人文主义认为，上帝是人类想象力的产物；数据主义认为，人类的想象力只是算法的产物。 这个时代信息爆炸，很容易让人的注意力被淹没。所以真正让人获取力量的是专注的能力。 "},{"title":"《人类群星闪烁时》","date":"2020-11-21T14:11:48.000Z","url":"/2020/11/21/%E3%80%8A%E4%BA%BA%E7%B1%BB%E7%BE%A4%E6%98%9F%E9%97%AA%E7%83%81%E6%97%B6%E3%80%8B/","tags":["文学"],"content":"本书是历史特写，忠于历史，文辞优美，写出了历史关头，人物的选择。 到不朽的事业中寻找庇护（不朽的逃亡者）：1513年9月25日，富有冒险精神的西班牙巴尔沃亚随船到达南美洲，去开拓和寻找财富，他不仅挤走了整支队伍的主人，还赶走了新派来的总督。但是，被他赶走的船队主人却回到了西班牙，向西班牙宫廷举报了他的恶劣行为。为了避免西班牙宫廷的惩罚，他决定率先去寻找南美大陆的财富，以此来庇护自己的安全，在艰苦的旅途之中，他成为了第一个看到太平洋的文明中的人类，并且他知晓了不远的国度中还有存有无限黄金。而就在此时，他的朋友皮萨罗为了抢夺功劳背叛了他，联合国王派下的新总督一起将其暗算 [1] 。 拜占庭的陷落：1453年5月29日，奥斯曼土耳其帝国苏丹穆罕默德二世攻占东罗马帝国最后的堡垒：君士坦丁堡，经过数次激战始终不见成效，此时这位天才皇帝想出一幕惊险之棋，将战船从陆地运送到拜占庭防守薄弱的靠海一隅，最终因为拜占庭疏忽的一座小门–凯尔卡门的发现，奥斯曼帝国毁灭了拜占庭这一人类文明的精华。 亨德尔的复活：1741年8月21日，落魄而江郎才尽的作曲家亨德尔突然在一首诗中找到灵感，写下了不朽之作《弥赛亚！》，而他自己也因此得到了救赎。 一夜天才：1792年4月25日，年轻上尉鲁热受到斯特拉斯堡市长的邀请，为莱茵军创作一首战歌，4月26日凌晨，《马赛曲》诞生了。此歌一出立即传遍全国大街小巷，激励着军人去战斗，去胜利。而此歌的作者鲁热却无为人知，并且一生穷困潦倒，他只做了一夜的天才。 滑铁卢的一分钟：1815年6月18日，由于懦弱平庸的副将格鲁希固守成命，拿破仑兵败滑铁卢。 玛丽恩巴德哀歌：1823年9月5日，歌德在离开玛丽恩巴德回家的路上，抑制不住心中对于那里一位少女的思念，悲不自胜，写下了晚年最著名的爱情诗篇：《玛丽恩巴德悲歌》。从此歌德痛定思痛，踏入了另一个创作高潮，写出了《浮士德》等伟大著作。 黄金国的发现：1848年1月，约翰·奥古斯特·苏特尔在自己的领地，今加利福尼亚，发现了黄金混合在泥沙之中，从而掀起了持续四年横扫世界的“淘金热”。人们不再劳动而是拼命的淘金，世界各地也涌来了无数的淘金者，他们霸占了属于苏特尔的财产和土地，最终使苏特尔家破人亡。 壮丽的瞬间：俄罗斯著名作家陀思妥耶夫斯基因参与反动的政治活动被逮捕并处于死刑，在执行死刑之际一纸官文的到来改变的死亡的命运，死刑不再，改判服役和当兵。陀思妥耶夫斯基历经磨难而幸存和日后的军旅生涯给了其丰富的写作素材，是其一生创作和思想的转折点。 飞越大洋的一次通话：1858年7月28日，在美国实业家塞勒斯·韦斯特·菲尔德立志要铺设一条连接欧美大陆的海底电报电缆，准备妥当后的首次铺设便遭遇失败，坚定的菲尔德终于在第三次铺设时成功，人人奉菲尔德为英雄。但好景不长，电缆的失灵又使愤怒的人们反过来炮轰抨击他。时隔六年，决心不减的菲尔德再次尝试终于成功。 逃向上帝：列夫·托尔斯泰未完成的剧本《黑暗中的光明》之续尾。 封闭的列车：1917年4月9日，列宁登上了从瑞士过境德国回到俄国的列车，这列封闭的列车就像一枚炮弹，把革命的导师送回了祖国，打垮了一个帝国。 南极争夺战：挪威人阿蒙森和英国人斯科特各自率领一支探险队，为使自己成为世界上第一批到达南极的人而进行激烈的竞争，但是他们之前一个月挪威人阿蒙森的队伍已经先他们到达，失望的斯科特同其他四人在返回的途中不幸遇难，在他留下的笔记本中记述了斯科特对国家的自豪和对家人的思念。 西塞罗：古罗马生命最后的4年。 威尔逊的梦想与失败：美国总统威尔逊以保障人类永久和平为梦想，却惨遭失败。 "},{"title":"数据密集型应用系统设计 - Designing Data Intensive Applications","date":"2020-10-11T15:09:02.000Z","url":"/2020/10/11/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-Designing-Data-Intensive-Applications/","tags":["系统架构"],"content":"数据密集（Data-Intensive）与计算密集（Compute-Intensive）是当今两大负载类型。前者以大数据为代表，后者以深度学习和 HPC 为主要代表。 谨以本书献给那些追逐梦想的人们。 另一个电子版本。 前言数据密集型应用要处理的瓶颈往往是数据的规模、数据的复杂度和数据产生与变化的速率；与之对应的是计算密集型应用，CPU 往往成为其瓶颈。 本书是关于数据处理系统及其相关技术的（NoSQL、消息队列、缓存、搜索引擎、批处理和流处理框架）。 每一种技术都基于一定的设计理念，而且只适用于特定的场景。 不要过度优化。 可靠、可扩展与可维护的应用系统现在的典型系统架构已经很明确了，因为业界已经有成功的案例，对这些组件做了很好的抽象，我们只要做好拿来主义就行了。 可靠性（Reliability）fault tolerance 和 resilience 是系统的容错的体现。 硬件故障对于大型 IDC，即使磁盘的 MTTF 很高，磁盘数量大了以后，每天发生磁盘损坏也是正常的事情。 硬件容错的方案是制造冗余（冗余磁盘、冗余电源）。 软件容错是第二种方式。 软件错误软件错误可以被认为是 bug。检查 bug 的方法就是不断地做契约检查、测试。 人为失误运维错误是系统下线的首要原因。 常见的做法有： 以最小出错的方式来设计系统。 想办法分离最容易出错的地方、容易引发故障的接口。 充分的测试。 当出现人为错误时、提供快速恢复机制。 设置详细而清晰的监控子系统，包括性能指标和错误率。 推行管理流程并加以培训。 可扩展性（ Scalability）如果系统以某种方式增长，我们应对增长的措施有哪些。 描述负载Twitter 的例子Twitter 的高扇出（fan-out）的结构： 2011 年时： 用户发送 tweet 可以 达到 12k request/sec 用户有 300 k request/sec 的 home timeline 的读请求 用户有不同的扇出结构，决定了他们的潜在写放大的系数。 对于 home timeline 的读，有两种方式可以获取所有内容： lazy 方案 这个方案是基础方案，基于 MySQL 的联表查询。 每次每个 follower 读取自己的 home timeline 时，首先 join 自己的 follows 表里的 followee（通过 user_id = follower_id），然后用 followee 去 join user 表（ 通过 followee_id = user_id 这一步其实可以省略），然后用 user 表去 join tweets（通过 user_id = sender_id）。 这种 join 方法可以通过 server side join 来优化，但本质上还是逐步联表。每次做联表查询的时候 join 一次。 如果有必要，这里还可以把 join 的结果缓存起来优化频繁刷新的场景。 这种方法的缺点是，读取大量数据时老老实实地联表查询过多，性能不好。 eager 方案 这个方案是性能优化方案，基于动态创建的广播队列。 每次每个 followee 发送 tweet 时，会先插入数据到 tweet 表里，然后通过广播的方式把这个 tweet 插入到每个 follower 的一个总的 tweets 列表里。这个列表可以是数据库，也可以是缓存的 list，也可以是 mq 的 topic。因为 mq 的 topic 不适合多对多的生产者和消费者的映射关系，而且动态创建 topic 的成本也很高。缓存的 list（如 redis 的 list）的创建销毁成本很低，很适合这种场景。 这种方案的优点是比方案 1 性能高两个数量级，缺点是如果 fan-out 很大的话，广播的时间会非常长。 因此 Twitter 最后的解决方案是先对大多数 followee 的 tweets 采用方案 2，而对于 fanout 特别多的 followee 的 tweets 使用方案 1，用户最终看到的内容，始终是方案 2 和方案 1 延迟合并的结果。 这个例子可以应用在非常多的 OLAP 场景内：即对于大数据量的数据汇总查询，我们可以优先采取 eager write 或者 broadcast 的方法在写事务的时候插入汇总数据；然后对于 fan-out 特别高的数据，在查询的时候 lazy 查询。选择方案时，需要考虑的因素主要是写成本比较高，还是读成本比较高。如果全量写的不会被全量读，而写成本很高的话，不如用 lazy read ；如果读的场景很高，联表查询出现的比例很高，则适合 eager write。 描述性能批处理系统更看重吞吐量，即每秒处理的记录数；而在线系统更看重响应时间，即客户端从发送请求到接收响应之间的时间差（response time = server side latency + communication overhead）。响应时间不是一个固定的数字，而是一个可度量的数字分布。 我们可以用平均值来说明一些问题，但更多的情况下关注分布，我们使用百分位数（percentile），如 p50、p90、p95、p99。亚马逊使用 p999 来定义起内部服务的响应时间标准。 定义 SLA 有助于我们确定我们的标准，我们要为最慢的响应（tail latencies 长尾效应）优化到什么地步（百分位越高，越难优化）。 排队延迟往往在百分数响应时间中影响很大。因为服务器并行处理的请求优先，正在处理的少数请求可能阻挡后续的请求。这被称为队头阻塞。做负载测试的时候不要等待队头阻塞（无意中缩短队列长度），要尽可能多地发送请求。 实践中，总是会使用滑动窗口来持续监控性能变化。 在实践之中，最慢的响应，决定了用户的 RT。 针对特定级别负载设计的架构不太可能应付超出预设目标 10 倍的实际负载-引入 APM 监控非常重要。 在多台机器上分配负载被称为无共享架构。这种架构易于水平扩展。如果服务负载高度不可预测，则引入自动的弹性扩展是好的，否则手动扩展更能处理意外情况。 超大规模的系统往往针对特定应用而高度定制，很难有一种通用架构。背后取舍的因素很多，如数据读写量、复杂程度、存储量，响应时间要求。 对特定应用而言，通常我们要做出某些假设（在可用性、一致性上做假设，如单元化场景下的弱一致性假设），有所取舍，才能在我们需要获得进展的方面取得结果-我们应该只优化最频繁的操作，或其他亟需我们优化的操作。 可扩展架构通常是从通用模块逐步构建而来，背后往往有规律可循。本书将讨论通用模块和常见模式。 可维护性软件的成本在于整个生命周期内持续的维护。而遗留系统总有其过期的原因，很难给出通用的优化建议。 可维护性可以被分为三个方面： 可运维性：运维/运营/SRE 团队易于保持系统平稳。 简单性：新的工程师能够轻松理解系统。 可演化性：能够轻松对系统改进 可运维性运维团队可能有很多操作，数据系统设计可以提供如下便利： Observability 文档 简单性大泥球应用除了功能以外，还提供很多额外意外的复杂性。这种意外的复杂性是可以消除的-而不必减少功能。 消除复杂性最好的手段之一就是抽象。抽象可以隐藏大量的细节，而且可以对外提供干净、易懂的接口。 可演化性易于修改的系统，易于演化。我们总是处在不断变化的需求中。 数据模型与查询语言语言的边界就是世界的边界。-《逻辑哲学论》 大多数程序都是通过一层一层叠加数据模型的方式来构建的（如网络协议中不同层使用不同的包）。 不同的数据模型支持的操作不一样，有的操作很好，有的操作很不好-数据结构决定算法，数据结构加算法等于程序。精通一种数据模型需要很大功夫。 关系模型与文档模型历史 Edgar Codd关系型数据库的核心用例最初是商业数据处理，曾经出现过网络模型和层次模型等不同的范式作为竞争对手，但最终关系模型成为最终的赢家。 在关系模型里，relation 最终被当作表，行即元组。 NoSQL 是关系模型的有力竞争者，最初出现在 Twitter tag 里。它用 schemaless 换取了表达能力的提升，sharding 和 replica 换取了 scalability 的提升。 NoSQL 对 OO 的编程语言的适配性更好。 Linkedin profile 的例子告诉我们，education 和 position 对 user 而言是多对一的关系，可以建模为单独的行，也可以建模为嵌套的文档-因此可以使用 json document 来标表示（这可以转化为 json tree），也可以用关系型数据库的 xml/json 类型来表达。但行业、地区等全局的常量数据，则比较适合用单独的表来存放，使用 id 来引用，而严重不适合冗余存放。 不变的业务 fk、物理 fk 适合冗余，而时间/状态则不适合冗余。冗余可以减少联表查询的复杂度，但也会增加 update 的难度。 IBM 的 IMS 是最初的层次模型，可以很好地处理一对多问题，但不能很好地处理多对多问题-这种困境近似于现在文档数据库遇到的困境。 网络模型的代表是 CODASYL。在 CODASYL 里面每层有多个父节点，因此实现了多对多。在这种模型里，外键是指针，指针不是外键。这种模型按照路径遍历非常麻烦，更新也非常麻烦。 而使用了关系型数据库后，查询优化器会根据索引和表间关系，来生成“访问路径”-也就是执行计划。查询优化器是是一个被持续优化的怪兽。 文档数据库是某种意义上的层次模型-父文档保存了子文档。 文档型数据库的优点：性能更好，模型更像是程序自己的数据结构，适合一对多模型。 关系型数据库则强在 join、多对一和多对多的表达上。但，只要文档数据库可以通过标识符来引用其他文档，则文档数据库的表达能力并没有因而减弱。 如果原始数据有类似树型/层次/文档的复合结构，则比较适合使用文档数据库；否则应该对数据进行分解（规范化），得到关系型数据库的表。 通常，关系型表的数据结构相关的代码是更复杂的。但，如果需要引用嵌套的数据，则嵌套层次越深，文档型模型越不好用。 通常情况下，流式/批处理框架/消息队列里的 event，也适于使用文档数据库。事实上，除了订单系统里的订单/子订单以外，应该大量数据模型都可以放进文档型数据库里。 如果确实需要 join，则文档数据库的弊端就出现了。反范式化很难维护一致性，而且程序的流程会变复杂，流程变差了。 总而言之，关联性越高和数据库选型的关系是：文档型 -&gt; 关系型 -&gt; 图 数据库。 模式灵活性应该说，文档型数据库有模式灵活性，它支持读时模式（与之相对地，关系型数据库支持的是写时模式）。文档型数据库往往不在写时执行强制模式校验，读时的兼容性必须由读时的应用程序来保证。 关系型数据库因为执行写时校验，所以出现模式变更时，往往需要成本很高的 migrate 操作。 如果外部模式很多，或者模式很易变-最典型的例子，配置型数据，则很适合使用文档型数据库；反之，关系型数据库则要被派上用场。模式的损害在于，它不易于变动。 数据局部性与性能文档型数据库还有一个缺点，就是对它更新，需要原地重写，写的开销很大，可能引起存储问题。 融合的趋势关系型数据库和文档数据库的融合是大势所趋。当代的 RDBMS 已经可以很好地处理 XML；而一部分的文档型数据库则可以在查询时支持 join（mongo 是在 client 端支持的，这种方案性能不够好，但支持也比不支持强）。 数据查询语言数据库里的查询语言SQL 其实是种声明式查询语言，而 CODASYL 实际上是命令式。 命令式的查询语言，会把查询过程 HOW 写出来（所以我们经常做的客户端查询，都是命令式的查询），告诉计算机，要按照怎样的特定顺序，执行某些操作（第三步可以被扩展，扩展为 map reduce 的不断串联/并联执行）。 而声明式的查询语言，只会把 what 写出来（LINQ 最为明显），指定查询哪些模式，满足哪些条件，需要做怎样的数据处理/聚合。剩下的查询过程，由查询优化器来推导。 声明式的语言都有一个特性，就是无法/也不需要指定执行的流程的细节，这给了编译器/运行时重排执行流程，甚至并行化执行的机会。-声明式其实是一种高级抽象，能够实现复杂查询流程的数据库，才能提供很漂亮的声明式查询语言，这体现了架构设计的一种取舍。 MongoDB 里面的 AST 式的查询语言，本身只是重新发明了一遍 SQL 罢了。 web 领域的查询语言即使只在 Web 领域，CSS 代表的声明式语言，也比 JavaScript 代表的命令式查询要优雅很多。 MapReduce 查询MapReduce 起源于谷歌，MongoDB 和 couchDB 等文档型数据库也部分支持 MapReduce。 map 是函数式编程里的 collect，而 reduce 则是 fold 或者 inject。 MapReduce 不是声明式查询语言，也不是一个完全命令式的查询 API，而是介于两者之间：查询（及处理）的逻辑用代码片段来表示，这些代码片段会被框架来重用（代码片段的设计思路，也被用于 Stream 这项新兴技术中）。通常我们使用 map 来生成逻辑 KV，然后用 reduce 对相同的 Key 的 value 进行聚合处理。 map reduce 我们使用纯函数，因为没有副作用，所以纯函数的顺序和执行为之是非常自由的。 MapReduce 实际上是一种偏底层的编程模型，需要执行在计算集群上（否则性能并不好）。SQL 是极高层的计算模型，可以通过 MapReduce 来间接实现。当然，这两者之间并不必然有关系。 图计算模型多对多模型是不同数据模型之间的重要区别特征。关系型数据库只适合处理简单的多对多关系，复杂的多对多关系需要使用图模型。 图包括顶点和边，常见的图有： 社交网络 Web 图 公路或铁路网 图的强大之处在于，它不仅可以存储同构数据，它提供了单个数据存储区中保存完全不同类型对象的一致性方式。 有多种不同但相关的方法可以构建和查询图中的数据，常见的图有属性图（property graph）和三元存储模型（triple-store），相关的查询语言有三种：Cypher、SPARQL 和 Datalog。 图计算模型比关系型数据库或者 CODASYL 更加自由，不需要指定 schema，而任何顶点都可以和其他顶点互联。 属性图在属性图中，每个顶点包括： 唯一的标识符 出边的集合 入边的集合 属性的集合（键-值对） 每个边包括： 唯一的标识符 边开始的顶点（尾部的顶点） 边结束的顶点（头部的顶点） 描述两个顶点间关系类型的标签 属性的集合（键-值对） 把这两种定义转化为 SQL，可以得到两张表：顶点表和边表。 关于图模型还有一些值得注意的地方： 任何顶点都可以连接到其他顶点。没有模式限制哪种事务可以或者不可以关联。 给定某个顶点，可以高效地得到它的所有入边和出边，从而遍历图，即沿着这些顶点链条一直向前或者向后。 通过对不同的类型的关系使用不同的标签，可以在单个图中存储多种不同类型的信息，同时仍然保持整洁的数据类型。-传统的关系模型难以表达不同国家的不同地区结构和颗粒度。 图是易于演化的，可以动态地往图里添加功能，图可以很容易适应并扩展。 图是一种前程远大，应用场景广泛的技术。 Cypher 查询语言Neo4j 是从黑客帝国里诞生的概念，Cypher 是另一个（和密码学里的 Cypher 恰巧同名），这两个名词都是从人名里诞生的。 我们可以先创建库和数据： 相应的查询语句是这样的： 这里的式子分两层：第一层在右边，表明这是任意一个处于特定地点的地点，而第二层在左边，表明这是和第一层变量相关联的顶点。person 是一个待求值的变量。 遍历有两种基本思路： 从每个 person 开始，沿着出边过滤。 从 us 和 eu 这两个顶点开始，沿着入边过滤。 使用声明式的查询语句，可以让查询优化器自由地决定执行策略。 同样地，我们可以用关系型数据库来表达图数据库。但通常， SQL 查询要求我们能够制定 join 的次序和数量；对于图查询，join 操作的数量不是预先确定的。这种不能确定 join 顺序和次数的查询，容易诱发 SQL 的反模式。 WITHIN*o.. 的意思是，沿着 WITHIN 边，遍历 0 次或多次。 在 SQL 1999 中，查询这种可变的遍历路径，可以使用被称为递归公用表表达式（即 WITH_RECURSIVE 语法）来表示。 从这个例子可以看出来，SQL 不如 Cypher，SQL 不具备找到一行记录后自递归的方法。 三元存储与 SPARQL三元存储模型几乎等同于属性图模型，他们只是用不同的名词来描述了相同的思想。 在三元组中，所有信息都以非常简单的三部分形式存储（主语，谓语，客体）。 三元组里主体相当于顶点，谓语和宾语相当于 proerpties 中的 key 和 value。 三元组中的主体相当于顶点，谓语是途中的边，客体是头部顶点。 语义网Datomic 是一个三元组存储（其实是五元组，带有 2 元版本数据）。语义网（Semantic Network）不是三元组，语义网本身没有靠谱的实现，从未实际出现。 SPARQLSPARQL（音“sparkle”）出现得比 Cypher 早，Cypher 的模式匹配是借用 SPARQL 的。 Datalog 出现得更早Datalog 出现得更早，为 Cypher 和 SPARQL 奠定了基础。它是 Datomic 的查询语言。Datalog 是 Prolog 的一些子集。 小结数据的模型发展的脉络，不过是： 树型 -&gt; 文档 -&gt; 关系模型 -&gt; 图 关联越多，越适合使用后面的数据库。关系模型的平衡性最好，可以模拟其他数据模型。从这个顺序来讲，文档模型是关系模型在复杂性上的退化/或者简化。但唯有关系模型是强制使用模式的。 如果需求不断变化，模式可能不断变化，应该尽量选择无模式的数据模型。 每种模型都有自己的查询语言和框架。 这些模型在实现的时候，需要做一些权衡取舍。 数据存储和检索从最基本的层面看，数据库只做两件事情：向它插入数据时，它就保存数据；之后查询时，它应该返回那些数据。 作为应用开发人员，我们大多数情况下不可能从头开始实现一个自己的存储引擎，往往需要从现存的存储引擎中选择一个适合自己的。其他针对事务型工作负载和针对分析型工作负载的存储引擎存在很大的差异。 我们将研究关系型数据库和 NoSQL 数据库，我们将研究两个存储引擎家族，即日志结构的存储引擎和面向页的存储引擎，比如 B-tree（B-tree 是页的组织）。 数据库核心：数据结构数据存储里通常有三种数据结构：日志、页和索引。 日志许多数据库内部都使用日志，日志是一种只支持追加式更新的数据文件。一个数据库还要处理其他问题：并发控制、回收磁盘空间、错误处理和部分完成写记录等。但日志始终是一个很有用的机制，被用在很多地方。 索引在日志里面查找结果是不好的，所以引入第二种数据结构-索引。 索引的基本设计思想是，在原始数据上派生额外数据结构，在索引上保留关键数据或者元数据，作为路标，帮助定位想要的数据。 不同的索引支持不同的搜索方式。 索引必然导致写性能下降，因为索引很难使用追加写，但追加写是性能最高的写入方式。 哈希索引KV 结构随处可见，是构造更多更复杂索引的基础构造块。如，继承/封装 hashmap 是常见的存储方法。 一个特别简单粗暴的例子：Bitcask 的存储格式，使用 csv 来存储 kv 值，使用 hashmap 来存储 key 和文件系统里的 offset 来充当索引。 我们不能只依赖于一个数据文件，这会导致磁盘空间耗尽-所以我们对大规模存储应该采取分段的形式。 但使用多段数据，往往意味着数据需要压缩。压缩可以让段变小，因为段被合并后就不会再被修改，所以很适合放进新文件里。这样可以把旧文件段留出来，提供读写支持。 每个段都有自己的内存哈希表。-这里引出了一个范式，一段数据，到底在内存里是怎么被组织的，在硬盘里又是怎么被组织的，可以完全不一样。 这个方法是最简单的方法。但要在实践中行之有效，还要考虑如下问题： 文件格式：CSV 不是最佳的文件格式，二进制才是。 删除记录：如果要删除键和值，在日志里追加一个删除日志是简单的做法（墓碑）。墓碑会让记录在被合并时删除键值的实际内容。 崩溃恢复：从头到尾读取日志是一个方法，快照内存里的 hashmap 是另一个方法-这和 RDB/AOF 的设计思想是很像的，快照可以加速崩溃恢复，快照本身就是 compaction 过的值。 部分写入的记录：文件要加上校验和。 并发控制：只有一个写线程追加写入（类似 log4j 的设计），多个线程并发读-单线程后台消费是一种解决并发问题的基本思路。 为什么要使用追加写，而不是原地更新？这应该是几乎所有的存储使用日志配合数据页的解决方案需要回答的问题。 追加写的顺序写性能好。 顺序写的并发控制和崩溃恢复会简单得多-只有一个数据文件很难处理脏数据和正确的数据。 有了文件合并，可以减少数据文件本身的碎片程度-所以数据文件本身还是 要紧凑，不能作为写的中间文件。 内存里的 hash 表有什么缺点？ （因为装填因子的存在）内存利用率不高。 区间查询效率不高。 SSTables 和 LSM-TreeSSTables 是排序字符串表，以它优化 Bitcask 的例子的话，会产生如下变化： 每个的日志段里只能存在一个 kv 值，不按照它们的写入顺序排序，而按照 key 的字典序排序，每个 key 只出现一次（这就像 TreeMap 了）。 段按照特定的时间段顺序排序，这也就意味着 compaction 多个段的时候，可以按照时间的顺序读取同一个 key，只保留某个 key 的最新值，丢弃其他段里的其他值。 在内存里保存的索引不需要指向所有的 key value 值，只要能够找到特定的段上的区间起止值，就可以找到特定的段上的最新的 kv，这样我们可以得到一个稀疏的索引。 我们的值写入永远都是随机写入的，相关的存储引擎是这样工作的： 写入先写入内存中的平衡数据结构（通常是某种平衡树，如红黑树），这被叫作内存表（Mem table）。 当内存表的大小达到某个阈值以后，将其生成一个 SSTable 写入磁盘中，然后再生成下一个内存表继续供写入（这应该是一个原子切换）。 如果有读操作，先在内存表里查找，然后按照写顺序查找最新的磁盘段文件、次新的磁盘段文件，以此类推，直到找到目标（或为空）。 后台周期性地执行段合并与压缩过程，以合并多个段文件并丢弃那些已被覆盖或者删除的值。 为了防止数据库崩溃，也要准备 WAL。WAL 使用纯粹的追加写，而不是排序写（这样的性能最好）。一段日志对应一段 WAL。 上述算法实质上是 LevelDB（Riak）和 RocksDB �所使用的，可以嵌入其它程序中提供 KV 存储。这两个引擎都收到 Google 的 BigTable 论文的影响（它引入了 SSTable 和 Mem table 两个术语）。 这种索引结构由 LSM-Tree 命名（这一章可能总体上被称作 LSM-Tree 算法）。Lucene 也使用类似的方案存储 term 和相关的 doc。 总有很多细节，值得深入优化。如果有个 Key 找不到，则 LSM-Tree 算法的表现可能很慢。这样可以引入布隆过滤器，近似计算集合的内容。 还有其他的策略可以影响甚至决定 SSTables 压缩和合并时的具体顺序和时机。最常见的方式是大小分级和分层压缩。分层压缩是 LevelDB 和 RocksDB 使用的策略，HBase 使用大小分级，Cassandra 同时支持这两种压缩。 在大小压缩中，较新的和较小的 SSTables 被连续合并到较旧和较大的 SSTables 里。 在分层压缩中，键的范围分裂成多个更小的 SSTables，旧数据被移动到单独的“层级”，这样压缩可以逐步并行并节省磁盘空间。 LSM 的基本思想（保存在后台合并的一系列 SSTable）足够简单有效。即使数据集远远大于可用内存，它仍然能够正常工作。由于磁盘是顺序写入的，LSM-Tree 可以支持非常高的写入吞吐量。 （要实现上面的结构，要特别考虑各种写操作的并发安全性，高性能还在其次）。 B-treelog-structure 日志索引结构正在逐渐受到更多的认可，但目前最广泛使用的索引结构是 B-tree。 从 1970 诞生以来，B-tree 经历了长久的时间的考验，时至今日，它仍然是几乎所有关系型数据库中的标准索引实现。 B-tree 也按 Key 对键值对排序（证明这个特性极端重要，对于存储而言，区间查找的重要性超乎想象地有用，这也是为什么 hash 类的存储结构使用场景不广泛的原因）。 B-tree 首先把数据库分解成固定大小的块和页（因为操作系统通常使用块作为名称，所以数据库经常使用页），这样更接近底层硬件的设计。页是内部读写的最小单元。 每个页面都有自己的地址。 ![B-tree 的例子.png](B-tree 的例子.png) B-tree 中一个页所包含的子页引用数量称为分支因子（branching factor）。这种设计使得 B-tree 在 O(logn) 的深度上保持平衡。（如果 使用 B+ 树）一个分支因子为 500（通常应该为几百）的 4kb 页只要 4 层就能够存储 256tb 左右的数据。 如何使 B-tree 更可靠？ 对 B-tree 的底层写操作基本上是使用新数据来代替磁盘上的旧页，（通常）这不会改变该页的磁盘存储位置。这与 LSM-tree 形成鲜明的对比，后者只是追加写（实际上在 SSTable 内部还是排序更新文件，但总体上是追加写），新旧替换的操作发生在后台线程的 compaction 里。 为了做崩溃恢复，B-tree 当然还是需要引入 WAL（而且 WAL 也会进化，从 binlog 进化到 redo log）。 如果要原地更新数据页，还要考虑并发控制问题，所以需要考虑锁存器（一种轻量级锁）；相比之下，日志结构化的方法先显得更简单了，因为它的实际原地更新是在后台发生的。 如何优化 B-tree？ 引入 COW，SNAPSHOT Isolation。 保存 key 的缩略信息，节省页空间，这样树具有更高的分支因子，从而减少层数（这就引入了 B+ 树）。 尽量让相邻的页在磁盘上尽量连续。 在叶子上添加额外的指针，这样寻找兄弟不需要找 parent（这也是 B+树的特性）。 分形树引入了一些 log-structure 来减少磁盘寻道。 对比 B-tree 和 LSM-treeLSM-tree 的优点是什么？ 通常认为，LSM-tree 对写入更快，而 B-tree 对读写更快。当然，真正的性能表现只能选取特定的 workload 进行负载测试才能看出来。 磁盘的总带宽是有限的，SSD 的可擦除写的次数是有限的，所以日志结构的写入可能带来的写放大值得关注，至少 compaction 可能降低初始写入的性能。 因为 compaction 的存在，所以 LSM-tree 的的碎片比 B-tree 要少，所以磁盘上的文件通常要更小。这个结论未必对，因为 LSM-tree 里面是存在重复的键值对的，B-tree 没有这种重复的成本。 LSM-tree 的缺点是什么？ compaction 会影响正在进行的读写操作。如果初始写入吞吐量很高，则压缩可能不能真正匹配上它的写入速率。 通常我们不能限制初始写入的速率。 因为多副本的存在，LSM-tree 不具备 B-tree 能够简单地锁住记录而提供事务功能的优点。 其他索引结构索引包括： 主键索引 二级索引：值得关注的是 posting-list，或者追加唯一标识使二级索引成为唯一索引的场景。 B-tree 和 log-structure 都可以拿来实现二级索引（甚至主键索引）。 索引中存储的要么是值，要么是堆文件的位置信息。堆文件才是真正存储数据的地方。 有了堆文件，只是更新值而不变更键，可以触发原地变更，否则需要牵扯到更多的文件修改和指针值修改。 但从索引到堆文件的额外跳转意味着太多的性能损失，所以聚集索引是很重要的。但创造聚集索引的次数是有限的，聚集索引和非聚集索引之间的折中是覆盖索引。覆盖索引只通过索引就可以回答某些简单的查询。 如果要同时查询多个列的信息，需要引入多列索引，但普通的多列索引在处理复杂的二维搜索的时候可能出现索引跳跃的问题： 这种时候可能需要引入专门的空间索引（SPATIAL index），如 R 树（PostgreSQL 支持 R 树查询）。 如果我们使用模糊索引，可以在某个编辑距离内搜索特定的文本。 我们很多数据结构设计起来都是为了适应磁盘的限制（注意，这里的磁盘和 SSD 是两样东西），比如 B+tree 的深度和链表结构就是为了适应访问文件块的次数和寻道时间。我们之所以使用磁盘，有至少几个原因： 磁盘可以持久化数据。 磁盘的成本比内存低。 磁盘上的文件更加容易使用外部工具运维-因为已经在进程之外了。 但如果没有磁盘的限制，我们可以得到极大的性能提升。这种内存提升不是因为磁盘的性能比较差，而是因为避免了用写磁盘的格式对内存数据结构进行编码的开销。因为只要内存足够大，虚拟内存可以使使用磁盘的存储引擎充分利用内存。但如果可以自由地使用数据结构，像 Redis 一样的方案可以提供很多样的实现。 有一种类似虚拟内存的页内存管理机制的方案，anti-caching。反缓存把足够冷的记录交换出内存，写入磁盘，再需要时再单独取回。这个方案比页式内存管理好的地方是，颗粒度更低，比操作系统管理内存的方案更有效。 如果将来 NVM 技术得到普及，可能还需要进一步改变存储引擎设计。 事务处理与分析处理事务是在商业数据处理中诞生的，主要指组成一个逻辑单元的一组写操作。广义的事务处理不一定意味着 ACID，只是意味着低延迟的读取和写入。 数据库被广泛用于处理业务交易，也被用于数据分析，这两种模式有显著差异： OLTP 基于键处理，每次查询返回少量记录，随机访问，低延迟写入，数据量小。 OLAP 对大量记录进行汇总（aggregate），通常要搭配 ETL。 这两种模式都需要交互式响应。SQL 非常灵活，被证明能够同时胜任 OLTP 和 OLAP。但从上世纪 90 年代初期开始了一种趋势，大企业放弃使用 OLTP 系统用于分析目的，儿子单独的数据库上运行分析。这个单独的数据库被称为数据仓库。 数据仓库企业可能有几十种不同的交易处理系统（Transaction Process System）。这些系统每一个都足够复杂，也每一个都非常重要，数据库管理员往往不愿意让业务分析人员在 OLTP 数据库上直接运行临时分析查询，这些查询代价很高，可能损害并发执行事务的性能。 数据仓库里包含公司所有 OLTP 系统的只读副本，通过 ETL 流程导入数据。 几乎所有的大型企业都有数据仓库，但是在小型企业中却几乎闻所未闻。所以在小公司里，OLTP 和 OLAP 是隔离的。 单独的数据仓库，可以针对分析访问模式进行优化。值得注意的是，本章前半部分讨论的索引算法适合 OLTP，但不擅长应对分析查询。 OLTP 数据库和数据仓库之间的差异有许多图形化的数据分析工具，它们可以生成 SQL 查询、可视化结果并支持分析师探索数据，例如通过诸如向下钻去、切片和切丁等操作。 数仓和 OLTP 系统的相似之处是：他们都有 SQL 接口。这也可以看出 SQL 作为声明式语言，抽象表达能力之强。 目前市面上有商业数据仓库系统通过商业许可销售系统，也有一些开源的 SQL on hadoop 的解决方案，正在逐渐流行。 星型与雪花型分析模式不像事务处理领域广泛使用的不同数据模型，数据仓库在分析型业务上相当公式化地使用星型模型，也成为维度建模（dimensional modeling）。 模式的中心是一张事实表，事实被捕获为单独的事件成为事实表中的每一行。因为事实表在中央而维度表在四周，这个模式被称为星型模式。 每一行里都有很多属性，和引用其他维度表的外键。这些维度表通常代表事件的对象（who）、什么（what）、地点（where）、时间（when）、方法（how）以及原因（why）。 星型模式有个变体，其中维度被进一步被细分为子空间-维度表之间还可以再进一步用外键互相引用。雪花模型比星型模型更加规范化了（normalization）。但大多数分析人员，雪花模型比星型模型更简单。星型 -&gt; 雪花 在典型的数据仓库中，表通常非常宽，事实表通常超过 100 列，有时候有几百列。维度表也可能非常宽。 列式存储如果事实表中有数亿万亿行、PB 大小的数据，则高效地存储和查询这些数据将成为一个具有挑战性的问题。维度表则通常小很多。所以此节中，将主要关注事实表的存储。 虽然事实表通常超过 100 列，但典型的数据仓库查询往往一次只访问其中的 4 或 5 列。 通常，面向行的存储引擎仍然需要（如果不能处理覆盖索引）将所有行都加载进内存中进行加载、解析和过滤。 面向列的存储的想法很简单：不要将一行中的所有值存储在一起，而是将每列中的所有值存储在一起。 面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行-这样实际上会造成存储的稀疏，但制造了存储上的对齐。 列压缩除了仅从磁盘中加载查询所需的列之外，还可以通过压缩数据进一步降低对磁盘吞吐量的要求。列的值序列有很多重复的话，是压缩的好兆头。在数据仓库中特别有效的一种技术是位图编码（bitmap encoding）。 一列如果有 n 种值，则可以有 n 种位图，每个位图上的一位，代表一行在上面是不是有值。这样重复的字面量存储空间被减少到一个比特。而且可以使用游程编码，对 product_sk in (30, 68, 69)这样的查询，可以对位图进行按位或，然后用求等。 这个设计思想可以总结为：拿可枚举值作为位图数量（横向数据有限），事实数量（纵向数据无限）作为比特。 有一个常见的误解：Cassandra 和 HBase 都源于 BigTable，但它们使用列族，将行主键与列族的列存储在一起，并且不使用列压缩（因为他们不能简单实用位图来节省空间）。所以 BigTable 模型仍然面向行，可以被称作表格型 KV。 内存带宽和矢量化处理面向列的存储有利于 CPU 利用内存带宽，而且快速矢量化处理。 列存储中的排序在列存储中，行的存储顺序不重要，最简单的方法是按照插入顺序保存，这样插入一个新行只是追加到每个列文件。 但单独排序某一列没有意义，如果这样的话无法知道列中的某一项具体属于哪一行。如果我们知道某列中的第 k 项一定属于同一行，基于这种约定我们可以重建一行。 相反，即使数据是按列存储的，它也需要一次排序整行。 只要涉及到排序，我们就要考虑排序键。第一个排序键往往是最重要的，我们通常选择的排序键是日期之类的列，这类列 selectivity 最高。这样我们进行范围查找的时候，解空间可以一下子收敛到很小的范围，加快查找的结果。 排序的另一个优点是，他可以帮助进一步压缩列。有大量重复值的列压缩率最好。第一列的压缩率最好，第二第三列的排序键的情况会更复杂。因为它们的值域里面相邻的重复值，可能因为归属于不同的第一键而被切割得七零八落-这就是局部簇聚性的局限了。 排序优先级进一步下降的列基本上会呈现接近随机的顺序，因此通常无法压缩。 几种不同的排序面向列的存储具有多个排序顺序，这有些类似在面向行的存储汇总具有多个二级索引。但面向行的存储，行的数据只在一处，二级索引里保存的是指向行的指针；对于列存储，通常没有任何指向别处数据的指针，只有包含值的列。拥有多个维度的存储，对保持查询业务的高可用有一定帮助。 列存储的写操作B-tree 使用原地更新的方式，必然会带来数据页的裂。而列式存储每插入一行就要更新所有列，代价更大，所以选择 LSM-tree 有其必然性。 通常列式存储在内存中使用的数据结构是面向行还是面向列的，无关紧要（这就是为什么可以使用一个 RB-tree 的原因）。 聚合：数据立方体和物化视图未必每个数据仓库都基于列存储（但数据仓库的事实表如果有几百列，又会倾向于使用列存储）。 我们通常需要使用聚合方法处理原始数据的很多列，每次都重新处理非常浪费时间。所以这诞生了两类解决方案： 物化视图：将之前的查询结果缓存在磁盘上。我们常说的数据血缘表即是这种表。 虚拟视图：我们常说的 view，编写查询的快捷方式，隐藏了真实的细节，差异化地管控查询的细节- SQL on hadoop 就是为分布式文件系统设计的虚拟视图。 物化视图的写入成本很高，但查询效果很好。所以数据仓库喜欢用物化视图而RDBMS 喜欢使用虚拟视图。 物化视图的一种常见情况被称为数据立方体。 一个二维的数据立方体是这样的：每个事实只包含两个维度表的外键，每个维度是二维矩阵的一个方向，而二维矩阵格子是事实的完整属性。这样，我们可以沿着任意维度应用聚合操作，得到减少一个维度的总和。 注意，这个立方体里有一列专门的聚合列，产生了单一维度的聚合格子（这一列不能存储复合值，它必须从属于这一维度），这个聚合列才是加速的关键。 一般来说，事实表的维度不止五个。我们很难想象五维超立方体是什么样子的。我们可以简单想象一下： 数据存放在特定的格子里 格子上存储了它拥有的所有维度的外键 格子的内容就是维度1-维度2-维度3-…-维度 x 限定的事实属性 数据立方体针对某些查询会非常快，因为她已经被预先计算出来了。但它不能解决非特定维度聚合的问题，所以数据仓库还是必须存储原始数据。 小结OLTP 面向用户，OLAP 面向业务分析师。 OLTP 方面，有两个流派的存储引擎： 日志结构流派，它追加更新，后台合并数据页。 原地更新流派（而不是 B-tree 流派），它原地更新数据页。 数据编码与演化数据编码格式编码模式要处理模式变化，才能兼容新旧系统和新旧数据。 向后兼容：新代码理解老数据。向前兼容：老代码理解新数据-这一条比较难做到，类似软分叉。 程序通常使用（至少）两种不同的数据表示形式： 在内存中，保存在专门的数据结构中，使用指针优化 cpu 进行高效访问和操作的优化。 在传输和存储时，将其编码为某种自包含的字节序列，由于指针对其他进程没有意义，所以这个字节序列看起来与内存中使用的数据结构大不一样。 从 1 到 2 被称为编码，从 2 到 1 被称为解码。 许多编程语言都内置支持将内存中的对象编码为字节序列。但它有种种缺点： 不利于异构系统集成 容易导致安全问题 不利于版本管理（进而处理向前兼容和向后兼容） 效率不高 因此我们产生了一些流行的格式，Json、XML 与二进制变体。这些格式处理数字、模式、二进制数据都有一些小小的问题。 明文是前后兼容性最好的格式，也是最不紧凑的格式。所以越是大数据量的场合，越要发明一些新颖的格式来解决容量问题。 数据流格式进程内通信是共享内存的通信；进程间通信是基于字节序列的数据编码通信。我们编写程序时进行函数间调用，就是进程内通信；我们编写 API 进行服务间通信，就是进程间通信。 基于数据库的数据流基于数据库的数据流要注意模式演化和兼容性问题。 基于服务的数据流：REST 和 PRC服务器公开的 API 被称为服务，API 通常包括一组标准的协议和数据格式。Web 浏览器、服务器和网站作者都同意这些标准，所以可以使用任何浏览器访问任何网页。 Web 浏览器不是唯一的客户端，移动设备或者桌面计算机上的应用程序也可以向服务器发出网络请求。 此外，服务器本身也可以成为另一项服务的客户端。这种方法可以用于将大型应用程序按照功能区域分解为较小的服务，服务之间通过请求传递数据。这种构建应用程序的方式被称为 SOA 或者微服务架构。 SOA/微服务体系结构的一个关键设计目标是，通过使服务可独立部署和演化，让程序更易于更改和维护。 网络服务当 HTTP 被用作与服务通信的底层协议时，它被称作 Web 服务。 REST 不是一种协议，而是一种基于 HTTP 原则的设计理念。它强调： 简单的数据格式 使用 URL 来标识资源 并且使用 HTTP 功能进行缓存控制、身份验证和内容类型协商 REST 在微服务架构非常受欢迎。 相比之下，SOAP 是基于 XML 的协议，虽然它最常用于 HTTP，但其设计目的是独立于 HTTP，并避免使用大多数 HTTP 的功能。SOAP 相关的复杂框架通常是 Web Service Framework，被称为 WS-*。因此它的 API 通常使用 WSDL 来生成代码，使用本地类和方法调用来访问远程服务。 SOAP 过于复杂，对于没有 SOAP 供应商支持的编程语言的用户来说，试图与 SOAP 服务集成非常困难。 远程过程调用（RPC）的问题EJB、RMI、DCOM 和 CORBA，各有其局限性。 RPC 思想试图使向远程网络服务发出请求看起来与在同一进程中调用编程语言中的函数或方法相同（这种抽象被称作位置透明）。这种方法有根本的缺陷（我们无法克服这些分布式计算与生俱来的缺陷），网络请求与本地函数调用非常不同： 本地函数调用是可预测的，并且成功或失败仅取决于控制的参数。而网络请求不可预测，因此必须有所准备，重试所有的请求。 本地函数调用要么返回一个结果，要么抛出一个异常，或者永远不会返回（因为无限循环或进程崩溃）。网络请求返回时可能没有结果。 如果重试失败的网络请求，可能会发生请求实际上已完成，只是响应丢失的情况，这又要求我们建立重复数据消除（幂等性）机制。 调用本地函数的时间大致相同，而网络请求的耗时则不同。 调用本地函数有时候只要传输指针就行（有时候传递数据，或者说，针对复杂数据量传递指针，简单数据传递数据），而远程请求则必须全部传递数据。 客户端和服务端可能用不同编程语言来实现，所以 RPC 框架必须处理数据类型转换的问题。 RPC 的发展方向RPC 的性能会更好，但 RESTful API 还有其他一些显著的优点：它有利于实验和调试，支持所有的主流编程语言和平台，并且有一个庞大的工具生态系统。 RPC 的数据编码和演化如果 RPC 经常要用于跨组织边界的通信，维护服务的兼容性会变得更加困难。服务的提供者无法控制其客户，也不能强制他们升级。 管理 API 版本的方法有： 在 URL 或 HTTP Accept 头中使用版本号 使用 API 密钥来标识特定客户端的服务 使用单独的管理接口来更新 API 版本的选项 基于消息传递的数据流消息是介于 RPC 和数据库之间的异步消息传递系统。客户端的请求通过低延迟传递到另一个进程中。 与 RPC 相比，消息传递有几个优点： 消息代理可以充当缓冲区 它可以自动将消息重新发送到崩溃的进程，从而防止消息丢失 它避免了发送方需要知道接收方的IP 地址和端口号 它支持将一条消息发送给多个接收方 它在逻辑上将发送方与接收方分离 与 RPC 的差异在于，消息传递通信通常是单向的。 消息代理有一类的消息队列，有请求队列，也有回复队列。 分布式 Actor 框架Actor 模型是被用于单个进程内并发的编程模型。逻辑被封装在 Actor 中，而不是直接处理线程。 每个 Actor 通常代表一个客户端或实体，它可能有某些本地状态（不与其他 Actor 共享），并且它通过发送和接收异步消息与其他 Actor 通信。不保证消息传送：在某些错误情况下，消息将丢失。由于每个 actor 一次只处理一条消息，因此不需要担心线程，每个 Actor 都可以由框架独立调度。虽然很相似，但 Goroutine 不同于 Actor，它是 CSP 模型。Actor 和线程也不一样，Actor 使用自己的时间片，而不是调用方的时间片。 在分布式 Actor 框架中，这个编程模型被用来跨越多个节点来扩展应用程序。 分布式 Actor 框架实质上是将消息代理和 Actor 编程模型集成到单个框架中。 Actor 可以很好地支持滚动更新。 小结预祝你的应用程序可以快速迭代，顺利部署。 分布式数据系统主要出于以下目的，我们需要在多台机器上分布数据： 扩展性 容错与高可用性 延迟考虑 系统扩展能力我们经常可以拿来垂直扩展的系统，由一个操作系统管理更多的 CPU，内存和磁盘，通过高速内部总线使每个 CPU 都可以访问所有的存储器或磁盘。这种架构被称作共享内存架构（shared memory architecture）。 共享内存架构只能提供有限的容错能力。 另一种方法是共享磁盘架构（shared disk architecture），它拥有多台服务器，每个服务器有个字独立的 cpu，然后将数据存储在可共享访问的磁盘阵列上，服务器和磁盘阵列之间往往通过高速网络连接。 无共享架构采用这种架构（shared nothing）时，运行数据库软件的机器或者虚拟机称为节点。每个节点使用本地的 CPU、内存和磁盘。 本部分将重点放在无共享体系架构上，并不是因为它一定是所有应用的最佳选择，而是因为它需要应用开发者更多的关注和深入理解。例如把数据分布在多节点上，就需要了解在这样一个分布式系统下，背后的权衡设计和隐含限制，数据库并不能魔法般地把所有复杂性都屏蔽起来。 （我们经常做的无状态服务搭配数据库的架构模式是近于共享磁盘架构的，而我们的单元化架构模式是近于无共享架构的。） 复制与分区将数据分布在多个节点上有两种常见方式：复制和分区。 在了解以上概念之后，我们会讨论分布式环境中错综复杂的权衡之道，很可能我们在设计系统时不得不面对这些艰难选择（没有做过艰难选择，不能算是解决过很难的问题）。 数据复制数据复制是指通过互联网络在多台机器上保存相同数据的副本。它有几个好处： 使数据更接近用户 提高冗余 读扩展（冗余提供了超量部署，读扩展也降低了延迟，负载和） 如果复制的数据一成不变，那么复制就非常容易：只需将数据复制到每个节点，一次即可搞定。然而所有的技术挑战都在于处理那些持续更改的数据。 目前流行的复制数据变化的方法有： 主从复制 多主节点复制 无节点复制 复制技术存在许多需要折中考虑的地方，比如采取同步复制还是异步复制，以及如何处理失败的副本。 数据库复制是个很古老的话题，因为网络的基本约束条件，自始至终没有发生过本质的变化（计算机发展的早期就已经摸清楚了这些基本问题，而且推导出了问题的基本解法）。 实践中大多数开发人员仍然假定数据库只运行在单节点上，分布式数据库成为主流也是最近发生的事情（长久以来 MySQL 始终是个非分布式数据库，所以才有各种中间件方案）。 许多应用开发人员在这方面经验还略显不足，对诸如“最终一致性”等问题存在一些误解。因此，在“复制滞后问题”中，我们会详细讨论最终一致性，包括读自己的写和单调读。 主节点和从节点每个保存数据库完整数据集的节点称之为副本。当有了多副本，不可避免地会引入一个问题：如何确保所有副本之间的数据是一致的？ 指定某一个副本为主副本（或称为主节点）。当客户写数据库时，必须将写请求首先发送给主副本，主副本首先将新数据写入本地存储。 其他副本则全部称为从副本（或称为从节点）。 同步复制与异步复制 上图的第一个节点显示了同步复制的工作流程，第二个节点显示了异步复制的工作流程。 同步的优点是，如果用户收到看 OK，则所有从节点 OK 了。同步复制的缺点是，如果有从节点阻塞，所有写入都会被阻塞（主从延迟是很常见的情形，所以同步复制产生的写阻塞会很频繁）。 实践中，如果数据库启用了同步复制，通常意味着其中某一个从节点是同步的，而其他节点则是异步模式。万一同步的从节点变得不可用或性能下降，则将另一个异步的从节点提升为同步模式。这样可以保证至少有两个节点（即主节点和一个同步从节点）拥有最新的数据副本。这种配置有时被称为半同步（这项技术可能是 FaceBook 率先提出的）。 主从复制还可以配置为全异步模式，这样配置性能最高，但可能丢失所有尚未复制到从节点的写请求-这是后面要谈到的“复制滞后问题”的体现。 异步模式看起来不靠谱，但还是被广泛使用，特别是从节点数量巨大或者分布于广域地理环境。 复制涉及的问题非常复杂，多副本一致性和共识问题后续再讨论。链式复制（Chain Replication）能够兼容高吞吐和高可用的场景，已经应用在微软的 Azure 存储中。 配置新的从节点新增从节点不能使用直接停机拷贝的方式，除非我们的主节点停写，直至拷贝完成。但停写的时间不能太长，否则高可用不能被保证。所以常见的做法是： 生成一个一致性快照，MySQL 使用 innodbbackupex。 将一致性快照应用（Apply）到从节点上。 从节点请求快照点之后发生的数据更改日志。这种日志的快照点位有特别的叫法，PostgreSQL 将其称为“log sequence number”，MySQL 将其称为“binlog coordinates”。 获得日志后，从节点来应用这些快找点之后的所有数据变更。 处理节点失效从节点失效：追赶式恢复如果发生网络闪断，只要从节点明确知道故障之前处理的最后一笔事务，然后连接到主节点，请求从那笔事务之后中断期间所有的数据变更。 从节点失效：节点失效节点切换，极度危险！ 处理主节点故障的情况则比较棘手：选择某个从节点将其提升至主节点；客户端也需要更新，这样之后的写请求会发送给新的主节点，然后其他从节点要接受新的主节点的变更数据，这一过程称之为切换。 故障切换可以手动执行，也可以自动进行。自动切换的步骤通常如下： 确认主节点失效。一般基于超时的心跳机制。 选举新节点。一般基于共识算法选举新节点，需要选出和失效的主节点数据差异最小的从节点。 重新配置系统使新主节点生效。 在上述切换过程中还充满了各种各样的变数： 如果使用了异步的复制，新的主节点未必收到了原主节点的所有数据（任何一种共识算法都解决不了这个问题）。如果这时候新的节点收到了新的冲突的写请求，这时候可能产生脏数据。常见的解决方案（高可用）方法是：新的主节点丢弃未完成复制的请求，但这可能会未被数据更新持久化的承诺。-另一种强一致性的做法是，在新主和老主确认校验一致之前，禁止新节点的写。这种禁止对可用性伤害很高，如果校验长时间无法完成，集群会瘫痪掉。 如果在数据库之外有其他系统依赖于数据库的内容并在一起协同使用，丢弃数据的方案就特别危险。所以强一致性的数据（余额、序列号等交易因子业务）不能使用丢弃后写的数据方案。 在某些情况下，可能出现两个从节点都认为自己是新主节点，这种情况被称为脑裂。这非常危险，两个主节点都可能接受写请求，并且没有很好地解决冲突的方法（没有办法自动处理，可能需要引入手工处理）。作为一种安全应急方案，有些系统会采取措施来强制关闭其中一个节点。 如何设置合适的超时时间来检测主节点失效呢？主节点失效后，超时时间设置得越长也意味着总体恢复时间就越长。但如果超时时间设置得太短，可能导致很多不必要的切换，遇到网络流量暴增可能会让系统频繁切换而崩溃。-超时时间太长或者太短都是陷阱，至少应该让超时时间长于一个应用超时时延的 margin。 复制日志的实现基于语句的复制这是最基础的方案。 最简单的情况，主节点记录锁所执行的每个写请求（操作语句）并将该操作作为日志发送给从节点。 区块链就是使用这种方案，但这种方案有诸多限制： 限制语句必须是确定性的语句。 语句本身不能依赖于本地现有数据（自增列），或者会限制所有语句的执行顺序。这实际上仍然会限制事务的并发执行-只有序列化执行能够无措执行。 有副作用的语句。 我们自己做 C/S 类型的数据同步，也可能采取基于语句的复制的方案，如果我们不能解决上面的问题，我们可能会遇到很大的问题。这就看出 Log-Structure 这种设计模式的重要了。 基于预写日志的复制所有对数据库写入的字节序列都被记入日志，这种日志就是 WAL。WAL 的缺点就是它描述的数据结果非常底层，某些磁盘块里的某些字节发生了改变，会让复制方案和存储引擎紧密耦合。 基于行的逻辑日志复制另一种方法是复制和存储引擎采用不同的日志格式，这样复制与存储逻辑剥离。这种复制日志称为逻辑日志。 MySQL 的 binlog 是这样工作的：针对一个事务，产生涉及多行的多条日志记录，并在后面跟着一条记录，指出该事务已提交。 （因为 binlog 是逻辑日志，所以它不与存储引擎绑定，是 Server 层日志。 binlog 特别适合用来跨版本复制是它的一个优点，但不适合特种的存储引擎的问题恢复。） 基于触发器的控制这里的触发器不是数据库内置的 trigger，而是应用层程序。基于应用层的程序比较灵活，也开销更高，而且也更加容易出错。 复制滞后问题（replication lag）主从复制要求所有的写请求都经过主节点。为了保证主从复制的写吞吐量，所以往往会开启异步复制。只要开启异步复制，都可能产生各种复制滞后，这也就意味着我们必然面对现实中的最终一致性。 读自己的写（read-your-writes）许多应用让用户提交一些数据，接下来查看他们自己提交的内容。 因为（基于主从的）异步复制的存在，所以可能会有一些用户在提交请求后需要（在副本上）查询自己提交的读。这就需要 read-after-write-consistency。 那么如何保证这种一致性呢？ 如果用户可能访问会被修改的内容，从主节点读（读主库是一种写后读，如果使用单元化等方案发生主从切换，不能保证写后读一致性，则强一致性无从保证）；否则，在从节点读取。这需要在业务规则上区分，什么样的数据是属于用户自己的某次修改的，什么样的数据是属于别人的修改的。 如果大部分的内容可能被大部分用户修改，那么尚书方法将不太有效。如果大部分的数据都需要经由主节点，这就丧失了读操作的扩展性。这时候可以尝试（一个弱时间假设），在更新后一分钟的时间内，读主节点；其他时间读从节点。这就要求：我们的时间假设掐得非常准，也要我们监控那些特别慢的节点。 客户端可以记住最近更新时的时间戳，并附在读请求中，据此信息，应用可以确定此时读出的数据是不是足够新。如果不够新，要么交给其他副本读，要么等待直至读到相应时间戳的数据为止。这个时间戳可以是逻辑时间戳（日志序列号），也可以是实际系统时钟。通常采取这种方案的系统要具有“写事件驱动读带有时间戳”的特点。 如果副本分布在多数据中心，情况复杂些，必须先把请求路由到主节点所在的数据中心（该数据中心可能离用户很远）。 单调读（monotonic-read）单调读的定义是，一个用户每次读不应该看到回滚现象。 单调读是一种比强一致性弱，但比最终一致性强的保证。至此四种一致性之间的关系为：强一致性、单调读、最终一致性、（一般）弱一致性。 保证单调读的方法是让用户每次在一个分片上读数据-换言之，使用随机负载均衡的方案配合主从复制的读扩展，没有办法保证单调读。 前缀一致读（consistent prefix reads）前缀一致读是一种保证，对于一系列按照某个顺序发生的写操作，那么读取这些内容时也会按照当时写入的顺序。 这是分片数据库在多分片写时特有的一个问题。一般情况下，即使以相同的顺序写入数据库，读取也无法保证保证总是看到一致的序列-这和 kafka 多分区无法保证全局有序是一样的。实现前缀一致读的最简单的方法是破坏分区写这个先决条件，保证有因果关系的写入都交给一个分区来完成。 所以全局有序性 = producer’s consistent prefix read + consumer’s monotonic read如果使用单元化/Set 化方案，只要发生主从切换，则无法保证单调读。 复制滞后的解决方案使用最终一致性系统时，最好先思考这样的问题：（系统最大的风险是，）如果复制延迟增加到几分钟甚至几小时，那么应用层的行为会是什么样子？ 如果需要强一致性设计，需要考虑写后读的一致性（写后读也不是很简单的，这里的写后读专指能读到写的写后读）；如果系统设计时假定是同步复制，但最终它事实上成为了异步复制，就可能会导致灾难性后果。 如果需要做特别的设计，需要在应用层上做，应用层也可以提供更灵活、强力的保障措施；而代价则是，应用层中处理这些代码非常复杂、且容易出错。 如果应用程序开发人员不必担心这么多底层的复制问题，而是假定数据库在做“正确的事情”，情况就变得简单。而这也是事务存在的原因，事务是数据库提供更强保证的一种方式。 在单节点上支持事务已经非常成熟，然而在转向分布式数据库（即支持复制和分区）的过程中，有许多系统却选择放弃支持事务，并生成事务在性能与可用性方便代价过高，然后断言在可扩展的分布式系统中最终的一致性是无法避免的终极选择。关于这样的表述，首先它有一定的道理，但情况远不是它所声称的那么简单。-我们应该跳出一个又一个有过取舍的实现，形成一个一般的、成熟的观点。 多主节点复制主从复制的方法比较常见。 主从复制存在一个明显的缺点：系统只有一个主节点，而所有写入都必须经由主节点。只要发生单点故障，主从复制就 hi 影响所有的写入操作。 对主从复制模型进行自然的扩展，则可以配置多个主节点，每个主节点都可以接受写操作，后面复制的流程类似：处理写的每个主节点都必须将该数据更改转发到所有其他节点，这就是多主节点复制。 多主复制的好处是：（从吞吐量维度）提高写的可用性。 适用场景在一个数据中心内部使用多主节点基本没有太大意义。 多数据中心为了容忍整个数据中心级别的故障或者更接近用户，可以把数据库的副本横跨多个数据中心。 在多数据中心环境下，部署单主节点的主从复制方案与多主复制方案之间存在如下差异： 性能：多数据中心的方案使得终端用户体验到的性能更好。 容忍数据中心失效：每个数据中心的副本一开始就是活的，不需要经过主从提升的操作-这要求异地的数据中心一开始就是多活的。 容忍网络问题：多数据中心如果采用异步复制方案，可以更好地容忍网络闪断。因为多数据中心天然就有远传输距离，采用异步复制也是名正言顺的。 多主复制可能存在一个潜在的问题，就是不同的数据中心可能同时修改相同的数据，因而必须解决潜在的写冲突。 由于多祝福值在许多数据库中还只是新增的高级功能，所以可能存在配置方面的细小缺陷；去与其他数据库功能交互时会出现意想不到的副作用。 离线客户端操作另一种多主复制比较适合的场景是，应用在与网络断开后还需要继续工作。 在这种情况下，每个设备都有一个充当主节点的本地数据库（用来接受写请求），然后在所有设备之间采用异步方式同步这些多主节点上的副本。 从架构层面来看，上述设置基本上等同于数据中心之间的多主复制，只不过是个极端情况，即一个设备就是数据中心。这就好像当前的架构在 C/S 和 P2P 架构之间的区别被模糊化了。 印象笔记之类的服务就是采取这种方案。 协作编辑EtherPad 或者谷歌文档通常允许多人同时编辑文本文档或电子表格。 我们通常不会将协作编辑完全等价于数据库复制问题，但两者确实有很多相似之处。当一个用户编辑文档时，所做的更改会立即应用到本地副本（Web浏览器或客户端应用程序），然后异步复制到服务器以及编辑同一文档的其他用户。 为了防止编辑冲突，必须先将文档锁定。 为了加快协作编辑的效率，可编辑的粒度需要非常小。例如，单个按键甚至是全程无锁。 处理写冲突多主复制意味着多头写入，这也意味着同时写入一行时，只要复制到远端就会产生冲突。保留近端而抛弃远端，也是一种在用户体验上可以接受的方案，至少可以产生“单调读”的错觉。多端写其实也是另一种违反单一前缀读的例子。 同步与异步冲突检测之所以会产生异步写冲突，是因为多个主节点写入时无法相互阻塞。所以为了减少这样的冲突，逼不得已的时候可能需要使用同步复制。而使用同步复制，还不如回退回单主从复制的方案。 避免冲突现实中处理写冲突的方案多少有些瑕疵，所以避免冲突反而成为大家普遍推荐的首选方案。避免写冲突的方式可能有： 对特定记录的每次写入只在一个主节点上（对 update 和 insert 实行分片错开），这相当于用分片的形式将多主复制退化为单主复制 实现 id 的跳跃（对 insert 实行交错的主键自增） 收敛于一致状态主从复制模型的数据更新符合顺序性原则，如果同一个字段有多个更新，则最后一个写操作讲决定该字段的最终值。 分布式数据库必须以一种收敛趋同的方式来解决冲突。实现收敛的冲突解决有以下可能的方式： 给每个写入分配唯一的 id，最大的写入 id 作为胜利者，丢弃其他写入。如果基于时间戳，这种技术被称为最后写入者胜利。虽然这种方法很流行，但是很容易造成数据丢失。 为每个副本（replica）分配一个唯一的 id（所以说副本之间也有主从关系），并制定规则，如序列号高的副本写入始终优先于序号低的副本。这样也会造成数据丢失。 以某种方式定义 merge 算法，自动 merge 利用预定义好的格式来记录和保留冲突的所有信息，然后依靠应用层的逻辑，事后解决冲突（可能会提示用户）。这就是印象笔记等解决方案的相关做法。 自定义冲突解决逻辑大多数多主节点复制模型都有工具来让用户编写应用代码来解决冲突。可以在写入时执行或在读取时执行这些代码逻辑。 在写入时执行。只要数据库系统在复制变更日志时检查 在读取时执行。当检测到冲突时，所有冲突写入值都会暂时保存下来。下一次读取数据时，会将数据的多个版本读返回给应用层。 git 两种策略都采用了，在向远端 push 遇到冲突时，会要求近端 merge 远端，将多个版本列出来，然后强迫用户手工处理。 什么是冲突冲突的定义很复杂，我们最好简单地把同一条记录的冲突的相关修改当作冲突。 目前诞生了很多自动解决冲突的算法，但这些算法目前还处于早期阶段，未来它们可能被整合到更多的数据系统中。 拓扑结构我们常见的拓扑结构有如下几种： 最常见的拓扑结构是全部-至-全部，Eureka 之类的解决方案就是使用这种拓扑结构，支持简单的多主写入，无惧数据丢失-只要写入能够频繁重试，数据能够最终收敛到正确值。 默认的情况下 MySQL 只支持环形拓扑结构。这种拓扑结构需要放置复制中的写请求出现无限循环，通常的解决方案是在复制日志中内置一种标记，能够记录已经处理过这个写请求的节点。GTID 是一类这种解决方案。 全部-至-全部的拓扑结构的问题是，可能出现一些日志先发出，后到达的情况，出现不满足前缀一致性读的错乱。比如，update 的日志必须出现在 insert 之后。为了使得日志消息正确有序，可以使用一种称为版本向量的技术。 无主节点复制（leaderless）到目前为止本章所讨论的复制方法，都是“主方法”。客户端现象某个主节点发送请求，由主节点决定写操作的顺序，从节点按照相同的顺序来应用主节点所发送的写日志。 一些数据存储系统则采用不同的设计思路：选择放弃主节点，允许任何副本直接接受客户端的写请求。 其实最早的数据复制系统就是无主节点的（或者称为去中心复制，无中心复制）。但到了关系型数据库主导的时代，这个想法被大家选择性遗忘了。当亚马逊内部采用了 Dynamo 系统之后，无助复制又再次称为了一种时髦的数据库架构。实际上 Eureka 和 区块链都可以算是无主复制（区块链可能可以说是随机主复制更合适），Dynamo 是唯一一个主流的无主复制数据库（DynamoDB 是另一件东西）。 在一些无领导者的实现中，客户端直接将写入发送到到几个副本中，而另一些情况下，一个协调者（coordinator）节点代表客户端进行写入。但与主库数据库不同，协调者不执行特定的写入顺序-这和 MySQL 单主的全同步复制有显著区别。我们将会看到，这种设计上的差异对数据库的使用方式有着深远的影响。 节点失效时写数据库以一个三副本数据库，其中一个副本当前不可用。在基于主节点复制模型下，如果要继续处理写操作，则需要执行切换操作。 对无节点配置，则不存在这样的切换操作。用户只要写入二个副本，即可认为写入成功。 如果失效的节点重新上线，客户端开始读取它，则可能会将陈旧（过时）值视为响应。 为了解决这个问题，当一个客户端从数据库中读取数据时，它不仅仅发送它的请求到一个副本：读请求也被并行地发送到多个节点。客户可能会从不同的节点获得不同的响应。即来自一个节点的最新值和来自另一个节点的陈旧值。版本号用于确定哪个值更新（参阅“检测并发写入”）。 读修复和反熵复制方案应确保最终将所有数据复制到每个副本。​ 在Dynamo风格的数据存储中经常使用两种机制： 读修复（Read repair）当客户端并行读取多个节点时，它可以检测到任何陈旧的响应。客户端发现某个副本具有陈旧值，并将新值写回复制品。这种方法适用于频繁阅读的值。 这个做法和 Cache-Aside Pattern 和 WeakHashMap 的惰性机制很像，但可能损害持久性（duration）。 反熵（Anti-entropy process）此外，一些数据存储具有后台进程，该进程不断查找副本之间的数据差异，并将任何缺少的数据从一个副本复制到另一个副本。与基于领导者的复制中的复制日志不同，此反熵过程不会以任何特定的顺序复制写入，并且在复制数据之前可能会有显著的延迟。我们能不能通过反熵过程来修复数据不一致，取决于我们能不能找到全局有序的预写日志。 并不是所有的系统都实现了这两个；例如，Voldemort目前没有反熵过程。请注意，如果没有反熵过程，某些副本中很少读取的值可能会丢失，从而降低了持久性，因为只有在应用程序读取值时才执行读修复。 读写的法定人数要保证读取一定能够读到最新值，就要求写副本足够多，并行读副本也足够多。把道理推广到一半情况，如果有 n 个副本，每个写入必须由w节点确认才能被认为是成功的，并且我们必须至少为每个读取查询r个节点（r 专指并行读）。只要 w + r &gt; n，读取的节点中一定会包含最新值。 设 old = n - w，只要 r &gt; old 则 r 一定包含最新值，因此 w + r &gt; n。满足这些r、w值的读写称为法定票数读和法定票数写。你可以认为，r和w是有效读写所需的最低票数。r 和 w 往往要相互配合。 在 Dynamo 风格的数据库中，参数n，w和r通常是可配置的。一个常见的选择是使n为奇数（通常为3或5）并设置 $w = r =（n + 1）/ 2$（向上取整）。但是可以根据需要更改数字。例如，设置$w = n$和$r = 1$的写入很少且读取次数较多的工作负载可能会受益。这使得读取速度更快，但具有只有一个失败节点导致所有数据库写入失败的缺点（因为只要少一个节点，w 就注定失败）。 仲裁条件$w + r&gt; n$允许系统容忍不可用的节点，如下所示： 如果$w &lt;n$，如果节点不可用，我们仍然可以处理写入。 如果$r &lt;n$，如果节点不可用，我们仍然可以处理读取。 对于$n = 3，w = 2，r = 2$，我们可以容忍一个不可用的节点。 对于$n = 5，w = 3，r = 3$，我们可以容忍两个不可用的节点。 通常，读取和写入操作始终并行发送到所有n个副本。参数w和r决定我们等待多少个节点，即在我们认为读或写成功之前，有多少个节点需要报告成功。我们能够容忍的节点数 &lt; min(w, r)。 Quorum 一致性的局限性通常，r和w被选为多数（超过 $n/2$ ）节点，因为这确保了$w + r&gt; n$，同时仍然容忍多达$n/2$个节点故障。但是，法定人数不一定必须是大多数，只是读写使用的节点交集至少需要包括一个节点。其他法定人数的配置是可能的，这使得分布式算法的设计有一定的灵活性。 但是，即使在$w + r&gt; n$的情况下，也可能存在返回陈旧值的边界条件。这取决于实现，但可能的情况包括： 如果使用松散的法定人数（见“松散法定人数与带提示的接力”），w个写入和r个读取落在完全不同的节点上，因此r节点和w之间不再保证有重叠节点。 如果两个写入同时发生，不清楚哪一个先发生。在这种情况下，唯一安全的解决方案是合并并发写入。如果根据时间戳（最后写入胜利）挑选出胜者，则由于时钟偏差，写入可能会丢失。我们将返回“检测并发写入”中的此主题。 如果写操作与读操作同时发生，写操作可能仅反映在某些副本上。在这种情况下，不确定读取是返回旧值还是新值。 如果写操作在某些副本上成功，而在其他节点上失败（例如，因为某些节点上的磁盘已满），在小于w个副本上写入成功。所以整体判定写入失败，但整体写入失败并没有在写入成功的副本上回滚。这意味着如果一个写入虽然报告失败，后续的读取仍然可能会读取这次失败写入的值。 如果携带新值的节点失败，需要读取其他带有旧值的副本。并且其数据从带有旧值的副本中恢复，则存储新值的副本数可能会低于w，从而打破法定人数条件。 即使一切工作正常，有时也会不幸地出现关于时序（timing）的边缘情况。 因此，尽管法定人数似乎保证读取返回最新的写入值，但在实践中并不那么简单。Dynamo 风格的数据库通常针对可以忍受最终一致性的用例进行优化。允许通过参数w和r来调整读取陈旧值的概率，但把它们当成绝对的保证是不明智的。所以无主写远比单主、多主写危险得多。 注意，这里使用的 quorum 和后面共识算法会再次提到的 quorum 是不一样的，此处的 rwn 算法是适应无主复制的，并不一定和后面要讲到的防脑裂多数票算法一样。它们都恰好使用了 quorum 和 rwn，但共识算法的 quorum 依赖于多数共识（防止小分区产生的脑裂），所以 w 的数量是需要强制过半的。 监控旧值从运维的角度来看，监控数据库是否返回最新的结果是很重要的。即使应用可以容忍陈旧的读取，您也需要了解复制的健康状况。如果显著落后，应该提醒您，以便您可以调查原因（例如，网络中的问题或超载节点）。 对于基于领导者的复制，数据库通常会公开复制滞后的度量标准，您可以将其提供给监视系统。这是可能的，因为写入按照相同的顺序应用于领导者和追随者，并且每个节点在复制日志中具有一个位置。通过从领导者的当前位置中减去随从者的当前位置，您可以测量复制滞后量。比对位点的位置是监控这类日志的基础方案。 然而，在无领导者复制的系统中，没有固定的写入顺序，这使得监控变得更加困难。而且，如果数据库只使用读修复（没有反熵过程），那么对于一个值可能会有多大的限制是没有限制的 - 如果一个值很少被读取，那么由一个陈旧副本返回的值可能是古老的。 宽松法定票数与数据回传松散法定票数（sloppy quorum）意味着，网络中断时，写入和读取仍然需要 w 和 r 个成功的响应，但包含了那些不在先前指定的 n 个节点。比方说，如果你把自己锁在房子外面，你可能会敲开邻居的门，问你是否可以暂时停留在沙发上。 一旦网络中断得到解决，代表另一个节点临时接受的一个节点的任何写入都被发送到适当的“本地”节点。这就是所谓的数据回传（hinted handoff）。 （一旦你再次找到你的房子的钥匙，你的邻居礼貌地要求你离开沙发回家。） 运维多个数据中心无主复制还适用于多数据中心操作，因为它旨在容忍冲突的并发写入，网络中断和延迟尖峰。- 多主复制也可以容忍这些东西。 Cassandra和Voldemort在正常的无主模型中实现了他们的多数据中心支持：副本的数量n包括所有数据中心的节点；Riak 将客户端和数据库节点之间的所有通信保持在一个数据中心本地，因此n描述了一个数据中心内的副本数量。 所有的跨数据中心写入都用类似多主复制的方案，采取异步写入方案。 检测并发写Dynamo 风格的数据库允许多个客户端同时写入相同的主键，这意味着即使使用严格的法定人数也会发生冲突。这种情况与多领导者复制相似，但在 Dynamo 样式的数据库中，在读修复或数据回传期间也可能会产生冲突。总体而言，比多主复制更差。 无主节点复制的致命缺点是：请求在不同节点上可能呈现不同的顺序。 如果每个节点只要接收到来自客户端的写入请求就简单地覆盖了某个键的值，那么节点就会永久地不一致。所以我们需要引入一些解决冲突的技巧，来让系统的副本值收敛、统一。 最后写入者胜（丢弃并发写入）实现最终融合的一种方法是声明每个副本只需要存储最“最近”的值，并允许“更旧”的值被覆盖和抛弃。然后，只要我们有一种明确的方式来确定哪个写是“最近的”，并且每个写入最终都被复制到每个副本，那么复制最终会收敛到相同的值。 关键的设计在于，如何定义“最新的”。事实上，说“发生”是没有意义的：我们说写入是并发（concurrent）的，所以它们的顺序是不确定的。 即使写入没有自然的排序，我们也可以强制任意排序。例如，可以为每个写入附加一个时间戳，挑选最“最近”的最大时间戳，并丢弃具有较早时间戳的任何写入。这种冲突解决算法被称为最后写入胜利（LWW, last write wins），是 Cassandra 唯一支持的冲突解决方法，也是 Riak 中的一个可选特征。 LWW实现了最终收敛的目标，但以持久性为代价：如果同一个Key有多个并发写入，即使它们都被报告为客户端成功（因为它们被写入 w 个副本），但只有一个写入将存活，而其他写入将被静默丢弃。此外，LWW甚至可能会删除不是并发的写入。 有一些情况，如缓存，其中丢失的写入可能是可以接受的。如果丢失数据不可接受，LWW不是解决冲突的一个好选择。 与LWW一起使用数据库的唯一安全方法是确保一个键只写入一次，然后视为不可变，从而避免对同一个主键进行并发更新（final 化也是一种高明的办法）。例如，Cassandra推荐使用的方法是使用UUID作为键，从而为每个写操作提供一个唯一的键。 Happens-before 关系和并发如果 A 在 B 之前发生或者 B 在 A 之前发生，他们之间的关系可以归为 Happens-before；否则它们可以被归为并发。如果一个操作发生在另一个操作之前，则后面的操作应该覆盖较早的操作，但是如果这些操作是并发的，则存在需要解决的冲突。 另一种标准：如果两个操作都意识不到对方的存在，就称这两个操作并发；否则他们就不是并发的。 确定并发关系一个基于版本号的算法的工作原理如下： 服务器为每个键保留一个版本号，每次写入键时都增加版本号，并将新版本号与写入的值一起存储。 当客户端读取键时，服务器将返回所有未覆盖的值以及最新的版本号。客户端在写入前必须读取。 客户端写入键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起。 （来自写入请求的响应可以像读取一样，返回所有当前值，这使得我们可以像购物车示例那样连接多个写入。） 当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值（因为它知道它们已经被合并到新的值中），但是它必须保持更高版本号的所有值（因为这些值与传入的写入属于并发）。 这种算法的 merge 是发生在客户端上的。 合并同时写入的值这种算法可以确保没有数据被无声地丢弃，但不幸的是，客户端需要做一些额外的工作：如果多个操作并发发生，则客户端必须通过合并并发写入的值来继承旧值。 Riak称这些并发值为兄弟（siblings）。 然而，简单地 union 无法保证被删除的数据真的被删除。所以我们需要在数据结构里提供墓碑标志位，以保证数据在真正合并时被删除-真正的删除算法需要仔细设计！ 版本矢量如何解决多副本的并发写入问题？ 使用简单的版本号只适合单副本（实际上是单主）的架构模式。我们需要为每个副本和每个主键均定义一个版本号。每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本中看到的版本号。这个信息指出了要覆盖哪些值，以及保留哪些并发值。 所有副本的版本号集合称为版本向量（version vector）。 版本向量有时也被称为矢量时钟，即使它们不完全相同。在比较副本的状态时，应当采用版本向量。 小结复制很难，有很多微妙的问题。 如果可以，最好使用单主从复制；否则需要承受脆弱的一致性问题。 我们需要仔细考虑三种一致性： 写后读：只读主 单调读：只读一个分片 前缀一致读：只写一个分片 数据分区分区(partition)，在MongoDB，Elasticsearch和Solr Cloud中被称为分片(shard)，在HBase中称之为区域(Region)，Bigtable中则是 表块（tablet），Cassandra和Riak中是虚节点（vnode)， Couchbase中叫做虚桶(vBucket)。但是分区(partition) 是约定俗成的叫法。 通常情况下，每条数据（每条记录，每行或每个文档）属于且仅属于一个分区。实际上，每个分区都是自己的小型数据库，尽管数据库可能支持同时进行多个分区的操作。 分区主要是为了可扩展性。不同的分区可以放在不共享集群中的不同节点上（参阅第二部分关于无共享架构的定义）。因此，大数据集可以分布在多个磁盘上，并且查询负载可以分布在多个处理器上。（所以分区会衍生一个问题，请求路由）。 对于在单个分区上运行的查询，每个节点可以独立执行对自己的查询，因此可以通过添加更多的节点来扩大查询吞吐量。分区和复制都是一种实现读扩展的方式。然而分区会让复杂查询变得更复杂。 分区与复制分区通常与复制结合使用，使得每个分区的副本存储在多个节点上。 这意味着，即使每条记录属于一个分区，它仍然可以存储在多个不同的节点上以获得容错能力。 一个节点可能存储多个分区。 每个分区领导者(主)被分配给一个节点，追随者(从)被分配给其他节点。 每个节点可能是某些分区的领导者，同时是其他分区的追随者。 大多数情况下，分区方案的选择与复制方案的选择是独立的。 键-值数据的分区分区目标是将数据和查询负载均匀分布在各个节点上。如果每个节点公平分享数据和负载，那么理论上10个节点应该能够处理10倍的数据量和10倍的单个节点的读写吞吐量（暂时忽略复制）。 如果分区是不公平的，一些分区比其他分区有更多的数据或查询，我们称之为偏斜（skew）。数据偏斜的存在使分区效率下降很多。在极端的情况下，所有的负载可能压在一个分区上，其余9个节点空闲的，瓶颈落在这一个繁忙的节点上。不均衡导致的高负载的分区被称为热点（hot spot）。 避免热点最简单的方法是将记录随机分配给节点。这将在所有节点上平均分配数据，但是它有一个很大的缺点：当你试图读取一个特定的值时，你无法知道它在哪个节点上，所以你必须并行地查询所有的节点。 键的范围不一定均匀分布，因为数据也很可能不均匀分布（skew 是天然存在的）。 根据键的范围分区一种分区的方法是为每个分区指定一块连续的键范围（从最小值到最大值），如纸百科全书的卷。如果知道范围之间的边界，则可以轻松确定哪个分区包含某个值。如果您还知道分区所在的节点，那么可以直接向相应的节点发出请求（对于百科全书而言，就像从书架上选取正确的书籍）。 键的范围不一定均匀分布，因为数据也很可能不均匀分布。为了均匀分配数据，分区边界需要依据数据调整。 分区边界可以由管理员手动选择，也可以由数据库自动选择。 Bigtable使用了这种分区策略，以及其开源等价物HBase，RethinkDB和2.4版本之前的MongoDB。 根据键的散列分区由于偏斜和热点的风险，许多分布式数据存储使用散列函数来确定给定键的分区。 一个好的散列函数可以将将偏斜的数据均匀分布。出于分区的目的，散列函数不需要多么强壮的加密算法。许多编程语言都有内置的简单哈希函数（它们用于哈希表），但是它们可能不适合分区：例如，在Java的Object.hashCode()和Ruby的Object#hash，同一个键可能在不同的进程中有不同的哈希值。这证明散列算法必须是 common-lang 的一部分。 一旦你有一个合适的键散列函数，你可以为每个分区分配一个散列范围（而不是键的范围），每个通过哈希散列落在分区范围内的键将被存储在该分区中。 这个图有两个值得注意的东西： hashcode 的结果的高位可以做分桶键（短 URL 服务有这样的例子）。 键范围是桶范围。 这种技术擅长在分区之间分配键。分区边界可以是均匀间隔的，也可以是伪随机选择的（在这种情况下，该技术有时也被称为一致性哈希（consistent hashing））。 不幸的是，通过使用键散列进行分区，我们失去了键范围分区的一个很好的属性：高效执行范围查询的能力。曾经相邻的密钥现在分散在所有分区中，所以它们之间的顺序就丢失了。在MongoDB中，如果您使用了基于散列的分区模式，则任何范围查询都必须发送到所有分区。Riak ，Couchbase 或Voldemort不支持主键上的范围查询。目前的分布式数据库的成果无法很好地解决散列分区导致的范围查询失效的问题，有的实现索性直接放弃。 但，有一种“组合分区键 + 区间查找键”的思路可以兼顾部分场景下的多种查找的问题（制造数据局部性的思想又发挥作用了）：Cassandra采取了折衷的策略。 Cassandra中的表可以使用由多个列组成的复合主键来声明。键中只有第一列会作为散列的依据，而其他列则被用作Casssandra的SSTables中排序数据的连接索引。尽管查询无法在复合主键的第一列中按范围扫表，但如果第一列已经指定了固定值，则可以对该键的其他列执行有效的范围扫描。 ​ 组合索引方法为一对多关系提供了一个优雅的数据模型。例如，在社交媒体网站上，一个用户可能会发布很多更新。如果更新的主键被选择为(user_id, update_timestamp)，那么您可以有效地检索特定用户在某个时间间隔内按时间戳排序的所有更新。不同的用户可以存储在不同的分区上，对于每个用户，更新按时间戳顺序存储在单个分区上。 负载倾斜与消除热点如前所述，哈希分区可以帮助减少热点。但是，它不能完全避免它们：在极端情况下，所有的读写操作都是针对同一个键的，所有的请求都会被路由到同一个分区。 这种场景也许并不常见，但并非闻所未闻：例如，在社交媒体网站上，一个拥有数百万追随者的名人用户在做某事时可能会引发一场风暴。这个事件可能导致大量写入同一个键（键可能是名人的用户ID，或者人们正在评论的动作的ID）。哈希策略不起作用，因为两个相同ID的哈希值仍然是相同的。 如今，大多数数据系统无法自动补偿这种高度偏斜的负载，因此应用程序有责任减少偏斜。例如，如果一个主键被认为是非常火爆的，一个简单的方法是在主键的开始或结尾添加一个随机数。只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中。 然而，将主键进行分割之后，任何读取都必须要做额外的工作，因为他们必须从所有100个主键分布中读取数据并将其合并。此技术还需要额外的记录：只需要对少量热点附加随机数;对于写入吞吐量低的绝大多数主键来是不必要的开销。因此，您还需要一些方法来跟踪哪些键需要被分割。 也许在将来，数据系统将能够自动检测和补偿偏斜的工作负载；但现在，您需要自己来权衡。 这证明 hot key 的写入解决方案是破坏 hot key 的均衡性，引入散列分布。但散列分布的结果一定是全区间搜索（散列是一把双刃剑），其实得不偿失。另一个思路可能需要应用层削峰。 分区与二级索引到目前为止，我们讨论的分区方案依赖于键值数据模型。现实中二级索引有其存在的必要性：需要加速特定值的查询。但一般的键值数据库都放弃了对二级索引的支持（Redis 就不支持二级索引），这就是搜索引擎等全文搜索服务存在的原因。 按文档的二级索引（document partitioned） 在这种索引方法中，每个分区是完全独立的：每个分区维护自己的二级索引，仅覆盖该分区中的文档。它不关心存储在其他分区的数据。无论何时您需要写入数据库（添加，删除或更新文档），只需处理包含您正在编写的文档ID的分区即可。出于这个原因，文档分区索引也被称为本地索引（local index）（而不是将在下一节中描述的全局索引（global index））。 但是，从文档分区索引中读取需要注意：除非您对文档ID做了特别的处理，否则没有理由将所有具有特定颜色或特定品牌的汽车放在同一个分区中因此，如果要搜索红色汽车，则需要将查询发送到所有分区，并合并所有返回的结果。 这种查询分区数据库的方法有时被称为分散/聚集（scatter/gather），并且可能会使二级索引上的读取查询相当昂贵。即使并行查询分区，分散/聚集也容易导致尾部延迟放大（参阅“实践中的百分位点”）。然而，它被广泛使用：MongoDB，Riak，Cassandra，Elasticsearch，SolrCloud 和 VoltDB 都使用文档分区二级索引。大多数数据库供应商建议您构建一个能从单个分区提供二级索引查询的分区方案，但这并不总是可行，尤其是当在单个查询中使用多个二级索引时（例如同时需要按颜色和制造商查询）。 分散的本地索引会带来如下问题： 并行查找 并发写失败 按文档的二级索引是本地索引，它跟着文档的主键走，写简单（无跨分片事务），读复杂（有并行查找的问题）。类似 ER-sharding 按关键词的二级索引（term partitioned）​ 我们可以构建一个覆盖所有分区数据的全局索引，而不是给每个分区创建自己的次级索引（本地索引）。但是，我们不能只把这个索引存储在一个节点上，因为它可能会成为瓶颈，违背了分区的目的。全局索引也必须进行分区，但可以采用与主键不同的分区方式。 关键词(Term) 来源于来自全文搜索索引（一种特殊的次级索引），指文档中出现的所有单词。 关键词分区的全局索引优于文档分区索引的地方点是它可以使读取更有效率：不需要分散/收集所有分区，客户端只需要向包含关键词的分区发出请求。全局索引的缺点在于写入速度较慢且较为复杂，因为写入单个文档现在可能会影响索引的多个分区（文档中的每个关键词可能位于不同的分区或者不同的节点上） 。 理想情况下，索引总是最新的，写入数据库的每个文档都会立即反映在索引中。但是，在关键词分区索引中，这需要跨分区的分布式事务，并不是所有数据库都支持（请参阅第7章和第9章）。 在实践中，对全局二级索引的更新通常是异步的（也就是说，如果在写入之后不久读取索引，刚才所做的更改可能尚未反映在索引中）。例如，Amazon DynamoDB声称在正常情况下，其全局次级索引会在不到一秒的时间内更新，但在基础架构出现故障的情况下可能会有延迟。 全局关键词分区索引的其他用途包括Riak的搜索功能和Oracle数据仓库，它允许您在本地和全局索引之间进行选择。 词条索引是个全局索引，索引跟着自己的分区算法走，读取简单，但写入复杂。 全局索引的核心问题是：到底是不是跟着主维度走？跟着主维度走，则自己的维度无法兼顾，读复杂；不跟着主维度走，则文档插入时的写复杂。 ES 的索引是被异步更新的，它是文档索引，还是词条索引？ 分区再平衡将负载从集群中的一个节点向另一个节点移动的过程称为再平衡（reblancing）。 无论使用哪种分区方案，再平衡通常都要满足一些最低要求： 再平衡之后，负载（数据存储，读取和写入请求）应该在集群中的节点之间公平地共享。 再平衡发生时，数据库应该继续接受读取和写入。 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I/O负载。 平衡策略反面教材：hash mod N模$N$方法的问题是，如果节点数量N发生变化，大多数密钥将需要从一个节点移动到另一个节点。我们需要一种只移动必需数据的方法。 固定数量的分区幸运的是，有一个相当简单的解决方案：创建比节点更多的分区，并为每个节点分配多个分区（这是 Redis 的集群方案，减少再平衡的成本，这可以被称作固定桶/方案方案）。 现在，如果一个节点被添加到集群中，新节点可以从当前每个节点中窃取一些分区，直到分区再次公平分配。 只有分区在节点之间的移动。分区的数量不会改变，键所指定的分区也不会改变。唯一改变的是分区所在的节点。这种变更并不是即时的 — 在网络上传输大量的数据需要一些时间 — 所以在传输过程中，原有分区仍然会接受读写操作。 ES 恰好是这种动态平衡方式（所以一开始的时候的分片尽可能多是有好处的，改变 ES 的分片数量的再平衡又是另一个问题了）。 在这种配置中，分区的数量通常在数据库第一次建立时确定，之后不会改变。虽然原则上可以分割和合并分区（请参阅下一节），但固定数量的分区在操作上更简单，因此许多固定分区数据库选择不实施分区分割。因此，一开始配置的分区数就是您可以拥有的最大节点数量，所以您需要选择足够多的分区以适应未来的增长。但是，每个分区也有管理开销，所以选择太大的数字会适得其反。 如果数据集的总大小难以预估（例如，如果它开始很小，但随着时间的推移可能会变得更大），选择正确的分区数是困难的。由于每个分区包含了总数据量固定比率的数据，因此每个分区的大小与集群中的数据总量成比例增长。如果分区非常大，再平衡和从节点故障恢复变得昂贵。但是，如果分区太小，则会产生太多的开销。当分区大小“恰到好处”的时候才能获得很好的性能，如果分区数量固定，但数据量变动很大，则难以达到最佳性能。这证明做大规模数据存储分区设计的时候，事先计算是很重要的-每天产生多少数据，要产生多少天。 动态分区对于使用键范围分区的数据库，具有固定边界的固定数量的分区将非常不便：如果出现边界错误，则可能会导致一个分区中的所有数据或者其他分区中的所有数据为空。手动重新配置分区边界将非常繁琐。 出于这个原因，按键的范围进行分区的数据库（如HBase和RethinkDB）会动态创建分区。当分区增长到超过配置的大小时（在HBase上，默认值是10GB），会被分成两个分区，每个分区约占一半的数据。与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。此过程与B树顶层发生的过程类似（参阅“B树”）。 每个分区分配给一个节点，每个节点可以处理多个分区，就像固定数量的分区一样。大型分区拆分后，可以将其中的一半转移到另一个节点，以平衡负载。在HBase中，分区文件的传输通过HDFS（底层分布式文件系统）来实现。 动态分区的一个优点是分区数量适应总数据量。如果只有少量的数据，少量的分区就足够了，所以开销很小;如果有大量的数据，每个分区的大小被限制在一个可配置的最大值。动态分区可以借助阈值实现分区的固定大小和分区的恰当数量，进而总是得到固定开销。 按节点比例分区通过动态分区，分区的数量与数据集的大小成正比，因为拆分和合并过程将每个分区的大小保持在固定的最小值和最大值之间。另一方面，对于固定数量的分区，每个分区的大小与数据集的大小成正比。在这两种情况下，分区的数量都与节点的数量无关。 Cassandra 和 Ketama 使用的第三种方法是使分区数与节点数成正比——换句话说，每个节点具有固定数量的分区。在这种情况下，每个分区的大小与数据集大小成比例地增长，而节点数量保持不变，但是当增加节点数时，分区将再次变小。由于较大的数据量通常需要较大数量的节点进行存储，因此这种方法也使每个分区的大小较为稳定。 当一个新节点加入集群时，它随机选择固定数量的现有分区进行拆分，然后占有这些拆分分区中每个分区的一半，同时将每个分区的另一半留在原地。随机化可能会产生不公平的分割，但是平均在更大数量的分区上时（在Cassandra中，默认情况下，每个节点有256个分区），新节点最终从现有节点获得公平的负载份额。 Cassandra 3.0引入了另一种再分配的算法来避免不公平的分割。 随机选择分区边界要求使用基于散列的分区（可以从散列函数产生的数字范围中挑选边界）。实际上，这种方法最符合一致性哈希的原始定义（参阅“一致性哈希”）。最新的哈希函数可以在较低元数据开销的情况下达到类似的效果。 运维：手动还是自动平衡在全自动重新平衡（系统自动决定何时将分区从一个节点移动到另一个节点，无须人工干预）和完全手动（分区指派给节点由管理员明确配置，仅在管理员明确重新配置时才会更改）之间有一个权衡。 在全自动重新平衡（系统自动决定何时将分区从一个节点移动到另一个节点，无须人工干预）和完全手动（分区指派给节点由管理员明确配置，仅在管理员明确重新配置时才会更改）之间有一个权衡。例如，Couchbase，Riak和Voldemort会自动生成建议的分区分配，但需要管理员提交才能生效。 全自动重新平衡可以很方便，因为正常维护的操作工作较少。但是，这可能是不可预测的。再平衡是一个昂贵的操作，因为它需要重新路由请求并将大量数据从一个节点移动到另一个节点。如果没有做好，这个过程可能会使网络或节点负载过重，降低其他请求的性能。 这种自动化与自动故障检测相结合可能十分危险。例如，假设一个节点过载，并且对请求的响应暂时很慢。其他节点得出结论：过载的节点已经死亡，并自动重新平衡集群，使负载离开它。这会对已经超负荷的节点，其他节点和网络造成额外的负载，从而使情况变得更糟，并可能导致级联失败。 出于这个原因，再平衡的过程中有人参与是一件好事。这比完全自动的过程慢，但可以帮助防止运维意外。 最佳再平衡机制 = 自动故障检测 + 手工决策。 请求路由数据如果出现再平衡，读写这些数据的时候需要恰到好处地找到数据所在的节点，进而找到分片。 这个问题可以概括为 服务发现(service discovery) ，它不仅限于数据库。任何可通过网络访问的软件都有这个问题，特别是如果它的目标是高可用性（在多台机器上运行冗余配置）。 概括来说，这个问题有几种不同的方案: Sefl-As-Router 法：允许客户联系任何节点（例如，通过循环策略的负载均衡（Round-Robin Load Balancer））。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求;否则，它将请求转发到适当的节点，接收回复并传递给客户端。 Dedicated-Proxy 法：首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求；它仅负责分区的负载均衡。 Sefl-As-Client 法：要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介。 这是一个具有挑战性的问题，因为重要的是所有参与者都同意 - 否则请求将被发送到错误的节点，而不是正确处理。 在分布式系统中有达成共识的协议，但很难正确地实现。 许多分布式数据系统都依赖于一个独立的协调服务。 执行并行查询如何执行并行查询也是一个“请求路由”的子命题。 然而，通常用于分析的大规模并行处理（MPP, Massively parallel processing） 关系型数据库产品在其支持的查询类型方面要复杂得多。一个典型的数据仓库查询包含多个连接，过滤，分组和聚合操作。 MPP查询优化器将这个复杂的查询分解成许多执行阶段和分区，其中许多可以在数据库集群的不同节点上并行执行。涉及扫描大规模数据集的查询特别受益于这种并行执行。 小结分区有不同方法。 二级索引因此也有不同方法。 请求分区也有不同的方法。 事务我们的写入操作可能存在非常多的问题，完善的容错机制非常复杂，事务是简化这些问题的首选机制。但事务并不是天然存在的，它是被人为创造出来，简化应用层的编程模型。 当然，事务并不必然存在于所有存储系统中，Redis 之类的方案就不天然支持事务（pipeline 就不是事务，mset/lua 脚本是）。 深入理解事务最早的事务来自于 IBM 1975 年的 System R。 大部分的情况下：NoSQL 提供 shard 和 replication，RDBMS 提供 relation 和 transaction，这两者是相互对立的。 ACID 的含义不同的系统的 ACID 实现其实是不一样的。 原子性（Atomicity）多线程编程里的原子性指的是，如果一个线程执行一个原子操作，这意味着另一个线程无法看到该操作的一半结果。系统只能处于操作之前或操作之后的状态，而不是介于两者之间的状态。这对应的是 ACID 的隔离性。 ACID原子性的定义特征是：能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。 或许 可中止性（abortability） 是更好的术语，但本书将继续使用原子性，因为这是惯用词。这需要用到 undo log。 一致性（Consistency）一致性在不同场景下有不同的含义： 我们讨论了副本一致性，以及异步复制系统中的最终一致性问题。副本一致性指的是多个副本的数据相同。这要求我们实现读己之写一致性、单调读一致性、前缀读一致性。 一致性散列（Consistency Hash）)是某些系统用于重新分区的一种分区方法。这里的一致性指的是系统重新达到平衡。 在CAP定理中，一致性一词用于表示可线性化（Linearizability）-和副本一致性最容易混淆。 在ACID的上下文中，一致性是指数据库在应用程序的特定概念中处于“良好状态”。 ACID一致性的概念是，对数据的一组特定陈述必须始终成立。即不变量（invariants）。 原子性，隔离性和持久性是数据库的属性，而一致性（在ACID意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。因此，字母C不属于ACID，也就与各种 WAL 无关。 隔离性（Isolation）ACID意义上的隔离性意味着，同时执行的事务是相互隔离的：它们不能相互交叉。传统的数据库教科书将隔离性形式化为可序列化（Serializability），这意味着每个事务可以假装它是唯一在整个数据库上运行的事务。数据库确保当事务已经提交时，结果与它们按顺序运行（一个接一个）是一样的，尽管实际上它们可能是并发运行的。所以可序列化本来是唯一的隔离级别。 持久性（Durability）持久性 是一个承诺，即一旦事务成功完成，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。 如“可靠性”一节所述，完美的持久性是不存在的： 一般的 RDBMS 因为日志写缓冲的关系，可能丢失一些事物操作。 硬盘还是会毁灭，除非引入足够多的副本。 单对象和多对象事务操作隔离性可以避免这个问题：通过确保用户2 要么同时看到新邮件和增长后的计数器，要么都看不到。反正不会看到执行到一半的中间结果。 存储引擎最起码的设计目标是保证对但对象的写入是有原子性和隔离性的。 CAS以及其他单一对象操作被称为“轻量级事务”，甚至出于营销目的被称为“ACID”，但是这个术语是误导性的。事务通常被理解为，将多个对象上的多个操作合并为一个执行单元的机制。 多对象事务的必要性应用仍然在没有事务的情况下实现。然而，没有原子性，错误处理就要复杂得多-没有原子性，无法精确丢弃错误数据；缺乏隔离性，就会导致并发问题-对共享资源进行并发写，不隔离则有逻辑判断错误。 弱隔离级别并发错误难以检测。 可序列化（serializable）的隔离等级意味着数据库保证事务的效果与连续运行（即一次一个，没有任何并发）是一样的。 只要弱于可序列化的隔离级别，都会有些微妙的错误发生。 读已提交最基本的事务隔离级别是读已提交（Read Committed），它提供了两个保证： 从数据库读时，只能看到已提交的数据（没有脏读（dirty reads））。 写入数据库时，只会覆盖已经写入的数据（没有脏写（dirty writes））。 防止脏读设想一个事务已经将一些数据写入数据库，但事务还没有提交或中止。另一个事务可以看到未提交的数据吗？如果是的话，那就叫做脏读（dirty reads）。 依照脏读做决策，可能读到未被持久化的数据。脏（不管是读或者写）等于只写内存而未提交。 防止脏写但是，如果先前的写入是尚未提交事务的一部分，又会发生什么情况，后面的写入会覆盖一个尚未提交的值？这被称作脏写（dirty write）- 第一个写是脏写，覆盖被称为更新丢失。 实现读已提交防止脏读可以用读锁，但会带来性能问题。所以从 RC 开始，引入快照读的思想： 对于写入的每个对象，数据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。 当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 只有当新值提交后，事务才会切换到读取新值。 快照隔离和可重复读不能正确隔离，产生不可重复读的例子： 爱丽丝在银行有1000美元的储蓄，分为两个账户，每个500美元。现在一笔事务从她的一个账户中转移了100美元到另一个账户。如果她在事务处理的同时查看其账户余额列表，不幸地在转账事务完成前看到收款账户余额（余额为500美元）-因为另一个 update 语句还未执行完，隔离性问题在分布式事务更复杂，而在转账完成后看到另一个转出账户（已经转出100美元，余额400美元）。对爱丽丝来说，现在她的账户似乎只有900美元——看起来100美元已经消失了。 这种异常被称为不可重复读（nonrepeatable read）或读倾斜（read skew）。不幸的是，术语偏差（skew） 这个词是滥用的：以前使用它是因为热点的不平衡工作量，而这里偏差意味着时间异常。 快照隔离（snapshot isolation）是这个问题最常见的解决方案。想法是，每个事务都从数据库的一致快照（consistent snapshot） 中读取——也就是说，事务可以看到事务开始时在数据库中提交的所有数据。即使这些数据随后被另一个事务更改，每个事务也只能看到该特定时间点的旧数据。所有的快照都是一致性快照，因为它们是事务 ACID 的结果。 快照隔离对长时间运行的只读查询（如备份和分析）非常有用。所以读越多越适合 MVCC；写越多 MVCC 越可能出问题。 实现快照隔离从性能的角度来看，快照隔离的一个关键原则是：读不阻塞写，写不阻塞读。这允许数据库在处理一致性快照上的长时间查询时，可以正常地同时处理写入操作。且两者间没有任何锁定争用。这也是 MVCC 的原则。 数据库必须可能保留一个对象的几个不同的提交版本，因为各种正在进行的事务可能需要看到数据库在不同的时间点的状态。因为它并排维护着多个版本的对象，所以这种技术被称为多版本并发控制（MVCC, multi-version concurrentcy control）。MVCC 的出现，在允许并发的基础上实现了隔离。 如果一个数据库只需要提供读已提交的隔离级别，而不提供快照隔离，那么保留一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本。支持快照隔离的存储引擎通常也使用MVCC来实现读已提交隔离级别。一种典型的方法是读已提交为每个查询使用单独的快照，而快照隔离对整个事务使用相同的快照。 表中的每一行都有一个 created_by 字段，其中包含将该行插入到表中的的事务ID。此外，每行都有一个 deleted_by 字段，最初是空的。如果某个事务删除了一行，那么该行实际上并未从数据库中删除，而是通过将 deleted_by 字段设置为请求删除的事务的ID来标记为删除。在稍后的时间，当确定没有事务可以再访问已删除的数据时，数据库中的垃圾收集过程会将所有带有删除标记的行移除，并释放其空间。 UPDATE 操作在内部翻译为 DELETE 和 INSERT 。 一致性快照的可见性规则当一个事务从数据库中读取时，事务ID用于决定它可以看见哪些对象，看不见哪些对象。通过仔细定义可见性规则，数据库可以向应用程序呈现一致的数据库快照。工作如下： 在每次事务开始时，数据库列出当时所有其他（尚未提交或中止）的事务清单，即使之后提交了，这些事务的写入也都会被忽略。 被中止事务所执行的任何写入都将被忽略。 由具有较晚事务ID（即，在当前事务开始之后开始的）的事务所做的任何写入都被忽略，而不管这些事务是否已经提交。 所有其他写入，对应用都是可见的。 一行被 update 几次就有几个版本，算是用 cow 来实现并发的一个实例。 索引和快照隔离索引如何在多版本数据库中工作？一种选择是使索引简单地指向对象的所有版本，并且需要索引查询来过滤掉当前事务不可见的任何对象版本。当垃圾收集删除任何事务不再可见的旧对象版本时，相应的索引条目也可以被删除。 另一种方法是是重构整棵新的 B-tree。 可重复读与命名混淆现在没有明确的可重复读的定义。 防止更新丢失如果应用从数据库中读取一些值，修改它并写回修改的值（读取-修改-写入 read modify write 过程），则可能会发生丢失更新（lost update）的问题。 原子写如果你的代码可以用这些操作来表达，那这通常是最好的解决方案。 显式锁定如果数据库的内置原子操作没有提供必要的功能，防止丢失更新的另一个选择是让应用程序显式地锁定将要更新的对象。 要加锁就要在全部的地方加锁。 写倾斜与幻读定义写倾斜可以将写倾斜视为丢失更新问题的一般化。如果两个事务读取相同的一批对象，然后更新其中一些对象（不同的事务可能更新不同的对象），则可能发生写入写倾斜。在多个事务更新同一个对象的特殊情况下，就会发生脏写或丢失更新（取决于时机）。 所以已知的并发写问题有： 脏写：写入提交前就被覆盖。 更新丢失：覆盖提交前写入。 写倾斜：并发读批量而交叉写，导致读失效。 写倾斜绝不可能被 RR 解决，解法有： 真正使用可序列化隔离级别。 对事务依赖的所有行进行显示加锁。 更多写倾斜的例子会议系统的可预订时间是多行记录，如果没有锁定全部时间，则可能在插入时产生写倾斜。 为何产生写倾斜读后写依赖的读未被锁定，所以写可能出现逻辑错误。 不是所有时候都有可以锁定的行-后面会讲怎么解决。 一个事务中的写入改变另一个事务的搜索查询的结果，被称为幻读。幻读不同于写倾斜，但幻读可能导致写倾斜。RR 可以解决只读时的幻读（这里这本书的描述指的是我们常见的不可不重复读）问题。 实体化冲突我们可以引入一些不存储写入信息，但可以供锁定的行，即“锁表”。如会议室的例子，我们可以制造锁表，每 15 分钟是锁表里的一行。这种方法被称为物化冲突（materializing conflicts），因为它将幻读变为数据库中一组具体行上的锁冲突。 这就是上面说的解法 2，大多数时候，解法 1 比 2 好，因为解法 2 影响了应用的模型设计。 可串行化弱隔离级别的问题，只有使用可串行化来解决。 实际串行执行数据库设计人员只是在2007年左右才确信，单线程循环执行事务是可行的。多线程并发在过去的30年中被认为是获得良好性能的关键所在。 在存储过程中封装事务如果数据库事务需要等待来自用户的输入，则数据库需要支持潜在的大量并发事务，其中大部分是空闲的。大多数数据库不能高效完成这项工作，因此几乎所有的OLTP应用程序都避免在事务中等待交互式的用户输入，以此来保持事务的简短。-但同一个事务里面多次写入是可以的。 出于这个原因，具有单线程串行事务处理的系统不允许交互式的多语句事务。取而代之，应用程序必须提前将整个事务代码作为存储过程提交给数据库。 但存储过程太烂了，语法不标准和丑陋、难以调试。 分区事务在单核上执行，并发度不高。 在多核上执行需要配合多数据分区-类似区块链的分片方案。跨分区的存储过程需要跨分区的锁定。 两阶段加锁大约30年来，在数据库中只有一种广泛使用的序列化算法：两阶段锁定（2PL，two-phase locking），- 实际上其他隔离级别出现 update 时，都会触发两阶段加锁。 实现两阶段锁读要求锁保护自己，写要求锁保护自己，读写要互斥，要注意锁要升级。 “两阶段”这个名字的来源：第一阶段（当事务正在执行时）获取锁，第二阶段（在事务结束时）释放所有的锁。 MVCC 要求读互不干扰，而 2PL 要求读写互斥、写写互斥。 两阶段锁的性能不好即使你保证所有的事务都很短，如果有多个事务想要访问同一个对象，那么可能会形成一个队列。 谓词锁（predicate lock）它类似于前面描述的共享/排它锁，但不属于特定的对象（例如，表中的一行），它属于所有符合某些搜索条件的对象，如： 谓词锁限制访问，如下所示： 如果事务A想要读取匹配某些条件的对象，就像在这个 SELECT 查询中那样，它必须获取查询条件上的共享谓词锁（shared-mode predicate lock）。如果另一个事务B持有任何满足这一查询条件对象的排它锁，那么A必须等到B释放它的锁之后才允许进行查询。 如果事务A想要插入，更新或删除任何对象，则必须首先检查旧值或新值是否与任何现有的谓词锁匹配。如果事务B持有匹配的谓词锁，那么A必须等到B已经提交或中止后才能继续。 谓词锁的出现让我们能够锁定还未出现的数据-防止幻读。 索引范围锁不幸的是谓词锁性能不佳：如果活跃事务持有很多锁，检查匹配的锁会非常耗时。因此，大多数使用2PL的数据库实际上实现了索引范围锁（也称为间隙锁（next-key locking）），这是一个简化的近似版谓词锁。 通过使谓词匹配到一个更大的集合来简化谓词锁是安全的。例如，如果你有在中午和下午1点之间预订123号房间的谓词锁，则锁定123号房间的所有时间段，或者锁定12:00~13:00时间段的所有房间（不只是123号房间）是一个安全的近似，因为任何满足原始谓词的写入也一定会满足这种更松散的近似。 在房间预订数据库中，您可能会在room_id列上有一个索引，并且/或者在start_time 和 end_time上有索引（否则前面的查询在大型数据库上的速度会非常慢）： 假设您的索引位于room_id上，并且数据库使用此索引查找123号房间的现有预订。现在数据库可以简单地将共享锁附加到这个索引项上，指示事务已搜索123号房间用于预订。 或者，如果数据库使用基于时间的索引来查找现有预订，那么它可以将共享锁附加到该索引中的一系列值，指示事务已经将12:00~13:00时间段标记为用于预定。 这里的索引区间锁的用意是不要持有多把锁，而是只索引一个值（如 room id）。 如果没有可以挂载间隙锁的索引，数据库可以退化到使用整个表上的共享锁。这对性能不利，因为它会阻止所有其他事务写入表格，但这是一个安全的回退位置。 序列化快照隔离（SSI）一方面，我们实现了性能不好（2PL）或者扩展性不好（串行执行）的可序列化隔离级别。另一方面，我们有性能良好的弱隔离级别，但容易出现各种竞争条件（丢失更新，写入偏差，幻读等）。序列化的隔离级别和高性能是从根本上相互矛盾的吗？ 也许不是：一个称为可序列化快照隔离（SSI, serializable snapshot isolation） 的算法是非常有前途的。它提供了完整的可序列化隔离级别，但与快照隔离相比只有只有很小的性能损失。 SSI是相当新的：它在2008年首次被描述，并且是Michael Cahill的博士论文的主题。 纯悲观锁性能不佳。纯乐观锁在系统满负载的时候一样性能不佳。 序列化快照隔离是一种乐观（optimistic） 的并发控制技术。在这种情况下，乐观意味着，如果存在潜在的危险也不阻止事务，而是继续执行事务，希望一切都会好起来。当一个事务想要提交时，数据库检查是否有什么不好的事情发生（即隔离是否被违反）；如果是的话，事务将被中止，并且必须重试。只有可序列化的事务才被允许提交。 它有两种实现方法： 如果读提交在后，检测对旧MVCC对象版本的读取（读之前存在未提交的写入），如果发生冲突，中止事务。 如果写提交在后，检测影响先前读取的写入（读之后发生写入），如果发生冲突，写事务退出。 分布式系统的挑战要构建可靠的系统，要依赖于对故障的理解。 本章对分布式系统中可能出现的问题进行彻底的悲观和沮丧的总结-问题是不可克服的。 故障与部分失效单机程序的确定性比较好，行为可预测。 在分布式系统中，尽管系统的其他部分工作正常，但系统的某些部分可能会以某种不可预知的方式被破坏。这被称为部分失效（partial failure）。难点在于部分失效是不确定性的（nonderterministic）：如果你试图做任何涉及多个节点和网络的事情，它有时可能会工作，有时会出现不可预知的失败。正如我们将要看到的，你甚至不知道是否成功了，因为消息通过网络传播的时间也是不确定的！ 这种不确定性和部分失效的可能性，使得分布式系统难以工作。 云计算和超算超级计算机更像是一个单节点计算机而不是分布式系统：通过让部分失败升级为完全失败来处理部分失败——如果系统的任何部分发生故障，只是让所有的东西都崩溃（就像单台机器上的内核崩溃 kernel panic 一样）。 在分布式系统中，怀疑、悲观和偏执狂才能生存。 不可靠的网络我们无法区分：请求丢失、远程节点崩溃、响应丢失的任何一种情况，所以我们并不知道远端节点是否处理过这个请求。 真实世界的网络故障partition 在这里意味着网络分区：网络的一部分由于网络故障而被切断（而继续工作）。 检测故障许多系统需要自动检测故障节点。例如： 负载平衡器需要停止向已死亡的节点转发请求（即从移出轮询列表（out of rotation））。 在单主复制功能的分布式数据库中，如果主库失效，则需要将从库之一升级为新主库（参阅“处理节点宕机”）。 不幸的是，网络的不确定性使得很难判断一个节点是否工作（后面还会反复强调这一点）。 如果出了什么问题，你可能会在堆栈的某个层次上得到一个错误响应，但总的来说，你必须假设你根本就没有得到任何回应。您可以重试几次（TCP重试是透明的，但是您也可以在应用程序级别重试），等待超时过期，并且如果在超时时间内没有收到响应，则最终声明节点已经死亡。-所以心跳检测超时是检测故障的首选方案。 超时与无穷的延迟如何设置超时时间是个两难的问题： 太短的超时时间可能会误杀系统，进而： 导致系统容量错误地缩小，将其负载转移到其他节点可能会导致级联失效（cascading failure）。 造成了双节点写-可能破坏前缀一致读一致性。 太长的超时时间会让系统可用性降低，用户会等待更多的时间。 设想一个虚构的系统，其网络可以保证数据包的最大延迟——每个数据包要么在一段时间内传送，要么丢失，但是传递永远不会比$d$更长。此外，假设你可以保证一个非故障节点总是在一段时间内处理一个请求$r$。在这种情况下，您可以保证每个成功的请求在$2d + r$时间内都能收到响应，如果您在此时间内没有收到响应，则知道网络或远程节点不工作。如果这是成立的，$2d + r$ 会是一个合理的超时设置。 网络拥塞和排队一些对延迟敏感的应用程序（如视频会议和IP语音（VoIP））使用UDP而不是TCP。这是在可靠性和和延迟可变性之间的折衷：由于UDP不执行流量控制并且不重传丢失的分组，所以避免了可变网络延迟的一些原因（尽管它仍然易受切换队列和调度延迟的影响）。 在延迟数据毫无价值的情况下，UDP是一个不错的选择。例如，在VoIP电话呼叫中，可能没有足够的时间重新发送丢失的数据包，并在扬声器上播放数据。在这种情况下，重发数据包没有意义——应用程序必须使用静音填充丢失数据包的时隙（导致声音短暂中断），然后在数据流中继续。重试发生在人类层。 （“你能再说一遍吗？声音刚刚断了一会儿。“） 同步网络 vs 异步网络我们不可能在异步网络里预测延迟（实际上任何网络都不可以）。 不可靠的时钟单调钟与时钟System.currentTimeMillis() 是墙上时钟，如果操作系统的时间回拨，这个时钟会出错。 System.nanoTime()都是单调时钟。这个名字来源于他们保证总是前进的事实（而时钟可以及时跳回）。 在分布式系统中，使用单调钟测量经过时间（elapsed time）（比如超时）通常很好。 依赖同步时钟如果有极强的硬件，可以保证时间差不太多。 有序事件的时间戳如果不对事件排序，则必然发生 LWW。 如果写来自不同的源，很难对事件进行真正的排序，无法确认因果关系，可能发生更新丢失。 时钟读数存在置信区间一个有趣的例外是Spanner中的Google TrueTime API，它明确地报告了本地时钟的置信区间。当你询问当前时间时，你会得到两个值：[最早，最晚]，这是最早可能的时间戳和最晚可能的时间戳。在不确定性估计的基础上，时钟知道当前的实际时间落在该区间内。间隔的宽度取决于自从本地石英钟最后与更精确的时钟源同步以来已经过了多长时间。 全局快照的同步时钟快照隔离最常见的实现需要单调递增的事务ID。如果写入比快照晚（即，写入具有比快照更大的事务ID），则该写入对于快照事务是不可见的。在单节点数据库上，一个简单的计数器就足以生成事务ID。 但是当数据库分布在许多机器上，也许可能在多个数据中心中时，由于需要协调，（跨所有分区）全局单调递增的事务ID可能很难生成。事务ID必须反映因果关系：如果事务B读取由事务A写入的值，则B必须具有比A更大的事务ID，否则快照就无法保持一致。在有大量的小规模、高频率的事务情景下，在分布式系统中创建事务ID成为一个站不住脚的瓶颈。 Spanner以这种方式实现跨数据中心的快照隔离【59，60】。它使用TrueTime API报告的时钟置信区间，并基于以下观察结果：如果您有两个置信区间，每个置信区间包含最早和最近可能的时间戳（ $A = [A{earliest}, A{latest}]$， $B=[B{earliest}, B{latest}] $），这两个区间不重叠（即：$A{earliest} &lt; A{latest} &lt; B{earliest} &lt; B{latest}$），那么B肯定发生在A之后——这是毫无疑问的。只有当区间重叠时，我们才不确定A和B发生的顺序。 为了确保事务时间戳反映因果关系，在提交读写事务之前，Spanner在提交读写事务时，会故意等待置信区间长度的时间。通过这样，它可以确保任何可能读取数据的事务处于足够晚的时间，因此它们的置信区间不会重叠。为了保持尽可能短的等待时间，Spanner需要保持尽可能小的时钟不确定性，为此，Google在每个数据中心都部署了一个GPS接收器或原子钟，允许时钟在大约7毫秒内同步。 这个方案可能是唯一在工业界能够落地的方案。 暂停进程主节点如何维护自己的任期？使用租约机制： 一种选择是领导者从其他节点获得一个租约（lease），类似一个带超时的锁。任一时刻只有一个节点可以持有租约——因此，当一个节点获得一个租约时，它知道它在某段时间内自己是领导者，直到租约到期。为了保持领导地位，节点必须在周期性地在租约过期前续期。 想象一下，线程在lease.isValid()行周围停止15秒，然后才终止。在这种情况下，在请求被处理的时候，租约可能已经过期，而另一个节点已经接管了领导。然而，没有什么可以告诉这个线程已经暂停了这么长时间了，所以这段代码不会注意到租约已经到期了，直到循环的下一个迭代 ——到那个时候它可能已经做了一些不安全的处理请求。 有很多种原因造成进程停顿： GC 的 stw 操作系统自身暂停进程 虚拟化 上下文切换 在单台机器上编写代码时，可以通过共享内存通信；而分布式场景下通信时，必须通过通信来共享内存。 在嵌入式系统中，实时是指系统经过精心设计和测试，以满足所有情况下的特定时间保证。这个含义与Web上实时术语的模糊使用相反，它描述了服务器将数据推送到客户端以及流处理，而没有严格的响应时间限制。 调整垃圾回收的方法（非常重要!） 一个新兴的想法是将 GC 暂停视为一个节点的短暂计划内的临时离线，并让其他节点处理来自客户端的请求，同时一个节点正在收集其垃圾。如果运行时可以警告应用程序一个节点很快需要GC暂停，那么应用程序可以停止向该节点发送新的请求（可以在服务端自己摘除，也可以靠客户端的滑动窗口熔断），等待它完成处理未完成的请求，然后在没有请求正在进行时执行GC。这个技巧隐藏了来自客户端的GC暂停，并降低了响应时间的高百分比。一些对延迟敏感的金融交易系统使用这种方法-这要求我们能够：1、预测 gc，2、在 gc 到来之前在 LB 切换流量，停止新的流量，3、gc 过后重新打开 LB。 这个想法的一个变种是只用垃圾收集器来处理短命对象（这些对象要快速收集），并定期在积累大量长寿对象（因此需要完整GC）之前重新启动进程。一次可以重新启动一个节点，在计划重新启动之前，流量可以从节点移开，就像滚动升级一样。- 这要求我们能够严格预测、控制 ygc 的频率和时长（这需要不断调整 ygc 的参数，改变 young 区范围大小和垃圾收集算法，让 young 区足够小，甚至有意识地让对象进入 old 区来避免过长时间的 ygc，这时候不如直接上 g1/zgc，让它自己在回收循环里面自我调优-因为这就是在手工做同样的事情），并且能够定期重启服务。 使用对象池，明确区分不易回收的对象，尽量减少没必要的、重复的 ygc 对象，这可以和方法 2 搭配使用。 主动 gc：在 jdk7 使用 system.gc，其它jdk版本使用 jmap -histo:live。 知识、真相与谎言真理由多数所定义节点不一定能相信自己对于情况的判断。分布式系统不能完全依赖单个节点，因为节点可能随时失效，可能会使系统卡死，无法恢复。相反，许多分布式算法都依赖于法定人数，即在节点之间进行投票：决策需要来自多个节点的最小投票数，以减少对于某个特定节点的依赖。 最常见的法定人数是超过一半的绝对多数（尽管其他类型的法定人数也是可能的）。多数法定人数允许系统继续工作，如果单个节点发生故障（三个节点可以容忍单节点故障；五个节点可以容忍双节点故障）。系统仍然是安全的，因为在这个制度中只能有一个多数——不能同时存在两个相互冲突的多数决定-RAFT 的根基就在这里。 fencing 令牌 我们假设每次锁定服务器授予锁或租约时，它还会返回一个防护令牌（fencing token），这个数字在每次授予锁定时都会增加。 我们可以要求客户端每次向存储服务发送写入请求时，都必须包含当前的屏蔽令牌。 服务器要原子化地同时具有处理资源和令牌的功能，能够比对当前的令牌是不是最高级的。 如果将ZooKeeper用作锁定服务，则可将事务标识zxid或节点版本cversion用作屏蔽令牌。由于它们保证单调递增，因此它们具有所需的属性。 对于不明确支持屏蔽令牌的资源，可能仍然可以解决此限制（例如，在文件存储服务的情况下，可以将防护令牌包含在文件名中-另一个方法，把令牌写进资源的一个属性中，如表的 version）。 如果没有办法实现 fencing 盾牌，可以学习 Spanner 进行等待。 拜占庭故障拜占庭容错系统的协议的实现异常复杂。 但是，我们通常不使用拜占庭容错协议，而只是让服务器决定什么是客户端行为（在 C/S架构中），而不是允许的。在没有这种中心授权的对等网络中，拜占庭容错更为重要-所以简单粗暴的设计是中心化服务。 大多数拜占庭式容错算法要求超过三分之二的节点能够正常工作（即，如果有四个节点，最多只能有一个故障）。 系统模型与现实 同步模型 同步模型（synchronous model）假设网络延迟，进程暂停和和时钟误差都是有界限的。这并不意味着完全同步的时钟或零网络延迟；这只意味着你知道网络延迟，暂停和时钟漂移将永远不会超过某个固定的上限【88】。同步模型并不是大多数实际系统的现实模型，因为（如本章所讨论的）无限延迟和暂停确实会发生。 部分同步模型 部分同步（partial synchronous）意味着一个系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟，进程暂停和时钟漂移的界限【88】。这是很多系统的现实模型：大多数情况下，网络和进程表现良好，否则我们永远无法完成任何事情，但是我们必须承认，在任何时刻假设都存在偶然被破坏的事实。发生这种情况时，网络延迟，暂停和时钟错误可能会变得相当大。 异步模型 在这个模型中，一个算法不允许对时机做任何假设——事实上它甚至没有时钟（所以它不能使用超时）。一些算法被设计为可用于异步模型，但非常受限。 同步模型不切实际，部分同步模型是常见的。 进一步来说，除了时间问题，我们还要考虑节点失效。三种最常见的节点系统模型是： 崩溃-停止故障 在崩溃停止（crash-stop）模型中，算法可能会假设一个节点只能以一种方式失效，即通过崩溃。这意味着节点可能在任意时刻突然停止响应，此后该节点永远消失——它永远不会回来。 崩溃-恢复故障 我们假设节点可能会在任何时候崩溃，但也许会在未知的时间之后再次开始响应。在崩溃-恢复（crash-recovery）模型中，假设节点具有稳定的存储（即，非易失性磁盘存储）且会在崩溃中保留，而内存中的状态会丢失。 拜占庭（任意）故障 节点可以做（绝对意义上的）任何事情，包括试图戏弄和欺骗其他节点，如上一节所述。 对于真实系统的建模，具有崩溃-恢复故障（crash-recovery）的部分同步模型（partial synchronous）通常是最有用的模型-常见的就是性价比最高的。 算法的正确性如果我们正在为一个锁生成屏蔽令牌（参阅“屏蔽令牌”），我们可能要求算法具有以下属性： 唯一性 没有两个屏蔽令牌请求返回相同的值。 单调序列 如果请求 $x$ 返回了令牌 $t_x$，并且请求$y$返回了令牌$t_y$，并且 $x$ 在 $y$ 开始之前已经完成，那么$t_x &lt;t_y$。 可用性 请求防护令牌并且不会崩溃的节点，最终会收到响应。 safety 和 liveness唯一性和单调序列是 safety。 最终一致性是一个 liveness。 大多数分布式系统一定要保证 safety，尽量确保 liveness。 将系统模型映射到现实世界这并不是说理论上抽象的系统模型是毫无价值的，恰恰相反。它们对于将实际系统的复杂性降低到一个我们可以推理的可处理的错误是非常有帮助的，以便我们能够理解这个问题，并试图系统地解决这个问题。我们可以证明算法是正确的，通过显示它们的属性总是保持在某个系统模型中 证明算法正确并不意味着它在真实系统上的实现必然总是正确的。但这迈出了很好的第一步，因为理论分析可以发现算法中的问题，这种问题可能会在现实系统中长期潜伏，直到你的假设（例如，时间）因为不寻常的情况被打破。理论分析与经验测试同样重要。 本章小结这类部分失效可能发生的事实是分布式系统的决定性特征。每当软件试图做任何涉及其他节点的事情时，偶尔就有可能会失败，或者随机变慢，或者根本没有响应（最终超时）。在分布式系统中，我们试图在软件中建立部分失效的容错机制，这样整个系统即使在某些组成部分被破坏的情况下，也可以继续运行。 为了容忍错误，第一步是检测它们，但即使这样也很难。大多数系统没有检测节点是否发生故障的准确机制，所以大多数分布式算法依靠超时来确定远程节点是否仍然可用。 如果你习惯于在理想化的数学完美（同一个操作总能确定地返回相同的结果）的单机环境中编写软件，那么转向分布式系统的凌乱的物理现实可能会有些令人震惊。相反，如果能够在单台计算机上解决一个问题，那么分布式系统工程师通常会认为这个问题是平凡的，现在单个计算机确实可以做很多事情。如果你可以避免打开潘多拉的盒子，把东西放在一台机器上，那么通常是值得的。 有可能给网络提供硬实时的响应保证和有限的延迟，但是这样做非常昂贵，且导致硬件资源的利用率降低。大多数非安全关键系统会选择便宜而不可靠，而不是昂贵和可靠。 一致性与共识这一章探讨的问题和第五章的复制问题有极大的关系，复制既是达成共识的手段，也是达成共识所需要解决的问题的本身。本章要考虑在第八章的网络问题（特别是不可靠网络延迟）的基础上，如何构建共识算法，进而达到一致。 处理故障的最简单方法是简单地让整个服务失效，并向用户显示错误消息，否则要考虑容错。 构建容错系统的最好方法，是找到一些带有实用保证的通用抽象，实现一次，然后让应用依赖这些保证。事务是一种这样的抽象，共识算法是另一种这样的抽象，两者是正交的。分布式系统最重要的抽象之一就是共识（consensus）：是让所有的节点对某件事（某个 proposal）达成一致，且不可撤销。 一致性保证大多数可复制的数据库提供的是最终一致性，最终一致性意味着所有的数据的值最终会收敛（convergence）到相同的值。但分布式多副本的场景下，如何维护副本状态，是一个很复杂的问题。 可线性化可线性化的准确定义非常复杂，但它表现得好像只有一个副本，所有操作都是原子的（没有中间状态，读到的状态不可撤销）-另一种类似的等价定义是所有客户端可以看到相同的数据视图。 如何达到可线性化将分布式数据的主键定义为寄存器，可线性化系统的工作方式是：如果某一个客户端读到的寄存器值发生了跳变，所有的客户端读到的值都只能是该最新值。 举例：客户端 a 在全局时钟 1 读到 v2，则 b 在全局时钟 2（这里的时钟指的是客户端的请求在服务器端发生的时间，不分读写，2 在 1 之后）读到的值至少是 v2，否则发生了倒退，不满足可线性化。 线性化的依赖条件线性一致性在什么情况下有用？ 锁定和领导选举所有的锁操作都强依赖于可线性化，否则会出现问题（Redis 的主从复制方案不满足线性化，所以在自动主从切换的时候会出问题）。 约束和唯一性保证如何保证一个值全局唯一，即全局的唯一值插入或者满足全局的业务主键唯一？这个问题和上一个问题是等价的。 跨信道的时序依赖如果端到端存在两个通信信道，如消息队列和数据库，则读消息队列 读到的数据可能和数据库里读到的数据库不一致。这时候也是需要让读这两个信道的客户端读到线性一致性的数据的。但本章提供的解决方案，只有异构共识算法可能解决这个问题。现实之中通常使用版本加读修复的方式来部分解决这个问题。 实现可线性化系统我们已知的复制机制： 简单的主从复制：全同步的从节点，不考虑快照隔离则满足线性一致性。所以半同步复制的 MySQL 集群大部分时候是满足可线性化的。 共识算法：Zookeeper 和 etcd 可以实现可线性化。 多主复制：不可以，因为写冲突。 无主复制：LWW 必定不是线性化的，因为网络不可靠可能导致乱序写。达不到因果一致性就更谈不上可线性化。 可线性化和 quorum本书讲了一个复杂的例子，从节点每次读之前都执行读修复，且主节点写之前先做 volatile 式的读。这个例子不可取，所以无主复制就是不可线性化的。 可线性化的代价多数据中心的数据库之间的复制默认是多主异步复制。只要发生网络中断，可能无法满足可线性化。 CAP 理论CAP 没有准确的定论，A 的定义都存在争议，C 专指可线性化。CAP 其实是鼓励大家探索无共享系统（不要共享硬件，做到 shared-nothing）。 线性一致性和网络延迟虽然线性一致是一个很有用的保证，但实际上，线性一致的系统惊人的少。例如，现代多核CPU上的内存甚至都不是线性一致的，除非使用内存屏障或者 fenc 指令。这种不一致性是由 cache 和主存之间的异步刷新决定的，这种异步刷新至关重要。 由此反推，非常多的数据库不支持线性化算法主要是为了性能。 顺序保证排序、可线性化和共识之间存在着某些深刻的联系。 顺序与因果关系顺序决定了因果关系，有些事件必须发生在某些事情之前（happens-before），这叫作因果一致性。 全序（total order）支持任何两个元素之间进行比较，即全部的事件可以在一个时间线上简单线性排序-一个数轴上的自然数满足全序关系。 {a, b} 和{b, c}不满足全序关系，数学集合只能是偏序（partially order）。 可线性化事件满足全序（但满足全序不等于可线性化事件）；并发时间线上的并发事件不可比较，但同一根并发的时间线上的事件可以被比较-想象 git 的分支模型，同一branch 上的事件都满足因果关系，但 git 的事件本身不是可线性化的。 可线性化包含因果一致性。 在可线性化之下有一种稍弱的顺序一致性，强于因果一致性。顺序一致性也存在一个时间线，每个客户端始终始终可以满足单调读（即不回退）和前缀一致读（即所有客户端都读到 1、2、3，而不是有的客户端只读到 1、3），但不能满足读到新版本的时间线顺序完全一致（即有的客户端 1 读到 2 时，还有客户端 2 会读到 1，但最终客户端 2 会读到 2）。 非可线性化的因果一致性（Causal Consistency）是三种一致性模型里面最弱的，算是在网络延迟中可以被接受的，可以容错的最强一致性模型。很多时候看起来需要可线性化的场景，真正需要的是因果一致性，就好像并发模型需要 happens-before 一样。 建立因果关系最简单的方法是使用在写操作时对读的数据标定版本-序列号，百试百灵。 序列号排序序列号是一种逻辑时钟，区块的 pre-transaction 是另一种（但链表结构不可简单排序）。 我们需要一个真正的自增算法。binlog 就使用单调递增的序号来标记操作。 非因果序列发生器如果没有单一的序列号生成的主节点，可以产生各自独立的序列号： 不同的机器产生奇偶序列号 使用墙上时钟-会发生 LWW 预先分配序列号的区间范围 这些序列号无法正确捕获跨节点操作的顺序。 Lamport 时间戳 每个服务器节点为每个主键维护（已处理的请求数，节点 id）。 每个写操作携带自己已知的版本，如果该版本大于当前服务器节点的版本，则使用此版本加 1 作为数据的最新版本，否则使用服务器自己使用的版本加 1 作为数据的最新版本。 返回最新版本给客户端，以备下次写请求携带。 比对版本时先比对版本，其次比对节点 id，节点 id 越高时间戳越大。 这个算法类似奇偶序列号，但可产生的序列号的范围比奇偶序列号大。 Lamport 时间戳虽然能够告诉我们全序，但我们无法区分两个事件是并发的，还是有因果关系的。 时间戳排序依然不够为了确保结果是全局唯一的，需要在收集所有确定的信息的基础上做全局排序，这样的全局排序才有意义。 全序关系广播（total order broadcast）主从复制的经典流程是：选取一个主节点，它维护日志的事件写入顺序，并严格按照这个顺序广播给其他从节点。如果主从复制能够解决单一主节点的吞吐量和可用性限制，它就是全序关系广播或者原子广播。 原子广播要保证：所有消息严格按照顺序，一条不漏地到达远端。 使用全序关系广播数据库使用全序关系广播，可以实现状态机复制（state machine replication）。 有了全序关系广播，必然带来日志，写日志的编号可以产生序列号或者 fencing token-这就要求写请求耦合在写日志流程里。 全序关系广播不等于线性化，但如果它解决了全局的 cas问题，则它上升为共识算法。 全序关系广播还不完全等于 Zookeeper 的 zab 广播，因为它允许异步复制模型（zab 不允许）。 使用全序广播实现线性一致性存储可以通过将全序广播当成仅追加日志的方式来实现这种线性一致的CAS操作： 在日志中追加一条消息，试探性地指明你要声明的用户名。 读日志，广播它们，等待回复。 检查是否有任何消息声称目标用户名的所有权。如果这些消息中的第一条就你自己的消息，那么你就成功了：你可以提交声称的用户名（也许是通过向日志追加另一条消息）并向客户端确认。如果所需用户名的第一条消息来自其他用户（理论上如果在其他系统发生了状态冲突，必然发生一个冲突，所以这里实际上比对的不是第一条，而是唯一一条，类似 2PC 的 participant 投票中止），则中止操作。 全序广播可以实现顺序一致性（因为不同的节点同步完成的时间不一样），它可以实现写的线性化，不能实现写的线性化。 使用线性一致性存储实现全序广播可以用全序广播实现线性一致性存储（实现线性写），也可以反过来。 最简单的方法是假设你有一个线性一致的寄存器来存储一个整数，并且有一个原子自增并返回操作。或者原子CAS操作也可以完成这项工作。 该算法很简单：每个要通过全序广播发送的消息首先对线性一致寄存器执行自增并返回操作。然后将从寄存器获得的值作为序列号附加到消息中。然后你可以将消息发送到所有节点（重新发送任何丢失的消息），而收件人将按序列号连续发送消息。 这个算法的难点，就是如何正确地实现分布式场景下的原子 CAS。 构造一个全序广播 = 构造一个线性存储 = 共识问题，这是一个深刻的结论。 分布式事务与共识领导选举、原子提交（atomic commitment 也就是我们经常要解决的分布式事务问题）都需要解决共识问题。 FLP 不可能定律，假定我们不能使用超时检测机制或者时钟。如果我们可以使用超时，我们可以达到稳定共识。 原子提交与二阶段提交（2PC）2pc 也是一种共识算法。 从单节点到分布式原子提交原子提交可以防止系统状态被破坏，对于多对象事务修改二级索引（特别是基于词条的索引而不是基于文档的索引）特别重要。 事务提交必须是不可撤销的 —— 事务提交之后，你不能改变主意，并追溯性地中止事务。这个规则的原因是，一旦数据被提交，其结果就对其他事务可见，因此其他客户端可能会开始依赖这些数据。 提交事务的结果有可能通过事后执行另一个补偿事务来取消，但从数据库的角度来看，这是一个单独的事务，因此任何关于跨事务正确性的保证都是应用自己的问题。-引入 saga 模型。 两阶段提交 正常情况下，2PC事务以应用在多个数据库节点上读写数据开始。我们称这些数据库节点为参与者（participants）。当（经过一系列的预先的本地 write data，类似 MySQL 的更新内存页）应用准备提交时，协调者开始阶段 1 ：它发送一个准备（prepare）请求到每个节点，询问它们是否能够提交。然后协调者会跟踪参与者的响应： 如果所有参与者都回答“是”，表示它们已经准备好提交，那么协调者在阶段 2 发出提交（commit）请求，然后提交真正发生。 如果任意一个参与者回复了“否”，则协调者在阶段2 中向所有节点发送中止（abort）请求。 系统的承诺 所有的本地事务依赖于一个全局的 txid。 所有的本地事务答应 commit 后，锁定资源，而且不会放弃事务（不可撤销）。 协调者做出决定后，要把决定写入 wal 中。这个时刻被称作提交点（commit point）。 一旦协调者的决定落盘，提交或放弃请求会发送给所有参与者。如果这个请求失败或超时，协调者必须永远保持重试，直到成功为止。没有回头路：如果已经做出决定，不管需要多少次重试它都必须被执行。如果参与者在此期间崩溃，事务将在其恢复后提交——由于参与者投了赞成，因此恢复后它不能拒绝提交。-尽最大努力通知，不可撤销。 单节点原子提交将这两个事件混为一谈：将提交记录写入事务日志。redo log 的 prepare 写 binlog 和 commit，这个最后一个 commit 等于两个不可撤销的操作合在一起。 协调者故障在第一阶段参与者故障会造成系统故障，在第二阶段协调者故障会造成系统阻塞。所以要尽快恢复协调者，依靠日志尽快让系统从阻塞中恢复。 三阶段提交作为2PC的替代方案，已经提出了一种称为三阶段提交（3PC）的算法。然而，3PC假定网络延迟有界，节点响应时间有限；在大多数具有无限网络延迟和进程暂停的实际系统中，它并不能保证原子性。 通常，非阻塞原子提交需要一个完美的故障检测器（perfect failure detector）。 实践中的分布式事务分布式事务性能不好，因为： 写文件系统 网络往返 可能存在的阻塞点 恰好一次的消息处理exactly-once 有两种方法： at-least-once + 幂等 分布式事务在异构系统（mq + db）中实现 副作用回滚 XA事务X/Open XA（扩展架构（eXtended Architecture）的缩写）是跨异构技术实现两阶段提交的标准。 XA不是一个网络协议——它只是一个用来与事务协调者连接的C API。其他语言也有这种API的绑定；例如在Java EE应用的世界中，XA事务是使用Java事务API（JTA, Java Transaction API）实现的，而许多使用Java数据库连接（JDBC, Java Database Connectivity）的数据库驱动，以及许多使用Java消息服务（JMS）API的消息代理都支持Java事务API（JTA）。 停顿时持有锁在全局提交以前，本地事务不会释放锁。如果要避免永久加锁，可能需要手工处理。 从协调者故障中恢复孤立（orphaned）的存疑事务确实会出现。 唯一的出路是让管理员手动决定提交还是回滚事务。管理员必须检查每个存疑事务的参与者，确定是否有任何参与者已经提交或中止，然后将相同的结果应用于其他参与者。解决这个问题潜在地需要大量的人力，并且可能发生在严重的生产中断期间（不然为什么协调者处于这种糟糕的状态），并很可能要在巨大精神压力和时间压力下完成。 许多XA的实现都有一个叫做启发式决策（heuristic decistions）的紧急逃生舱口：允许参与者单方面决定放弃或提交一个存疑事务，而无需协调者做出最终决定。要清楚的是，这里启发式是可能破坏原子性（probably breaking atomicity）的委婉说法，因为它违背了两阶段提交的系统承诺。 分布式事务的限制 协调者是系统的单点。 协调者不是无状态的。 xa 要兼容死锁的状态协议。 分布式事务有扩大失效（amplifying failures）的趋势，这又与我们构建容错系统的目标背道而驰。 容错共识一个或多个节点可以提议（propose）某些值，而共识算法决定（decides）采用其中的某个值。 共识里的节点是指进程。 一致同意（Uniform agreement）：没有两个节点的决定不同。 诚实性（Integrity）：没有节点决定两次，也不能反悔。比如 Raft 里的每个 candidate 做了投票以后，就要乖乖地做 follower。 有效性（Validity）：如果一个节点决定了值 v ，则 v 由某个节点所提议。 终止（Termination）：由所有未崩溃的节点来最终决定值。 其中 1、2、3 是 safety，4 是容错共识所必须有的 liveness。 如果你不关心容错，那么满足前三个属性很容易：你可以将一个节点硬编码为“独裁者”，并让该节点做出所有的决定。终止属性正式形成了容错的思想。它实质上说的是，一个共识算法不能简单地永远闲坐着等死 —— 换句话说，它必须取得进展。 共识的系统模型假设，当一个节点“崩溃”时，它会突然消失而且永远不会回来。在这个系统模型中，任何需要等待节点恢复的算法都不能满足终止属性。特别是，2PC不符合终止属性的要求。 ​ 当然如果所有的节点都崩溃了，没有一个在运行，那么所有算法都不可能决定任何事情。算法可以容忍的失效数量是有限的：事实上可以证明，任何共识算法都需要至少占总体多数（majority）的节点正确工作，以确保终止属性。 克服拜占庭故障，稳健地达成共识是可能的，只要少于三分之一的节点存在拜占庭故障（pow 算法不受此限制）。 共识算法与全序广播VSR、paxos、Raft 和 Zab。 这些算法的本质不是“先提议，再决定”，而是“先决定，然后做全序关系广播”。具体地，一个广播有多条消息，每条消息是按照相同的顺序发送到所有节点，有且只有一次。如果仔细想想，这其实相当于进行了多轮的共识过程：在每一轮，节点提出他们接下来想要的发送的消息，然后决定下一个消息的发送顺序（message 和 order 的顺序每轮变一次）。 全序广播持续的多轮共识（每一轮共识对应于一条消息）： 由于协商一致性：所有节点决定以相同的顺序发送相同的消息。 由于诚实性：消息不能重复（或出现反悔）。 由于合法性：消息不会被破坏，也不是凭空捏造的（所以不能防拜占庭错误）。 由于可中止性：消息不会丢失，liveness 一定会发生。 视图戳复制，Raft 和 Zab 直接实现了全序广播，因为这样做比重复一次一值（one value a time）的共识更高效。在 Paxos 的情况下，这种优化被称为Multi-Paxos。 主从复制与共识单纯的主从复制即“独裁类型的”，不可容错的共识算法，只使用了基本的全序广播。要制造 termination，就要求“总是能选出主节点”。 Epoch 和 Quorum目前这些共识协议都 定义了一个形式化的主节点，然后定义了一个时代编号（epoch number），对应于 Paxos 中的 ballot number，VSP 中的 view number，Raft 中的 term number，并且在每个世代里，主节点是唯一的。 term 是一个全局的 version，和 Lamport 时钟里的版本号类似，但又不太一样。出现 term 的算法，要假定算法要么有全局生成 term 的能力，要么有全局维护 term 递增的机制。 如果主节点失效，节点就开始投票选主节点，选举会赋予一个单调递增的 epoch 号。 如果存在两个互相冲突的主节点，则拥有高 epoch 的主节点会获胜。 主节点成立后，会进行两轮投票： 首先投票谁是主节点 对主节点的提议进行投票 这两轮投票来自于 quorum、quorum 之间要重叠，这样可以保证目前已知的 epoch 是最高的。 共识的局限性共识可以提供全序关系广播，以容错的方式实现线性化的原子操作。从另一个角度来讲，共识算法是带有容错能力（加上了选主投票）的 2 pc（2pc 自己就带着一个对 proposal 投票的机制，但 2pc 要求全票通过，共识算法只要求 quorum 投票通过）。 consensus = leader election + atomic/total order broadcast consensus 能够解决 cas 问题，则是 linearizability。 我们的 broadcast 可以采取异步的方式，也可以采取同步的方式（同步的方式可以得到 ballot）。 大多数共识算法不能动态添加或删除节点（参考 ES）。动态选举有些永远都处理不了的 corner case（会造成活锁问题）。 成员与协调服务Zookeeper 与 etcd 都可以保存少量的、可以载入内存的数据设计。 Zookeeper 可以提供如下特性： 线性一致性的原子操作（唯一需要共识算法的功能） 操作的全序排序 失效检测 变更通知 服务发现领域可以实现线性一致性，但不需要，因为它的性能负担大到不切实际的地步。 成员服务是“真理掌握在大多数人身上”的一个好例子，所以成员服务也可以使用 Zookeeper。 附带 Paxos 的一个简单流程 假设已经选择了单一主 proposer。 proposer 用 prepare 请求发出一个提案 n 给所有的 acceptor。 acceptor 如果已经 prepare 过了提案版本小于 n 的请求，则把自己得到的最高的(提案版本，v）返回给 proposer，从此不再 accept 版本小于 n 的请求；否则 acceptor 不再响应提案。 proposer 收到了足够多的响应，把最高的 v 加在 n 上，拼出一个 (n, v)的 accept 请求给所有的 acceptor。 所有的 acceptor 必须通过广播等机制把这一结果同步到所有的 learner 身上。 数据派生系统从数据记录系统产生数据，数据派生系统负责处理这些数据。 Unix 的哲学很重要： 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件，甚至是操作系统，要尽早尝试，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。 分布式数据处理的难点在于 join。 在没有背压的时候，内存缓冲区/blockingqueue 可以实现背压。"},{"title":"亿级订单架构设计","date":"2020-10-04T14:17:11.000Z","url":"/2020/10/04/%E4%BA%BF%E7%BA%A7%E8%AE%A2%E5%8D%95%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","tags":["系统架构"],"content":" 要做演练，发现问题。 要建立规范。 要有容错设计（对上下游）。 要建立梯队。 长期重要的事情要早投入。 单纯的拆可以提高系统容量，但也可以通过精简的思路来提高系统容量。 分布式 id：时间若干位-空间若干位（包含单元）-订单属性若干位-用户属性若干位。 平台型业务对于容量的理解不能只停留在扩容上。 带宽被打满，就要切机房。切换能力要依赖于服务治理的深度和广度。 "},{"title":"现代垃圾收集器","date":"2020-09-27T08:12:22.000Z","url":"/2020/09/27/%E7%8E%B0%E4%BB%A3%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","tags":["JVM","Java"],"content":"所有的垃圾收集器，都基于弱分代假设。实际的垃圾回收效率取决于堆内对象的分布状况。垃圾回收并不能解决内存泄漏或者应用程序逻辑的不良分配习惯问题，要处理 JVM 内存回收问题的根本方法是对程序进行调优。 有几个常用原则： 减少临时对象，尽量复用内存。 使用对象池。 主动提前释放对象。 主动 gc。 好的代码比 tuning 更重要。 选 gc 算法比 tuning 参数重要，tuning 参数是最后一步。 其他情况，可以通过 tuning garbage collector 来解决。 操作系统的影响 SWAP 可能会显著增加 GC 时间，因为被换出的堆还要被换入。 美团的实践参考： 《从实际案例聊聊Java应用的GC优化》 《Java中9种常见的CMS GC问题分析与解决》 Minor GC Major GC Full GC 垃圾收集器分类 可以看到一个现象：在大部分时候，g1 比 cms 快，但极端的百分位里，cms比 g1 快。 常用工具命令行终端 标准终端类：jps、jinfo、jstat、jstack、jmap 功能整合类：jcmd、vjtools、arthas、greys 可视化界面 简易：JConsole、JVisualvm、HA、GCHisto、GCViewer 进阶：MAT、JProfiler 命令行推荐 arthas ，可视化界面推荐 JProfiler，此外还有一些在线的平台 gceasy、heaphero、fastthread，美团内部的 Scalpel（一款自研的 JVM 问题诊断工具，暂时未开源）也比较好用。 指标评价标准评判 GC 的两个核心指标： 延迟（Latency）： 也可以理解为最大停顿时间，即垃圾收集过程中一次 STW 的最长时间，越短越好，一定程度上可以接受频次的增大，GC 技术的主要发展方向。 吞吐量（Throughput）： 应用系统的生命周期内，由于 GC 线程会占用 Mutator 当前可用的 CPU 时钟周期，吞吐量即为 Mutator 有效花费的时间占系统总运行时间的百分比，例如系统运行了 100 min，GC 耗时 1 min，则系统吞吐量为 99%，吞吐量优先的收集器可以接受较长的停顿。 简而言之，即为一次停顿的时间不超过应用服务的 TP9999，GC 的吞吐量不小于 99.99%。举个例子，假设某个服务 A 的 TP9999为 80 ms，平均 GC 停顿为 30 ms，那么该服务的最大停顿时间最好不要超过 80 ms，GC 频次控制在 5 min以上一次。如果满足不了，那就需要调优或者通过更多资源来进行并联冗余。（大家可以先停下来，看看监控平台上面的 gc.meantime分钟级别指标，如果超过了 6 ms 那单机 GC 吞吐量就达不到 4 个 9 了。） gc 动作耗时比较容易被忽略的是： 所以年轻代的扫描如果大头是 copying 就会非常快。 Mutator 类型 Mutator 的类型根据对象存活时间比例图来看主要分为两种，在弱分代假说中也提到类似的说法，如下图所示 “Survival Time”表示对象存活时间，“Rate” 表示对象分配比例： IO 交互型： 互联网上目前大部分的服务都属于该类型，例如分布式 RPC、MQ、HTTP 网关服务等，对内存要求并不大，大部分对象在 TP9999 的时间内都会死亡， Young 区越大越好。 MEM 计算型： 主要是分布式数据计算 Hadoop，分布式存储 HBase、Cassandra，自建的分布式缓存等，对内存要求高，对象存活时间长，Old 区越大越好。 值得注意的是，中间件都是 IO 密集型应用，只要调大 young 区就可以解决问题，大部分的 young 区的收集器效果差异不大，Hadoop之类的业务反而需要 CMS/G1的调优。 已提交的内存 注意看，已使用内存对 JVM而言就是 committed memory。The committed memory is a sum of all of the memory which has been allocated by processes, even if it has not been “used” by them as of yet. 我们可以把动态扩容引起的空间震荡称作 thrash caused by heap expansion。 关于-XX:+DisableExplicitGC的争论 此处补充一个知识点，CMS GC 共分为 Background 和 Foreground两种模式，前者就是我们常规理解中的并发收集，可以不影响正常的业务线程运行，但 Foreground Collector却有很大的差异，他会进行一次压缩式 GC。此压缩式 GC 使用的是跟 Serial Old GC 一样的 Lisp2 算法，其使用Mark-Compact 来做 Full GC，一般称之为 MSC（Mark-Sweep-Compact），它收集的范围是 Java 堆的Young 区和 Old 区以及 MetaSpace。由上面的算法章节中我们知道 compact 的代价是巨大的，那么使用Foreground Collector 时将会带来非常长的 STW。如果在应用程序中 System.gc 被频繁调用，那就非常危险了。 这里提到的 Foreground 可以被System.gc显式触发MSC（Mark-Sweep-Compact）导致。 但值得注意的是： 目前互联网中的 RPC 通信会大量使用 NIO 这也就意味着堆外内存的收集有时候是必须的-因为 NIO内部自己触发垃圾收集也需要引用 System.gc 的能力。不过要配合XX:+ExplicitGCInvokesConcurrent、-Dsun.rmi.dgc.client.gcInterval、-Dsun.rmi.dgc.server.gcInterval一起使用。 值得关注的资料有： 《JVM源码分析之堆外内存完全解读》 如何追踪新 load classjcmd &lt;PID&gt; GC.class_stats|awk &#39;&#123;print$13&#125;&#39;|sed &#39;s/\\(.*\\)\\.\\(.*\\)/\\1/g&#39;|sort |uniq -c|sort -nrk1 如果有必要，使用-XX:+TraceClassLoading和-XX:+TraceClassUnLoading 过早晋升一个容易被忽略的过早晋升的原因是，分配速率接近于晋升速率，对象晋升年龄较小。通常产生这个问题的根因是 young 区过小。如果一次 Major GC 后 tenured 或者 humongous 的区域大规模减少，则其实老年代里的对象大部分都是过早晋升的对象。注意：MaxTenuringThreshold 最大值为 15（因为 JVM 中使用 4 个比特来表示对象的年龄）。 分析内存泄漏的基本思路 两次 dump，diff 顽固分子。不过捕捉 gc 前后的堆非常困难。 频繁 Major GC 或者 Major GC 时间过长，通常指向程序内存泄漏或者空间过小-程序内存泄漏触发的频繁 ygc 可能会让它提前晋升了。 CMS 退化MSC 的出现就意味着真正意义上的 Full GC 出现了，这种时候我们的要调优 CMS 的执行频率，让高水位的 GC 问题通过 GC 前置来解决。 堆外内存泄漏 内存使用率不断上升，甚至开始使用 SWAP 内存，同时可能出现 GC 时间飙升，线程被 Block 等现象，通过 top 命令发现 Java进程的 RES 甚至超过了 -Xmx 的大小。出现这些现象时，基本可以确定是出现了堆外内存泄漏。 也就是说堆外内存的数据除了 NMT 来确定，也可以通过 RES 来确定。 首先，我们需要确定是哪种原因导致的堆外内存泄漏。这里可以使用 NMT（NativeMemoryTracking） 进行分析。在项目中添加-XX:NativeMemoryTracking=detail JVM参数后重启项目（需要注意的是，打开 NMT 会带来 5%~10% 的性能损耗）。使用命令 jcmd pid VM.native_memory detail 查看内存分布。重点观察 total 中的committed，因为 jcmd 命令显示的内存包含堆内内存、Code 区域、通过 Unsafe.allocateMemory 和DirectByteBuffer 申请的内存，但是不包含其他 Native Code（C 代码）申请的堆外内存。 如果 total 中的 committed 和 top 中的 RES相差不大，则应为主动申请的堆外内存未释放造成的，如果相差较大，则基本可以确定是 JNI 调用造成的。 整体而言，堆外内存的分布是不透明的，目前没有工具可以简单地告诉我们全部的堆外内存的分布情况，只能间接推算出问题的根因，转而去代码里寻找原因。 GCLocker Initiated GC 由于 Native 代码直接使用了 JVM 堆区的指针，如果这时发生 GC，就会导致数据错误。因此，在发生此类 JNI 调用时，禁止 GC的发生，同时阻止其他线程进入 JNI 临界区，直到最后一个线程退出临界区时触发一次 GC。 添加 -XX+PrintJNIGCStalls 参数，可以打印出发生 JNI 调用时的线程，进一步分析，找到引发问题的 JNI 调用。 GC 调优的三大思路（解决这些问题的 ROI 从高到低）： 代码问题 区域配置问题 垃圾回收行为问题 根因鱼骨图 其他建议 主动式 GC： 也有另开生面的做法，通过监控手段监控观测 Old 区的使用情况，即将到达阈值时将应用服务摘掉流量，手动触发一次 Major GC，减少 CMS GC 带来的停顿，但随之系统的健壮性也会减少，如非必要不建议引入。 禁用偏向锁： 偏向锁在只有一个线程使用到该锁的时候效率很高，但是在竞争激烈情况会升级成轻量级锁，此时就需要先消除偏向锁，这个过程是 STW 的。如果每个同步资源都走这个升级过程，开销会非常大，所以在已知并发激烈的前提下，一般会禁用偏向锁 XX:-UseBiasedLocking 来提高性能。 虚拟内存： 启动初期有些操作系统（例如 Linux）并没有真正分配物理内存给 JVM ，而是在虚拟内存中分配，使用的时候才会在物理内存中分配内存页，这样也会导致 GC 时间较长。这种情况可以添加 XX:+AlwaysPreTouch 参数，让 VM 在 commit 内存时跑个循环来强制保证申请的内存真的 commit，避免运行时触发缺页异常。在一些大内存的场景下，有时候能将前几次的 GC时间降一个数量级，但是添加这个参数后，启动的过程可能会变慢。 所以 AlwaysPreTouch 会让 reserved 内存变成 committed内存。 JVM 启动参数 分类 参数 作用 基本参数 -XX:+PrintGCDetails、-XX:+PrintGCDateStamps、-XX:+PrintGCTimeStamps GC 日志的基本参数 时间相关 -XX:+PrintGCApplicationConcurrentTime、-XX:+PrintGCApplicationStoppedTime 详细步骤的并行时间，STW 时间等等 年龄相关 -XX:+PrintTenuringDistribution 可以观察 GC 前后的对象年龄分布，方便发现过早晋升问题 引用相关 -XX:+PrintReferenceGC 观察系统的软引用，弱引用，虚引用等回收情况 空间变化 -XX:+PrintHeapAtGC 各个空间在 GC 前后的回收情况，非常详细 老的配比公式 空间 倍数 总大小 3-4 倍活跃数据的大小 新生代 1-1.5 活跃数据的大小 老年代 2-3 倍活跃数据的大小 永久代 1.2-1.5 倍Full GC后的永久代空间占用 例如，根据GC日志获得老年代的活跃数据大小为300M，那么各分区大小可以设为：先计算新生代的大小，再反推其他堆的大小。 总堆：1200MB = 300MB × 4* 新生代：450MB = 300MB × 1.5* 老年代： 750MB = 1200MB - 450MB* GC 对业务的影响 明确应用程序的系统需求是性能优化的基础，系统的需求是指应用程序运行时某方面的要求，譬如： 高可用，可用性达到几个9。 低延迟，请求必须多少毫秒内完成响应。 高吞吐，每秒完成多少次事务。 明确系统需求之所以重要，是因为上述性能指标间可能冲突。比如通常情况下，缩小延迟的代价是降低吞吐量或者消耗更多的内存或者两者同时发生。 延迟和吞吐量和内存占用中存在一个不可能三角形。 举例：假设单位时间T内发生一次持续25ms的GC，接口平均响应时间为50ms，且请求均匀到达，根据下图所示： ![gc 时间线](gc 时间线.png) 那么有(50ms+25ms)/T比例的请求会受GC影响，其中GC前的50ms内到达的请求都会增加25ms，GC期间的25ms内到达的请求，会增加0-25ms不等，如果时间T内发生N次GC，受GC影响请求占比=(接口响应时间+GC时间)×N/T。可见无论降低单次GC时间还是降低GC次数N都可以有效减少GC对响应时间的影响。 为什么接口响应时间内的请求受影响呢，因为 50ms 的请求都没有走完自己的生命周期，就被停顿。 案例案例1 Minor GC每分钟100次 ，Major GC每4分钟一次，单次Minor GC耗时25ms，单次MajorGC耗时200ms，接口响应时间50ms。 （50ms+25ms）× 100次/60000ms = 12.5%，50ms × 100次/60000ms = 8.3% 。 按照通常的观点，每分钟 100 次 Minor GC 是很频繁的，这也意味着 Eden 区过小。 更重要的是对于虚拟机来说，复制对象的成本要远高于扫描成本 这句话存疑，从现代的 gc 日志来看，单纯 scan 的时间非常久，copy 的时间非常短。 这个案例的意思是： 如果新生代临时对象非常多，而新生代非常小，则对象晋升非常快，既会导致频繁的 Minor GC，也会导致频繁的 Major GC。所以足够大的 young 区会总体降低 gc 的频次，而不会显著提升单次 Minor GC 的时间。 案例2cms 的 remark 不能只扫描老年代，只能全堆扫描（新生代+老年代）。由此可见堆中对象的数目影响了Remark阶段耗时。remark 的时间久意味着新生代的使用率比较高（反过来也一样），而触发了较多的跨代引用（注意，remark 是 MajorGC cms 的一个阶段）。remark 存在的意义就是正确地校正浮动垃圾的影响。这种类似活锁的问题在两类线程并发时是难以彻底解决的。 降低Remark阶段耗时问题转换成如何减少新生代对象数量。 新生代GC和老年代的GC是各自分开独立进行的，只有 Minor GC 时才会使用根搜索算法 这句话存疑，至少对 g1 而言，根搜索算法是不局限于年轻代的。 可以使用 CMSScavengeBeforeRemark 配合 CMSMaxAbortablePrecleanTime 参数，强制在 remark 之前进行 preclean（也就是一次隐藏的 Minor GC），可以减少 Remark 的耗时（这样可以减少跨代引用扫描的时间）。因为这个隐藏的 preclean存在，并发标记也并不一定是纯并发的。 新生代持有老年代多是正常的，老年代持有新生代的比例不足 1%，所以只要使用一个抽象的卡表来代表老年代的 dirty 情况，就可以用空间换时间，而避免 Minor GC 的问题。 案例3 首先，什么时候可能会触发STW的Full GC呢？ Perm空间不足； CMS GC时出现promotion failed和concurrent mode failure（concurrent mode failure发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再被使用的对象，这时停止所有的线程，同时终止CMS，直接进行SerialOld GC）； 统计得到的Young GC晋升到老年代的平均大小大于老年代的剩余空间； 主动触发Full GC（执行jmap -histo:live [pid]）来避免碎片问题。 解决方法： Perm 区不要扩容，一开始就锁定资源。 使用 CMSPermGenSweepingEnabled、CMSClassUnloadingEnabled-这要求有动态类可以被回收，如果大量的类不是可回收的动态类，那么方案 1 才有用。 CMSCMS 的垃圾收集器默认在新生代就使用 ParNew，ParNew 天然是个 STW 收集器。 ParNew 使用标记-复制算法。标记-复制算法可以分为三个阶段： 标记阶段，即从GC Roots集合开始，标记活跃对象； 转移阶段，即把活跃对象复制到新的内存地址上； 重定位阶段，因为转移导致对象的地址发生了变化，在重定位阶段，所有指向对象旧地址的指针都要调整到对象新的地址上。 CMS 是个并发收集器。其操作步骤包括： 初始标记 并发标记 再标记 并发收集 CMS 将在 Java 14 中被 removed 掉。 ParallelGCThreads 可以和 ParNew，Parallel Scavenge 一起工作，却不能改变 CMS 的线程数。 Parallel Scavenge 与 G1都可以设置停顿时间目标（都是 MaxGCPauseMillis，不过 PS 是 young 区收集器，G1 是全区收集器，PS 有个 PS old，算是 parallel 化的 serial），CMS 却偏偏没有。 G1老的垃圾收集器总是面临几个问题： 所有针对老年代的操作必须扫描整个老年代空间； 年轻代和老年代是独立的连续的内存块，必须先决定年轻代和老年代在虚拟地址空间的位置。 G1是一种服务端应用使用的垃圾收集器，目标是用在多核、大内存的机器上，它在大多数情况下可以实现指定的GC暂停时间（因为它引入了更好的停顿预测模型），同时还能保持较高的吞吐量。 G1的缺点是：停顿预测模型还不够智能-即使使用了 pre-write barrier 和 post-write barrier。 并发标记的准确度不够高，所以需要重标记，甚至依然有 concurrent mode 失败的场景。 G1 在发生垃圾回收的前后，各种 region 的配比会变化，比如：Eden: 3072.0K(194.0M)-&gt;0.0B(201.0M) 显示垃圾回收后，有 7mb 的 region 增加给了 eden 区。如果不指定 region，则 G1 会根据实际可用的机器内存大小来决定 region，尽量达到 2048 region。 这种调整 young 区、tenure 区的行为会在 mixedgc 或者冷启动的时候发生得很剧烈，会造成一波 stw 的小高潮，这在有高峰时段的服务上小心谨慎。 G1 phases其中： 蓝色 Young-only 黄色 标记过程的停顿 红色 Mixed gc 停顿 G1 region 关于 gc 日志可以参考《Understanding G1 GC Log Format》。 在 jvm 里，minor gc 是一种 minor gc event。 查看 gc 日志的命令 minor gc 的日志 发生在年轻代的GC算法，一般对象（除了巨型对象）都是在eden region中分配内存，当所有edenregion被耗尽无法申请内存时，就会触发一次young gc，这种触发机制和之前的young gc差不多，执行完一次younggc，活跃对象会被拷贝到survivor region或者晋升到oldregion中，空闲的region会被放入空闲列表中，等待下次被使用。 ParallelTime 到 Eden 就是 PrintGCDetails 的结果。 一般 8 核的 cpu，就会产生 8 个并行 gc worker 线程。 从这个图我们也可以看出，如果让 g1 自己选择 region 里面新老分布的比例的话，（通常）young 会多小（在一个 4g 的堆上，可能只有 200m 的年轻代），g1 的年轻代往往会有一个自动扩容的过程。如果 gc 时间不到 10ms，real 都显示不出来。 global concurrent marking 的日志InitiatingHeapOccupancyPercent 到了是最容易触发触发并发收集的。 Percentage of the (entire) heap occupancy to start a concurrent GC cycle. GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap and not just one of the generations, including G1, use this option. A value of 0 denotes ‘do constant GC cycles’. The default value is 45. 但实际上我们在实践中发现，8g 的堆，y 区到了 4g 的满状态，也只是触发 ygc，而不是 mixed gc。 现实中的 Concurrent Cycles 往往会执行一轮又一轮，直到内存空间的比例降到足够低的水位为止。 搜索 GC pause 可以看到各种各样的 gc 停顿。要找混合垃圾回收直接搜“mixed GCs”或者“(G1 Evacuation Pause) (mixed)”。 实际上 mixed 的 phase 之间的顺序是：young -&gt; initial mark -&gt; concurrent mark 的其他阶段 + clean up -&gt; young -&gt; mixed gc。其中 initial mark 的时间最久，整体来讲也是 stw 的。concurrent clean up 的 stw 一般不会被 jmx 工具统计到，但它的时间非常长，而且混合了并发和 stw 的事件。 一般的 gc 日志的顺序是“[GC pause (G1 Evacuation Pause) (young)” -&gt; “concurrent-root-region-scan-start” -&gt; “Concurrent Cycles” -&gt; “ [GC pause (G1 Evacuation Pause) (young)” -&gt; “[G1Ergonomics (Mixed GCs) start mixed GCs” -&gt;“(G1 Evacuation Pause) (mixed)”（这一步会循环执行）。 每次 gc 开始时，Heap before GC invocations=15872 (full 0)，其中invocations=15872是自JVM启动以来，执行GC的次数。每一次 initial-mark，这个值就会加 1。 可中断的 mixedgc 一旦收集器确定了 GC 回收集 并且 GC 回收、整理工作已经开始，这个过程是without stopping的，即 G1收集器必须完成收集集合的所有区域中的所有活动对象之后才能停止；但是如果收集器选择过大的 GC回收集，此时的STW时间会过长超出目标pause time。 这种情况在mixed collections时候比较明显。这个特性启动了一个机制，当选择了一个比较大的collectionset，Java12 中将把 GC 回收集（混合收集集合）拆分为mandatory（必需或强制）及optional两部分(当完mandatory的部分，如果还有剩余时间则会去处理optional部分)来将mixed collections从withoutstopping变为abortable，以更好满足指定pause time的目标。 其中必需处理的部分包括 G1 垃圾收集器不能递增处理的 GC 回收集的部分（如：年轻代），同时也可以包含老年代以提高处理效率。 将 GC 回收集拆分为必需和可选部分时，垃圾收集过程优先处理必需部分。同时，需要为可选 GC 回收集部分维护一些其他数据，这会产生轻微的CPU 开销，但小于 1 ％的变化，同时在 G1 回收器处理 GC 回收集期间，本机内存使用率也可能会增加，使用上述情况只适用于包含可选GC 回收部分的 GC 混合回收集合。 参考： 《Java12新特性 – 可中断的 G1 Mixed GC》 full gcFull GC (Allocation Failure) 是最常见的 fgc 的原因。 常用的 jvm 配置 另外： G1MixedGCLiveThresholdPercent：每个 region 里 live 对象到达多少的时候可以进入 CSet。 XX:G1MixedGCCountTarget=8 能够决定 mixed gc 的轮数。 参考： 《G1从入门到放弃》 《可能是最全面的G1学习笔记》 g1 的 gc 日志可以看《Understanding G1 GC Logs》。 《Java Hotspot G1 GC的一些关键技术》 ZGCzgc 是 java11 推出的垃圾收集器，在 java16 中做到了 max pause 1ms。它基本基于 Azul 的 pauseless gc 和 c4，做到了它们的早期方案，但不支持分代收集。zgc 在 allocation rate 高的时候的 tuning 手段就是加大堆。 ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器，它的设计目标包括： 停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB级别的堆（未来支持16TB）。 与CMS中的ParNew和G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因。 ![zgc 过程.png](zgc 过程.png) ZGC只有三个STW阶段：初始标记，再标记，初始转移。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GCRoots的数量成正比，一般情况耗时非常短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GCRoots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。下面介绍着色指针和读屏障技术细节。 着色指针![zgc 的 64 位地址空间.png](zgc 的 64 位地址空间.png) 其中，[0~4TB) 对应Java堆，[4TB ~ 8TB) 称为M0地址空间，[8TB ~ 12TB) 称为M1地址空间，[12TB ~16TB) 预留未使用，[16TB ~ 20TB) 称为Remapped空间。 当应用程序创建对象时，首先在堆空间申请一个虚拟地址，但该虚拟地址并不会映射到真正的物理地址。ZGC同时会为该对象在M0、M1和Remapped地址空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址，但这三个空间在同一时间有且只有一个空间有效。ZGC之所以设置三个虚拟地址空间，是因为它使用“空间换时间”思想，去降低GC停顿时间。“空间换时间”中的空间是虚拟空间，而不是真正的物理空间。后续章节将详细介绍这三个空间的切换过程。 与上述地址空间划分相对应，ZGC实际仅使用64位地址空间的第041位，而第4245位存储元数据，第47~63位固定为0。 ZGC将对象存活信息存储在42~45位中，这与传统的垃圾回收并将对象存活信息放在对象头中完全不同。 读屏障 读屏障是JVM向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。需要注意的是，仅“从堆中读取对象引用”才会触发这段代码。 ZGC中读屏障的代码作用：在对象标记和转移过程中，用于确定对象的引用地址是否满足条件，并作出相应动作。 ZGC并发处理演示 接下来详细介绍ZGC一次垃圾回收周期中地址视图的切换过程： 初始化：ZGC初始化之后，整个内存空间的地址视图被设置为Remapped。程序正常运行，在内存中分配对象，满足一定条件后垃圾回收启动，此时进入标记阶段。 并发标记阶段：第一次进入标记阶段时视图为M0，如果对象被GC标记线程或者应用线程访问过，那么就将对象的地址视图从Remapped调整为M0。所以，在标记阶段结束之后，对象的地址要么是M0视图，要么是Remapped。如果对象的地址是M0视图，那么说明对象是活跃的；如果对象的地址是Remapped视图，说明对象是不活跃的。 并发转移阶段：标记结束后就进入转移阶段，此时地址视图再次被设置为Remapped。如果对象被GC转移线程或者应用线程访问过，那么就将对象的地址视图从M0调整为Remapped。 其实，在标记阶段存在两个地址视图M0和M1，上面的过程显示只用了一个地址视图。之所以设计成两个，是为了区别前一次标记和当前标记。也即，第二次进入并发标记阶段后，地址视图调整为M1，而非M0。 着色指针和读屏障技术不仅应用在并发转移阶段，还应用在并发标记阶段：将对象设置为已标记，传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在ZGC中，只需要设置指针地址的第42~45位即可，并且因为是寄存器访问，所以速度比访问内存更快。 注意可能会有多轮并发标记。 ![zgc 并发标记示范.png](zgc 并发标记示范.png) 这个图里的 0 和 1 属于同一个内存页面，因为 0 是活跃对象，所以 0 被转移出来，而 1 和整个页面都被回收了。 并发标记和并发转移是对称操作，从对象的稳定状态都应该是 remmaped 态。 常用的 jvm 配置 -Xms -Xmx：堆的最大内存和最小内存，这里都设置为10G，程序的堆内存将保持10G不变。 -XX:ReservedCodeCacheSize -XX:InitialCodeCacheSize：设置CodeCache的大小， JIT编译的代码都放在CodeCache中，一般服务64m或128m就已经足够。我们的服务因为有一定特殊性，所以设置的较大，后面会详细介绍。-XX:+UnlockExperimentalVMOptions -XX:+UseZGC：启用ZGC的配置。 -XX:ConcGCThreads：并发回收垃圾的线程。默认是总核数的12.5%，8核CPU默认是1。调大后GC变快，但会占用程序运行时的CPU资源，吞吐会受到影响。-XX:ParallelGCThreads：STW阶段使用线程数，默认是总核数的60%。 -XX:ZCollectionInterval：ZGC发生的最小时间间隔，单位秒。 -XX:ZAllocationSpikeTolerance：ZGC触发自适应算法的修正系数，默认2，数值越大，越早的触发ZGC。 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive：是否启用主动回收，默认开启，这里的配置表示关闭。 -Xlog：设置GC日志中的内容、格式、位置以及每个日志的大小。 理解ZGC触发时机相比于CMS和G1的GC触发机制，ZGC的GC触发机制有很大不同。ZGC的核心特点是并发，GC过程中一直有新的对象产生。如何保证在GC完成之前，新产生的对象不会将堆占满，是ZGC参数调优的第一大目标。因为在ZGC中，当垃圾来不及回收将堆占满时，会导致正在运行的线程停顿，持续时间可能长达秒级之久。 ZGC有多种GC触发机制，总结如下： 阻塞内存分配请求触发：当垃圾来不及回收，垃圾将堆占满时，会导致部分线程阻塞。我们应当避免出现这种触发方式。日志中关键字是“Allocation Stall”。 基于分配速率的自适应算法：最主要的GC触发方式，其算法原理可简单描述为”ZGC根据近期的对象分配速率以及GC时间，计算出当内存占用达到什么阈值时触发下一次GC”。自适应算法的详细理论可参考彭成寒《新一代垃圾回收器ZGC设计与实现》一书中的内容。通过ZAllocationSpikeTolerance参数控制阈值大小，该参数默认2，数值越大，越早的触发GC。我们通过调整此参数解决了一些问题。日志中关键字是“Allocation Rate”。 基于固定时间间隔：通过ZCollectionInterval控制，适合应对突增流量场景。流量平稳变化时，自适应算法可能在堆使用率达到95%以上才触发GC。流量突增时，自适应算法触发的时机可能会过晚，导致部分线程阻塞。我们通过调整此参数解决流量突增场景的问题，比如定时活动、秒杀等场景。日志中关键字是“Timer”。 主动触发规则：类似于固定间隔规则，但时间间隔不固定，是ZGC自行算出来的时机，我们的服务因为已经加了基于固定时间间隔的触发机制，所以通过-ZProactive参数将该功能关闭，以免GC频繁，影响服务可用性。 日志中关键字是“Proactive”。 预热规则：服务刚启动时出现，一般不需要关注。日志中关键字是“Warmup”。 外部触发：代码中显式调用System.gc()触发。日志中关键字是“System.gc()”。 元数据分配触发：元数据区不足时导致，一般不需要关注。 日志中关键字是“Metadata GC Threshold”。 理解ZGC日志 一次完整的GC过程，需要注意的点已在图中标出。 ![zgc 日志举例.png](zgc 日志举例.png) 注意：该日志过滤了进入安全点的信息。正常情况，在一次GC过程中还穿插着进入安全点的操作。 GC日志中每一行都注明了GC过程中的信息，关键信息如下： Start：开始GC，并标明的GC触发的原因。上图中触发原因是自适应算法。 Phase-Pause Mark Start：初始标记，会STW。 Phase-Pause Mark End：再次标记，会STW。 Phase-Pause Relocate Start：初始转移，会STW。 Heap 信息：记录了GC过程中Mark、Relocate前后的堆大小变化状况。High和Low记录了其中的最大值和最小值，我们一般关注High中Used的值，如果达到100%，在GC过程中一定存在内存分配不足的情况，需要调整GC的触发时机，更早或者更快地进行GC。 GC 信息统计：可以定时的打印垃圾收集信息，观察10秒内、10分钟内、10个小时内，从启动到现在的所有统计信息。利用这些统计信息，可以排查定位一些异常点。 !(zgc-日志举例 2.png)[zgc-日志举例 2.png] 理解 ZGC 停顿原因 GC时，初始标记：日志中Pause Mark Start。 GC时，再标记：日志中Pause Mark End。 GC时，初始转移：日志中Pause Relocate Start。 内存分配阻塞：当内存不足时线程会阻塞等待GC完成，关键字是”Allocation Stall”。 安全点：所有线程进入到安全点后才能进行GC，ZGC定期进入安全点判断是否需要GC。先进入安全点的线程需要等待后进入安全点的线程直到所有线程挂起。 dump线程、内存：比如jstack、jmap命令。 这 6 种 STW，在其他垃圾收集器里也是很常见的。 ShenandoahRedHat 的分代收集器，只有 Openjdk 才有。 总结[Garbage Collector.xmind](Garbage Collector.xmind) ![Garbage Collector.png](Garbage Collector.png) 关于 cms 和 g1 的深入讨论，参考这个帖子。 调优经验在现代系统中，系统进入峰值时，峰值效应明显，要针对 peak server workloads 做好准备。 通常 ygc 始终是全 stw 的，fullgc 也不可避免的有好几个 stw 阶段。 指定堆的大小是为了保证垃圾回收的可预测性，也能进而保证堆扩展（heap expansion）不出错-在混布（mixed deployment）时保障资源有界。 指定最大停顿时间则意味着我们要指定系统在 high probability（90%的情况下）应该达到的一个软实时目标。PS 和 G1 都支持这种调优策略，而且能够自动适应调整堆内部大小。PS 是吞吐量收集器，G1 是 regionalized, parallel-concurrent, incremental garbage collector。PS 和 G1 的低延迟垃圾收集器。cms 可以被认为是一个并发收集器，而 g1 的 ygc 和 mixedgc 可以被认为都是 stw 的- mixed gc 的并发标记阶段是可以并发执行的。 对于有并发阶段存在的垃圾收集器而言，InitiatingHeapOccupancyPercent（全堆）/CMSInitiatingOccupancyFraction（老年代，需配合 CMSInitiatingOccupancyOnly 使用，否则只生效一次 ）等阈值保证了系统可以提前触发回收，这样可以保证并发收集留有余地，不至于有并发模式失败。 如果配置了-XX:MetaspaceSize，那么触发FGC的阈值就是配置的值；MaxMetaspaceSize 指的是元空间最大的大小-如果不设置则为无限大。参考《JVM参数MetaspaceSize的误解》。 gc 日志中的 Allocation Failure 可能代表 y 区内存分配失败，也可能代表 old 区内存分配失败。实际上，内存分配失败、回收后空间水位过高、经常越过高水位，都是持续发生 gc 的元凶，它们通常都由 gc 不友好、内存泄漏的代码导致。 ygc 有意想不到的直接晋升到 old 区的几种可能，所以 old 区通常要设计得比 y 区大：ygc 剩余垃圾大于 eden，触发担保机制；大对象；动态年龄判断。如果 old 区很稳定，可以证明应用的对象朝生夕死分布得很好。单纯的年龄阈值并不一定能够适应复杂的 ygc 的年龄分布，所以 MaxTenuringThreshold 会和 TargetSurvivorRatio 一起使用，如果 ygc 的结果超出了 desired_survivor_size，也会触发老年代晋升。 看待 gc 时间需要客观：ygc 的时间总是会造成 stw 的停顿。如果设定了很小的 gc 时间目标，则 jvm 可能很保守地制造小堆，进而在数据密集型应用上触发频繁的垃圾回收，进而是总的停顿时间变大。有时候稍微大的堆（在 8g 机器上使用 2-4g 的年轻代）或者稍微大的停顿时间目标 100 ms 可以解决我们的问题。否则，我们只能通过压测，不断调节年轻代的大小来解决我们的问题。 一般一个 mixed gc 一天才出现一次，算是比较健康的。但使用自适应策略导致冷启动和 mixed gc 以后堆布局的重建容易出现多轮回收的问题（多的时候会有 20 几轮 ygc 才能把 young 区的数量建设到比较稳定的状态），比较麻烦。当然，一般情况下，gc 对于 tp999、tp9999 的抬升效应并没有那么明显，有很多其他因素会导致我们的 rt 出现明显抬升。 垃圾调优一定要解决确定存在的问题-而不能解决不存在的问题。如果需要调优 cpu，则注意垃圾收集器、标记线程、回收线程和垃圾回收的频次。调优年轻代的时候是有代价的：更大的年轻代意味着更低的回收频率（这通常会优化次数相关的告警），但会带来更大的 ygc meantime，也意味着进入老年代的时间更缓慢，但老年代的大小会变小，可能又会导致老年代的 fgc（这又取决于老年代是不是稳定的）。 cms/g1 都使用了三色标记算法，白色（未被扫描）、灰色（field 未被扫描）、黑色（已全被扫描）三种对象里面，灰色对象和白色对象的引用交替增删，可能造成部分白色对象不被回收，这就是这类垃圾收集器的浮动垃圾的根源。 card 和 rset 本身都是帮助 gc 的过程工具，一个 point-out，一个 point-in。都是用空间换时间。g1 的停顿预测模型是以衰减标准偏差为理论基础。扫描 dirty_card 的时间，会占据预测停顿时间的一部分。 C4（Continuous Concurrently Compacting Collection）待续 参考： 《新一代垃圾回收器ZGC的探索与实践》 《【译】深入理解G1的GC日志（一）》 "},{"title":"MySQL 的配置","date":"2020-09-14T15:15:54.000Z","url":"/2020/09/14/MySQL-%E7%9A%84%E9%85%8D%E7%BD%AE/","tags":["数据库","MySQL"],"content":""},{"title":"异地多活与单元化","date":"2020-09-02T13:55:50.000Z","url":"/2020/09/02/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E4%B8%8E%E5%8D%95%E5%85%83%E5%8C%96/","tags":["系统架构","单元化"],"content":"背景介绍名词解释ldc logical data centeridc internet data center ldc 是 idc 的进化版，是一种单元化部署方案。 扩展模式 vs 镜像模式扩展模式是把服务/数据库分拆，然后部署到不同的机房里面，相当于放大了一个物理机房。 镜像模式是每个机房里部署的服务都是一样的，每个机房承担一定流量。 镜像模式的容灾效果更好，难度在如何切分流量上。容灾还要考虑机房级容灾、部署地容灾的问题。多地部署带来距离，距离带来延时，延时带来 replica 的风险。 单元化部署所谓 cell，是一个能完成所有业务操作的自包含集合（每个单元，都是其他单元的镜像）。一般的 soa 架构，服务是分层的，而且每一层的任一节点都可以被其他机房调用。而单元化部署的结果是，本单元的上层节点，只会调用本单元的下层节点。它具有一个站点全部的功能，但不具有一个站点全部的流量。 这种单元化部署实际上就要求底层的数据也要做 sharding。单元化的结果是，数据库连接可以更好地被复用-多个单元互相跨 db 连接，其实很浪费资源。 单元化是按核心数据维度，对业务系统的部署及核心流量进行隔离，从而达到更灵活的扩展能力和更强的容灾能力的解决方案。 现实妥协架构总有显示的黑暗面。 如何解决： 分拆解决不了全局数据依赖 分拆一定会带来异地时延 所以有些部署单元要全局冗余，然后对拷。 问题定义 高可用架构要去除单点的潜在威胁。 涉及多数据中心、多地部署的设计的意义和价值很难在日常工作中体现出来，但体现了超前布局的思考。 所谓的单点包括： 单服务器 单应用 单数据库 单机房 单地部署 多活架构 机房维度：机房越少、服务的部署就越受限，容灾的灵活度就越小。单机房最不灵活，因为冗余最少。每多一个机房，机房间容灾就越弱。但跨机房容灾部署很难保证一致性（全世界范围内，目前没有解决方案来解决这个问题）。 热备/冷备维度：热备对资源的利用率高，但要求有跨机房流量调配能力。 蚂蚁的单元化所谓单元，是指一个能完成所有业务操作的自包含集合，在这个集合中包含了所有业务所需的所有服务，以及分配给这个单元的数据。 引入服务治理引入服务治理机制，使整个服务可以在物理上灵活扩展。 强依赖：服务注册中心/服务命名+查找机制。 在阿里的语境里，是由服务注册中心的中间件来进行流量调配的。 分库分表一个比较好的实践是：逻辑拆分先一步到位，物理拆分慢慢进行。 以账户表为例，将用户 ID 的末两位作为分片维度，可以在逻辑上将数据分成 100 份，一次性拆到 100 个分表中。这 100个分表可以先位于同一个物理库中，随着系统的发展，逐步拆成 2 个、5 个、10 个，乃至 100个物理库。数据访问中间件会屏蔽表与库的映射关系，应用层不必感知。 换言之，蚂蚁的数据总是分成 100 个逻辑分片。至于这 100 个逻辑分片是 100 张表，还是会膨胀为 100 个库 * x 张表，都可以由数据库中间件进行屏蔽，且自由扩展。 强依赖：数据库中间件，把逻辑读写转换为物理表读写。 同城多机房所有机房共用一个服务注册中心，所有的请求由它统一分发 要突破单机房的容量限制，最直观的解决办法就是再建新的机房，机房之间通过专线连成同一个内部网络。应用可以部署一部分节点到第二个机房，数据库也可以将主备库交叉部署到不同的机房。这一阶段，只是解决了机房容量不足的问题，两个机房逻辑上仍是一个整体。 缺点： 服务层逻辑上是无差别的应用节点，每一次 RPC 调用都有一半的概率跨机房； 每个特定的数据库主库只能位于一个机房，所以宏观上也一定有一半的数据库访问是跨机房的。 每个机房独占一个服务注册中心，所有的请求独立分发 改进后的同城多机房架构，依靠不同服务注册中心，将应用层逻辑隔离开。只要一笔请求进入一个机房，应用层就一定会在一个机房内处理完。当然，由于数据库主库只在其中一边，所以这个架构仍然不解决一半数据访问跨机房的问题。 这个架构下，只要在入口处调节进入两个机房的请求比例，就可以精确控制两个机房的负载比例。基于这个能力，可以实现全站蓝绿发布。 两地三中心城市 1：idc1（registry1 + leader） + idc2（registry2 + replica1）。所有的服务都访问 leader 数据库。城市 2：idc3（registry3 + replica2） 另一个城市为备份的中心，访问replica，隔离对 leader 的依赖。 可以概括为同城热备，异地冷备（蚂蚁就是采用这种方案，通常每个 idc 平摊流量）。两地三中心还有一种形态，就是只有一个中心是活的，另有一个同城灾备，一个异地灾备。 所谓 “ 双活 ” 或 “ 多 活 ” 数据中心，区别于 传统 数据中心 和 灾备中心的模式，前者多个或两个数据中心都处于运行当中，运行相同的应用，具备同样的数据，能够提供跨中心业务负载均衡运行能力，实现持续的应用可用性和灾难备份能力，所以称为 “双活 ” 和 “ 多活 ” ；后者是生产数据中心投入运行，灾备 数据中心处在不工作状态，只有当灾难发生时，生产数据中心瘫痪，灾备中心才启动。 “两地三中心”是一种在金融系统中广泛应用的跨数据中心扩展与跨地区容灾部署模式，但也存在一些问题。异地灾备机房距离数据库主节点距离过远、访问耗时过长，异地备节点数据又不是强一致的，所以无法直接提供在线服务。 在扩展能力上，由于跨地区的备份中心不承载核心业务，不能解决核心业务跨地区扩展的问题；在成本上，灾备系统仅在容灾时使用，资源利用率低，成本较高；在容灾能力上，由于灾备系统冷备等待，容灾时可用性低，切换风险较大。 两地三中心看起来很美好，其实无法解决立刻切换的问题-异地延迟无法消除。 单元化 蚂蚁金服发展单元化架构的原始驱动力，可以概括为两句话： 异地多活容灾需求带来的数据访问耗时问题，量变引起质变； 数据库连接数瓶颈制约了整体水平扩展能力，危急存亡之秋。 单元化的设想，涉及到业务层和核心层的分离（单一系统的业务层和核心层，中台层的业务中台和核心中台）： 单元化架构基于这样一种设想：如果应用层也能按照数据层相同的拆片维度，把整个请求链路收敛在一组服务器中，从应用层到数据层就可以组成一个封闭的单元。数据库只需要承载本单元的应用节点的请求，大大节省了连接数。“单元”可以作为一个相对独立整体来挪动，甚至可以把部分单元部署到异地去。 单元化有几个重要的设计原则： 核心业务必须是可分片的（有些业务是不可分片的：比如风控、营销的全局配置） 必须保证核心业务的分片是均衡的，比如支付宝用用户 ID 作分片维度 核心业务要尽量自包含，调用要尽量封闭 整个系统都要面向逻辑分区设计，而不是物理部署 逻辑上只分 10 个 RegionZone，每个 R Zone 承载 20 个逻辑分片。 注意，这种两地三中心的 ldc 之间存储的不是同构数据，而是异构数据，即一部分分片，这是一种自然而然的想法-现实中的 idc 通常全局都是同构的，且全局只有一个主同时存在。 进入三地五中心，正好每个中心一个 R Zone。 回到前面买早餐的例子，小王的 ID 是 12345666，分片号是 66，应该属于 Regional Zone 04；而张大妈 ID 是 yig54321233，分片号 33，应该属于 Regional Zone 02。 应用层会自动识别业务参数上的分片位，将请求发到正确的单元。业务设计上，我们会保证流水号的分片位跟付款用户的分片位保持一致，所以绝大部分微服务调用都会收敛在Regional Zone 04 内部。 但是转账操作一定会涉及到两个账户，很可能位于不同的单元。张大妈的账号就刚好位于另一个城市的 Regional Zone02。当支付系统调用账务系统给张大妈的账号加钱的时候，就必须跨单元调用 Regional Zone 02的账务服务。图中用红线表示耗时很长（几十毫秒级）的异地访问。 涉及多个账户的操作，完全可能跨单元。 城市级容灾的方案，强依赖于 OB 的选主、换主的机制： 这也意味着，不同城市的不同 idc能够承载多个 R zone的数据，进而激活多个 R zone 的中间件的流量切换规则。 一个城市整体故障的情况下，应用层流量通过规则的切换，由事先规划好的其他单元接管。 数据层则是依靠自研的基于 Paxos 协议的分布式数据库OceanBase，自动把对应容灾单元的从节点选举为主节点，实现应用分片和数据分片继续收敛在同一单元的效果。我们之所以规划为“两地三中心”“三地五中心”这样的物理架构，实际上也是跟OceanBase 的副本分布策略息息相关的。数据层异地多活，又是另一个宏大的课题了，以后可以专题分享，这里只简略提过。 这样，借助单元化异地多活架构，才能实现开头展示的“26 秒完成城市级容灾切换”能力。 强依赖的技术组件： DNS 层（最顶层基础设施层） 反向代理层（子网网关） 网关 /WEB 层（接入层网关） 服务层（可再分为业务层和核心层） 数据访问层。 单元化流量管控是一个自上而下的、复杂的、系统性工程： DNS 层照理说感知不到任何业务层的信息，但我们做了一个优化叫“多域名技术”。比如 PC 端收银台的域名是 cashier.alipay.com，在系统已知一个用户数据属于哪个单元的情况下，就让其直接访问一个单独的域名，直接解析到对应的数据中心，避免了下层的跨机房转发。例如上图中的cashiergtj.alipay.com，gtj 就是内部一个数据中心的编号。移动端也可以靠下发规则到客户端来实现类似的效果。 反向代理层是基于 Nginx 二次开发的，后端系统在通过参数识别用户所属的单元之后，在 Cookie 中写入特定的标识。下次请求，反向代理层就可以识别，直接转发到对应的单元。 网关 /Web 层是应用上的第一道防线，是真正可以有业务逻辑的地方。在通用的 HTTP 拦截器中识别 Session 中的用户 ID 字段，如果不是本单元的请求，就 forward 到正确的单元。并在 Cookie 中写入标识，下次请求在反向代理层就可以正确转发。 服务层 RPC 框架和注册中心内置了对单元化能力的支持，可以根据请求参数，透明地找到正确单元的服务提供方。 数据访问层是最后的兜底保障，即使前面所有的防线都失败了，一笔请求进入了错误的单元，在访问数据库的时候也一定会去正确的库表，最多耗时变长，但绝对不会访问到错误的数据。 一般应用层或者业务中间件只能加上拦截器进行 forward/routing。 统一路由规则： 这么多的组件要协同工作，必须共享同一份规则配置信息。必须有一个全局的单元化规则管控中心来管理，并通过一个高效的配置中心下发到分布式环境中的所有节点。 规则的内容比较丰富，描述了城市、机房、逻辑单元的拓扑结构，更重要的是描述了分片 ID 与逻辑单元之间的映射关系。 服务注册中心内置了单元字段，所有的服务提供者节点都带有“逻辑单元”属性。不同机房的注册中心之间互相同步数据，最终所有服务消费者都知道每个逻辑单元的服务提供者有哪些。RPC框架就可以根据需要选择调用目标。 注意看，上图的右边提供了一个细分的物理寻址的结构。 （注解放在接口定义上比较优雅）。 RPC框架本身是不理解业务逻辑的，要想知道应该调哪个单元的服务，信息只能从业务参数中来。如果是从头设计的框架，可能直接约定某个固定的参数代表分片ID，要求调用者必须传这个参数。但是单元化是在业务已经跑了好多年的情况下的架构改造，不可能让所有存量服务修改接口。要求调用者在调用远程服务之前把分片ID 放到 ThreadLocal 中？这样也很不优雅，违背了 RPC 框架的透明原则。 于是我们的解决方案是框架定义一个接口，由服务提供方给出一个实现类，描述如何从业务参数中获取分片ID。服务提供方在接口上打注解，告诉框架实现类的路径。框架就可以在执行 RPC 调用的时候，根据注解的实现，从参数中截出分片ID。再结合全局路由规则中分片 ID 与逻辑单元之间的映射关系，就知道该选择哪个单元的服务提供方了。 这里通过接口指定了注解的参数的契约，用注解来解耦了配置对流程的入侵。用配置来减少对原流程契约的改造，使服务成为整体框架的一个插件。 改造这些东西带来的工程经验，是书本上学不到的。 蚂蚁要改造的业务分别是：交易、收单、微贷、支付、账务。 不同的数据的延时性、闭合性不同，影响了 zone 的分法： 可以按照选择好的维度进行分区的数据，真正能被单元化的数据。这类数据通常在系统业务链路中处于核心位置，单元化建设最重要的目标实际上就是把这些数据处理好。比如订单数据、支付流水数据、账户数据等，都属于这一类型。 这类数据在系统中的占比越高，整体单元化的程度就越高，如果系统中全部都是这样的数据，那我们就能打造一个完美单元化的架构。不过现实中这种情况存在的可能性几乎为零，因为下面提到的两类数据，或多或少都会存在于系统当中。不能被分区的数据，全局只能有一份。比较典型的是一些配置类数据，它们可能会被关键链路业务访问，但并不频繁，因此即使访问速度不够快，也不会对业务性能造成太大的影响。 因为不能分区，这类数据不能被部署在经典的单元中，必须创造一种非典型单元用以承载它们。乍看与上面一类相似，但两者有一个显著的区别，即是否会被关键链路业务频繁访问。如果系统不追求异地部署，那么这个区别不会产生什么影响；但如果希望通过单元化获得多地多活的能力，这仅有的一点儿不同，会让对这两类数据的处理方式截然不同，后者所要消耗的成本和带来的复杂度都大幅增加。究其原因是异地部署所产生的网络时延问题。根据实际测试，在网络施工精细的前提下，相距约 2000 公里的 2 个机房，单向通信延时大约 20ms 左右，据此推算在国内任意两地部署的机房，之间延时在 30ms 上下。假如一笔业务需要 1 次异地机房的同步调用，就需要至少 60ms 的延时（请求去，响应回）。如果某个不能单元化的数据需要被关键业务频繁访问，而业务的大部分服务都部署在异地单元中，网络耗时 60ms 的调用在一笔业务中可能有个几十次，这就是说有可能用户点击一个按钮后，要等待数秒甚至数十秒，系统的服务性能被大幅拉低。这类数据的典型代表是会员数据（全体客户信息），对于支付宝这类 To C 的系统来说，几乎所有的业务都需要使用到会员信息，而会员数据却又是公共的。因为业务必然是双边的，会员数据是不能以用户维度分区的。 Rzone：最符合理论上单元定义的 zone，每个 RZone 都是自包含的，拥有自己的数据，能完成所有业务。 GZone：部署了不可拆分的数据和服务，这些数据或服务可能会被RZone依赖。GZone 在全局只有一组，数据仅有一份。 CZone：同样部署了不可拆分的数据和服务，也会被 RZone 依赖。跟 GZone 不同的是，CZone 中的数据或服务会被 RZone 频繁访问，每一笔业务至少会访问一次；而 GZone 被 RZone 访问的频率则低的多。 ![rcgzone 部署.png](rcgzone 部署.png) RZone 是成组部署的，组内 A/B 集群互为备份，可随时调整 A/B 之间的流量比例。可以把一组 RZone部署的任意机房中，包括异地机房，数据随着 zone 一起走。 GZone 也是成组部署的，A/B 互备，同样可以调整流量。GZone 只有一组，必须部署在同一个城市中。 CZone 是一种很特殊的 zone，它是为了解决最让人头疼的异地延时问题而诞生的，可以说是支付宝单元化架构的一个创新。 CZone解决这个问题的核心思想是：把数据搬到本地，并基于一个假设：大部分数据被创建（写入）和被使用（读取）之间是有时间差的： 把数据搬到本地：在某个机房创建或更新的公共数据，以增量的方式同步给异地所有机房，并且同步是双向的，也就是说在大多数时间，所有机房里的公共数据库，内容都是一样的。这就使得部署在任何城市的RZone，都可以在本地访问公共数据，消除了跨地访问的影响。整个过程中唯一受到异地延时影响的，就只有数据同步，而这影响，也会被下面所说的时间差抹掉。 时间差假设：举例说明，2 个用户分属两个不同的 RZone，分别部署在两地，用户 A 要给用户 B 做一笔转账，系统处理时必须同时拿到 A 和 B 的会员信息；而 B 是一个刚刚新建的用户，它创建后，其会员信息会进入它所在机房的公共数据库，然后再同步给 A 所在的机房。如果A 发起转账的时候，B 的信息还没有同步给 A 的机房，这笔业务就会失败。时间差假设就是，对于 80%以上的公共数据，这种情况不会发生，也就是说 B 的会员信息创建后，过了足够长的时间后，A 才会发起对 B 的转账。 总结： 分 AB （服务）组可以调配流量，也可以互为主备-是为多活。 RZone 准备 AB （服务）组，每个 ldc 有且只有一组，共用一组 sharding 的单主数据库。 全局只有一组 GZone，在同城的一个 ldc 内（不跨城低延迟），只有一组单主的数据库（无分片），每个 ldc 有一个组（非 A 即 B）。 CZone 在不同城市里多主部署（无分片数据），每个 ldc 有自己的一组，两地四中心则有 ABCD 四个（服务）组。 弱一致性带来弱依赖假设，我们可以接受主从延迟，大部分的交易依赖于同一个交易上下文，大家其实都是写后读交易。但少部分数据不是写后读的，适合放在 Czone 里。大部分情况下，弱一致性可以制造流畅的交易，但要对弱一致性准备兜底的重试方案，不然的话就会丢失交易（掉单）。RZone 和 CZone 存的都是交易流水数据，CZone 是一种技术创新。写后读的弱一致性问题在分布式场景下广泛存在，倒也不限于单元化。着眼点应该放在分布式系统本身上面。 如果业务使用的主要是没有前后依赖的流水型数据，则比较易于单元化改造；如果是状态型数据，则单元化改造难度较高。因为单元化总是会造成比较明显的时延，除非流程有办法禁写、禁读，否则无法保证交易无差错。业务系统必须对这种分布式不一致性有所防范，甚至引入校对工具。 因为单元化不能在完整地切换数据存储，且数据切换完毕以后再切换上层业务流量，则可能出现脑裂多写，数据不一致的情况。所以自底向上切服务，且有强一致性切换是很重要的。 如果没有强一致性切换，则数据在远程拷贝的时候要注意数据回环问题，使用校验工具做好校验。 容灾的基本步骤包括自底向上激活、预热，切换流量，把有状态的服务先启动起来，然后启动无状态服务，然后切换其他中间件，最后切换流量调配规则。这样可以让慢的服务热到足够快，提供丝滑般的体验： 数据库切换 缓存容灾切换 多活规则切换 中间件切换 负载均衡切换 域名解析切换 基于 OB 的单元化![基于 OB 的单元化.png](基于 OB 的单元化.png) ![OB 弹性容量.png](OB 弹性容量.png) ![OB 灰度能力.png]（OB 灰度能力.png） 可以看出： CZone 也从 Rzone 拷贝数据，被 RZone 访问。这样说的话 CZone 存的也不是交易数据，而是不可拆分的全局数据（会员、风控）的低时延副本。 GZone 和 RZone 使用独立的 OB 集群。 在三地五中心架构下，每个 RZone 在每个中心都有一个副本，冗余非常高。 容灾分为同城容灾和异地容灾：OB 切主的时候，单元的 Zone 也会切主。 单元化对不同的企业可以有不同的实现 城商行大 GZone 模式：即把城商行的所有服务和数据不做拆分，直接装入一个GZone内，在GZone的基础上实现同城双活即应用同城双中心部署，数据库同城三中心部署。 区域银行 RZone 模式：即将这家区域银行的主要业务拆分成两个逻辑业务单元两个分片，将其装入一个城市的两个IDC内，在另外一个城市建设冷备，其数据库每个分片实现5副本部署，其中4副本在主城市两个中心内部署，1副本部署在了本机房内。该架构实现了同城容灾能力，同时也实现了细粒度的灰度能力和弹性能力，但同样无法实现异地容灾能力。 另一种 Set 化方案 每个的 Set 的入口就部署在各个城市之中，这是由 CDN 和接入层机房决定的。 接入层管理所有的流量，这样可以让属于某个 Set 的流量进入特定的 Set（换言之，凡是有可能带有跨 Set 可能的系统边界上，流量调拨的服务都应该是跨 Set 的） 每个 Set 之间完全镜像。 Set 路由服务也部署在全局数据和全局服务之前。 Set 之间也做数据同步。 结算和红包和每个 Set 单独部署的。 所有可能出 Set 和入 Set 的流量，都需要中间层。 行业内常见的思路无非是异地冷备或者异地多活，异地冷备浪费资源，而且切换不一定平滑。活是相对于备而言的。 中国人民银行的2号令，第三十二条：支付机构应当具备必要的技术⼿段，确保支付指令的完整性、 ⼀致性和不可抵赖性，支付业务处理的及时性、准确性和支付业务的安全性。具备灾难恢复处理能⼒和应急处理能⼒，确保支付业务的连续性。 只要存在异步的拷贝数据的方案，就一定无法解决延迟带来的数据不一致性问题。到底数据不一致对业务带来多少影响，要仔细评估写后写类业务自身的情况。 切换时要业务停写，然后切换路由规则，真正切流量的时候，强一致性业务，要做好数据校验。 退款、运营等后置、异步流程，可以容忍低活。元数据服务可以部署城市级 Set。 增加 Set 可能出现 100% 的资源增加的情况。 业务改造要改造： 识别流量中的分片标识 接入路由 SDK 存储层要加 Set 列 接入支持 Set 的中间件 要有故障切换和流量管控平台。 理论上一个 Set 只能属于一个机房，一个机房可以部署多个 Set（一个物理 idc 可以映射多个逻辑 ldc）。 这种架构里面，流量最大，对可用性要求最高的就是接入层服务、网关服务（其实还包括日志服务）。 在存储层没有准备好的情况下，流量层 -&gt; 存储层 -&gt; 单个业务到全链路 -&gt; 异地。 在有多个上游的时候，下游服务可以考虑跟上游的分片规则解耦。解耦的话，上下游不用相互配合改造。 有一些柔性 FO 的方案，可以让一部分数据放进黑名单里，不影响其他数据的可用性。 Set 化架构要求服务和数据的分区隔离，于是老服务都必须进行一定的改造才能适应Set化架构，订单功能包括用户SET和商家SET的功能，所以订单的服务相对来说有很多特殊性的地方。 如果商家信息和用户信息属于不同的信息类型，使用不同的订单中心，需要考虑下单时跨 Set 的问题，至少有两种跨 Set：用户在 A Set 向 B Set 下单，用户从 A Set 去到 B Set，然后向 B Set 的商家下单。 有些店铺属于大连锁，所以可能会产生两套数据，门店数据会 Set 化，大连锁数据不 Set 化。 如果交易有多维度查询的需求，可能有 id 维度写，然后从用户、商家和大连锁维度各自的副本进行分片和查询。 Set 间的数据按理来说是要彼此隔离的，但 id 的全局唯一性还是要仔细考虑的，只有这样做，才能够预防迁移（特别是容灾导致的迁移）。除此之外，还可以有：重新生成主键并建立 mapping；容灾时独立写入；使用 step 分段模式生成独立的 leaf 号段。 给数据打标/染色的方式很多，逐一改表是最麻烦的方法，简单的基础方法是给流量染色，异步地流量染色可以考虑把标记写进 id 的号段里面。一个例子：48 位 set 内自增 id + 4 位预留 + 6 位商家 Set + 6 位用户 Set。但，即使实现了流量染色，可能还是不可避免地要改表。改不改表，可以作为一个区分方案工程量的标准。一个好的 id 生成算法，能够精确地确定时+空+自增，其中时要明确时间精度，空要确认-单元-城市-集群-机房-链路-库等不同的颗粒度，自增要保证在特定的时间里的并发可以被满足。对于例子里的架构，原始的集群和机房的关系是单集群多机房。 为了兼容 Set 化和非 Set 化的上游服务，所有请求在进入下游之前，要先通过路由服务。用中间层来制造变量设计，解决常量设计的问题。 跨域消息的兼容性最好的实现方案是：跨域 set 复制-这也是蚂蚁的跨 zone 的基础方案。复制转发的最简单方式是通过消费到了用户的消息再通过自构建RPC的方式进行转发（模仿 client 是最简单的消费复制方式，另一种方式是在 broker 里改造，这两种方法都不需要改造 producer，充分利用解耦来减少对生产方的改造，而且可以充分利用 mq 的堆积性和持久性）。 订单数据改造特别重要，基本方式有：在 SQL 上添加 SET 标识的注释，databus 解析 binlog 感知到了进行同步；只拉取关键数据的 binlog，通过组装方式查询获取；所有数据加上版本，依靠版本确认最终一致；延迟敏感型业务使用同步调用同步，其他情况下用 MQ 同步。不同步数据，无法解决跨 Set 查询的问题-这个问题有两个基本解决思路：跨 Set 路由查询；复制其他 Set 数据到本地。 Set 化是采用业务属性进行划分，如果这个属性没有很好的 Set 属性，那么 Set 化收益将不复存在。 中心服务是一种特殊的 Set。如果这种 Set 支持其他 Set 的 fallback，则这种 Set 本身可能被 fallback 打爆。有一类架构方案认为，中心 Set 应该处理 Set 标丢失的流量。 读扩展是有限的，MySQL 的从库扩充不能超过 20 台。 单机房容量是有限的。扩展受限，意味着容量受限和冗余受限。 如果大量 idc 的主库集中在同一个 IDC，机房故障的时候，可能导致大量的主从切换。主从切换产生的脑裂问题很难在业务层面解决，只有在数据层自己解决。换言之，部署的灵活性是由切换方案决定的。 单机-单服务-单数据库-单地域，机构的拓扑结构变复杂一倍，就要引入新的中间层中间件，让架构变量化程度更高一点。多地域的 Set 化，最终导致我们要对接入层进行隔离改造。 机房的隔离，是解决机房容量全局共享的不二法则。 一般 Set 的互备，一定要基于数据拷贝。 阿里只单元化了买家链路（按照用户 Id 拆分），而卖家链路没有单元化，这可能和流量的特点有关系。而蚂蚁则完全进行了单元化。阿里使用 MySQL 加 DRC 进行单元化（这证明 MySQL 没有很好的远程拷贝方案）；而蚂蚁使用 OB，直接强一致性可切。 单元化的具体方案本身高度依赖于业务特征（流量和数据划分规则，这是业务系统改造要回答的首要问题，这个问题没有完美答案，任何一种规则都有它不能解决的边界问题），也需要公司基础服务和组件进行改造，所以没有同行的技术路径，只有一些基础要领。 外卖类业务的划分规则要遵循其强 LBS 属性的核心特征，交易方在一个地域内，容易形成闭环。 用户应该属于二级 region，二级 region 动态地分配在 Set 中，所以 region 是流量标识里面的常量部分。各层通过 region 和 Set 的动态绑定，把流量路由到特定的 Set 中。 数据如果做分 Set 冗余，则需要考虑是不是做全量冗余；冗余越多，成本越高，但可切换性越高。所以最终设计出来的方案，几冗余几分片，非常重要。 要解决基于 binlog 产生的数据回环，有一种做法是给 binlog 写注释，注明本操作源于哪个 set，让 client 过滤，还有第二种方案是给数据表加两个列，一个表明 insert_set，一列表明 update_set。 跨 set 订单的基本逻辑是，先写远端 Set，然后会写回本 Set，如果 mq 出问题，降级到 rpc，主动同步。这样，交易实际上可以在远端做，也最终不影响本 Set 的数据闭环。 高可用中牺牲多少一致性 幂等总是难以保证的，柔性设计会牺牲一致性。 不柔性的设计，强一致性的设计，会增加切换的难度。 牺牲一致性，意味着有些单会在脑裂中出错。什么样的错误单可以被容忍？有异步化流程，或者可以事后通过对账补偿的业务，可以被容忍，这是流水型业务。余额、库存类实时生效的关键交易因子产生的错误，是不可以被容忍的，这是状态型业务。这也意味着，这类业务在做高可用的时候，必须评估集群切换对业务的破坏。强一致性业务不能容忍有损运行。流水型业务和状态型业务的区别是，到底写是不是会影响写后写，写后写依赖的全局状态到底有多深和广。 LiteSet有些公司会把灰度链路叫作 LiteSet。LiteSet 要求全链路的 Tracer 传递完全正确（有一些方案会传入“gray-release-xxx”相关的流量标记字段进 cell 里）。它作为链路粒度的流量隔离方案（基本不支持存储层隔离的方案，还支持 fallback 回中心链路），多用于全链路灰度、按业务线流量隔离部署、全链路压测（这样真的是全链路压测吗？）等，需要围绕流量在中间件里的流动，建造单独的监控体系。与此相比还有一种泳道方案，只在线下测试环境里面做链路灰度隔离。set 化方案和泳道方案本质上是一种方案，前者偏稳定，固若金汤；后者偏灵活，随用随建随销毁，因此也能衍生出 LiteSet 这个新方案。 参考文献： 《蚂蚁金服异地多活的微服务体系》 《“两地三中心”和“双活”简介–容灾技术方案》 《蚁金服支付宝系统的单元化》 《支付宝如何实现全分布式单元化技术架构？》 《同城双活与异地多活架构分析》 "},{"title":"压力测试需要关注的注意事项","date":"2020-08-18T07:05:02.000Z","url":"/2020/08/18/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E9%9C%80%E8%A6%81%E5%85%B3%E6%B3%A8%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","tags":["性能测试"],"content":"真正的高可用高并发架构，只有在压测中才能显示合理性和不合理性。有时候我们怀疑积压来自于服务，其实可能来自于数据，或者缓存或者消息队列。 确认核心链路的范围：纵向看，深度到哪里（哪里已经不是本架构域需要关注和改造的范围，哪里需要 mock）；横向看，一个请求会涉及多宽的 scope（服务的宽幅）。产出是：需要关注的服务和拓扑结构。 寻找压测指标：容量应该在什么条件下摸到多高。高度由现在的日常业务高峰和大促的流量增长综合评估得出，首先确定业务系统应该支持的 qps/tps 数量。然后考虑容灾等级，即允许在几个机房、几台机器挂掉以后，服务还能正常运行。如果一个服务应该支持的日常峰值（考虑大促），乘以冗余数量（如果是两地三中心，应该考虑将单机房的压测峰值乘以 3）。 确定压测过程中压测指标： VM 性能指标项： fullgc 次数 gc time（总数和平均值） gc count（注意和同环比看是不是显著增加，是不是有可疑的波动） block 状态线程数（看看系统是不是已经达到吞吐瓶颈了） 服务性能指标项： 接口 TP999 的响应耗时（没有办法统计这项指标的可以看 MAX 和 AVG） 服务错误率（最好看监控中出现的错误出现的次数和种类，如果有错误细节就更好） 数据库性能指标项： 读写性能（读 qps、写 tps） 响应时间 主从延迟（需要有 dba 基础设施，专门监控主从延迟时间） MQ性能指标项： 是否产生堆积（能否看到是哪一个消费者，消费者的哪一个 partition 产生了堆积，堆积的原因到底是单纯的吞吐线程数量不够，还是消费流程产生了瓶颈，还是出现了异常死信？） 消息发送时延 消息消费时延 缓存指标（以 Redis 为例，Tair 同理）： 缓存的读写时延（是否有明显的阻塞操作，特别是 Redis 的 io 模型是单线程的 io 模型，时延直接关联吞吐） 是否出现大 key 是否出现内存存量暴增的方案 搜索引擎： 从 RDBMS 里同步数据是不是有延迟（可能受到了 MQ 之类的数据搬运工具的时延影响，也可能碰到了搜索引擎自己的索引构建瓶颈）。 当前的分片模式是否能够支持压测中产生的读写。 确定压测的数据范围： 是否使用流量复制技术。如果使用流量复制技术，则变更请求中的什么部分，保证不会产生新的交易 - 如果压测环节出现问题，压测流量是怎么被隔离的。通常要确认数据库是否有影子表，缓存是否有影子 Category、搜索引擎是否能够单独把影子流量存在影子索引里。甚至有必要使用测试的业务线，使用测试的商品、测试的结算方式等等。 测试用的流量如何染色，染色的流量如何保证不丢-特别要小心线程池中丢失测试标记，和 Java 组件（缓存、数据库、搜索引擎）不能识别和传递压测流量的问题，这时候可能要考虑对数据库中间件，缓存中间件等读写 proxy 进行压测改造。 确定预案： 如果压测出现问题，是否有关闭压测的能力。 压测各个环节是否可以自动采集相关时间范围或者 trace 范围的异常。 如果压测出现问题，所有的中间件是否有自动扩容的能力。 如果压测出现问题，所有的服务是否有限流和熔断的能力。 测试产出压测报告： 压测中要监控的指标的截图或者表格 错误的内容 数据比对：所有压测流量是否都准确地落入链路的各个环节。 要记得关闭压测流量以后，消除影响：该缩容的缩容，该滚动重启的重启 - 清理缓存。 "},{"title":"MySQL 与数据迁移","date":"2020-08-15T07:54:30.000Z","url":"/2020/08/15/MySQL-%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/","tags":["系统架构","MySQL"],"content":"如何不停机地进行数据迁移要做到不停机的平滑数据迁移，需要使用标准化流程，寻找一个合理的批次切分点，对存量数据和增量数据进行迁移。 注意： 增量迁移过程中，最好不要修改源表的表结构，即执行 DDL 语句。 增量迁移过程中，不要修改源表主键的值（即自增主键），很容易造成目标表 insert 冲突。 注意，这里可以看出，binlog 因为切不准，所以必须比备份超前一些，这要求 binlog ： 1、严格地单调有序2、apply 要能够支持幂等操作：update 和 delete 的幂等是简单的，insert 的幂等要防异常，如果有必要 apply 可以在外部做。 一般的校验机制是校验新老库的最后 1000-10000 条数据是否一致。校验的时候要对原表加读锁（S 锁），这样写操作会被禁止（禁止写的标准方法之一，不停机的停机）。这种锁表的时间最好维持在 1s 以内，如果存在多张表的迁移，最好并发同步，并发锁表，让迁移的停顿在 1 s 以内。 平滑扩容 为原主库增加路由策略，如原本 id % 2 = 0的请求路由到库 1，现在 id % 4 = 0 和 id % 4 = 2 的请求路由到库 2。有些公司依赖于服务网关，有些公司依赖于 keeplived。 增加 db 的集群，先作为从库的集群，日后作为主库的集群-如果使用双主架构，此时可能会变成四主。 使用同步追加 binlog 的方式，让从库完全追上主库，可以作为主库使用-在从库数据追上的一瞬间，要给要同步的表加锁（还是 s lock），完全禁止写-然后验证数据一致性。 如果数据一致了，在这一瞬间切换 1 中的路由策略，把 id % 4 = 2 的请求路由到库 2。 如果 3-4 的时间比较久，整体的架构方案要有能够不生成 id % 4 = 2 的请求的方案，相当于可以临时禁掉对这部分 db 写的流量（对于整个业务集群而言，属于半停机）。这就要求，请求生成的序列号服务有管控流量的能力，这需要引入 redis 的 cluster 算法或者一致性散列等算法。 解除 4 主之间的同步，变成两两双主的同步。 把 id % 4 = 2 集群里的 id % 4 = 0 的数据删除，另一个集群以此类推。这样可以让容量整体增大一倍（性能则不止一倍）。 "},{"title":"常见的服务器调用堆栈","date":"2020-08-02T05:08:55.000Z","url":"/2020/08/02/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B0%83%E7%94%A8%E5%A0%86%E6%A0%88/","tags":["Java","Spring"],"content":"自顶向下调用$ 是内部类的意思 $$ 是由 Lambda 生成的内部类的意思：。当然 Spring 的 CGLIB 可以自己控制 naming pattern。 内部类生成的类名后往往带有一个数字，这个数字表示编译器生成这个内部类的顺序 Thread.run() ThreadPoolExecutor$Worker.run() ThreadPoolExecutor.runWorker() Netty.DefaultServerHandler.run() Netty.DefaultServerHandler.handleRequest() ThriftServerPublisher$MTProccessor.process() Thrift 接口$Processor.方法名() com.sun.proxy$Proxy 数字.方法名() XXXServiceImpl$$EnhancerBySpringCGLIB$$1fb0b39f.被拦截的方法 ThriftInvoker.invoker() RhinoLimiterFilter.filter() ThriftInvoker.invoke() ThriftInvoker.doinvoke() java.lang.reflect.Method.invoke() sun.reflect.DelegatingMethodAccessorImpl 数字.invoke() thrift接口Impl$$EnhancerBySpringCGLIB$$随机名称.被拦截的方法 org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) Spring Test 的调用堆栈org.Springframework.Test.Context.Cache.DefaultCacheAwareContextLoaderDelegate.LoadContext -&gt; org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal -&gt; org.springframework.boot.test.context.SpringBootContextLoader.loadContext -&gt; org.springframework.boot.SpringApplication.run -&gt; org.springframework.boot.SpringApplication.refreshContext-&gt; org.springframework.boot.SpringApplication.refresh"},{"title":"CSP","date":"2020-07-31T06:09:50.000Z","url":"/2020/07/31/CSP/","tags":["信息安全"],"content":"何谓 CSPCSP （内容安全策略）的实质就是白名单制度，开发者明确告诉客户端，哪些外部资源可以加载和执行，等同于提供白名单。它的实现和执行全部由浏览器完成，开发者只需提供白名单的配置也就是CSP规则，下图为Github使用的CSP规则。 Content-Security-Policy: default-src ‘none’; base-uri ‘self’; block-all-mixed-content; connect-src ‘self’ uploads.github.com www.githubstatus.com collector.githubapp.com api.github.com www.google-analytics.com github-cloud.s3.amazonaws.com github-production-repository-file-5c1aeb.s3.amazonaws.com github-production-upload-manifest-file-7fdce7.s3.amazonaws.com github-production-user-asset-6210df.s3.amazonaws.com cdn.optimizely.com logx.optimizely.com/v1/events wss://alive.github.com; font-src github.githubassets.com; form-action ‘self’ github.com gist.github.com; frame-ancestors ‘none’; frame-src render.githubusercontent.com; img-src ‘self’ data: github.githubassets.com identicons.github.com collector.githubapp.com github-cloud.s3.amazonaws.com *.githubusercontent.com; manifest-src ‘self’; media-src ‘none’; script-src github.githubassets.com; style-src ‘unsafe-inline’ github.githubassets.com; worker-src github.com/socket-worker.js gist.github.com/socket-worker.js CSP 大大增强了网页的安全性。攻击者即使发现了漏洞，也没法注入脚本，除非还控制了一台列入了白名单的可信主机（或者 origin/domain/host）。 如何为网站添加CSP规则增加CSP规则有两种方式 在响应头中增加Content-Security-Policy或Content-Security-Policy-Report-Only字段 通过网页的标签 CSP解决的安全问题CSP可以有效解决XSS，HTTP劫持等问题，通过配置好的规则，确定页面中是否包含非法资源，与WAF配合让XSS攻击无从下手，下图为2019-2020年度漏洞占比，XSS占比漏洞最高。 CSP策略的两种使用方式 Content-Security-Policy （拦截所有非法请求） Content-Security-Policy-Report-Only （上报所有非法请求，不进行拦截） 使用第二种方式的时候就需要增加report-uri字段告诉浏览器需要上报到什么地址。 CSP语法一条CSP策略包含多条CSP指令，每个指令之间以;进行分割，每个指令包含指令名和指令值，均以空格进行分割，一个完整的CSP规则应该是以下格式的： Content-Security-Policy: [指令名1] [指令值1] [指令值2]; [指令名2] [指令值1] [指令值2]; 指令值的组成指令值允许使用以下几种： 主机类型 指令值 解释  完整的指明了协议和域名 www.github.com 指明了域名，不限制协议 *.github.com 允许 github 所有子域名，不包含github.com本身，允许的协议是当前页面url使用的协议，而非任何协议都可以 https://*.github.com https协议下的 github 所有子域名，不包含github.com本身  下的资源 10.10.10.1 ip类资源 10.10.10.1:443 ip类+端口资源 http: 允许所有http协议资源 指令值的协议类型不支持通配符，不支持*://*.github.com这种形式，详细参考： 关键字类型关键字类型除*外需要用单引号包起来 指令值 解释 ‘none’ 不允许访问任何资源 ‘self’ 允许访问同源资源 * 允许访问所有资源 ‘unsafe-inline’ 允许内联资源如on事件，内联script、style标签 ‘unsafe-eval’ 允许使用eval等危险函数 ‘report-sample’ 在报告中体现部分违规代码 除了以上两种类型以外CSP还支持nonce-source和hash-source类型，用来指明当前页面合法的内联代码段 ，CSP项目目前不支持使用这两种方式进行配置，不做过多介绍。 可用的指令名 指令值 解释 default-src default-src代表很多指令的集合，在这些指令没有被指定的情况下，浏览器会使用default-src的指令值给对应的指令 script-src 用于限制全局js加载源 script-src-elem 限制标签中的js代码和标签的src属性 script-src-attr 限制除标签和src属性以外的js代码 style-src 限制全局css style-src-elem 限制标签中的代码和带有rel=”stylesheet”属性的link标签代码 style-src-attr 限制单个DOM元素的内联样式代码 img-src 限制标签的src属性 font-src 限制字体的加载源 connect-src 限制使用js加载的url，如a标签ping属性，XMLHttpRequest等 media-src 限制、等标签的src属性 object-src 限制的src属性、的archive属性、标签的data属性等，限制flash插件加载 child-src 限制和，worker等元素的加载源，建议设置frame-src 和 worker-src代替 frame-src 限制frame和iframe加载源 worker-src 限制各类Worker加载源 frame-ancestors 与frame-src相反限制谁能嵌入我 from-action 限定当前页面表单的提交地址 base-uri 限制base标签指定的url manifest-src 限制manifest.json加载源 plugin-types 通过限制可以加载的资源类型来限制可以嵌入到文档中的插件集，embed、object、applet 通过上述配置一个CSP规则就诞生了。 小例子一个站点接入的CSP规则如下 这个时候攻击者在页面中加入了&lt;script src=&quot;;，那么这段代码将触发CSP报告，因为CSP规则中script-src-elem指令只允许访问自身和cdn.jsdelivr.net"},{"title":"高性能 MySQL","date":"2020-07-25T01:57:21.000Z","url":"/2020/07/25/%E9%AB%98%E6%80%A7%E8%83%BD-MySQL/","tags":["MySQL","高性能"],"content":"译者序MySQL 最初是放在 LAMP 里一起讨论。 淘宝网最初使用 LAMP 架构，使用 MySQL 4.0。03 年底改用 IOE，从 08 年开始又筹划去 IOE。09 年的时候 MySQL 的架构也从垂直拆分改成水平拆分。2012 年 MySQL 的单库已经有了 6.5 万的 QPS。 本书是 mysqlperformanceblog.com 的几个专家（同样也是 percona 的创始人）的作品，对于 InnoDB/XtraDB 等存储引擎的性能优化和诊断方法有很深入和详细的介绍。 推荐序作者在性能优化领域工作多年，这本书诞生于 MySQL 还没有什么可扩展性和可测量性的时代，直到现在这些方面已经有了长足的进步。说到合理的方法，他们简直把这件事当成了科学，首先定义需要解决的问题，然后通过合理的猜测和精确的测量来解决问题。 性能优化 = 定义问题 + 猜测 + 测量 要关注： 吞吐量 响应时间 吞吐量 = 线程数/响应时间 追求新技能，如排队理论对性能的影响。 MySQL 的架构和历史MySQL 能够应用的场景： 嵌入到应用程序中 数据仓库 内容索引 部署软件 高可用的冗余系统 在线事务处理系统 MySQL 最重要、最与众不同的特性是它的存储引擎架构，这种设计将查询处理（Query Processing）及其他系统任务（Server Task）和数据的存储/提取相分离。 MySQL 的逻辑架构第一层：client + connector。连接处理、授权认证、安全等等。第二层：Server。职责是：实现函数、查询解析、缓存、优化，所有的跨存储引擎的功能都在这一层实现，包括存储过程、触发器、视图。第三层：storage engine。实现数据的存储和提取。每个引擎都互有优势（pros）和劣势（cons）。server 和 storage engine 之间通过统一的接口 API 进行通信。存储引擎层不解析 SQL。 连接管理和安全性（在 Server 层）每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个 CPU 核心或者 CPU 中运行。服务器会缓存线程，不必为每个新建的连接创建和销毁线程（常见的设计模式，要考虑伸缩性，和线程池的分层）。MySQL 还支持 SSL 连接，所以具有使用 X.509 认证的能力。 Server 层有自己的 privilege 模型。 优化与执行MySQL 会解析查询，并创建内部数据结构（AST），然后对其进行各种优化，包括： 重写查询 决定表的读写顺序 选择合适的索引 用户可以通过特殊的关键字提示器（hint），影响它的决策过程，也可以通过解释器（explain）来理解 server 是怎样决策的。 用户可以优化： 查询 优化索引 优化其他查询条件 优化翻页 优化排序 schema 配置 进而使应用可以高效运行。 优化器并不关心使用什么存储引擎，但存储引擎会影响优化器。优化器会询问存储引擎一些统计信息，包括但不局限于存储容量、具体操作的开销信息、表的统计信息，进行一些类似 cost-based 的优化。 对于 select 语句，在解析查询以前，Server 层会先检查查询缓存（Query Cache），如果能够找到对应的查询，则不再进入 parser、optimizer 和 execution 的全过程。这要求 server 层能够很好地控制 cache 的 consistency。 并发控制（Concurrency Control）理论上只要有多个查询（事务或者事务里的语句）在同一时刻修改数据，都会产生并发控制问题（另一种的 Race Condition）。 邮箱的例子：邮件如果是单链表，并发访问可能导致数据结构的分叉。所以基本的方案必须通过加锁来维护数据结构的正确性（也就是业务的正确性）。然而加锁的方案只是基础方案，不是一个高性能方案。高性能方案应该是混合使用 lock 和 lock-free 的方案。 读写锁读通常没有问题，但通常的业务逻辑总是读写混合的。所以锁系统应该提供差异化的读锁（share lock）和写锁（exclusive lock）。 读锁相互共享。写锁相互阻塞。 锁粒度尽量只锁定需要修改的部分数据 - 只对修改的数据片进行精确的锁定，是在并发力度下性能最优的锁定策略，可以尽量避免锁冲突（lock contention）。 锁本身也需要资源，这部分的性能开销往往为人所忽略。 在存储引擎的设计中，锁管理是个非常重要的决定。将锁固定在某个级别，可以为某个应用场景提供更好的性能，但同时会支持对另外一些应用场景的良好的支持。 最容易被忽略也最常见的表锁的使用场景，Alter Table - 所以需要 online ddl 工具的支持。 server 层可以自己实现表锁，存储引擎层也可以实现表锁。server 层的表锁可以直接忽略存储引擎层的表锁。 行级锁行级锁可以最大程度地支持并发处理（同时也带来了最大的锁开销）。 只有存储引擎层可以实现行级锁。 事务在理解事务以前，接触数据库的其他高级特性言之尚早。 事务就是一组原子性的 SQL 查询，或者一个独立的工作单元。事务其实是所有 statement 的组。 银行的模型，saving 和 checking，需要三个步骤： 检查支票账户的余额高于 200 美元。 从支票账户的余额中减去 200 美元。 在储蓄账户的余额中加入 200 美元。 ACID 的标准定义： 原子性一个事务必须被视为一个不可分割的最小工作单元。 一致性数据库总是从一个一致性的状态，转换到另外一个一致性的状态。 隔离性事务的修改在最终提交以前，对其他事务是不可见的。 持久性一旦事务提交，则修改可以被永久保存到数据库中。即使系统崩溃，变更后的数据也不会丢失。 事务的出现使存储引擎对资源消耗变大了，因为支持事务则流程会变复杂。用户可以选择使用事务的存储引擎，也可以选择不使用事务的存储引擎（不支持事务也支持 LOCK TABLES 等操作，一样可以进行并发控制）。 隔离级别可读未提交大多数情况下，无益处（虽然性能最好）。 可读已提交一个事务开始时，只能看见已提交的事务所做的修改。这个级别又叫不可重复读（nonrepetable read）。 可重复读每个事务从头到尾都能得到 consistency read。但因为不能防止 phantom row 所以不能防止 phantom read。 可串行化强制事务串行执行，每一行都加了锁（最起码每个 select 隐式地成为 select in share mode）。 死锁InnoDB 可以自动检测死锁，也可以自动处理死锁-将持有最少的 row x lock 的事务进行回滚。 避免死锁的方法是避免数据冲突。 事务日志WAL 就是事务日志，通常是追加写。 写完事务日志以后，buffer pool 里的 dirty pages 会通过 fsync 之类的操作写进磁盘里。 MySQL 中的事务支持事务的存储引擎有： InnoDB NDB Cluster XtraDB PBXT 自动提交（autocommit）模式MySQL 默认会设置 autocommit 为 1。autocommit 对 InnoDB 生效，对 MyISAM 不生效（相当于 autocommit 总是为 1）。 大批量操作数据的命令（如 ALTER 类的 DDL 语句），会强制操作对事务的修改提交。 在事务中混合使用存储引擎同一个事务可以跨表操作。 表可以由不同的存储引擎存储。 混合使用事务性和非事务性的存储引擎会导致事务无法回滚。 所以表要显式地指定存储引擎。 隐式锁定和显式锁定insert、delete、update 会隐式地锁定表里的记录。但 MySQL 支持如下的显式锁： select … lock in share mode（非 SQL 标准） select … for update（非 SQL 标准） LOCK TABLES（server 层） UNLOCK TABLES（server 层） （InnoDB 中的）MVCC包括 MySQL、PostgreSQL、Oracle 都实现了 MVCC，但各自的实现机制不一样，因为 MVCC 没有统一的标准（没有人能说其他实现是错的）。 可以认为 MVCC 是行级锁的一个变种，但大多数情况下 MVCC 代表着无锁操作。 MVCC 为每行保存了两个隐藏列，一行保存行的创建时间（创建事务版本），一行保存行的删除时间（删除事务版本）。这里说的时间，实际上指的是系统版本号（system number version）。每个事务开始的时候，会取当前事务的版本号，作为事务自己的版本。 SELECT InnoDB 只查找版本早于当前版本的数据行（行的系统版本号小于或等于事务的系统版本号），这样读到的数据，要么在数据开始以前就已经存在，要么是本事务创造的（如果这是一个长事务，则之前已经 insert 过很多带有本 transaction version 的行了）。 行的删除版本未定义，或者大于当前版本号，这样可以保证事务读到的行，在事务开始以前未被删除 INSERT为每插入的每一行保存当前系统版本号作为行含本号。 DELETEInnoDB 为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE插入新的一行，保存当前系统版本作为行版本号。保存当前系统版本号到原来的行作为删除标识。 大多数操作都可以不用加锁，只能读取到符合标准的行。RU 总是读取到最新行，Serialize 总是对每个读取的行加锁。 MySQL 的存储引擎在文件系统中，MySQL 将每个数据库（也可以称之为 schema）保存为数据目录下的一个子目录。创建表时，MySQL 会在数据库子目录下创建一个表同名的.frm 文件，保存表的定义（数据则存在 .idb 文件里）。 存储引擎使用操作系统中的目录和文件保存了库和表的定义。在 windows 操作系统中，定义是大小写不敏感的；在 unix 操作系统中，大小写是敏感的。 InnoDB 存储引擎InnoDB 是默认的事务型存储引擎（transactional storage engine），也是最重要、使用最广泛的存储引擎。它被设计成用来处理大量的 short-lived 事务，短期事务大部分情况是正常提交的，很少会被回滚。InnoDB 也适用于非事务性存储。 InnoDB 的历史InnoDB 有着复杂的发展历史，最初有旧的 innodb 存储引擎，但最终 Oracle 旗下的 InnoDB 公司提供的 InnoDB plugin 在当前版本原生编译时就成为当代的 InnoDB 引擎。近期的版本主要改进集中在可测量性、可扩展性、可配置化、性能、各种新特性和对 Windows 的支持上。 InnoDB 概览InnoDB 的数据存放在表空间（table space）中，表空间是由 InnoDb 管理的一个黑盒子，由一系列数据文件组成。InnoDB 将表的数据和索引存放在单独的文件中（合一）。 InnoDB 的表基于聚簇索引建立（EveryThing is an Index in InnoDB），因此 InnoDB 的索引结构和其他存储引擎有很大不同，聚簇索引对主键查询有很高的性能。不过它的二级索引中必须包含主键列，所以主键列很大的话，其他的所有索引都会很大。因此，表上的索引较多的话，主键应该尽可能小。 MyISAM 存储引擎MyISAM 无事务，崩溃后无法恢复。因为它无事务的特性，所以很多人都一直认为 MySQL 无事务。在无事务的时代，用户依然可以使用 LOCK TABLES 和 UNLOCK TABLES 来进行并发控制。 存储MyISAM 将索引和数据文件分开存储。MyISAM 中的表可以分为 dynamic row 和 fixed row。 MyISAM 特性靠加锁来支持并发。 需要修复表（不是什么好特性）。 （即使对 BLOB 和 TEXT）支持全文索引 + 复杂查询。 Delayed Key Write，对索引的更新是延迟的，所以一旦发生 crash，数据会丢失，又需要修复表（所以不是什么好特性）。 MyISAM 支持对行级进行压缩的压缩表。压缩表可以极大地提高性能，但数据出问题还是要修复。 MyISAM 最典型的性能问题是表锁的问题。 其他存储引擎 Archive Blackhoe Csv Federated Memory Merge NDB 它让 MySQL 引入了 share nothing 的架构 第三方存储引擎OLTP 类存储引擎Percona 的 XTRDB 是基于 InnoDB 的一个改进版本。XtraDB 可以作为InnoDB 的一个完全的替代产品。 PBXT 支持引擎级别的复制，外键约束，对 SSD 的支持较好，被 MariaDB 所包含。 TokuDB 使用一种新的叫作分形树（fractal trees）的索引数据结构。TokuDB 是缓存无关的，因此即使其大小超过内存性能也不会下降，也就没有内存生命周期和碎片的问题。TokuDB 是种大数据存储引擎，因为其拥有很高的压缩比，可以在很大的数据量上创建大量索引。 RethinkDB 最初是为 SSD 设计的，和 PBXT 差不多。 选择合适的存储引擎除非必须使用 InnoDB 不具备的特性而不能妥协，否则应该使用 InnoDB。 实际上，OLTP 的场景下使用 InnoDB，OLAP 场景，使用大数据框架来分析，已经成为了大多数互联网公司的标配场景。 不要轻易认定“MyISAM 比 InnoDB快”之类的经验之谈。在很多已知场景下，InnoDB 的速度是 MyISAM 望尘莫及的，特别是能够使用聚簇索引查询，或者所访问的数据都可以放入内存中的应用。 转换表的存储引擎ALTER TABLE 这个操作会执行很长时间，MySQL 会把原表复制到新表中（这种新表被重新组织过，可以消除空洞）。在复制的过程中会消耗系统所有的 I/O 能力，而且表上会加读锁（变成了 READ ONLY 的表，算是一种半停机的设置）。 如果转换表的存储引擎，将会失去和原引擎相关的所有特性。一张表切换两次不同的引擎，可能导致外键都丢失。 EXPORT 和 IMPORT可以使用 mysqldump 把表导出，然后修改 CREATE TABLE 的 engine 选项，注意同时修改表名，因为同一个 db 里不能存在相同的表名。 CREATE 和 SELECT 如果数据量不大的话，这样做很好；否则需要考虑分批处理，因为这样会产生过多的 undo。 可以考虑使用 Percona Toolkit 提供的 pt-online-schema-change 的工具。 MySQL Timeline5.5 版本的 MySQL 是史上质量最高的版本。体现了 Oracle 收购了 MySQL AB 以后对产品的关注。 总结虽然有很多不同的插件 API，但存储引擎 API 还是最重要的。如果能理解 MySQL 在存储引擎和服务层之间处理查询时如何通过 API 来回交互，就能抓住 MySQL 基础架构的精髓。 对 InnoDB 而言，一切操作都是事务。 Oracle 一开始收购了 InnoDB，而后收购了 MySQL，最终导致了两者的融合。 MySQl 基准测试基准测试（benchmark）是 MySQL 新手和专家都需要掌握的一项基本技能。简单地说，基准测试是针对系统设计的一种压力测试。本章讲讨论基准测试的重要性、策略和工具。我们将特别讨论一下 sysbench，这是一款非常优秀的 MySQL 基准测试工具。 为什么要做基准测试基准测试是唯一有效的、可以学习系统在给定的工作负载下会发生什么的方法。 基准测试的问题是这不是真实压力的测试，真实压力不可预期而且变化多端。测试工具的局限会影响结果的有效性。 使用基准测试对容量的余量进行规划，也不能简单地把基准测试里得到的 tps 增长看作容量的增长。 基准测试的策略对系统进行测试，即 full-stack。单独测试 MySQL，即 single-component。尽量做 full-stack 测试，因为： 用户关注的是整个应用的性能 MySQL 并非总是应用的瓶颈，如何揭示瓶颈？ 只有对应用做整体测试，才能发现各部分之间的缓存带来的影响。 整体应用的集成测试更真实 尽量使用生产真实数据的拷贝。 测试何种指标吞吐量（throughput）单位时间能够处理的事务数，是最重要的需要关注指标。 响应时间（response time）因为应用本身的响应时间本身是受各种因素影响而波动的，所以大部分情况下关注 top percentile 90 之类的指标即可。可以用图表来关注这些指标。 并发性（concurrency）MySQL 的并发性不同于应用的并发性。应用的并发性通常指可以同时存在多少个会话，MySQL 的高并发则关注到底可以同时存在多少个数据库连接。很多时候并发性测试并不是寻找某个指标，而是看特定的并发性的前提下（如 128 个 server 线程），到底能够达到多大的 tps 和 rt。 可扩展性（scalability）在业务压力变化的情况下，可以测量增大系统的业务压力（或者提供更好的软硬件配置），吞吐量是不是也能线性增加（即是不是可以直接 scale up）。 大部分系统通常不能线性增加性能。 基准测试方法应该避免一些常见的错误： 使用真实数据的子集而不是全集。 使用错误的数据分布。 使用不真实的分布参数。 在多用户的场景中，只做单用户的测试。 在单服务器上测试分布式应用-同样地，不要用单线程来测试多线程应用。 与真实用户行为不匹配。 反复执行同一个查询。 没有检查错误。 忽略了系统预热。 使用默认的服务器配置。 测试时间太短。 测试要掌握业务的全貌，应该关注： 注意 normal case 的分布，注意这些分布肯定不是均匀分布，所以真实的差异性流量是很必须的，这也导入了 corner case。 如果流量和身份有关，则应该注意流量构成的差异。 应该注意错误日志。 设计和规划基准测试对于 OLTP 型业务，可以考虑 TPC-C；对于 OLAP 和即席查询的业务，可以考虑 TPC-H。 应该写下详细的测试规划，记录规划里的参数和预期的返回值。 基准测试应该运行多长时间为了到系统稳定为止，应该运行尽可能长的时间。 获取系统的性能和状态要定期地快速采样整个系统的性能快照（类似 JMX/top 方案，把系统的性能的涨落寻找出来）。 获得准确的测试结果对 IO 密集型（IO-Bound）应用，不要采用 CPU 密集型（CPU-Bound）应用的测试标准。 确认测试结果是否重复，每次重新测试之前要确保系统的状态是否是一致。有必要的话要重启系统。 如果测试以前要改数据或者 schema，要注意用快照还原数据库。插入不同数量级的数据造成的磁盘碎片度和在磁盘上的分布肯定不同。一个确认磁盘数据的分布尽可能一致的方法是，每次都进行快速格式化并进行磁盘分区复制。 基于默认的配置进行测试通常没有意义，因为默认配置是基于消耗很少内存的极小应用的。 如果测试中出现异常数据，不要轻易地当作坏数据点进行丢弃。 运行基准测试并分析结果要把“数字”变成“知识”。 绘图的重要性考虑使用 gnuplot。 基准测试工具集成测试工具 ab 最简单 http_load JMeter 复杂很多，但对集成测试已经够用 单组件式测试工具 mysqlslap 随着 MySQL 本身发布，可以根据 schema 生成 SELECT 语句，测试可以执行并发连接数，并指定 SQL 语句。 sql-bench 单线程测试，自带测试用例。 Super Smack Database Test Suite Percona’s TPCC-MySQL Tool sysbench 全功能测试工具，它可以测试 cpu 性能（通过计算素数），磁盘 io 性能（通过模拟文件读写），db 性能（只要指定好 db 的文件夹和数据库）。 服务器性能剖析测量服务器的时间花在哪里的工具是性能剖析技术。 应该抱有空杯心态，抛掉一些对性能的常见误解。 性能优化定义对性能的定义有很多种，如吞吐量、响应（延迟）时间等。原则一、性能即响应时间（Response Time）。我们可以简单地采用一种方案来定义提升性能，就是看特定的工作负载下，降低响应（延迟 latency）时间。吞吐量比响应时间更容易测量，但测量响应时间更容易让我们的系统得到优化。 资源是用来消耗的。纯粹地降低资源的消耗不一定就能提高性能。高版本的 InnoDB 有更多的 CPU 利用率，并不是它性能变差了，可能反而性能变好了（CMS、G1 等 JVM 垃圾收集器同理）。 如果降低响应时间，得到的一个副产品就是系统的吞吐量提升了（通常，工作线程的可复性用变高了）。 原则二、无法测量就无法有效地优化。不要把时间花在修改东西上，应该把时间花在测量响应时间上（实际上修改东西也需要反复测试，盲目地修改等于盲目地反复测试，是一个线性复杂度的工程师时间浪费）。如果通过测量没有得到答案，那么要么测量的方式错了，要么测量得不够完整。与其把 90% 的时间花在修改系统上，不如把 90% 的时间花在测量上。 完成一项任务的时间通常可以分为两个部分：执行时间和等待时间。执行时间的优化方法，是优化子任务的执行频率、效率和并行度。等待时间的优化方法则复杂得多，需要很强的诊断工具。 测量通常是错的，例如多数的测量不是全量采样，多数的测量也只是系统的间断快照，而不是连续的快照。重点是测量有多不准确。 通过性能剖析进行优化profiler 的工作方式总是相似的：在任务启动时启动计时器，在任务结束时停止计时器，然后减去不同的时间得到响应时间。 响应时间的统计结果通常包括： 排名 调用次数 （平均）响应时间 执行时间 等待时间 （有可能的话）执行结果 很多时间我们既要做基于执行时间的分析，也要坐基于等待时间的分析。但很多时候系统本身不提供很细致的内部测量点，所以我们并不能真的分析出一个响应时间内部，执行时间占多少，等待时间占多少。例如，我们并不一定知道，一个 sql 执行的时候，磁盘 io 的等待时间是多少。 理解性能剖析只理解总计和平均值，会缺失很多信息。如： 值得优化的查询（worthwhile query）：如果一个优化花了 1000 美元，却没有带来任何业务收益。其实等于做了一个 1000 美元的逆优化。 异常情况：即使没有做过 profiling，也有些问题需要解决-当然如果有办法做全链路跟踪，没有 profiling 的死角的话，可以不考虑这个问题。 未知的未知（unknown-unknown，拉姆斯菲尔德的笑话）：工具总有局限性，只能在一定精度内说明问题。 被掩藏的细节：平均值不能说明问题。我们更多地需要直方图、百分比、标准差等等工具。 对应用程序进行剖析对性能的剖析建议还是自上而下进行。这样可以追踪用户发起到服务器响应的整个流程。 性能瓶颈可能有很多影响因素： 外部资源：比如调用了外部的 web 服务或者搜索引擎。 应用需要大量时间处理的数据，比如分析一个超大的 xml 文件（或者查询一张超大的表并且返回结果也超大）。 在循环中执行昂贵的操作，比如滥用正则表达式。 使用低效的算法。 性能剖析会让系统变慢吗？局部来看，会。因为性能剖析总有开销（例如，Visual Studio 构建出的程序有 debug 的版本和 release 版本，debug 的版本里带有测量点，因此更慢一些）。全局来看，不会，因为性能剖析最终会让我们设计出更快的程序。 好的监控工具应该可以全天候测量应用程序的性能（在任何时间、任何环境）。 MySQL 企业监控器可以提供查询的性能。通常这类工具不是在库里实现（如美团的 zebra 里的内部打点），就是在代理层实现（如架设一个 MySQL proxy，当然这本书的作者不建议这样做）。 剖析 MySQL 查询剖析服务器查询服务器端的剖析很有价值，因为在服务器端可以有效地审计效率低下的查询。 如果只是需要找出代价高的查询，可以使用慢查询日志（尽管 MySQL 提供了很多的的测量点）。 当代的 workbench 可以很方便地查看某个 server 的 status，间接地提供 profiling 的功能。 捕获 MySQL 的查询到日志文件中MySQL 的慢查询的日志精度最高、开销最低。性能开销可以忽略不计，但对硬盘的大小有要求，这要求我们打开 log rotation 工具。 MySQL 同样支持通用查询日志（general query log），但对性能剖析没有什么时机作用。 如果因为某些原因，无法在服务器上记录查询（也就是看不到慢查询日志），那么还有两种替代方案： SHOW FULL PROCESSLIST。查看慢查询、慢事务，进而 kill 查询、kill 事务。可以考虑使用 pt-query-digest。 通过 tcp 抓包，然后解析。可以考虑使用 tcp-dump + pt-query-digest。 分析单条查询三种方法，show status、show profile 和检查慢查询日志的条目。 show profile show profiles 其实是一种查表的方案。 除此之外，还可以使用show engine innodb status（结果只有一个 value），也可以查看当前存储引擎执行结果的一些统计数据 counter，比如事务的锁持有数据。 workbench 里的 server status 和 status and system variables 也可以看到系统变量（其实计数器就是一种特殊的变量）。 show statusshow status 其实是显示一组计数器，既包括全局级别（global）的计数器，也包括会话级别（session）的计数器。 读懂这些计数器，需要读懂 innodb 的数据结构。 show status 其实也是一种查表的方案。 使用慢查询日志我们使用 explain 得到的结果是评估出来的查询性能结果。而使用慢查询日志得到的是实际执行的查询情况，可以很方便地读到实际的查询结果。explain 无法解释系统发生抖动，而 slow query 却可以。 使用特殊的工具，如 pt-query-digest，可以把它转化为查表的形式。 使用 performance schema另一种正在快速开发中，代表未来发展方向的性能剖析方案。 还是一种查表的形式。 使用性能剖析server profiling 和 query profiling 可能都可以给性能优化提供帮助。用户需要对服务器如何执行查询有较深的了解。剖析报告应该尽可能多地收集需要的信息，给出诊断问题的正确方向。 但也有很多时候我们无法得到可靠的优化建议，因为： 我们可能只关注了 server profiling 而忽略了query profiling。 我们可能测量的只是查询开始之前的计数器，而不是查询开售的数据。 可能备份正在执行 可能发生了某种类型的 lock contention 或者其他争用。 诊断间歇性问题幻影问题，往往难以重现，而且需要观察几个月。乱枪打鸟式的乱试，或者随机修改服务器配置来试图侥幸地找到问题，是人之常情，却也是危险的。试错不仅浪费时间，而且可能有可能让问题变得更坏。 单条查询问题还是服务器问题服务有整体变慢吗，还是只有单条查询变慢？ 服务器的问题非常常见，特别是老版本的 MySQL 既不适合 SMP 服务器，又有一定的扩展性限制。通常升级新版本的 MySQL 可以解决如上问题，但一旦出现问题，需要对新版本的更复杂机制有所了解。 如何判断是单挑查询问题还是服务器问题？如果问题周期性地出现，那么可以在某次活动中观察到（比较常见），或者整页运行脚本收集数据，第二天来分析结果。 此外，还有三种常见技术： 使用 SHOW GLOBAL STATUS最好每秒执行一次，列出类似查表的数据，然后使用 awk 工具截取变化的变量，形成类似 jstat log之类的分段涨落数据。 使用 SHOW PROCESSLIST最好也可以频繁执行，列出类似查表的数据，它对线程、连接的统计有很好的效应。 如果 MySQL 版本较新，可以查询 INFORMATION_SCHEMA 的 PROCESSLIST表；或者使用 innotop 工具以较高频率刷新。 使用查询日志（query log）如果有必要，打开 long_query_time = 0 的标记，记录所有的查询。但这个配置需要重置所有连接才能全局生效（除非使用 percona 的版本，可以强制在不断开连接的前提下，自动刷新配置）。 捕获诊断数据如何尽可能多地收集数据，而不是恰好搜集到问题出现时的数据（特别是很容易收集不到）？ 我们至少需要： 一个可靠而且实时的“触发器”，也就是能区分什么时候问题出现的方法。 一个收集诊断数据的工具。 诊断触发器需要收集什么样的数据在 GNU/Linux 平台，可以考虑 oprofile、strace、tcpdump。如果MySQL 内部线程卡在一个地方很长时间，往往都有相同的堆栈跟踪信息。这时候可以先启动 gdb，然后 attach 到 mysqld 进程，将所有线程的堆栈都转储（dump）出来。可以使用sort | uniq | sort等命令来排序出总计最多的堆栈信息。 解释结果数据这一节细节太多，还是要读原文为准。 其他剖析工具使用 USER_STATISTICS 表如果我们执行如下语句，可以看到 MySQL Percona 的 InnoDB 内核里有一些内置表（最初由谷歌开发的）： 使用 stracestrace 是另一个可以拿来度量系统调用的时间。例子： 总结值得总结的东西还是前面提供的东西： 定义性能最有效的方法是响应时间 无法测量就无法优化 测量的最佳开始点是应用程序，而不是数据库 大多数系统无法完整地测量，测量有时候也会有错误的结果。 完整的测量会产生大量需要分析的数据，所以需要用到剖析器。 剖析是一种汇总信息，掩盖和丢弃了太多的细节。 有两种消耗时间的操作：工作和等待。 优化和提升是两回事。 注意你的直觉，但应该只根据直觉来指导解决问题的思路，而不是用于确定的问题。决策应当尽量基于数据而不是感觉。 Schema 与数据类型优化良好的逻辑设计和物理设计是高性能的基石。反范式的设计（计数表、汇总表、索引表）可以加快某些类型的查询，也可以使另一些类型的查询变慢。比如添加计数表和汇总表是一种很好的查询优化方式。 通常，我们要做 normalization，有时候要做冗余设计。 选择优化的数据类型 更小的通常会更好。通常更小的数据类型有更小的数据开销。 简单就好。使用最适配的数据类型通常比使用某些 hacky 的数据类型要好。 尽量避免 null。很多列的默认值都是 null（即使没有显式地指定 default null）。通常情况下指定 not null 意味着我们选择性地回避了 null 的陷阱。查询中允许为 null 的列，索引本身的结构会比较复杂，查询的结果有时候也会出现反直觉的设计。 SHOW CREATE TABL展示的是基本类型（的正式名称），而不是别名。 整数类型整数（whole numer）包括： TINYINT 8 位 SMALLINT 16 位 MEDIUMINT 24 位 INT 32 位 BIGINT 64 位 整数类型有可选的 UNSIGNED 属性，表示不允许负值。有符号和无符号使用同样的存储空间，所以无符号数的取值范围更大。 实数类型MySQL 支持不精确类型（ FLOAT 和 DOUBLE 浮点数，使用浮点运算进行近似计算），也支持精确类型（DECIMAL）。 浮点运算被 cpu 原生支持，所以性能更好。DECIMAL 的支持是被 MySQL 内部通过自身实现支持的。 存储财务数据时，应该尽量使用 DECIMAL 或者 BIGINT。 字符串类型 VARCHAR 可以变换存储空间的长度（除非指定了 ROW_FORMAT=FIXED），所以通常会更加节省存储空间。行总是存在数据页里面的，varchar 如果扩容，会导致数据页分裂。CHAR 则总是定长的适合存储很短，定长或者近乎定长的字符串，如 MD5。 有 VARCHAR 就有 VARBINARY。二进制数据和字符串数据的区别在于字符串数据有字符集和校对规则。 BLOB 和 TEXT 类型BLOB 和 TEXT 在 MySQL 里单独存储为对象的。 使用 BLOB 和 TEXT 会有可能会导致磁盘临时表（disk temp table），有必要的话可以考虑内存临时表（heap temp table）。如果 EXPLAIN 执行计划的 Extra 列包含“ Using Tempory”，则说明这个查询使用了隐式临时表。 日期和时间类型5.5 的 MySQL 的最小时间粒度是秒。 DATETIME与时区无关，使用 8 字节存储。可以使用 ANSI 的标准时间定义格式，如“2020-01-01 00:00:00”。 TIMESTAMP与时区有关，指的是 Unix 的描述（可以使用 FROM_UNIXTIME 函数转换为日期），使用 4 字节存储。 BIT最好不要用，很难理解和处理 选择标识符即 PK 列： 整数类型，整数通常是最好选择，而且可以使用 AUTO_INCREMENT。 ENUM 和 SET 是糟糕的选择。 应该避免使用字符串类型，因为他们很消耗空间。MyISAM 通常使用压缩索引，这导致查询慢很多。 尽量少用随机字符串，如 MD5()、SHA1（）。因为这些函数生成的新值会分布在很大的空间内。这会导致一些 select 语句变得很慢，而且 INSERT 变得更慢，这会导致页分裂，磁盘随机访问。会导致缓存的局部性原理失效，因为冷热数据的空间分布太不均匀。这种方案的唯一好处是可以消除热点。 特殊数据类型IP 地址类型与其用 VARCHAR，不如直接用整数存储。可以考虑用 INET_ATON() 或者 INET_NTOA()-但如果使用了 ORM 框架，这种方案反而会比较难用。 MySQL schema 设计中的陷阱 太多的列：MySQL 的存储引擎 API 和 server 层之间有一个行缓冲区。太多的列会使得行缓冲区转换出关键的行消耗过多的 cpu。 太多的关联。EAV（实体-属性-值）是一种常见的糟糕设计模式。EAV 很容易导致自关联（self-join）。MySQL 限制关联不能超过 61 张表，最好的实践是在 12 张表里做关联。- 更好的实践是不要关联。 慎用枚举。增加枚举值要 alter table，会导致全表锁这样的阻塞操作。 慎用 set。问题和枚举差不多，而且和枚举一样会让业务代码复杂。 慎用 null- 但有时候用 magic number 不如 null，null 可以代表未知值。如 datetime 的“0000-00-00 00:00:00”。 范式和反范式对任何给定的数据，通常都有很多种表示方法，从完全的范式化到完全的反范式化，以及两者的折中。在范式化的数据库中，每个事实数据会出现且只出现一次。相反，在反范式的数据库中，信息是冗余的，可能会存储在多个地方。 冗余会导致数据不准确-“一个人有两块表，他就永远不知道时间。” 范式的优点和缺点优点： 通常性能更好 不容易有冗余引起的逻辑错误 缺点： 切范式会导致 join，join 可能性能不好 - 这在 ES 上表现得尤为明显。 反范式化的优点和缺点如果有两张表 join 起来的成本很高，把它们合成一张宽表（用合表的方式实现 join），加上索引，可以显著提升相关的查询效率。 这个章节里举了一个例子，在同时使用 where 和 order by limit 索引，查询优化器有可能走 order by 的索引，而不是 where 的索引，这样做不是基于基势的二分查找，效率可能和全表扫描差不多。 接下来它举了一个优化的例子，把 where 和 order by 的两列写在一个联合索引里，这样不用回表就完成了查询和排序（甚至只在存储引擎层就可以这样做）。 混用范式和反范式纯洁的范式和反范式只出现在实验室里（正如教学用的模式和架构只出现在课本上一样）。 最常见的反范式化数据是复制或者缓存，这些冗余的数据可以通过触发器级联更新，但更好的方案是选择不常被更新的列。很多时候为了排序的需要，我们需要把数据从一张表冗余到另一张表。 缓存表和汇总表有时候提升性能最好的方法是在同一张表中保存衍生的冗余数据。然而，有时候也需要一张完全独立的汇总表或者缓存表（特别是为满足检索的需求时）。 我们指的缓存表是可以比较简单地从 schema 的其他表获取（但每次获取的速度比较慢）数据的表。 而汇总表则保存的是使用 GROUP BY 语句聚合数据的表。也有人使用术语“累积表”（Roll-Up Table）来称呼这些表。 以网站为例子。我们可以为网站准备一个计数器表，记录每个小时的发送消息数。虽然不能保证计数器 100% 精确，但比实时维护计数器精确得多。实时计算统计值总是很昂贵的操作，要么必须扫描表中的大部分数据，要么查询语句只能在某些特定的索引上才能有效运行，而这类索引一般会对 UPDATE 操作有影响。计算最活跃的用户或者最常见的“标签”是这种操作的典型例子。而缓存表则对优化搜索和检索查询语句很有效。 除此之外的优化方法还有： 对缓存表使用不同的存储引擎 把缓存表导入专门的搜索系统 在使用缓存表和汇总表时，必须决定是实时维护数据，还是定期重建-其实还要考虑是增量重建，还是全量重建，如果使用全量重建，整张表的存储碎片会少很多。 当重建汇总表和缓存表时，通常需要保证数据在操作时依然可用。这就需要通过影子表来实现，通常影子表的实现为： 这样 a_old 里还存留有老的数据，有问题可以很容易地进行快速回滚操作。 物化视图（MV - Materialized Views）MySQL 不天然支持物化视图，SQL Server 和 Oracle 支持。MySQL 的解决方案是 Flexviews。 参考《MySQL物化视图方案 FlexViews》： Flexviews 是 MySQL 5.1 的存储过程解决方案，主要用来创建物化视图，支持表关联和大多数 MySQL 的聚合函数。 物化视图 (MV - MaterializedViews)在一个段中存储查询结果，并且能够在提交查询时将结果返回给用户，从而不再需要重新执行查询 —在查询要执行几次时（这在数据仓库环境中非常常见），这是一个很大的好处。物化视图可以利用一个快速刷新机制从基础表中全部或增量刷新。 Flexviews 支持从 SQL 转换为 Flexviews 的 API 的调用，类似 MapReduce。它可以分析 binlog，增量而不是全量地分析数据。 计数器表应用中经常需要计数，但在更新计数器时可能碰到并发问题。 计数器表的几种形态： 只有一列的计数器表，每次更新的时候事务严格串行：set count = count + 1。这个语句不会有写丢失的问题，但多事务并发更新一行性能非常差。 一行记录有两列，一列槽，一列计数器，每次更新的时候随机执行：set count = count + 1 where slot = RAND() * 100。这样可以一定程度提高性能，但查询真正的总数时，需要select sum(count)。 可以加上日期 date 作为更高层的分区列。 使表有 upsert 的能力（insert 可以用 ON DUPLICATE KEY 来来避免 integrity exception）：INSERT INTO DAILY_HIT_COUNTER(day, slot, cnt) VALUES(CURRENT_DAY, RAND() * 100, 1) ON DUPLICATE KEY UPDATE cnt = cnt + 1。 如果希望减少表的行数，以避免表变得太大，可以写一个周期执行的任务，合并所有的结果到 0 号槽，并且删除所有其他的槽： 加快 ALTER TABLE 的速度MySQL 的 ALTER TABLE 操作的性能对大表而言是个大问题。MySQL 执行大部分表结构操作的方法是用新的结构创建一个空表。从旧表中查出所有的数据插入新表，然后删除旧表。这样操作需要很长时间，而且很耗内存。 因此诞生了一种 online ddl 的方案。这些功能不需要在整个操作过程中锁表。 但一般而言，大部分 ALTER TABLE 操作会导致 MySQL 的服务中断（因为锁表）。 其基本思路有： 在一个不提供服务的从库上执行 alter table 操作，然后和主库进行切换； 影子拷贝（ghost 表），创建一张和原表无关的新表（需要考虑验证和同时插入的问题），然后在一个事务里通过重命名和删除表操作交换两张表。 大部分的改表工具是使用方法 2。 有时候直接 alter table 会导致大量的读和插入。但 alter column 会直接改 .frm 文件。 还有另一个巧妙变更 .frm 文件的方法： 创建一张有相同结构的空表，并进行锁需要的修改（例如增加 ENUM 常量）。 执行 FLUSH TABLES WITH READ LOCK。这将会关闭所有正在使用的表，并且禁止任何表被打开。 （通过操作系统命令）交换 .frm 文件。 执行 UNLOCK TABLES 来释放第 2 步的读锁。 快速创建 MyISAM 索引这个方法的中心思想是通过排序创建索引，这样创建索引更快且更紧凑-但现实中恐怕不会有很好的收益。 如果有索引没有建好，可以用 REPAIR TABLE 来重建索引。 创建高性能的索引索引（MySQL 中也叫作键（key））是存储引擎用于快速找到记录的一种数据结构。 索引基础索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要。因为 MySQL 只能高效地使用索引的最左前缀列。 因为索引过于复杂，所以简单地使用 ORM 往往不能有效地利用索引。 索引的类型在 MySQL 中，索引是在存储引擎层而不是服务器层实现的。所以不同的存储引擎实现的索引是不一样的。 B-Tree 索引大多数存储引擎都支持 B-Tree 索引。但 InnoDB 使用 B+Tree 索引。 存储引擎以不同的方式使用 B-Tree 索引，性能也各有不同。MyISAM 使用前缀压缩技术使得索引更小，但 InnoDB 则按照原数据格式进行存储。再如 MyISAM 索引通过数据的物理位置引用被索引的行，而 InnoDB则根据主键引用被索引的行（寻址问题）。 B-Tree 通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同（意味着 B-Tree 的深度对每个叶子而言是均衡的）。 B-Tree 索引能够加快访问数据的速度，因为存储引擎不在需要进行全表扫描获取需要的数据。 B-Tree 的叶子节点都存在于逻辑页中，不同的存储引擎的逻辑页大小不一样，InnoDB 为 16k。 B-Tree 索引对索引列是顺序组织存储的，所以很适合查找范围数据（所以我们做查询也应该尽量寻找范围查询的机会）。 B-Tree 索引适用于全键值、键值范围或建前缀查找。 全值匹配：全值匹配是指和索引中所有列进行匹配-索引有三列，匹配条件也有三列。 匹配最左前缀：即只使用索引的第一列。 匹配列前缀：只匹配某一列的值的开头部分。 匹配范围值：只查找第一列的某个范围里的值。 精确匹配某一列并范围匹配另一列：范围查询的列的右边的列都无法使用索引。（MySQL 无法很好地处理索引跳跃问题。） 只访问索引的查询：即覆盖索引。 因为索引树种的节点是有序的，所以如果 ORDER BY 子句满足前面列出的几种查询类型，则这个索引也可以满足对应的排序需求。 哈希索引哈希索引基于哈希表，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码。不同行的哈希码不一样。哈希表中存的是哈希码（而不是实际值）和每个数据行的指针。 只有 Memory 引擎显式支持哈希索引，而且它支持非唯一哈希索引。 哈希索引有如下缺点： 只包含哈希值和行指针，所以无法触发覆盖索引。不过 memory 中寻址很快，影响不明显（访问硬盘则不然）。 无法使用排序（因为既没有使用具体值，也没有按照具体值的顺序组织排列数据） 不能使用部分列匹配 因为没有存储实际值，所以哈希所以不支持 in、&lt;&gt;、&lt;=&gt;等操作，当然也不支持范围查询。 数据仓库中的“星型”schema，需要关联很多查找表，很适合使用哈希索引。 InnoDB 引擎有一个特殊的功能叫作“自适应哈希索引”（adaptive hash index）。InnoDB 注意到某些索引值被使用得非常频繁时，它会在内存中基于 B-Tree 再创建一个哈希索引。这是一个用户完全无法控制的行为。 创建自定义哈希索引：在 B-Tree 基础上创建一个伪哈希索引。 举例，varchar 的 url 上的字符串会很长，但如果有个 url_crc 列，则直接查询 crc32 的值，性能会比直接查 url 高很多（因为索引体积小而选择性（selectivity）很高）。即： 这种伪哈希索引的缺点是，必须使用触发器维护哈希值。 如果维护伪哈希值，则不要使用 sha1 和 md5 之类的强加密函数，它们的目的是为了尽最大可能消除冲突，所以生成的字符串通常会非常长。 crc32 生成的散列值可能会产生大量冲突（因为生日北仑，出现哈希冲突的概率可能比想象中快得多），所以查询必须带上原始列值（否则如何处理相同的哈希值呢？）。一个比较适中的方案是自己实现一个简单的 64 位哈希函数-返回整数而不是字符串，可以通过对 md5 进行截断实现：select conv(right(md5(&quot;www.mysql.com&quot;), 16), 16, 10)。 空间索引（Spatial Index）使用的数据结构是 R-Tree。这是一种全维度的索引，但只能使用在地理信息查询场景下。MySQL 的 GIS 相关功能并不完善（推荐 PostgreSQL 的 PostGIS）。 全文索引（fulltext Index）它的工作机制和其他所有索引都不一样。它查找中的是文本中的关键词，而不是直接比较索引的值。它不是简单的 where 匹配，而是在干类似搜索引擎的事情（被称为 match against）。 其他索引类别TokuDB 使用的其实是分形树索引（fractal trees index），它相当于 B-Tree 索引的升级版。 索引的优点B-Tree 按照顺序存储数据，相关的列值会存储在一起，所以能够支持 order by 和 group by。 索引有如下优点： 索引大大减少了服务器要扫描的数据量。 索引可以帮助服务器避免排序和临时表。 索引可以将随机 I/O 变为顺序 I/O。 可以参考三星系统（three-star system）来评价一个索引是否足够好： 索引将所有的记录放在一起则得到一星。 索引的数据顺序和索引在查找中的排列顺序一致则获得二星。 如果索引中的列包含了查询中需要的全部列则获得三星。 对于小表，索引不如全表查询；对于中大型表，索引优于全表查询；对于超大表，可能要引入分区表-或者按照现在的做法，使用分表。 高性能的索引策略独立的列如果查询的列不是独立的，则 MySQL 就不会使用索引。“独立的列”指索引不能是表达式的一部分，也不能是函数的参数。因为表达式或者函数不能简单地应用到 B-Tree 的搜索里。所以好习惯应该是始终把索引列单独放在比较符号的一侧，所有的函数、转换，放在另一侧。 前缀索引和索引选择性如果列值太长怎么办？一种解决方法是使用前文提到的伪哈希索引。 另一种方法是只索引开始的部分字符。到底索引效率多高，由可选择性决定（间接由基数决定）。 假设使用一列的全部内容的选择性为 x，则前缀索引的可选择性应该尽可能接近 x。这种比对就要求我们不断地 select count(left(指定列,前缀长度))/count(*)比对select count(指定列)/count(*)。 确定了索引长度以后，这样指定前缀索引： 前缀索引和哈希索引一样，是一种不精确存储值的索引，所以不能拿来排序和分组。 通常情况下，BLOB、TEXT 和特别长的 VARCHAR 是需要使用前缀索引的。一个典型的的应用场景，是使用前缀索引来索引很长的 16 进制唯一 id。 某些情况下，后缀索引也是解决问题的妙招。MySQL 不支持后缀索引（即不支持 使用 RIGHT(key, 5)这类语法建 key）。但可以通过反转字符串来建索引的方法，巧妙地解决这个问题。 多列索引不要为每个列创建相应的索引。有一些专家建议“应该为 where 中的所有列都加上索引”。但这种建议是非常错误的。这样建索引，充其量能够创建出一个一星索引。记住，好的索引和优秀的索引的查询性能可能差几个数量级。即使我们无法创建三星索引，我们也应该尽可能优化索引顺序和创建覆盖索引。 正确的做法是针对这张表的所有查询的最大公约数列建索引。 在 MySQL 在 5.0 引入了一种叫“索引合并”（index merge）的策略，一定程度上可以用表上的多个单列索引来查询指定的行。 大意是： 如果有一个 sql 类似where a = 1 or b = 2，or 的存在使得 mysql 不能直接使用索引。通常需要让用户转化为这种 union 查询： 但对于支持索引合并的 MySQL，使用原始的 SQL 可以使用一个钟 type 为 index_merge 的查询。 对此，本书提出了几个观点： 对多个查询条件相交的查询，意味着单列查询的索引创建得很糟糕，应该尽量创造多列索引。 对多个查询条件合并的查询，需要使用大量的 CPU 和内存资源来缓存、排序和合并。 优化器不会把这些资源消耗计算到查询成本（cost）中，优化器只关心随机页面读取。有时候这种查询还不如全表扫描，这时候还不如手动地将查询改成 union 为好。 如果在 explain 中看到索引合并，应该好好检查一下查询和表的结构，看看是不是已经是最优策略。可以通过参数 optimizer_switch 来关闭索引合并功能。也可以使用 ignore index 提示来让优化器忽略掉某些索引。 更多例子可以参考《 MySQL 优化之 index merge(索引合并) 》。 当代，使用 or 的查询已经不必转化为 in，也会自动把索引合并转化为 range 之类的查询。 选择合适的索引列顺序正确的索引顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组需求（这种讨论通常仅限于 B-Tree 索引，因为只有它是按照顺序存储数据的）。 在一个 B-Tree 索引中，索引列的顺序意味着索引首先按照最左列排序，其次是第二列，以此类推。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的排序、分组和 DISTINCT 子句的查询需求。 有一个经验法则：将选择性最高的列放到索引最前列。但这并不适用于所有场景-场景不同，选择可能也不同。 通常而言，将选择性最高的列放在前面通常是很好的。但性能实际上不止和所有索引列的选择性（整体基数），也和查询条件的具体值有关，也就是和值的分布有关-这可能会导出一个局部基数的概念。 可以使用 sarg 方法： 来确认到底对于具体的值而言，到底是 a 更少还是 b 更少（注意，这里看到局部基数的时候，关注的是小的结果集，而不是大的差异度）。 当然，这种依赖于具体值的查询可能对于所有查询而言是不公平的。除非我们有工具（诸如pt-query-digest）可以找出最差的查询出来优化。否则我们应该尽量基于全局基数和选择性，来设计我们的索引顺序。 这一节的基本原则归纳如下： B-Tree 索引本质上是支持范围查找的数据结构。 索引查询的最优场景是能够通过等值查询最快地找到组合查询条件的结果，所以整体基势高的列放在索引列的前缀搜索路径更短。 但如果出现局部基势不平衡的状况的话，则需要慎重地考虑查询查询的主要场景。一个经典的例子是，基于时间和状态的查询。通常状态的基势要比时间要低，但直接将状态作为前缀，在某些场景下搜索比将时间作为前缀更快（因为特定状态的局部基势特别小）。所以这时候可能要设计两种前缀策略的索引，在不同的查询场景下单独使用。举例就是，大的范畴（sex、gender、country、status） 更适合作为索引前缀，如果有遇到不需要大范畴的查询，可以考虑in (&#39;M&#39;, &#39;F&#39;)来使用最左前缀索引。 而另一方面，像 date、age 之类经常进行范围查找的列，应该尽量放在索引的后面。 聚簇索引聚簇索引并不是一种单独的索引类型，而是一种索引组织方式。 具体的细节依赖于特定的实现方式（在 Oracle 中，这叫 index-organized table），InnoDB 的做法是，在同一个结构中保存了 B-Tree 索引和数据行。 当有聚簇索引的时候，表的数据行实际上被放在叶子页（leaf page，对应于节点页）上。因为无法将数据行放在两个不同的地方，所以一张表只能有一个聚簇索引。 一些数据库服务器允许指定哪个列为聚簇索引，MySQL 只能使用主键作为聚簇索引（如果没有定义主键，InnoDB 会选择唯一的非空索引代替）。 聚簇索引的优点： 可以把相关的数据保存在一起（因为主键相关联的数据会被存储在相近的地方），这样可以提高 IO 性能。 数据访问更快，从索引到数据行的寻址求值变快了。 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。 聚簇索引的缺点： 聚簇索引只能提高（磁盘）IO 密集型应用的性能。如果数据全部存在内存中，那么聚簇索引也没有什么优势了。 插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到 InnoDB 表中速度最快的方式。如果不按照主键的顺序加载数据，那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表。 更新簇聚索引的代价很大，相当于强制 InnoDB 将每个被更新的行移动到新的位置。 当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行。 聚簇索引可能导致全表扫描变慢。尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。 二级索引可能比想象中大，因为二级索引的叶子节点包含了引用行的主键列。 二级索引访问需要两次索引查找，而不是一次。 InnoDB 和 MyISAM 的数据分布对比MyISAM 按照插入顺序来在磁盘上存储数据。MyISAM 的索引的 B-Tree 里是不包含表数据的。MyISAM 的二级索引直接包含指向数据行的“行指针 ”。 而 InnoDB 的 B-Tree 的叶子节点包含以下内容：主键值、事务 id 、用于事务和 MVCC 的回滚指针，以及所有的剩余列（如果索引是前缀索引，则 InnoDB 还会包含剩余的信息）。而二级索引只包含了簇聚索引的主键值，而不是行指针（这样做，如果出现簇聚索引的整理，不会触发二级索引的的更新）。 InnoDB 表中按主键顺序插入行如前所言，按照主键顺序插入行可以保证插入的性能最佳。但通常业务系统不能总是生成连续的顺序主键。所以可以定义一个代理键（surrogate key）（也就是我们经常提到的物理主键）。这种物理主键的数据和应用无关，最简单的方法是使用 AUTO_INCREMENT 自增列。 反过来说，大范围的随机聚簇索引对于 I/O 密集型应用是糟糕的。所以不要使用 UUID 来作为聚簇索引。这样产生的索引不仅插入时间更长，而且索引体积也更大（因为页分裂程度也变大了）。 顺序插入数据，每条记录总是在前一条记录的后面插入。当达到页的最大填充因子时（InnoDB 默认的填充因子是页大小的15/16），吓一跳记录会写入新的页中。 而非顺序的插入则有如下的缺点： 如果要修改的页已经从缓存中刷盘到硬盘上，需要从磁盘上读取目标页到内存中，这将导致大量的随机 I/O。 如果产生了页分裂，一次插入需要修改三个页而不是一个页。 页的数据可能变得稀疏，导致数据页有碎片。 顺序插入的唯一缺点是： 高并发的插入可能引发对 AUTO_INCREMENT_LOCK 的争用。 这个章节给我们的启示是，同样的一批数据，在 InnoDB 中完全可能成为不同的数据结构。最优的数据结构需要使用 optimize table 来获得。 覆盖索引如果使用包含所有需要查询的字段的值，我们称之为“覆盖索引”。 覆盖索引的好处是： 覆盖索引的条目（entry）小于数据的行（row）。扫描这种数据结构的访问量极小，对缓存的负载很重要。既不需要太多的内存，也不需要做太多的数据拷贝。 簇聚索引通常要回表，而覆盖索引减少了这种回表，减少了一次随机磁盘 I/O。 覆盖索引必须存储索引列的真实值。而哈希索引、空间索引和全文索引都不存储索引列的值。实际上只有 B-Tree 索引支持覆盖索引。 EXPLAIN 得到的列里面有“Using index”字样，则意味着覆盖索引生效。 如果索引能够覆盖 where，但覆盖不了 select，则 MySQL 会回表取所有的数据行（即使这一行本来不符合 where 条件，应该先在 index 查询时被过滤掉，这造成了实际上的随机I/O）。这个问题加重了 server 层的负担，只有依靠 index condition pushdown 来解决。 查询条件使用 * 无法使用覆盖索引，解决方案是延迟关联（deffered join）： 有了 ICP （Index Condition Pushdown）这一重大改进以后，很多上面提到的优化技巧可能不再需要了。 使用索引扫描来做排序MySQL 有两种方式可以生成有序的结果： 通过排序操作-Order By； 或者按照索引顺序扫描；如果 EXPLAIN 出来的 type 列的值为“index”，则说明 MySQL 使用了索引扫描来做排序。 能够满足索引扫描，又能排序的索引是最好的。 Order By 子句和查找性查询的限制是一样的：需要满足索引的最左前缀的要求；否则，MySQL 都需要执行排序操作，而无法利用索引排序。但有一种例外，如果 WHERE 子句或者 JOIN 子句中对这些列指定了常量，就可以“弥补”索引的不足。 如果使用多列索引，排序的时候多列的查找方向必须一致-因为索引排序的方向已经一致了。如果有 where a = 1， order by b 的语句，索引一定要加成 (a, b)。 压缩（前缀压缩）索引对于 MyISAM 而言，前缀压缩索引的工作方式是： 如果第一行出现了列值 perform，将其压缩为 7。 第二行出现了列值 performance，将其压缩为 7,ance。 压缩索引实际值并没有被直接存储，所以无法使用二分查找，总是必须使用正向全表扫描，所以对 DESC 的排序不友好。 冗余和重复索引重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引。应该避免这样创建索引。 MySQL 的唯一限制和主键限制，都是通过索引实现的。 应该尽量扩展已有的索引，而不是创建新索引。如已有一个 (A) 索引，可以直接扩展为 (A, B) 索引。 因为二级索引的叶子节点包含了主键值，所以在列 (A) 上的索引就相当于 (A, ID)。而且这里的 ID 基本上可以当作一个最左前缀索引使用。 未使用的索引未使用的索引应该删除-保持唯一约束的索引除外。 索引和锁索引可以让查询锁定更少的行。InnoDB 只有在访问行时才对其加锁，而索引能够减少 InnoDB 访问的行数，从而你减少锁的数量。 具体工作原理是： 如果能够在存储引擎层过滤掉不需要的行-即 where 的语句全部能够由索引做判断，则只锁定结果行（对 select 和 update 皆如此）。 如果不能过滤掉相关的行，则 server 层会锁定相关的行。在早期版本的 MySQL 里，2PL 的加锁会导致整个事务结束才释放无用的行；但 5.1 以后的 对 MySQL 5.1 及以后的版本而言，只要一过滤掉该行，该行的锁定就会被释放。 一般而言，如果 EXPALIN 的结果出现了 Using where，需要考虑多出来的锁定行。 索引案例学习支持多种查询条件经典的索引设计应该是(sex, country, region, city, age)。 范围查询应该放在索引的最后。 如果有查询不能遵循最左索引的匹配原则，则考虑使用 in (‘m’, ‘f’) 来触发最左匹配。 对于范围条件查询，MySQL 无法再使用范围列后面的索引列了；但使用 in 则没有这个限制。但 in 会导致大量的查询条件笛卡尔积出现，过多的查询条件笛卡尔积会让 MySQL 进行查询优化时消耗大量的内存，甚至会放弃 index dive。 避免多个查询条件应该尽量紧凑地使用 in 来优化复杂的查询，但对多个范围查询就很难处理了。 优化排序对于sex = &#39;M&#39; Order by rating limit 10;，创建(sex, rating)的索引，可以加速排序-换言之，查询条件和 order by的最左匹配可以搭配使用（rating 不需要在索引的最左前缀，只要它的最左前缀在 where 里被使用了就行了）。 防止翻页的方法另一个方法是用翻页来做内查询，只查出覆盖索引包含的主键值，然后再用覆盖索引的主键值来来进行外循环的查询。 维护索引和表找到并修复损坏的表最简单的修复表的方法是ALTET TABLE。 大部分让表损坏的操作，都是直接操作数据库文件的操作。单一的查询语句很难让 MySQL 损坏。 更新索引统计信息MySQL 的查询优化器通过两个 API 来了解存储引擎的索引值的分部信息，以决定如何使用索引：records_in_range()，不精确；info()，精确。 MySQL 使用基于成本的模型，而衡量成本的一个主要指标是评估需要扫描多少行。 MySQL 的统计信息可以自动更新。一旦关闭自动更新，需要定期地使用 ANALYZE TABLE 来手动更新。 减少索引和数据的碎片还是使用alter table。 总结尽量寻找三星的索引： 一星索引的含义是通过聚簇索引减少回表。 二星索引的含义是通过索引排序来减少查询排序。 三星索引的含义是用覆盖索引来减少回表。 查询性能优化查询优化、索引优化、库表优化需要齐头并进，一个不落。 在优化查询的同时，我们也要学习如何为高效的查询设计表和索引。 为什么查询速度会慢因为： 子任务太慢 子任务执行的次数太多 MySQL 从客户端到服务端再到存储引擎的步骤非常多。 慢查询基础：优化数据访问查询性能优化的基本原因是查询的数据太多。 是否向数据库请求了不需要的数据不需要的数据包括不需要的行，和不需要的列。 一些典型案例： 查询不必要的记录：使用 JDBC 查询全部的数据，只查询前面几条，就关闭结果集。这种情况需要使用 limit 优化。 多表关联时返回所有列：多表关联时应该使使用明确的表别名查询明确的列，而不应该直接查 *。否则会消耗大量无意义的内存、cpu 来处理这些结果列。 总是取出全部列：这样就无法使用覆盖索引。有些人为了代码片段的易用性而坚持这样做。 重复查询相同的数据：不断重复执行相同的查询，然后每次都返回完全相同的数据-这时候应该使用缓存。 MySQL 是否在扫描额外的记录在确定查询只返回需要的数据以后，接下来应该看看查询为了返回结果是否扫描了过多的数据。 对于 MySQL，最简单的衡量查询开销的三个指标如下： 响应时间 扫描的行数 返回的行数 响应时间响应时间 = 服务时间 + 排队时间 很多时候，排队时间很难以说明。但排队时间往往说明了服务的争用。 扫描的行数和返回的行数理想的情况下，扫描的行数和返回的行数应该是一样的。 扫描的行数和访问类型访问类型指的是：索引扫描、范围扫描、唯一索引查询、常数引用等。 rows 是 MySQL 预估要访问的数据行数。 我们应该尽量让扫描的行数等于返回的行数。 使用 where 有三重境界： 索引自己能够在存储引擎层过滤。 索引能够触发覆盖索引，where 剩下的部分在 server 层执行完，无需回表再查询数据。 （依靠索引）从数据表中返回（大部分的候选）数据，然后依靠 where 剩下的条件，过滤掉不符合条件的数据，这导致了大量的回表。 优化查询的三种基本思路是： 使用覆盖索引 改变库表结构，如使用汇总表、计数表、索引表 修改复杂的查询 重构查询的方式一个查询还是多个查询如果逻辑上有必要的话，不要畏惧把一个查询拆分成多个查询，现代的 MySQL 服务器的物理性能能够支撑大量的查询。这样就不是把所有的工作都交给数据库来做，而是由应用程序来承担一部分繁重的工作。 切分查询要对大查询分而治之，其实就是把大的执行流程拆分成小的执行流程。这样会产生小事务，小的事务日志，不会引起大面积的锁，也不会触发很大的主从延迟。 一个简单的例子是尽量分批删除数据（一万行是一个很好的颗粒度），而且最好能够在事务和事物之间进行select sleep(1)之类的操作。 分解关联查询分解关联查询可能是日常工作中最常用的技巧，其精髓在于使用 server 端的 in memory join 来代替 optimizer 的 join，这种 join 的灵活性更高。通常我们禁止直接在 MySQL 底层使用 join，server 端的 in memory join 成为了自然而然的替代品。 很多高性能的应用都会对关联查询进行分解。简单地，可以（每一次只）对每一个表进行单表查询，然后将结果在应用程序中进行关联。我们可以在一个 SQL 里对三张表进行大 join： 可以写成三个查询，从 tag 查起，然后查 tag_post，然后查 post。这样查有几个好处： 让缓存的效率更高。复杂的查询更稀有，而原子查询通常更容易被缓存（特别是热数据）。 将查询分解后，执行单个查询可以减少锁竞争-每个 statement 是一个单独的事务，锁的颗粒度变小了，持有锁的时间长度也变少了。 在应用层做关联，可以更容易对数据库做拆分。 查询本身的效率也会变高-通常单一的 JOIN ON 不如使用 in（）这种有跑徐的顺序查询效率高。 可以减少冗余记录。MySQL 的 nested loop join 本身可能会使内层循环重复访问一些数据。 更进一步，这样做其实在应用层实现了 hash join（这种 join 最好实现为 hashmap，或者直接上上一个查询的值填入下一个查询的 where 中，否则在 in memory 的实现里，也很容易实现为 nested loop join），在某些场景这比 nested loop join 效率高得多。 查询执行的基础 客户端发送一条查询给服务器。 服务器先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划。 MySQL根据优化器生成的执行计划，调用存储引擎的API执行查询。 返回结果给客户端。 MySQL 客户端/服务器端通信协议MySQL 的客户端和服务器端的通信协议是“半双工”的。这类似一个抛球游戏，只有拿到球的一方可以把球抛出去。 客户端使用一个单独的数据包将查询传给服务器。 服务器给用户的数据则由多个数据包组成。客户端必须接收完整的数据包（而不能自己选择读取多少即终止），服务器端往客户端推数据。 多数连接 MySQL 的库函数，都会把所有的数据缓存在内存中（MySQL 必须等到所有的数据都发完才能释放自己的资源），还可以逐行获取需要的数据。 查询缓存MySQL 对每一个语句解析以前，都会查询缓存。缓存的查找是通过一个对大小写敏感的哈希查找实现的。 查询优化处理语法解析器和预处理预发解析器的产出是一课“解析树”，而不是其他 RDBMS 的查询字节码。 查询优化器Optimizer 是基于成本的优化器，它的成本最初是随机读取一个 4K 数据页（4K 是数据页的标准成本）的成本。后来这个成本的含义变得更复杂了，如执行一次 WHERE 条件比较的成本。 使用以下语句： 得到的 value 数值 x 代表对 x 个数据页的随机查找成本。 优化器的局限有： 统计信息不准确。在 MVCC 架构下，并不能维护一个数据表行数的精确信息。 给出的执行计划中的成本估算不等于实际执行的成本。 MySQL 的最优可能并不是最快的。 MySQL 从不考虑其他并发执行。 MySQL 无法不受其控制的的操作的成本，如存储过程和用户自定义变量。 优化器可能错过最佳的执行计划。 Optimizer 能够执行的优化可以分为静态优化和动态优化。静态优化依赖于静态分析，类似于编译时优化，如常量替换；而动态优化则类似 jit。 常见的优化包括： 重新定义关联表的顺序 将外连接转化为内连接 使用等价变换原则 优化 count()、min() 和 max（）：表达式会被替换为一个常数，找到最大值或者最小值大致上等于寻找 B+ 树的最左最右的记录。Extra 里面如果出现了“select tables optimized away”，则意味着 MySQL 直接取到了结果，没有进行真的查询。同样，MyISAM 之类的引擎内部有常数可以直接被 count() 查出来。 预估并转化为常数表达式：在 where、on、using 里出现的常量，很容易让表查询的 where 产生 ref 为 const 的效果。MySQL 很只智能，分析完 where 之后，就知道要扫描的范围了。 覆盖索引扫描 子查询优化 提前终止查询（early termination algorithm）：当存储引擎需要判断存在性或者检索不同取值的时候，MySQL 可以使用这类优化。DISTING、NOT EXIST、LEFT JOIN。 等值传播 使用了 using（等价于 on a.id = b.id），则外部表 where 条件里的条件可以传播到内部表的查询里（下面我们会看到一个 in 的例子）。 列表 IN（）的比较：MySQL 里 IN（）不完全等价于 OR，MySQL 会先将 IN 列表中的数据先排序，然后通过二分查找的方式来确定列表中的值是否满足条件，这种方案的时间复杂度是对数复杂度。OR 的时间复杂度是线性复杂度。 总而言之，不要自以为比优化器聪明。当然优化器缺少某些功能特性，如哈希索引。 数据和索引统计信息MySQL 在服务器层有查询优化器，却没有保存数据和统计信息。 存储引擎提供给优化器的统计信息包括： 每个表或者索引有多少个页面 每个表的索引的基数有多少 数据行和索引长度 索引的分布信息 MySQL 如何执行关联查询MySQL 认为一个查询就是一次“关联”。 对于一个 UNION 查询，MySQL 先将一系列的单个查询结果放到一个临时表（DISK or HEAP）中，然后再从临时表中读出临时数据来完成 UNION 查询。在 MySQL 的概念中，每个查询都是一次关联，所以读取临时表也是一次关联。 MySQL 对任何关联都执行嵌套循环关联操作： 先在一个表中循环取出单条数据。 嵌套循环到下一个表中寻找匹配的行，直到找到所有的行为止，然后根据各个表匹配的行，返回查询需要的各个列。 MySQL 继续执行步骤 2 ，直到在最后一个表中寻找到所有匹配行。如果无法找到更多的匹配行，则 MySQL 返回上一层循环，看看能否找到更多的匹配记录（因为只有一条上层记录进入本循环），以此类推迭代执行。 把上面的思路套进一般的查询中，则可以认为 MySQL 会先在 Where 中找到 tbl1 中的所有行，然后使用 Using 列去寻找 tbl2 的 row，找到相应的 row 以后先保存相应的列，然后再去寻找 tblx 的 row，以此类推。 MySQL 在 FROM 子句中遇到子查询时，先执行子查询并将其结果放到一个临时表中（MySQL 的临时表中是没有任何索引的），然后将这个表当作一个普通表。 当 MySQL 执行 UNION 查询的时候，也执行类似操作。 当 MySQL 执行右外连接的时候时候，将它转化为等价的左外连接。 MySQL 并不支持全外连接。 执行计划（正如前面看到的），MySQL 并不会生成查询字节码来执行查询。MySQL 生成查询的一颗指令树，然后通过执行引擎执行完成这棵指令树并返回结果。任何查询都可用用一棵树来表示。 MySQL 使用的不是平衡树，而是左侧深度优先的树。 到底哪张表是左侧的深度优先树的最左节点，可以通过 EXPLAIN（EXTENDED）看出来，第一个 EXPALIN 的行就是第一层驱动表，而第二和第三个关联表则可以通过索引查询。 选择驱动表是一门学问。好的驱动表可以通过索引快速索引，通常小的驱动表可以更快返回，而决定性的差异在于：小表能够返回的最外层结果集更小。更小的结果集可以制造更少的嵌套循环，回溯操作也更小（如果只计算时间复杂度，看起来调转驱动表的顺序得到的 join 的总次数不会减少。但实际上小的驱动表的很多 join 是在一次循环的索引查找里 join 出来的；而大的驱动表则会产生更多的外层 loop 和回溯。只能认为这种循环和回溯的成本会更高，因为它会导致更多的交叉数据页的访问。，查询成本可以通过查看 last_query_cost 来获知）。 MySQL 不会直接选择 tbl1 inner join tbl2 inner join tbl3 里的 tbl1 来作为驱动表。它会在各种排列组合构成的搜索空间中进行搜索查询成本最低的执行计划。搜索空间的增长速度比很多人预料的快。MySQL 无法总是穷尽搜索空间，当需要关联的表超过 optimizer_search_depth 的限制的时候，优化器选择使用贪婪搜索来寻找最优的搜索顺序。但当代的 MySQL 也有一些启发式策略。 排序优化无论如何排序都是一个成本很高的操作，应该尽可能避免排序或者尽可能避免对大量数据进行排序。 MySQL 会首先使用索引进行排序。 如果不行，MySQL 会在内存中排序，内存不够会使用磁盘。不管内存够不够，这一过程都叫作 file sort。 第二步中的内存是内存中的“排序缓冲区”（sort buffer）。在排序缓冲区内的排序是快排；如果排序缓冲区不够大，则 MySQL 会把数据分块，对每个独立的块使用“快排”，然后将排序结果放到磁盘上，进行归并排序。 进行排序的时候，先排序还是先查找完所有的列，会诞生了两种不同的排序算法。当代的 MySQL 支持两种不同的排序算法。 查询很容易产生临时结果（using temporary; Using filesort），排序占用的空间会更大（特别是对于 varchar 类型的列，MySQL 会按照它能预估到的最大的空间来进行空间占用）。 查询执行引擎优化器生成了执行计划这一数据结构以后，交给执行引擎执行。执行引擎会调用存储引擎实现的接口，也就是“handler API”（查询涉及的每张表都由一个 handler 代表）来逐步执行执行计划。这种逐步执行相对于查询优化器的数据操作，简单了许多。 这种可以“搭积木组合”的 API 可以完成复杂查询，也支撑起了 MySQL 存储引擎的插件化架构。 返回结果给客户端如果查询可以被缓存，那么在这阶段 MySQL 会将结果放在缓存中。 MySQL 在关联执行完，开始返回第一行结果的时候，就可以给客户端返回响应了。所以MySQL 无需存储太多的结果，也不会消耗太多内存。这样也可以让 MySQL 客户端第一时间获得返回的结果。 题外话：从这点来看，通常在 JDBC 里看到 last packet recieved 之类的错误，往往意味着 MySQL 一开始就没有返回任何数据。所以人们才怀疑连接才死了。注意区分 duration 和 fetch time。 MySQL 查询优化器的局限关联子查询MySQL 的子查询实现得非常糟糕。我们期待着 in + 子查询 查询会先执行子查询，然后再查询原始 in 查询。 但实际上 MySQL 会把 in 改写为 exists 查询，通过 explain extened 可以看到先执行了外部的查询，然后执行了第二个子查询，这个子查询为 dependent subquery。 此处参考《MySQL关于in和exists的优化》：exist 的语义是将主查询的数据，放到子查询中做条件验证，根据验证结果（true或false Traditionally, an EXISTS subquery starts with SELECT , but it could begin with SELECT 5 or SELECT column1 or anything at all. MySQL ignores the SELECT list in such a subquery, so it makes no difference.）来决定主查询的数据结果是否得以保留。in 的语义是确定给定的值是否与子查询或列表中的值相匹配。in在查询的时候，首先查询子查询的表，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选。in 是把外表和内表作 hash 连接，而 exists 是对外表作loop循环，每次 loop 循环再对内表进行查询（笛卡尔积意味着 hash join）。一直以来认 为exists 比 in 效率高的说法是不准确的。*所以外表比小表大的时候，应该用 in，反之应该使用 exists。in 是从内到外的查询，exists 是从外到内的查询 所以早期版本的 MySQL 查询优化不当，往往会让用户在 Server 层进行 hash join。另外一种方法是，把 in 的列表查询直接转化为 exist 查询（但其实 直接使用 in，MySQL 也会做等价查询，不知道为什么这样会产生优化。）。但对于当代的 MySQL 而言，直接使用 in，听任底层的查询优化器去优化是个好主意。 在检查一个条件是否得到满足的时候，exists 表现得比 count 快很多。 如何用好关联子查询可不可以在 join 里面使用 subquery？可以。 不要通过主观猜测，要用测试来验证猜想。 等值传递如果有一个查询是 where in + 用其他条件 join 其他表，MySQL 会把 in 也下推到其他表里。如果 in 很大，则 MySQL 实际执行会非常慢。 并行查询MySQL 无法对某个查询进行并行优化-这和我们经常可以在服务器层面进行的 fork-join 优化不一样。 哈希关联当代版本的 MySQL 不支持哈希关联（但 8.0 以后的 MySQL 就支持了，Mariadb 很早就支持了）。我们可以使用哈希索引来巧妙地实现哈希关联。但正如我们上面看到的，使用了哈希索引就无法触发覆盖索引，也不能按值排序。 松散索引扫描相当于 Oracle 中的跳跃索引扫描（skip index scan）。 MySQL 8.0 才正式支持这一特性。 最大值和最小值优化对于无索引的查询 min 和 max，可以使用 using index（pk） limit 1 的方式进行优化。 在同一个表上查询和更新只有使用 deffered join 可以绕开 MySQL 的限制。 查询优化器的提示（hint） 优先操作 HIGH_PRIORITY HIGH_PRIORITY可以使用在select和insert操作中，让MYSQL知道，这个操作优先进行。SELECT HIGH_PRIORITY * FROM TABLE1; 滞后操作 LOW_PRIORITY LOW_PRIORITY可以使用在select,delete,insert和update操作中，让mysql知道，这个操作滞后。update LOW_PRIORITY table1 set field1= where field1= … 这两个提示都只在基于表锁的存储引擎非常有效。在innoDB和其他基于行锁的存储引擎，你可能永远用不上。在MyISAM中使用它们时，也要十分小心，因为它们会让并发插入失效，可能会严重下降性能。 延时插入 DELAYED 这个操作只能用于 insert 和 replaceINSERT DELAYED INTO table1 set field1= …INSERT DELAYED INTO，是客户端提交数据给MySQL，MySQL返回OK状态给客户端。而这是并不是已经将数据插入表，而是存储在内存里面等待排队。当mysql有 空余时，再插入。另一个重要的好处是，来自许多客户端的插入被集中在一起，并被编写入一个块。这比执行许多独立的插入要快很多。坏处是，不能返回自动递增 的ID，以及系统崩溃时，MySQL还没有来得及插入数据的话，这些数据将会丢失。并且导致last_insert_id()无法正常工作。 强制连接顺序straight_joinSELECT TABLE1.FIELD1, TABLE2.FIELD2 FROM TABLE1 STRAIGHT_JOIN TABLE2 WHERE…; 由上面的SQL语句可知，通过STRAIGHT_JOIN强迫MySQL按TABLE1、TABLE2的顺序连接表。如果你认为按自己的顺序比MySQL推荐的顺序进行连接的效率高的话，就可以通过STRAIGHT_JOIN来确定连接顺序。 分组使用临时表 SQL_BIG_RESULT和SQL_SMALL_RESULT SELECT SQL_BUFFER_RESULT FIELD1, COUNT(*) FROM TABLE1 GROUP BY FIELD1;这两个提示只对select语句有效，它们告诉优化器对 group by 或者 distinct 查询如何使用临时表及排序。sql_small_result 告诉优化器结果集会很小，可以将结果集放在内存中的索引临时表，以避免排序操作；sql_big_result 则告诉优化器结果集会很大，建议使用磁盘临时表做排序操作； 强制使用临时表sql_buffer_result SELECT SQL_BUFFER_RESULT * FROM TABLE1 WHERE …;这个提示告诉优化器将查询放入到一个临时表，然后尽可能地释放锁。这和前面提到的由客户端缓存结果不同。当你设法使用客户端缓存的时候，使用服务器端的缓存通常很有效。带来的好处是无须在客户端消耗太多的内存，还可以尽可能快的释放对应的表锁。代价是，服务器端需要更多的内存。查询缓冲sql_cache 和 sql_no_cache这个提示告诉mysql是否讲结果集缓存在查询缓存中。 关闭查询缓冲 SQL_NO_CACHE SELECT SQL_NO_CACHE field1, field2 FROM TABLE1; 有一些SQL语句需要实时地查询数据，或者并不经常使用(可能一天就执行一两次),这样就需要把缓冲关了,不管这条SQL语句是否被执行过，服务器都不会在缓冲区中查找，每次都会执行它。强制查询缓冲 SQL_CACHE SELECT SQL_CALHE * FROM TABLE1; 如果在my.ini中的query_cache_type设成2，这样只有在使用了SQL_CACHE后，才使用查询缓冲。sql_calc_found_rows严格来说，这并不是一个优化器提示。它不会告诉优化器任何关于执行计划的东西。它会让mysql返回的结果集包含更多的信息。查询中加上该提示，mysql会计算出去limit子句后这个查询返回的结果集的总数。而实际上只返回 limit 要求的结果集。可以通过函数found_row()获得这个值。 锁相关 for update 和 lock in share mode 这两个提示主要控制select 语句的锁机制。但只对实现了行级锁的存储引擎有效。使用该提示会对符合查询条件的数据加锁。对于 insert…select 语句不需要这两个提示，因为会默认添加上锁。唯一内置的支持这两个提示的引擎是innoDB。另外需要记住的是，这两个提示会让某些优化无法进行。例如索引覆盖扫描。innoDB不能在不访问主键的情况下用排他锁锁定行，因为行的信息锁定在主键中。 USE INDEX、IGNORE INDEX 和 FORCE INDEX USE INDEX 基本等于 FORCE INDEX，IGNORE INDEX 的语义和他们相反。 优化特定类型的查询优化 COUNT()COUNT() 的语义是，统计非空列。如果 COUNT() 里有表达式，则统计的是表达式有值的列。但因为 COUNT()的不能为空，所以它会统计所有的行。 如果 MySQL 坚信 COUNT(某列)中的某列不可能为空，它会把这个查询优化为COUNT(*)。 某些情况下，如果查询的条件是互斥的，可以通过查询补集的数量来反推特定集合的数量。 优化关联查询 如果查询 计划的关联顺序是 B、A，B 和 A 之间通过列 c 进行关联，则 B 上的 c 不需要加索引。 GROUP BY 和 ORDER BY 不要跨表找列，否则无法使用索引，而且必 filesort。 升级 MySQL 以后，关联的查询计划会发生变化。 优化子查询虽然前面我们说过子查询不是不可以用。但大多数情况下，子查询最好通过改写为 join（using、on，而不是 from 里的 select where）代替。 优化 GROUP BY 和 DISTINCT不要在 SELECT 中直接使用非分组列。 优化 LIMIT 分页常见的几种方法： 延迟查询：把 by 和 limit 下推到子查询里，order by 一定要命中索引，然后只查出 pk（即不回表），用 pk 查出所有列。 计算出真正的边界值：where position between a 和 b。 每次翻页的时候把上一次查询的时候的 id 查出来，然后在 id 的索引上进行其他 where 和 order by。 这几种方法都不一定性能好。在更复杂的场景下，真正性能好的方法是构造索引表，索引表要包含的数据有：原始表的主键、排序列和查询条件列，查出真正的主键以后，再回表查一次原始表，得到所有目标列。 优化 SQL_CALC_FOUND_ROWS可以优化“找到的结果多余 1000 条”的场景。大部分场景下可能用不着。 优化 UNION 查询MySQL 总是通过创建和填充临时表的方式来执行 UNION 查询。只要涉及临时表，就无法使用索引优化，所以需要尽量下推查询。 除非确实需要服务器消除重复的行，否则一定要使用 UNION ALL。如果不这样做，MySQL 会隐式地给临时表加上 DISTINCT 选项，会导致对整个临时表的唯一性检查。 静态查询分析依赖于 pt-query-advisor。 使用用户自定义变量用户自定义变量有诸多限制，很复杂，现实中的编程不应该使用。 案例学习使用 MySQL 构建一个对列表对列表有个常见的难题，就是随着列表越来越大和索引深度加深，找到未处理记录的速度会越来越慢。 给出一张表： 这样表的通常的查询模式通常是加锁（带锁的钥匙加锁）： 但这样整个事务的阻塞性太高了。我们使用阻塞事务归根结底是为了实现隔离。我们可以使用 where 条件隔离： 但这种锁模式有个缺点，就是如果原始要处理这些记录的进程（持有特定的 CONNECTION_ID）突然退出，则需要定时扫描，将他们解锁。 总结一下这个案例中的基础原则： 尽量少做事。 尽可能快地完成需要做的事情。用 UPDATE 代替 SELECT FOR UPDATE。 如果查询无法被优化，则我们需要使用不同的查询或者不同的策略去实现相同的目的。 计算两点之间的距离省略 使用用户自定义函数省略。 总结如果把创建高性能应用程序比作是一个环环相扣的“谜题”，除了 schema、索引和查询语句设计之外，查询优化应该是“解开难题”的最后一步了。 除此之外的原则：不做，少做，快速地做（一定要加上测试）。 MySQL 高级特性分区表分区表是个独立的逻辑表，底层由多个物理子表组成。实现分区的代码实际上是对一组底层表的句柄对象（Handler Object）组成。 这种句柄对象的设计有点类似 composite 模式，对于用户而言，对分区表的真正操作乃是一种黑盒操作。这是一种插件式架构的优势，也是一种劣势-不能自由地分派查询语句和操作，分区表不如数据库中间件自由。 我们可以使用 PARTITION BY 来创建分区表，查询的时候优化器有时可以过滤掉无用的分区，这样可以减少扫描的范围。但如果无法做分区过滤，则分区表的全表扫描的成本很难控制。 分区表就好像一个粗粒度的分表方案，是用来消解原本的超大表的规模的-当代的分表方案一样可以支持这种操作。 对分区表的每个操作都可能先打开并锁住所有的底层表。像 InnoDB 这样自己可以实现行锁的存储引擎，会在分区层释放对应表锁（以此推断，MyISAM 则不行）。 在以下场景下，分区表不能过滤掉额外的分区： null 值可能会使分区无效 分区列和索引列不匹配：分区列是一列，索引列是另一列。这几乎在日常的查询中是常见问题，这就可以看出能够精确路由到物理表的数据库中间件优于分区表的地方。 选择分区的成本可能很高。 打开并锁住所有底层表的成本很高-这等于所有的小锁创建以前求大锁这步是不能消除的，这又是一个数据库中间件取胜的地方。 维护分区的成本可能很高。 查询分区表的 where 语句必须带上分区列。 合并表是个类似分区表的技术，允许用户访问子表（而分区表不允许），是一种即将被淘汰的技术。 视图视图是一张虚拟表。view 很类似 table，但不能使用触发器。实现视图的方案实际上类似于把 select 语句放在一个临时表中，而给这个临时表加上了一个名字（create view tbl1 vs create temporary table tbl1）。 涉及视图的 select 和 update 可能会诞生潜在的临时表，这可以通过 explain 查看有没有 derived 字眼确认。 建立视图有一个优势，可以制造一个单独授权的列集合，而隐藏真正的 schema。 MySQL 还不支持物化视图，即查询还不是从某一张视图表中产出结果，而是根据合并算法或者临时表算法进行即席查询得到结果。 外键约束InnoDB 支持外键，MyISAM 不支持，且它强制使用索引。 外键意味着强制约束检查，对性能有影响。除非在应用层也需要做这种检查，否则不要使用外键（外键可以优化这种性能优化）。 MySQL 内部存储代码有以下方式可以存储代码： 触发器 存储过程 函数 定时任务（事件） 使用内置存储的代码可能性能会好，因为局部调用节省网络带宽、不受网络时延影响、受内部优化方案影响，可以缓存执行计划。 使用存储过程/触发器在基于语句的 binlog 复制中，有不少的问题。 存储过程是把复杂性存储在数据库中的解决方案，从另一个角度看，把复杂性存储在应用程序中可能是个可维护性更好的方案。毕竟，这些语句难以调试。 游标MySQL 在服务器端提供只读的、单向的游标，而且只能在存储过程或者更底层的客户端 API 中使用。 MySQL 的游标会查询所有数据，所以需要有意识地使用 LIMIT。 MySQL 不支持客户端游标，不过客户端 API 可以通过缓存全部查询结果的方式模拟客户端的游标。 绑定变量服务器端绑定变量就是 prepared statement，每一种语言的 connector 驱动器都有相关的实现。其基本工作流程是： 创建绑定变量的时候，client 向 server 发送 SQL 语句的原型。 服务器端收到这个原型后，解析并存储这个 SQL 语句的部分执行计划，返回给客户端一个 SQL 语句处理句柄。 以后每次执行这类查询，客户端都指定使用这个句柄。 绑定变量有如下优点： 不用重复解析语句。 只发送参数（对于 BLOB 和 TEXT，还可以分块传输）。 可以防止 SQL 注入。 客户端可以使用二进制协议，也可以使用非二进制协议使用绑定变量，常用的接口函数为mysql_query()。 用户自定义变量UDF 可以由 C 语言编写。但一着不慎，可以让服务器直接崩溃。 插件插件和插件接口配合使用。 字符集和校对默认的字符集是 Latin1。如果使用 UTF-8，则排序的时候按照每个字符三个字节方式分配存储空间。 全文索引当代的 InnoDB 也支持全文索引。但大多数情况下我们应该使用专业的搜索引擎。作者推荐接入 Sphinx 搜索引擎。 分布式（XA）事务有两种 XA 事务： 外部 XA 事务：MySQL 可以参与到外部的分布式事务中。 内部 XA 事务：通过 XA 事务协调存储引擎和二进制日志。 MySQL 的插件式架构导致在其内部需要使用 XA 事务，这包含几个方面： 在多个存储引擎之间共同提交一个事务的时候，实际上就是一个 XA 事务。 在在提交事务的同时，将事务提交都 binlog 里。 因为 XA 存在，MySQL 一个事务都会存在多个 fsync 调用（Undo、Redo、Binlog）。这需要双 1 提交的参数和 innodb_support_xa 的设置。 查询缓存MySQL 可以缓存查询计划和查询结果。 在表发生变化时，相关表的查询缓存会立刻（全部）失效。MySQL 不会很精细地只失效相关记录的缓存。 查询缓存可能成为服务器的资源竞争单点。 很多时候我们认为应该关闭查询缓存。很多时候查询缓存并不能提供足够好的查询命中率，但总是会带来写开销，而且引起了很多与内存、cpu 有关的 bug。因此，MySQL 8.0 去除了查询缓存。 MySQL 把缓存放在一个引用表中，通过一个哈希值引用。查询语句上，任何字符上的不同，都可能会导致缓存的不命中。 对查询缓存进行操作可能触发锁操作，这会引起系统停顿。特别是高并发场景下。 MySQL 自己管理内存，而不依赖操作系统的内存管理。在一个大内存块里通过取小块或者大块内存来存储查询结果。小块的好处是内存碎片小，内存利用率高；大块的好处是不用考虑扩容。查询缓存使用一种存储了自己类型、大小、数据、前驱后继指针的变长数据块，不断在内存区域里分割内存。 MySQL 更新查询缓存的顺序大致上是：每次读请求先检查缓存是否命中，如果命中则立刻返回，否则就完整地执行查询（如果这个操作是写操作，查询优化器会先失效缓存），每次写操作则需要检查查询缓存中是否有需要失效的缓存，然后再返回。注意这里在没有事务的加持下，是无法严格保证缓存和数据的任何一刻的强一致性的，MySQL 始终选择先更新数据，再更新缓存。 缓存非常适合需要消耗大量资源的查询。缓存命中率=Qcache_hits/(Qcache_hits + Com_select)。查询缓存还会影响 Qcache_inserts。另一种看待查询缓存的比率的方式是看 Qcache_hits 和 Qcache_inserts是不是能拿到 10 比 1，或者更高的比值。 查询缓存是由存储引擎实现的，如 InnoDB，但策略却是 Server 层实现的。查询缓存和表的事务计数器和表上的锁有关（而不是记录上的锁）。 优化服务器配置学习配置项最好的方法是理解 MySQL 的内核和行为开始。 大多数情况下我们只要保证基本配置正确（特别是 buffer pool、日志文件缓存的大小），然后就可以去专门调优 schema、索引和查询了。 MySQL 配置的工作原理最好的配置应该使用全局配置文件，而且要注意配置文件的位置（DBA 应该专门维护这个位置）。做配置的时候要注意配置是全局配置，还是会话级的，要确认会话级的配置如何生效（是否需要所有旧的连接都死掉，只对新连接生效）。 修改配置的时候要始终依靠监控确认变化提高了服务器的性能。 做配置的时候记得加注释，这能节省大家的时间。 我们可以不用很详细的基准测试，来不断寻找使性能优化的配置。大多数情况下我们使用很基础的开箱配置，但我们需要靠测试（甚至依赖于生产环境的实际监控），一点一点调优某几项配置。 什么不该做首先，不要根据某些“比率”来调优。性能和缓存命中率有关，但缓存命中率和缓存大小不一定有关（认为这两者必定有关大错特错）。Oracle DBA 很早就放弃了依据于命中率的调优。 其次，应该使用 Optimize 或者 Configuration 来代替 tuning。tuning 意味着一个缺乏纪律的新手对服务器进行微调，并观察发生了什么。 第三，不要相信搜出来的配置。 第四，不要相信很流行的内存消耗公式。 创建 MySQL 配置文件MySQL 编译的默认配置并不都是靠谱的。他们被设计成不要使用大量资源，因为 MySQL 的使用目标是非常灵活的。 不要使用整个默认的配置文件作为配置的起点，因为里面的配置项太多了（MySQL 的可配置性太强也可以说是个弱点，大多数配置已经是最佳配置了）。 不要把 Socket 文件和 PID 文件放到 MySQL 编译默认的位置。 需要指定 MySQL 用户来运行 mysqld 进程。 最需要关注的配置应该是： innodb_buffer_pool_size 减掉 OS 需要的内存、MySQL 自己运作需要的内存，设置得比 75% 略小，通过监控再增加。 innodb_log_file_size 减掉 OS 需要的内存、MySQL 自己运作需要的内存，设置得比 25% 略小，通过监控再增加。 这两个值对性能的影响巨大，而且默认值都太小了。最初配置的值配置得小一点可以再增加，但如果调得很大可以使 MySQL 崩溃。 还要关注 open_files_limit，现代操作系统上这个值都太小了，很容易遇到经典的 24 号错误。 配置内存的使用MySQL 的内存消耗分为两类：可以控制的内存和不可以控制的内存。 为缓存分配内存对 MySQL 最重要的缓存为： InnoDB 缓冲池 InnoDB 日志文件和 MyISAM 数据的操作系统缓存 MyISAM 键缓存 查询缓存 无法手工配置的缓存 InnoDB 缓冲池（Buffer Pool）缓冲池缓冲索引、行数据、插入缓冲、锁和其他内部数据结构。 很大的缓冲池会增大预热和关闭的时间。 MyISAM 键缓存（key cache）顾名思义，只缓存索引。数据缓存依赖于操作系统。 线程缓存MySQL 维护一个线程池，这个线程池的大小和连接请求的数量有关，大多数情况下不用配置。 表缓存表缓存可以节约打开文件描述符的成本。表缓存是服务器和存储引擎分离不彻底的产物。InnoDB 不那么依赖于表缓存。 数据字典有几千或者几万张大表时，会成为问题。 配置 MySQL 的 I/O 行为![innodb 的缓存和文件.jpeg](innodb 的缓存和文件.jpeg) 日志文件InnoDB 使用日志来减少提交事务时的开销。因为日志中已经记录了事务，就无须在每个事务提交时把缓冲池的脏块刷新（flush）到磁盘上，这样随机 I/O 就变成了顺序 I/O。 环形写InnoDB 的日志是环形写的，当写到日志的尾部时，会重新跳转到开头继续写，但不会覆盖还没应用到数据文件的日志记录。InnoDB 有个后台线程智能地刷新这些变更到数据文件中（可以批处理）。 日志文件受控于 innodb_log_file_size、innodb_log_files_in_group。这两个值默认只有 5mb，太小了，通常要调高到 x gb大小。 如果日志很小，则 MySQL 会创造很多检查点；如果日志很大，则 MySQL 在崩溃恢复时要做更多的工作。 此外，日志缓冲区由 innodb_log_buffer_size 控制，这个参数通常不会太大（除非需要应对大事务）。 mutex 写缓冲先使用一个 Mutex 锁住缓冲区，刷新到所需要的位置，然后移动剩下的条目到缓冲区的前面。这个 Mutex 可能影响性能，Mutex 释放的时候，可能有超过一个事务以及准备好刷新其日志记录。InnoDB 有一个组提交的功能，可以在一个 I/O 内操作提交多个事务。 防止丢失事务内容这个 flush 影响我们特别关注的 ACID 里面的 D，我们应该尽量使用 innodb_flush_log_at_trx_commit = 1（这是默认的，也是最安全的）。这个配置会让每次事务提交的时候都把日志（redo log，log buffer 里面默认就应该是 redo log）缓冲写到日志文件，并且刷新磁盘。注意这是两个操作，只做第一步，在服务器无问题的时候，不能保证不丢事务里的修改（通常至少丢失 1 秒。因为对 OS 而言，flush 不意味着 sync）。即使做了两步，缺乏主从复制的话，也不能保证不丢失事务里的修改。这个配置的缺点是，会降低事务写入的速度。如果没有这个配置，需要使用带有电池保护的写缓存的 RAID 卡。 InnoDB 表空间（Table Space）InnoDB 把数据保存在表空间内，本质上是一个由一个或多个磁盘文件组成的虚拟文件系统。它包含表和索引、UNDO LOG、InsertBuffer、DoubleBuffer。 我们尽可能使用 innodb_file_per_table 选项让 InnoDB 为每张表使用一个文件。每张表的表空间存储在“表名.ibd”的数据里。这个文件最好不要太大，不然 DROP TABLE 的性能会很差。 共享表空间里可能存在多个行的旧版本（因为 MVCC 机制），如果 purge 的线程打扫旧版本跟不上写入的速度，则事实上写入的性能变差了。 双写缓冲（Double Write Buffer）当 InnoDB 从缓冲池刷新页面到磁盘时，首先把它们写到双写缓冲，然后再把它写到其所属的数据区域（的原始页面）中。这可以保证每个页面的写入都是原子并且持久化的。双写缓冲保证了数据不会损坏。这个设计本质上是引入写在磁盘上的双副本，每个副本带有一个校验和，如果双写缓冲的页坏了，使用原始页面中的版本替换它；如果原始页面中的页坏了，使用双写缓冲中的版本替换它。 其他的 I/O 配置项sync_binlog 指定了两次刷新（binlog）到磁盘之间间隔了多少次写操纵，通常这个值为 1。即使这个值为 1，也可能会丢最后一次 binlog。 配置 MySQL 并发InnoDB 的并发配置主要控制有多少的线程的可以进入内核。 基于工作负载的配置省略 完成基本配置省略 安全和稳定的设置省略 高级 InnoDB 设置省略 总结省略 操作系统和硬件优化现代的服务器使用的都是多核服务器，配置 SSD（带有电池保护），要使用 RAID。 应该关注 vmstat 和 iostat 里的数据报告。 复制MySQL 内建的复制功能是构建基于 MySQL 的大规模、高性能应用的基础，这类应用使用所谓的“水平扩展”的架构。 复制概述复制解决的基本问题是让一台服务器的数据与其他服务器保持同步。 MySQL 支持以下的复制方式： 基于语句的复制（逻辑复制） 基于行的复制 复制基本不会对主库造成影响。值得注意的开销就是产生 binlog 的开销，和从库的 IO 线程请求复制带来的网络带宽开销。 复制解决的问题 数据分布：可以让复制在不同数据中心之间分布。 负载均衡：可以进行读扩展。 备份：复制是备份的补充，复制不是备份。 高可用性和故障切换：故障切换系统往往依赖于副本复制。 MySQL 升级测试：升级时，先使用高版本作为备库（因为 MySQL 总是向后兼容的），然后再做主从切换。 复制的工作方式 需要一个赋权的 REPLICATION SLAVE 账号 配置主从配置 如果要从已经运行了一段时间的主库上启动一台新的从库，通常需要先 clone 出一个基础版本的从库，然后使用 binlog 追主从之间的同步差。我们不能只指望 binlog 帮我们解决同步问题，因为 binlog 并不包含从开始到现在的所有变更。我们通常只能从 binlog 的某个时间点开始。 复制的原理基于语句的复制基于语句的复制是逻辑复制，在数据库领域是比较少见的。 基于语句的复制最大的好处是实现简单。因为使用了抽象的协议，基于语句的复制就好像一个隐藏的客户端一样工作，只通过 sql 接口来实现复制。这种复制对带宽的压力比较小，很小的语句可以更新很大的数据。 但基于语句的复制实际上有几个缺点： 有些语句是无法被复制的，如依赖环境变量的语句（current_user()、now()） 这些语句必须串行执行。 基于行的复制基于行的复制是后出现的，所以相比基于语句的复制有一定先进性。 在大规模查询面前，基于行的复制表现更好。 哪种更优没有哪种复制方式在各方面都很完美。默认情况下 MySQL 的 binlog 是基于语句的，但如果这种复制方式表现不够好，可以动态地切换为基于行的复制。 复制拓扑MySQL 不支持多主一从的拓扑结构。 不管使用什么拓扑方式，一主多从，如果只把读操作指向从库，则读并不是线性扩展的（因为写没有被分摊，对主库的 1000 tps 写等于对从库的 1000tps 写，要先减去这样的写负载，得到的余量做一个除法才能得到每台机器的读扩展余量）；对写则是完全不扩展的。对写扩展的唯一方法是做数据分片。 改变主库理论上的步骤有： 停止向老的主库写入 让备库追赶上主库 将一台备库配置为新的主库 将备库和写操作指向新的主库，然后开启主库的写入 但主从切换有一个不可克服的问题，就是没有办法保证任何情况下主库所有的修改都被同步到从库上了。完全有可能主库上相关的 update 没有更新到从库上，而从库上执行了对某一行的 update。 可扩展的 MySQL扩展性是由架构决定的。设计好的架构才能很好地扩展（架构实际上是一种约束）。 什么是可扩展性以车类比： 性能是汽车的时速 容量是车道乘以最大安全时速 可扩展性就是在不减慢交通的情况下，能增加更多车和车道的程度 正式的可扩展性的定义可扩展性是通过增加资源来提升容量的能力。 equal bang for the buck。 扩展有三种： 线性扩展 Amdahl 扩展：无法执行的一部分工作降低了扩展的 ROI USL（Univeral Scalability Law）扩展：信道带来的开销是二次方式的，最终也将降低扩展的 ROI 扩展 MySQL规划可扩展性先找一个原型撑一段，然后从容地规划容量路线图。 为扩展赢得时间尽量用索引、存储引擎、压缩表来赢得时间，然后寻找一个可扩展架构。 向上扩展MySQL 并不天然适用于最新硬件。一定要使用最新版本。 向上扩展财务上往往很糟糕，特别是考虑到查询在 MySQL 里无法使用多线程来提升单个查询的性能。 向外扩展按功能拆分如果这个服务是一个新闻网站，可以把数据库按功能分为论坛、新闻和支持。只要数据之间没有强的联表查询需求，则可以支持这样对数据分割。 数据分片对于不能放入分片里的数据，如登录数据或者城市列表，通常存储在单一节点上，并且存放在类似 memcached 的缓存里。 使用数据分片可能会增大架构的复杂度。有些可能已经价值几十亿美元、流量非常大的生意，是不使用数据分片的。 分区键（partitioning key）选择分区间要选择一个关键实体的主键，分区间会决定分区单元。好的分区键能够避免跨片查询。 有时候需要按照多个维度分区（此时应用需要从不同角度看到有效且连贯的数据视图）。除非使用某些方法来冗余存储数据，否则多个维度分区必然导致多份存储，冗余的方法是冗余跨片的数据内容和 FK。如评论和用户放在一个分片，而书籍只需要读取相关评论，可以只冗余评论相关的信息在自己的分片里。 跨分片查询有些聚合操作（min、max）需要查找所有分片，这就需要制造并行查询的语句，一个分片上执行一条。我们需要尽量在应用层（或者引入一个数据库抽象层）来并行执行查询并聚合结果集。 分配数据、分片和节点尽量让分片大小比节点容量小得多，这样单个节点上可以存储多个分片（小的分片可以用类一致性散列的算法进行迁移，也易于 alter，可以提高各种操作的并行度）。所以分库往往要分表。 分片的负载均衡的方法有：平均负载，或者直接按照区间进行分片。通常我们做数据分片的时候使用前者（对 HBase 而言也如此），这样做的结果是数据没有很好的空间局部性，这需要我们的权衡。 在我们需要空间局部性或者分片之间不均衡的时候，我们可能需要 rebalance 分片的内容，这比（在节点之间）转移分片复杂得多。 在节点上部署分片Server -&gt; MySQL instance -&gt; db -&gt; table Server 就是我们经常说的节点，我们部署的分片可以在下面三个层次做配比。分片的索引可以体现在下面三个层次的后缀上（我们通常使用表名后缀）。 固定分配将数据分配到分片上有两种主要的方法：固定分配和动态分配。两种方法都需要一个分区函数，使用行的分区键作为输入，返回存储该行的分片。 固定分配使用的分区函数仅仅依赖于分区键的值。哈希函数（例如 CRC32()）和取模都是桶算法。 固定分片的问题是：分片间的数据可能不均衡（分片如果很小，则这个问题可能有所缓解），且分片之间的数据难以迁移（特别是分片扩容，比如从 10 分片到 20 分片的时候）。 动态分配一般推荐对新应用采用动态分片。 这个表本身就是分区函数。给定分区键（用户 id）的值就可以获得分片👌 混合动态分配和固定分配以 URL 存储为例，对桶内实行固定分配，对桶实行动态分配。 显式分配省略 重新均衡分片数据最好使用内存发号来提供高性能，使用磁盘存储来实现 id 全局唯一。要注意单点的性能瓶颈和可用性瓶颈。 通过多实例扩展MySQL 对于多核硬件利用得不好。 在单机上配置多实例，需要监听不同的端口，挂载不同的目录和分区。这需要权衡复杂度管理和性能。 通过集群扩展最有前途的技术是 NDB Cluster。 向内扩展即使用归档，但要注意： 平衡归档的行和事务的大小，不要影响原 OLTP 的流程 维护数据的逻辑一致性，不要出现跨表和跨库查询 负载均衡 直接连接如果没有一个可以简单对等值换的服务器池，可以在应用里直连多个主备服务器，但要注意： 要确认是否能容忍脏数据 如果不能容忍脏数据，能否在会话里标记出强制最新 如果不能容忍脏数据，能否靠版本号进行检查 修改配置目前没有强一致性、强实时性的广播协议，能够快速地分发新的链接配置到各个服务器上，滚动发布更麻烦。 修改 DNS 名我们可以给负责写的服务器起个 DNS 名，给负责读的服务器起另一个 DNS 名。这样负责读的 DNS 名可以给主库也可以给从库（美团开源的 zebra 就是这样工作的）。 切换 IP 地址服务器并不绑定域名，但绑定 IP 地址。所以切换 IP 和域名是不一样的。我们可以通过 Pacemaker 来切换 IP 地址。 引入中间件引入中间件的问题是中间件本身也需要引入冗余。 负载均衡器很少有专门针对 MySQL 设计的负载均衡器，因为 MySQL 连接只是正常的 TCP/IP 连接。所以中间件要自己有以下特性： 能够依据于负载进行均衡 能够动态适应拓扑结构的变化（类似 Re-hash 算法） 能够进行健康检查（borrow connection 和 select 1） 负载均衡算法依赖于是否及时处理事务请求，算法还可以再细分 即时请求算法： 随机 轮询 最少连接数 最快响应 哈希 权重 非即时请求算法： 引入队列的队列算法 增加服务器MySQL 服务器需要预热才能启动，所以不能直接打开新服务器的负载。 要确保每个服务器的连接限制值足够高，这样可以应对服务器的 一主多备间的负载均衡我们很难绕开一个主库加多个备库的架构。 总结最好的策略是实现明确需求，并且为可能快速增长做好预先规划。 我们并不同意提倡为每个应用“尽早分片、尽量分片”（shard early，shard offen）。 高可用性本章讨论复制、可扩展性和高可用性三个主题中的第三个。归根结底，高可用性意味着“更少的宕机时间”。高可用经常与其他概念混淆，如冗余、保障数据不丢失，以及负载均衡。 什么是高可用性100% 的可用性是无法达到的。可用性的效果和开销的比例并不是线性的。可用性的定义包括应用是否能以足够好的性能处理请求。 画一个风险计算表，以概率、代价和风险敞口作为列，这样容易找到需要优先处理的项目。 导致宕机的原因 磁盘空间耗尽 糟糕的 SQL 糟糕的 schema 和索引设计 复制问题导致主从不一致 DROP table + 没有备份 如何实现高可用性 尝试避免导致宕机的原因 尽量保证发生宕机时可以快速回复 提升平均失效时间（MTBF） 测试恢复工具和流程包括从备份中恢复数据。 遵从最小权限原则。 保持系统干净、整洁。 用好的命名和组织约定来避免产生混乱,例如服务器是用于开发还是用于生产环境。 安排升级数据库服务器。在升级前,使用诸如 PerconaToolkit 中的 pt-upgrade 之类的工具仔细检查。 系统使用 INNODB 并进行适当的配置,确保 INNODB 是默认存储引擎。如果存储引擎被禁止,服务器就无法启动。 确认基本的服务器配置是正确的。 通过skip_name_resolve禁止DNS。 除非能证明有效,否则禁用查询缓存。 避免使用复杂的特性,例如复制过滤和触发器,除非确实需要。 监控重要的组件和功能,特别是像磁盘空间和RAID卷状态这样的关键项目,但也要避免误报,只有当确实发生问题时才发送告警。 尽量记录服务器的状态和性能指数,如果可能就尽量久地保存。 定期检查复制完整性。 将备库设置为只读,不要让复制自动启动。 定期进行查询语句审查。归档并清理不需要的数据。 为文件系统保留一些空间。在GNU/Linx中,可以使用-m选项来为文件系统本身保留空间。还可以在LVM卷组中留下一些空闲空间。或者,更简单的方法,仅仅创建一个巨大的空文件,在文件系统快满时,直接将其删除。 养成习惯,评估和管理系统的改变、状态以及性能信息。 降低平均恢复时间（MTTR）训练团队成员是最重要的高可用资产。不要指望后见之明。 需要打断整个“失效链条”。 避免单点失效思考并梳理整个应用，尝试去定位任何可能失效的单点。 为系统增加冗余的方法： 增加空余容量 增加重复组件（我们通常使用这种方法） 共享存储或磁盘复制共享存储通常使用的是 SAN。即多个 MySQL 实例挂载同一个文件系统。在使用共享存储的时候选择 InnoDB 存储引擎或其他稳定的事务型存储引擎。 MySQL 同步复制使用同步复制，主库上的事务只有在至少一个备库上提交后才能认为其执行完成（进而返回执行结果，否则提示上游重试）。如果只有一个备库提交即满足法定人数，则这是一个半同步复制。 MySQL 默认支持半同步复制，全同步复制需要使用 MySQL cluster 或者 Percona XtraDB Cluster 等方案。 基于复制的冗余复制管理器是使用标准 MySQL 复制来创建冗余的工具。 常见的工具有 MMM 和 MHA。国内互联网公司使用 MHA。 故障转移和故障恢复只有在遇到故障需要恢复时冗余才有用（备份也可以做到）。 提升备库或切换角色目前没有自动切换主备，而完全不需要人工干预的自动化工具。 备库的问题通常是不够“热”，有时候需要不断地“训练”它。 虚拟 IP 或者 IP 接管使用 IP - 机器的映射切换的方式来进行切换（switch）。这和负载均衡用到的策略很相似，但这里是用来做故障转移。 这种方案的做法不需要切换配置（切换主从需要修改 MySQL 启动配置的主从配置部分）。 中间件解决方案使用中间件进行流量路由-这又看得出能够拿来做负载均衡的工具，可以拿来做故障转移。 总结冗余会让系统变得相当复杂。分布式的系统意味着协调、同步、CAP 定理、拜占庭将军问题，以及所有其他各种杂乱的东西。 云端的 MySQL云是一种平台，而不是一种架构。 使用云可能有种潜在的缺点：iostat 或者 vmstat 等监控工具失效。 云并不天生是可扩展的，云仅仅是云而已，选择一个可扩展的平台，并不一定自动使引用变得可扩展，除非使用了 DBaaS 这类服务（如 RDS）。 应用层优化优化是一个复杂的系统性工程，也需要全方位的工作。应用优化的剩余部分日后再补充。 很多时候，并不是数据库的问题。 备份与优化备份是为了容灾，以及防止人们改变主意。 如果可以，我们最好执行在线备份，但离线备份是最安全的。 我们可以选择逻辑备份和物理备份。逻辑备份即（使用 mysqldump）导出 sql 或者 csv，而物理备份则是导出存储引擎相关的数据文件格式。 MySQL 用户工具主要关注一些接口工具和监控系统。"},{"title":"MySQL 中的日志","date":"2020-07-20T08:07:52.000Z","url":"/2020/07/20/MySQL-%E4%B8%AD%E7%9A%84%E6%97%A5%E5%BF%97/","tags":["数据库","MySQL"],"content":"Binlog初始定义BinLog 是记录 MySQL 实例数据变更的一个组件，日志中包含了一系列变更数据的操作，例如变更表结构、删除数据、更改/添加数据等 DML、DDL。这些操作在 BinLog 中统称为事件。 BinLog 记录什么，不记录什么BinLog 也会记录一些可能会发生数据变更的事件，例如没有找到对应行的 Delete 操作。 BinLog 不会记录纯查询，如 Select 和 Show。那要查询所有语句的记录怎么办（比如要分析长事务）？需要查找通用查询日志。 用途 主从同步：在主从同步的过程中，Binlog用于记录主库的数据变更，然后这些记录被主库内的线程发送至从库。从库的工作线程再把接收到的变更事件放到从库上执行，完成数据同步。主从同步通常被视为提升数据库吞吐能力的一种方法，因此Binlog是必不可少的环节。 数据恢复： 在生产环境中，总是会有意外导致数据丢失。在一些数据恢复的场景中，Binlog是必不可少的。当数据库从备份中恢复的时候，binlog中所记录的信息会在恢复后的数据上执行，补齐备份数据中未备份的记录。注意，这里的数据恢复不包括数据回滚，回滚依赖于 undo-log。 BinLog 结构 从上图可以看出，一个完整的binlog由两种文件组成 索引文件(Index File)： 索引文件用于跟踪多个binlog文件，便于主库创建新的binlog文件。索引文件中的每一行记录着所有关联和它关联的binlog文件名。在系统中，索引文件的文件名为{Host名}-bin.index 日志文件(Binlog file)： 日志文件是binlog的主体，如上图所示，它是由一系列事件(Binary Log Events)组成。在系统中，文件名为{Host名}-bin.NNNNNN。 后缀为六个数字用于区分不同的日志文件。 日志文件的开头记录的是的是 Format_description 事件，这个事件记录主库的信息和日志文件的状态。如果主库突然宕机或者重启，主库会重新创建一个日志文件然后在开头写入Format_description。当主库记录完成变更事件后，主库会写入Rotate事件。Rotate事件会指定下一个日志文件的文件名和读取事件的起始点。 BinLog 分组除开上述的Format_description事件和Rotate事件，日志文件都会把其他的变更事件进行分组(Group)。在MySQL中，每一个事务会被分成一组，组中包含了这个事务下执行的所有语句。一些非事务性语句会被单独分成一组，如Create和Alter语句等。如下图所示： MySQL能确保每一组变更的原子性，要么不执行，要么执行完每一个组的所有语句。在主从同步中，如果从库在同步过程突然中止，当从库重新启动后，从库会重新执行一个组的变更，而不是重新执行被终止的语句。如图中所示，当update被终止后，从库下次启动时会从Begin开始执行而不是从update开始执行（原子性会从 begin 开始，所以事务里的语句总是幂等的）。 日志格式上个部分我们介绍了binlog日志的结构，知道每一个binlog日志是由多个事件组成的。为了方便阐述，文中默认每个事件都是执行的语句或者一个完整事务。在早期的MySQL版本中，这是binlog日志唯一的格式。自从MySQL5.1起，日志的格式增加到了三种： Statement-based（我们实际上最习惯的是这种语句）： 这是MySQL默认的日志格式。在这个格式下，binlog日志中记录的是变更数据库的执行语句和事务。 Row-based: 在这个格式下，binlog日志中记录的是发生变更的数据行。 Mixed-logging: 这个格式是前两种格式的混合版，主库会根据执行的语句来决定binlog日志中记录的内容，可以是具体的行，也可以是执行的语句。 其实 Row-based 的 binlog 的设计逻辑近于 balance 数据（或者状态数据），而 Statement-based 的设计逻辑近于 transaction 数据（或者流水数据）。 每个日志格式都有其对应的优缺点，因为mixed-logging在实际生产环境中不常用。在这里仅对row-based和statement-based做比较，总结如下表： 格式 优点 缺点 Statement-based 1. 较少的日志大小 2. 因为记录了所有执行语句，所以可以方便的做后期审计。 不适用于包含以下函数的语句：如USER(), UUID(), UUID_SHORT(), NOW() 不适用于不稳定的语句，如带Limit的Delete和Update语句 Row-based 1. 记录了所有实际变更的数据，准确性高 2. 对于Insert, update 和 delete语句，所需要的行锁大大降低 日志文件大，IO耗费较大 日志事件结构 每个 binlog 事件由四个部分组成： 通用 Header：这里存放事件的基本信息：事件类型和事件数据大小。 Post Header：存放特定事件类型的相关信息。 事件实体：存储事件的数据，如执行过的语句和变更的实际数据。 Checksum：MySQL 5.6 新增的功能，用作检查数据是否损坏。 主从同步mysql主从复制需要三个线程：master（binlog dump thread）、slave（I/O thread 、SQL thread）： binlog dump线程：主库中有数据更新时，根据设置的binlog格式，将更新的事件类型写入到主库的binlog文件中，并创建log dump线程通知slave有数据更新。当I/O线程请求日志内容时，将此时的binlog名称和当前更新的位置同时传给slave的I/O线程。 I/O线程：该线程会连接到master，向log dump线程请求一份指定binlog文件位置的副本，并将请求回来的binlog存到本地的relay log中。 SQL线程：该线程检测到relay log有更新后，会读取并在本地做redo操作，将发生在主库的事件在本地重新执行一遍，来保证主从数据同步。 主库写入数据并且生成binlog文件。该过程中MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的（binlog 的生成有将事物序列化的机制）。 在事件写入二进制日志完成后，master 通知存储引擎提交事务（binlog 也是 WAL！）。 从库服务器上的 IO 线程连接 Master 服务器，请求从执行 binlog 日志文件中的指定位置开始读取 binlog 至从库。 主库接收到从库的 IO 线程请求后，其上复制的 IO 线程会根据 Slave 的请求信息分批读取 binlog 文件然后返回给从库的IO线程。 Slave服务器的IO线程获取到 Master 服务器上 IO 线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到 Slave 端自身的 Relay Log（即中继日志）文件的最末端，并将新的 binlog 文件名和位置记录到 master-info 文件中，以便下一次读取 master 端新binlog日志时能告诉 Master 服务器从新 binlog 日志的指定文件及位置开始读取新的 binlog 日志内容。 从库服务器的 SQL 线程会实时监测到本地Relay Log中新增了日志内容，然后把 RelayLog 中的日志翻译成SQL并且按照顺序执行SQL来更新从库的数据。 从库在relay-log.info中记录当前应用中继日志的文件名和位置点以便下一次数据复制。 主从复制的线程流程，和 Redis 的线程有点像。 Binlog是主从同步中的重要一环，如上图所示。 不同的binlog日志格式会影响从库的同步方式。在statement-based格式下，从库是直接执行binlog日志中读取到的语句或者事务。在row-based格式下，从库是根据日志内容直接更新对应的数据。 MySQL默认的日志格式是statement-based。在大多数主从同步的场景下，日志格式采用row-based（大多数情况下不使用默认配置），最主要的原因是row-based格式下，日志内容都是真实发生变更的数据，从库的数据准确性有很高的保证。 数据恢复在生产环境中，数据很有可能发生意外丢失。人为的操作失误往往会导致“删库跑路”的结局。为了应对各种意外的情况，数据库会周期性的做备份。当数据意外丢失后，备份数据可以拿过来恢复。然而，即使数据做了备份，也不能完全恢复到丢失那一刻的数据。 假设某数据库每一个整点备份一次，上午10点数据库备份了一次，而10：30分，数据库突然丢失数据。 这时候我们会立刻拿备份数据导入到生产数据库中，然而我们只能恢复到上午10点时的数据，10：00 ~10：30那段时间的数据并没有被导入备份，还是会缺失一部分数据。 所以，这30分钟的数据怎么恢复呢？ 这里就用到了 MySQL 的Point-In-time recovery(简称PITR)功能，PITR是用于恢复某个时间点的失效数据，用于弥补备份时间点到失效时间点这段数据“真空期”，实现这个功能的核心是binlog日志文件。 在详解binlog日志时我们了解到，binlog日志中存放着数据库所有的变更。PITR的原理很简单，就是将binlog内存储的变更数据重新执行一遍。需要恢复数据时，用mysqlbinlog命令执行binlog日志的内容。 PITR可以选定时间范围和位置范围来选择性恢复数据： 时间范围模式，使用–start-datetime或者–stop-datetime 变量。下图的含义是读取该binlog日志stop-datetime之前的所有变更： 日志位置模式，使用–start-position和 –stop-position 变量选择日志内的起始位置，如下图： Binlog 不同于 Redo logredo log有着和binlog 类似的功能，它也记录了变更数据库的信息，但是它和binlog还是有区别的，具体区别如下： 日志类型 Bin Log Redo Log 层次 引擎无关（MySQL 总是有 Bin Log） InnoDB 特有 作用 主从复制和 PITR 数据库崩溃后的恢复，不可指定具体时间点（单独恢复若干个事务） 内容 逻辑日志，记录语句的原始逻辑（更加接近我们熟悉的操作日志） 物理日志，记录某个数据页上的修改 丢失 binlog 造成的事故 binlog 的文件如果有滚动功能，就有限期清理的功能。如果限期清理的日志不足以提供 PITR 的所有支持，则无法支持备份的还原。也无法支持主从同步。如果数据在从库上丢了，在主库上进行回滚也是一种思路。 防止 binlog 丢失可以开启双 1 配置，不过写入性能最差。 innodb_flush_log_at_trx_commit如果innodb_flush_log_at_trx_commit设置为0：log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下，在事务提交的时候，不会主动触发写入磁盘的操作;如果innodb_flush_log_at_trx_commit设置为1：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去;如果innodb_flush_log_at_trx_commit设置为2：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。 注意：由于进程调度策略问题,这个”每秒执行一次 flush(刷到磁盘)操作”并不是保证100%的”每秒”。 sync_binlogsync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。当sync_binlog =N (N&gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。 注意：如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。 双 1 配置意味着每个事务的提交和每个 buffer 的写入都是积极写入磁盘中的，任何 buffer 层的惰性配置都不生效。 innodb_flush_log_at_trx_commit 控制 redo log。sync_binlog 控制 binlog。 主从延迟与同步机制参考：《MySQL同步机制、主从复制半同步和双主配置》 在2000年，MySQL 3.23.15版本引入了Replication。Replication作为一种准实时同步方式，得到广泛应用。这个时候的Replicaton的实现涉及到两个线程，一个在Master，一个在Slave。Slave的I/O和SQL功能是作为一个线程，从Master获取到event后直接apply，没有relay log。这种方式使得读取event的速度会被Slave replay速度拖慢，当主备存在较大延迟时候，会导致大量binary log没有备份到Slave端。 在2002年，MySQL 4.0.2版本将Slave端event读取和执行独立成两个线程（IO线程和SQL线程），同时引入了relay log。IO线程读取event后写入relay log，SQL线程从relay log中读取event然后执行。这样即使SQL线程执行慢，Master的binary log也会尽可能的同步到Slave。当Master宕机，切换到Slave，不会出现大量数据丢失。 在2010年MySQL 5.5版本之前，一直采用的是这种异步复制的方式。主库的事务执行不会管备库的同步进度，如果备库落后，主库不幸crash，那么就会导致数据丢失。于是在MySQL在5.5中就顺其自然地引入了半同步复制，主库在应答客户端提交的事务前需要保证至少一个从库接收并写到relay log中。那么半同步复制是否可以做到不丢失数据呢？下面分析。 在2016年，MySQL在5.7.17中引入了一个全新的技术，称之为InnoDB Group Replication。目前官方MySQL 5.7.17基于Group replication的全同步技术已经问世，全同步技术带来了更多的数据一致性保障。相信是未来同步技术一个重要方向，值得期待。MySQL 5.7 Group Replication。 主从复制机制： 对于异步复制，主库将事务Binlog事件写入到Binlog文件中，此时主库只会通知一下Dump线程发送这些新的Binlog，然后主库就会继续处理提交操作，而此时不会保证这些Binlog传到任何一个从库节点上。 对于全同步复制，当主库提交事务之后，所有的从库节点必须收到，APPLY并且提交这些事务，然后主库线程才能继续做后续操作。这里面有一个很明显的缺点就是，主库完成一个事务的时间被拉长，性能降低。 对于半同步复制，是介于全同步复制和异步复制之间的一种，主库只需要等待至少一个从库节点收到并且Flush Binlog到Relay Log文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全执行并且提交的反馈，这样就节省了很多时间。 所以关键在 dump 线程。 主从延迟的原因根据前面主从复制的原理可以看出，两者之间是存在一定时间的数据不一致，也就是所谓的主从延迟。我们来看下导致主从延迟的时间点： 主库 A 执行完成一个事务，写入 binlog，该时刻记为T1. 传给从库B，从库接受完这个binlog的时刻记为T2. 从库B执行完这个事务，该时刻记为T3. 那么所谓主从延迟，就是同一个事务，从库执行完成的时间和主库执行完成的时间之间的差值，即T3-T1。 我们也可以通过在从库执行show slave status，返回结果会显示seconds_behind_master，表示当前从库延迟了多少秒。 seconds_behind_master如何计算？ 每一个事务的binlog都有一个时间字段，用于记录主库上写入的时间 从库取出当前正在执行的事务的时间字段，跟当前系统的时间进行相减，得到的就是seconds_behind_master，也就是前面所描述的T3-T1。 是T2-T1么？ NO。正常情况下，如果网络不延迟，那么日志从主库传给从库的时间是相当短，所以T2-T1可以基本忽略。 是T3-T2 么？ YES，最直接的影响就是从库消费中转日志（relaylog）的时间段，而造成原因一般是以下几种： 1、从库的机器性能比主库要差 比如将20台主库放在4台机器，把从库放在一台机器。这个时候进行更新操作，由于更新时会触发大量读操作，导致从库机器上的多个从库争夺资源，导致主从延迟。 不过，目前大部分部署都是采取主从使用相同规格的机器部署。 2、从库的压力大 按照正常的策略，读写分离，主库提供写能力，从库提供读能力。出于对于主库的敬畏之心，将进行大量查询放在从库上，结果导致从库上耗费了大量的CPU资源，进而影响了同步速度，造成主从延迟。 对于这种情况，可以通过一主多从，分担读压力；也可以采取binlog输出到外部系统，比如Hadoop，让外部系统提供查询能力。 3、大事务的执行 一旦执行大事务，那么主库必须要等到事务完成之后才会写入binlog。 如：主库执行了一条insert … select非常大的插入操作，该操作产生了近几百G的binlog文件传输到只读节点，进而导致了只读节点出现应用binlog延迟。 因此，DBA经常会提醒开发，不要一次性地试用delete语句删除大量数据，尽可能控制数量，分批进行。 我们在生产上曾经见过，执行大规模的表压缩，主库机器性能比从库要好，导致从库执行这个改表的事务造成延迟。所以拆小事务不只是为了连接和防止表死锁，还可以防止从库延迟过大。 4、主库的DDL(alter、drop、repair、create) 1、只读节点与主库的DDL同步是串行进行，如果DDL操作在主库执行时间很长，那么从库也会消耗同样的时间，比如在主库对一张500W的表添加一个字段耗费了10分钟，那么只读节点上也会耗费10分钟。 2、只读节点上有一个执行时间非常长的的查询正在执行，那么这个查询会堵塞来自主库的DDL，读节点表被锁，直到查询结束为止，进而导致了只读节点的数据延迟。 5、锁冲突 锁冲突问题也可能导致从机的SQL线程执行慢，比如从机上有一些select …. for update的SQL，或者使用了MyISAM引擎等。 6、从库的复制能力 一般场景中，因偶然情况导致从库延迟了几分钟，都会在从库恢复之后追上主库。但若是从库执行速度低于主库，且主库持续具有压力，就会导致长时间主从延迟，很有可能就是从库复制能力的问题。 回头再看下主从复制的流程，主要看下红色的箭头： 1、上面两个箭头分别表示的是客户端写入主库和sql_thread执行relaylog，若粗细表示并发度，可见主库明显高于从库。 2、从库上的执行，即sql_thread更新逻辑，在5.6版本之前，是只支持单线程，那么在主库并发高、TPS高时，就会出现较大的主从延迟。 因此，在随后演进的版本中，官方的 MySQL提出了不断改进的多线程复制方法，用于减少主从延迟。 并行复制的原理MySQL 的主库往往是并发写，所以如果从库不能并行复制的话，高并发的业务场景下很容易导致主从延迟很高。 多线程复制 图中的coordinator是上图的sql_thread，但其功能已不再是更新数据，而是负责读取中转日志和分发事务，进行更新操作的是work线程，该线程数量由slave_parallel_workers控制。 coordinator作为重要的一环，那么其进行分发是具有一定的要求： 不能造成更新覆盖，要求更新同一行的两个事务须分配到同一个work 如：更新同一行的两个事务被分配给了两个work，由于各个work之间是独立执行，就有可能出现第二个事务比第一个事务先执行，结果两个事务在主库和从库的执行顺序不一致，导致主从不一致。 同一个事务不能被拆分，须分配到同一个work 如：同一个事务更新表1和表2的各一行，分配到两个work，最终执行结果一致，但如果在表1执行完成的瞬间，来一个查询请求，则就会看到事务执行到一半的结果，破坏了事务的隔离性。 a、按库并行这是MySQL最先推出的并行复制策略，模型如下： 如图所示，每个 worker 线程对应一个 hash 表，用于保存当前正在这个worker的执行队列里的事务所涉及到的库。其中hash表里的key是数据库名，用于决定分发策略。该策略的优点是构建hash值快，只需要库名，同时对于binlog的格式没有要求。 但这个策略的效果，只有在主库上存在多个DB，且各个DB的压力均衡的情况下，这个策略效果好。因此，对于主库上的表都放在同一个DB或者不同DB的热点不同，则起不到多大效果。 b、redo log 组提交 (group commit) 优化最先使用这个特性的是MariaDB，该特性如下： 1、能够同一组里提交的事务，定不会修改同一行； 2、主库上可以并行执行的事务，从库上也一定可以并行执行。 具体是如何实现： 1、在同一组里面一起提交的事务，会有一个相同的commit_id，下一组为commit_id+1，该commit_id会直接写道binlog中； 2、在从库使用时，相同commit_id的事务会被分发到多个worker并行执行，直到这一组相同的commit_id执行结束后，coordinator再取下一批。 该实现逻辑，就好比模拟了主库的并行模式，但仔细分析对比，其并没有真正做到模拟主库的并行模式，可以看下图： 从图中可以看出主库在事务提交完后下一组事务很快就会进入commit状态，而从库需要等到第一组事务完全执行完成后，第二组事务才能开始执行。这种模式下，大事务的劣势尤为明显，比如TRA2是个大事务，在从库执行时，其他两个事务均已完成，但TRA2未完成，那么需等待他完全执行完，下一组才能执行，导致这段时间内只有一个work线程运行，造成资源浪费。 后续MySQL也提供了相应的类似功能，由参数slave-parallel-type进行控制，当其配置为LOGICAL_CLOCK即运行类似于MariaDB的策略，但 MySQL 在其并行策略基础上进行了优化。 具体怎么提升并发度，这里就涉及到了binlog组提交的两个参数（可以去了解一下binlog提交的过程）： binlog_group_commit_sync_delay ，表示延迟多少微秒调用fsync； binlog_group_commit_sync_no_delay_count， 表示累积多少次以后才调用fsync。 通过控制这两个参数，制造更多同时处于prepare的事务，也就是让主库提交慢点，从库执行快点，从而增加从库复制的并行度。 c、WRITESET的并行复制MySQL5.7.22提出了一个基于WRITESET的并行复制，通过binlog-transation-dependency-tracking进行控制，有三种模式： COMMIT_ORDER，即redo log 组提交 (group commit) 优化。 WRITESET，表示对于事务中关联到的每一行，计算出hash值，组成writeset。如果两个事务没有操作相同的行，即writeset没有交集，可以并行。hash值通过”库名+表名+索引名+值“计算，若表上还有其他唯一索引，那么对每一个唯一索引，在insert语句上会多一个hash值。 WRITESET_SESSION，在WRITESET上多一层限制，即在主库上同一个线程执行的两个事务，在从库执行时，也要保证相同的先后顺序。 WRITESET在主库生成后写在binlog中，在从库执行时，不需要解析，节省工作量 不需扫整个binlog来决定分发到哪个worker 从库的分发策略不依赖于binlog内容，对于statement格式也适合。 怎么减少主从延迟主从同步问题永远都是一致性和性能的权衡（不要期望主库执行大规模的写操作，否则读会受到影响），得看实际的应用场景，若想要减少主从延迟的时间，可以采取下面的办法： 降低多线程大事务并发的概率，优化业务逻辑 优化SQL，避免慢SQL，减少批量操作，建议写脚本以 update-sleep 这样的形式完成。 提高从库机器的配置，减少主库写binlog和从库读binlog的效率差。 尽量采用短的链路，也就是主库和从库服务器的距离尽量要短（同机房部署、同城部署），提升端口带宽，减少binlog传输的网络延时。 实时性要求的业务读强制走主库，从库只做灾备，备份。 Redo/Undo Log在 MySQL 里，既有数据文件（data file），也有日志文件（log file）。日志在内存中也是有缓存 Log Buffer，也有磁盘文件 log file。Redo Log 和 Undo Log 都是 log file 的一种。 当数据 crash-recovery 时： 通过 Redo Log 将所有已经在存储引擎内部提交的事务应用 Redo log 恢复。-这提供了原子性（保证事务不会部分成功）和持久性（数据最终能存到 data file 里） 所有已经 prepared 但是没有 commit 的 transactions 将会应用 Undo log 做 roll back，也保证了原子性和隔离性（通过对 MVCC 的支持）。 事务执行时会先写 undo log，再执行 statement，再写 redolog，事务执行完前的一瞬间写 binlog。 acid 里面的 c 特指数据完整性（三大完整性），与这两种 log 无关系。 Redo LogRedo Log 是重做日志，提供前滚操作。Redo Log 记录某数据块被修改后的值，可以用来恢复未写入 data file 的已成功事务更新的数据。 Redo Log 通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成什么样。它用来恢复提交后的物理数据页（恢复数据页，且只能恢复到最后一次提交的位置）。 Redo Log 的出现有一个背景，那就是 MySQL 是必须依赖于 WAL 类的日志的：我们对数据库中的数据进行修改时，实际上是对 buffer pool 中的数据页进行修改，生成相应的 dirty page 的数据。这种 dirty page 的变更在 crash 的时候如果要不丢，则必须依赖 WAL。必定会产生 binlog + 其他日志，这通常需要一次顺序 io。这时候如果还要立即更新 data file 的话，会产生一次随机 io，如果有办法只写 wal，然后缓冲多次对 datafile 的随机 io 到一次顺序 io，则整体的写吞吐量会上升。 Redo Log 是 storage engine 层产生的。Binlog 是 Server 层产生的。Redo Log 记录的是数据库的数据库的新值，每执行一条 statement 就产生一条 redo log；而 Binlog 记录的是可以被重放的操作记录，每个 transaction 提交前产生一条 binlog。binlog 是 MySQL 4.x 以后引入的复制机制，之前一直都使用 redo log 进行复制。 Undo LogUndo Log 是回退日志，提供回滚操作，Undo 记录某数据被修改前的记录，可以在事务失败时进行 rollback。它一般是逻辑日志，根据每行记录进行记录（配合 MVCC 进行使用）。 当使用 MVCC 进行事务操作时，InnoDB 会通过 DB_ROLL_PTR（与 delete 这行的 transaction 有关）关联的 undo log 来保证事务的回滚。事务提交后，这个 undo log 会被放入删除列表中，通过 purge 线程来删除。 DB_TRX_ID，（创建）事务ID（在有些资料里，最初插入第一行时这个值为 null） 和 DB_ROLL_PTR，回滚段指针搭配使用；创建 trx_id 和删除 trx_id 搭配使用。 对数据的变更操作，主要来自 INSERT UPDATE DELETE，而UNDO LOG中分为两种类型，一种是 INSERT_UNDO（INSERT操作），记录插入的唯一键值；一种是 UPDATE_UNDO（包含UPDATE及DELETE操作），记录修改的唯一键值以及old column记录。"},{"title":"MySQL 的隔离级别和锁","date":"2020-07-19T08:22:15.000Z","url":"/2020/07/19/MySQL-%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E5%92%8C%E9%94%81/","tags":["数据库","MySQL"],"content":"数据库的隔离级别数据库的资源必然被并发访问，否则无法满足业务的并发吞吐的要求。但并发访问始终需要避免四类问题： 更新丢失：多个事务在不互相感知和协同的时候（主要是同时更新同一行），最后一个更新会把之前所有的事务更新覆盖掉。 脏读：事务 a 对数据进行修改，但未提交时，数据并未进入一致状态（未提交的事务是不可靠的）；这时候事务 b 来读取未提交的事务的不一致的数据，就会产生业务逻辑问题（实际上分布式事务里一样有这样的问题，只不过很多人意识不到）。 不可重复读：一个事务在读取某些数据后的某个时间，再次读取之前读过的数据，却发现其读出的数据已经发生了改变、或者某些记录已经被删除了。这种现象被称为“不可重复读”。 幻读：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象被称为“幻读”。 隔离级别规定了一个事务中所做的修改在哪些事务内和事务间是可见的。ANSI SQL 92 规定了 4 个隔离级别，MySQL 实现为以下四个级别： 可读未提交 Read Uncommitted不锁定任何数据。 不禁 insert 也不禁 update。 在这种隔离级别里面，会出现脏读和更新丢失，即事务之间相互干扰，事务内部的中间值都可以被读到。 可读已提交如果做更新操作，使用行锁（record-lock）锁定要写入的数据，禁对正要写的数据的update；读操作不加锁，可能出现不可重复读，即正在读而不在写的数据不会被锁，在一个事务内读的数据，可能会被其他事务的终值 update。 可读未提交每个查询产生一个 read view-所以会产生不可重复读。 可重复读如果做更新操作，锁定正在读写的数据。如果做读操作，使用 mvcc 来实现快照读（snapshot-read），克服了不可重复读。传统的 RR 会出现幻读，即有些行本身是不被读写的，不能阻止相邻行的插入，也就是说会影响 aggregate 的结果（如使用 count 来查询）或者 where 里的条件判断。 InnoDB 在查询和更新（触发锁定）的时候，使用 Next-Key-Lock 同时锁定 record + 相关的范围，防止相关查询条件涉及范围内不会插入新的记录被插入，不再出现幻读 - 但这种优化并不是真正序列化，只能保证事务里的 select 不会出现不可重复的结果（因为禁掉了相关区间范围里的数据），事务里有 insert 还是会触发冲突。有人因此认为 InnoDB 不能阻止幻读，还有另一个例子。对这个问题的完整解释在这里。 总结一下： 我们提到的幻读的官方定义是： The so-called phantom problem occurs within a transaction when thesame query produces different sets of rows at different times. 最终还是关注读，关注得到的 result set，影响读的关键因素始终还是 insert 等插入语句。 单纯的 RR 读是无锁的，而且依赖于 MVCC，只读取 insert_tx_version &lt; tx_ version &lt; delete_tx_version 的最新记录。 如果 RR 中使用了任何触发锁的 DML，则锁在事务提交以前不会释放，触发了邻键锁 Next-Key-Lock 中的 Gap-Lock，也可以直接阻塞掉其他事务的 insert，而且一下子把当前事务的操作同步到当前的 tx，从某种意义上将快照读升级为当前读（比如tx2 插入一条记录，tx1 update 修改了新纪录，然后 tx1 就可以把这条新纪录取出来，这叫作 write skew，因为 tx1 的 write，skew 到了 tx 的记录上（tx2自己读也能读到这个偏斜））。MySQL InnoDB 的 RR 只能在 Read-Only Transaction 上避免 phantom rows 和 phantom read。 避免这种幻读的情况是在事务开始以前提前求 S 或者 X 锁，例子见《對於 MySQL Repeatable Read Isolation 常見的三個誤解》。MVCC 能够在对单行锁定的时候实现防止插入，就是部分解决幻读的效果，但如果单纯地重复让两个事务并发执行，事务 1 读一次，事务 2 插入一次，事务 2 再读一次，临键锁并不会被触发，事务 2 的插入不会失败。只有行锁才会触发间隙锁，进而得到邻键锁，进而触发对幻读的保护。 按照 MySQL 的官方文档的例子，lock in share mode 也可以执行 insert。 可读未提交每事务查询产生一个 read view-所以会产生幻读。 可序列化禁掉正在读写的所有相关数据，其实就是锁定表。 禁掉当前表的 insert 和 update。 克服了一切并发事务的污染。 从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)-换言之，即使不显式地更改隔离级别，只要显式地使用 S 锁和 X 锁，都会触发 Serializable。 Serializable 隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。 默认隔离级别大部分其他数据库是Read committed，MySQL是 Repeatable Read。 MySQL 是一个更严格的数据库。 JDBC 默认提供第五种隔离级别。 MySQL 的锁锁可以用于管理共享资源，RDBMS 能够提供层次化的锁，而普通的文件系统没有这一关键特性（文件系统并不是没有锁，而是没有针对表和记录的锁。但 RDBMS 里复杂的并发访问导致的弱一致性问题始终是存在的，所以文件系统本身是无事务的，很容易出现写错误）。 Lock 和 Latch 锁类型 lock latch 对象 事务 线程 保护 数据库内容 内存数据结构 持续时间 整个事务过程 临界资源 模式 行锁、表锁、意向锁 读写锁、互斥量 死锁 通过 waits-for-graph、timeout 等机制来检测死锁的存在 无死锁检测机制，只有通过加锁顺序（lock-leveling）来避免死锁的出现 存在于 在 LockManager 的哈希表中 在每个数据结构的对象中 锁的颗粒度|锁类型|表|页|行||:–:|:–:|:–:||InnoDB|支持|不支持|支持||MyISAM|支持|不支持|不支持||BDB|支持|支持|不支持| 意向锁MySQL 的等值查询和 range 查询，也支持等值更新和 range 更新。这里面隐藏了另一个问题：对表进行修改，就需要加表锁，而加表锁和加行锁实际上是互斥的。能不能加表锁，需要逐一确认每一行的行锁吗？ 使用意向锁以后的工作方式是： 对行进行修改的事务需要先对表加意向锁（不同行锁可以完全兼容意向锁），然后再加行锁。 对表进行修改的事务需要等意向锁释放，然后再加表锁。 意向锁是一张表级锁（Intention locks are table-level locks that indicate which type of lock (shared or exclusive) a transaction requires later for a row in a table） 当代的 InnoDB 里，还有一种 Insert Intention Lock，是间隙锁的一种，专门针对insert操作。同一个索引，同一个范围区间插入记录（不唯一索引里面，同一索引值代表的总是一个区间。一个区间的确切范围是(删一个索引值,当前索引值]），（如果）插入的位置不冲突，（就）不会阻塞彼此，（通过锁兼容检测）可以提高插入并发。换言之，同一个区间，其实存在很多的 gap。This lock signals the intent to insert in such a way that multiple transactions inserting into the same index gap need not wait for each other if they are not inserting at the same position within the gap.Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to insert values of 5 and 6, respectively, each lock the gap between 4 and 7 with insert intention locks prior to obtaining the exclusive lock on the inserted row, but do not block each other because the rows are nonconflicting. 参考《MySQL中的锁4-插入意向锁和自增锁》：插入意向锁本质上可以看成是一个Gap Lock。 普通的Gap Lock 不允许 在 （上一条记录，本记录） 范围内插入数据插入意向锁Gap Lock 允许 在 （上一条记录，本记录） 范围内插入数据插入意向锁的作用是为了提高并发插入的性能， 多个事务同时写入不同数据 至同一索引范围（区间）内，并不需要等待其他事务完成，不会发生锁等待。 所以意向锁其实是一种同时对多颗粒度生效的锁。 普通的表级意向锁，使得单纯的行级锁，可以兼容表级锁，排斥表级写。 假设存在一个 4-7 的区间，有 2 个事务分别插入 5 和 6，这 2 个事务会持有 2 个插入意向锁，插入意向锁之间相互兼容-但插入意向锁和普通的间隙锁不兼容。 每个单一的事务，只要插入一行记录，即使插入完了，还会继续持有这一行的 record-lock；这个 record-lock 的存在，会阻塞包含这行记录的区间扫描的 select-for-update 索引区间锁，但不会阻塞其他事务往记录旁边加锁-即它不包含 gap-lock。 插入意向锁可以让多个插入事务高速同时插入，并且抗拒防幻读的 x/s 锁触发的 gap lock。所以单纯的插入事务可以用插入意向锁实现插入之间的高并发，与临键锁的互斥；临键锁也可以触发对插入意向锁的互斥。所以理论上 RR 能够防止幻读，是靠行锁触发 gap-lock，插入也需要求 gap-lock 实现的。但实际上是靠临键锁和 gap-lock 互斥，而插入意向锁互相兼容来实现的。 是否兼容 当事务A上了：Gap Insert Intention Record Next-Key 事务B能否上了：Gap 能 能 能 能 Insert Intention 不能 能 能 不能 Record 能 能 不能 不能 Next-Key 能 能 不能 不能 这个表告诉我们，gap 锁在先，不可以兼容插入意向锁；但插入意向锁在先，可以兼容 gap 锁，所以插入意向锁被排斥但兼容其他锁。gap 锁之间是相互兼容的，所以多个 delete 非唯一索引时，必定锁定一个区间（10，12，删除 12 的时候持有的 gap 锁是 [10,~)），持有同一段 gap 锁，可以锁定同一段范围，但他们会抵制插入。gap 锁本身不和 next-key 锁冲突，next-key 锁里潜在冲突的部分就是 gap 锁，而 gap 锁之间是相互兼容的。 delete 和 insert 很容易造成死锁： 事务 1 delete，事务 2 delete，gap-lock 同一个区间 事务 1 insert 进入这个区间，insert-intention-lock 被阻塞（开始死锁的第一步骤），等待事务 2 释放锁。 事务 2 再 insert 进入这个区间，它的 insert-intention-lock 被阻塞（开始死锁的第二步骤），等待事务 1 释放锁。 所以 delete 后 insert 可能触发锁升级类死锁，从 gap 到 insert intention 相当于一次锁升级。 It is also worth noting here that conflicting locks can be held on agap by different transactions. For example, transaction A can hold ashared gap lock (gap S-lock) on a gap while transaction B holds anexclusive gap lock (gap X-lock) on the same gap. The reasonconflicting gap locks are allowed is that if a record is purged froman index, the gap locks held on the record by different transactionsmust be merged. Gap locks in InnoDB are “purely inhibitive”, which means that theironly purpose is to prevent other transactions from inserting to thegap. Gap locks can co-exist. A gap lock taken by one transaction doesnot prevent another transaction from taking a gap lock on the samegap. There is no difference between shared and exclusive gap locks.They do not conflict with each other, and they perform the samefunction. S 锁、X 锁InnoDB 实现了标准的行级锁（换言之，所有的 ANSI SQL 都应该实现这两种锁），也就是共享锁（Shared Lock）和排他锁（Exclusive Lock）。 共享锁（读锁、S锁），允许事务读一行数据。 排他锁（写锁、X锁），允许事务删除或更新一行数据。 锁的兼容性（compatibility） 锁类型 X IX S IS X Conflict Conflict Conflict Conflict IX Conflict Compatible Conflict Compatible S Conflict Conflict Compatible Compatible IS Conflict Compatible Compatible Compatible 注意，s 和 x 锁都是行锁。可以看出，x 锁跟所有锁都不兼容。同类的意向锁总是兼容的（否则不相关的行会相互 block）。 MVCCInnoDB 在 RC 和 RR 级别可以支持 MVCC。但其实 SNAPSHOT 的 ISOLATION，应用在 RR 上能真正起到防幻读的作用。 mvcc 与语句之间的关系MySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) (与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC 的好处是读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，这也是为什么现阶段，几乎所有的RDBMS，都支持了MVCC。 在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁（或者说，锁保证了当前读），保证其他事务不会再并发修改这条记录。注意，MVCC 本质上是追求无锁读。因此，即使是加 S 锁的读（select * from table lock in share mode），也算是一种当前读而不是快照读。 MVCC.xmind 如果同时看 MVCC 和锁，则会得到这幅图： MVCC在MySQL的InnoDB中的实现MVCC 的多版本，就是乐观锁。每一行记录都有两个隐藏的版本列，一列记录创建这列的事务版本号，另一列记录删除这列的事务版本号。 SELECT时，读取创建版本号&lt;=当前事务版本号（不是已读未提交），删除版本号为空或&gt;当前事务版本号（不是已删除）。 INSERT时，保存当前事务版本号为行的创建版本号。 DELETE时，保存当前事务版本号为行的删除版本号 UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行（隐藏了一个新老交替的软删除，update = insert + delete）。 transaction version over row version。 用 read-view 来看 MVCC 长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。 除此之外，长事务还占用锁资源，可能会拖垮库。 自增锁的细节是特殊的表级别锁，专门针对事务插入 AUTO_INCREMENT 类型的列。 原理：每张表自增长值并不保存在磁盘上进行持久化，而是每次InnoDB存储引擎启动时，执行以下操作： 之后得到的值会用变量 auto_inc_lock 作缓存，插入操作会根据这个自增长值加1赋予自增长列。因为每张表只有同一时刻只能有一个自增锁，可以避免同一表锁对象在各个事务中不断地被申请。 自增主键不一定连续，因为自增锁不能保证自增主键真正连续。 这里我们可以做个实验，假设 Test 表有主键id和唯一索引列a，已经有了(1,1)这条记录 1.先插入一行(null,1) 2.InnoDB发现用户没有指定自增id，获取当前自增值2 3.将传入的值改成(2,1) 4.将表自增id改成3 5.继续执行插入(2,1)，由于已经存在a=1，所以报 Duplicate key error 为了提高插入的性能，在 MySQL5.1 版本之后，对于普通的 insert 语句，自增锁每次申请完马上释放，不是在一个事务完成后才释放，以便允许别的事务再次申请（2PL 的例外）。 两阶段锁传统RDBMS加锁的一个原则，就是 2PL (二阶段锁)：Two-Phase Locking。相对而言，2PL 比较容易理解，说的是锁操作分为两个阶段：加锁阶段与解锁阶段，并且保证加锁阶段与解锁阶段不相交。 可以看出，每个加锁是在单行语句执行的时候加上的，但解锁是事务提交的时候执行的。 两段锁协议可以保证事务的并发调度是串行化（串行化很重要，尤其是在数据恢复和备份的时候）的。 两段式加锁可以使用无意的 update 直接触发 gap-lock，进而 block 掉其他事务的 insert，见 Next-Key 锁的例子。 2PL 锁有例外： 自增锁不会等到事务结束就放锁。 semi-consistent 事务会在判定不需要锁定的记录（比如不符合查询条件的记录）上提前释放锁，而不必等到事务提交。 锁的实战SQL1：select * from t1 where id = 10;不加锁。因为MySQL是使用多版本并发控制的，读不加锁。 SQL2：delete from t1 where id = 10;这个问题没有简单答案，真正加锁的顺序，取决于“where 涉及的列 + 隔离级别的组合关系”。 在 RC 的隔离级别之下： 如果 id 是主键，update 不会回表，所以只要在行上加 record-lock 即可。 若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 10的记录，另一把锁对应于聚簇索引上的[name=’d’,id=10]的记录。为什么聚簇索引上的记录也要加锁？试想一下，如果并发的一个SQL，是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 此时，如果delete语句没有将主键索引上的记录加锁，那么并发的update就会感知不到delete语句的存在，违背了同一记录上的更新/删除需要串行执行的约束。- 锁就要锁到底，把相关索引都锁住。索引本身即锁。 若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在主键索引上的记录，也会被加锁。 若 id列上没有索引，只能走聚簇索引，进行全部扫描。从图中可以看到，满足删除条件的记录有两条，但是，聚簇索引上所有的记录，都被加上了X锁。无论记录是否满足条件，全部被加上X锁。既不是加表锁，也不是在满足条件的记录上加行锁。为什么不是只在满足条件的记录上加锁呢？这是由于MySQL的实现决定的。如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。注：在实际的实现中，MySQL有一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，**把不满足条件的记录放锁 (违背了2PL的约束)**。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。也就是说，最终长期锁定的行，还是少数。 在 RR 的隔离级别之下： id 主键，x 锁锁定一行记录。 id 唯一索引，x 锁锁定唯一索引上的记录，对应的聚簇索引上的记录一个。 id 非唯一索引，则同时加上 record-lock + gap-lock。 GAP锁有何用？ 其实这个多出来的GAP锁，就是RR隔离级别，相对于RC隔离级别，不会出现幻读的关键。确实，GAP锁锁住的位置，也不是记录本身，而是两条记录之间的GAP。所谓幻读，就是同一个事务，连续做两次当前读 (例如：select * from t1 where id = 10 for update;)，那么这两次当前读返回的是完全相同的记录 (记录数量一致，记录本身也一致)，第二次的当前读，不会比第一次返回更多的记录 (幻象)。 如何保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他的事务不会插入新的满足条件的记录并提交。为了实现这个功能，GAP锁应运而生。 如图中所示，有哪些位置可以插入新的满足条件的项 (id = 10)，考虑到B+树索引的有序性，满足条件的项一定是连续存放的。记录[6,c]之前，不会插入id=10的记录；[6,c]与[10,b]间可以插入[10, aa]；[10,b]与[10,d]间，可以插入新的[10,bb],[10,c]等；[10,d]与[11,f]间可以插入满足条件的[10,e],[10,z]等；而[11,f]之后也不会插入满足条件的记录。因此，为了保证[6,c]与[10,b]间，[10,b]与[10,d]间，[10,d]与[11,f]不会插入新的满足条件的记录，MySQL选择了用GAP锁，将这三个GAP给锁起来。 此外，在 RR 下，索引的 gap lock 的范围，如果查不到相关记录，也会锁定特定的范围： 索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为记录锁。 索引上的等值查询，向右遍历到最后一个不满足等值条件的节点时候，退化为间隙锁。 id 无索引 如图，这是一个很恐怖的现象。首先，聚簇索引上的所有记录，都被加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。这个示例表，只有6条记录，一共需要6个记录锁，7个GAP锁。试想，如果表上有1000万条记录呢？现实之中出现的过类似的 bug，支付服务因为触发全表间隙锁，导致了 insert 语句不能执行。 在这种情况下，这个表上，除了不加锁的快照读，其他任何加锁的并发SQL，均不能执行，不能更新，不能删除，不能插入，全表被锁死。 当然，跟组合四：[id无索引, Read Committed]类似，这个情况下，MySQL也做了一些优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，对于不满足查询条件的记录，MySQL会提前放锁。针对上面的这个用例，就是除了记录[d,10]，[g,10]之外，所有的记录锁都会被释放，同时不加GAP锁。semi-consistent read如何触发：要么是read committed隔离级别；要么是Repeatable Read隔离级别，同时设置了 innodb_locks_unsafe_for_binlog 参数。更详细的关于semi-consistent read的介绍，可参考：MySQL+InnoDB semi-consitent read原理及实现分析。 结论： 索引越精细加锁越少，索引不精细可能锁表。 在 RR 的级别下，只要是涉及任何写操作的 dml，如果涉及非唯一的索引（不管是不是主键），都会防止幻读而插入 Next-Key—Lock。 大范围的间隙锁会导致大范围的插入失败 - 事务一定要释放，2PL 产生的死锁不可忽略。 在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable 隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。 索引上 GAP lock 的实际 x-lock 锁定范围，是索引里面命中的 index filter 的 range。 而记录上 record-lock 的锁定范围，则由回表以后定位到的 record 确定。 SQL3 从图中可以看出，在Repeatable Read隔离级别下，由Index Key所确定的范围，被加上了GAP锁；Index Filter 锁给定的条件 (userid = ‘hdc’)何时过滤，视MySQL的版本而定，在MySQL 5.6版本之前，不支持Index Condition Pushdown(ICP)，因此Index Filter在MySQL Server层过滤；在5.6后支持了Index Condition Pushdown，则在index上读取数据后到引擎层进行过滤（也就是说现代版本的 MySQL 能让 index 过滤条件之外的 where 语句也可以在存储引擎层执行）。若不支持ICP，不满足Index Filter的记录，也需要加上记录X锁，若支持ICP，则不满足Index Filter的记录，无需加记录X锁 (图中，用红色箭头标出的X锁，是否要加，视是否支持ICP而定)；而Table Filter对应的过滤条件，则在聚簇索引中读取后，在MySQL Server层面过滤，因此聚簇索引上也需要X锁。最后，选取出了一条满足条件的记录[8,hdc,d,5,good]，但是加锁的数量，要远远大于满足条件的记录数量。 Using index condition是MySQL 5.6中引入的一种新特性，叫做Index Condition Pushdown(ICP)，是一种在存储引擎层使用索引过滤数据的一种优化方式。这里的“下推” 是指将原来在server层进行的table filter中可以进行index filter的部分，在引擎层面使用index filter进行处理，不再需要回表进行table filter。使用ICP可以减少存储引擎层返回需要被index filter过滤掉的行记录，省去了存储引擎访问基表的次数以及MySQL服务器访问存储引擎的次数。Using index condition仅适用于二级索引，一般发生在查询字段无法被二级索引覆盖的场景，该场景下往往需要回表。通过ICP，可以减少存储引擎返回的行记录，从而减少了IO操作。 结论：在Repeatable Read隔离级别下，针对一个复杂的SQL，首先需要提取其where条件。Index Key 确定的范围，需要加上 GAP 锁；Index Filter过滤条件，视MySQL版本是否支持ICP，若支持ICP，则不满足 Index Filter 的记录，不加X锁，否则需要X锁；Table Filter过滤条件，无论是否满足，都需要加X锁。 死锁死锁的原理 注意回顾两阶段加锁的原理，可以看到逆序加锁就会发生死锁。 第二个用例，虽然每个Session都只有一条语句，仍旧会产生死锁。要分析这个死锁，首先必须用到本文前面提到的MySQL加锁的规则。针对Session 1，从name索引出发，读到的[hdc, 1]，[hdc, 6]均满足条件，不仅会加name索引上的记录X锁，而且会加聚簇索引上的记录X锁，加锁顺序为先[1,hdc,100]，后[6,hdc,10]。而Session 2，从pubtime索引出发，[10,6],[100,1]均满足过滤条件，同样也会加聚簇索引上的记录X锁，加锁顺序为[6,hdc,10]，后[1,hdc,100]。发现没有，跟Session 1的加锁顺序正好相反，如果两个Session恰好都持有了第一把锁，请求加第二把锁，死锁就发生了。即索引的锁交叉了，但聚簇索引（记录）上的锁却冲突了（如果持有锁的事务总不 commit，则因为 2PL 的存在，死锁必然发生）。为了预防死锁，一般应用中推荐使用一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，数据库并不知道会用到哪些数据。这就会导致问题 2。 死锁的结论死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。而使用本文上面提到的，分析MySQL每条SQL语句的加锁规则，分析出每条语句的加锁顺序，然后检查多个并发SQL间是否存在以相反的顺序加锁的情况，就可以分析出各种潜在的死锁情况，也可以分析出线上死锁发生的原因。 避免死锁有哪些方法 引入死锁告警，在触发死锁的时候及时发现，调整事务的执行策略。 以固定的顺序访问表和行。 大事务拆小。大事务更容易发生死锁，如果业务允许，将大事务拆小。 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。 降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁（RC 连 gap 都没有，只有 record-lock）。 为表添加合理的索引-否则在 InnoDB 存储引擎层会锁全表（即使没有加上表锁，所有的间隙都加上 gap-lock，所有的行都加上 record-lock，都是不好对付的）。 事务要加上超时，业务重试的超时时长也要做好匹配的超时设计，否则任务重试（重复执行任务或者重复消费 mq 消息），都会导致同样的任务重复地开启同样的事务，导致同一个事务的执行流程彼此引起死锁。 如果有得选，必须先进行 select，至少确认一个 id 是存在的，再调用 update 或者 delete，避免触发大范围的全表锁定。如果不这样做，可能触发 IX 兼容但 X LOCK 和 IX 不兼容的死锁问题。 客户端需要保证异常处理机制，确保事务完成提交。 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。- 用另一种思路来看，先锁最容易引起冲突的行，可以直接把不相关的操作拒之门外，也是一种简洁的思路。 insert 引发的死锁插入操作是不会主动加显示的X Record锁，只有检测到Key冲突的时候才会把隐式锁转为显式锁。 S1插入记录，S2插入同一条记录，主键冲突，S2将S1的隐式锁转为显式锁，同时S2向锁队列中加入一个S Record锁请求，S3同样也加入一个S Record锁请求；当S1回滚后，S2和S3获得S Record锁，但随后S2和S3又先后请求X GAP Insert Intention插入意向锁，因此锁队列为： S2(S GAP)&lt;—S3(S GAP)&lt;—S2(X GAP Insert Intention)&lt;–S3(X GAP Insert Intention) S3, S2, S3形成死锁。 锁状态了解了死锁产生的原因，如何知道数据库当前锁的状态呢？如何查看死锁情况呢？ 目前在MySQL中锁相关的视图如下： information_schema.innodb_trx ：记录事务相关的信息，包括事务开始时间、事务SQL、事务权重（死锁发生时，回滚事务参考的权值）等 information_schema.innodb_locks：记录事务持有锁的信息，包括事务持有的锁类型、被锁的表等 infomation_schema.innodb_lock_waits：记录事务等待情况，每个事务被哪些事务所阻塞 死锁情况可通过show engine innodb status查看。"},{"title":"Spring IOC","date":"2020-07-19T04:03:57.000Z","url":"/2020/07/19/Spring-IOC/","tags":["Java","Spring"],"content":"总体的类图 ResourceSpring 的基本获取 Bean 的形式是获取配置文件（通常是 xml），而读取配置文件，首先要解决资源抽象问题。 除了 Resource 以外，还有另一种获取资源的方式，那就是通过 ResourceLoader： BeanDefinition从配置文件里映射出来的数据结构，首先绑定到 BeanDefinition 上： 存储属性的地方使用了一个包装器类型来包含属性值列表： XmlBeanDefinitionReaderResourceLoader + BeanDefinition + BeanDefinitionRegistry= BeanDefinitionReader，比如 XmlBeanDefinitionReader： 而 BeanDefinitionRegistry 则是另一个维护 map 的接口： 通常 BeanDefinitionRegistry 和 BeanFactory 被实现在同一个实现里： BeanFactoryBeanFactory 自有其继承体系： 在 AbstractAutowireCapableBeanFactory 里有 createBean 的一个例子 ApplicationContextBeanFactory 是 Spring 早期设计的抽象，应该尽量不被直接使用，当代的 Spring 应该使用更加现代的抽象 ApplicationContext，如： 如果我们使用 xml 来初始化 ApplicationContext，则我们应该使用 ClasspathXmlApplicationContext： 这里引用的最重要的 refresh 方法，就是所有谈到 Spring 的文档里都必然谈到的 AbstractApplicationContext 里的 refresh()（经典的模板方法模式，所有的扩展点的顺序要依照它设定的方法来实现）： 如何实现自动装配？对于 AutoWired 而言，答案是使用 AutowiredAnnotationBeanPostProcessor 的生命周期钩子。可见，我们所有的 field injection 相关的注入，都要考虑 BeanPostProcessor 的钩子方法进行扩展。 对于 field injection，最关键的方法是： 和之前我设计和实现的缓存注入的思路是一样的，实际上所有的动态注入的 annotation 都应该这样设计，才能满足 Spring 的依赖管理的布局。"},{"title":"Spring 与数据库","date":"2020-07-19T01:47:18.000Z","url":"/2020/07/19/Spring-%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93/","tags":["Java","Spring"],"content":"Java 执行事务的过程 1.获取连接 Connection con = DriverManager.getConnection()2.开启事务con.setAutoCommit(true/false); 在 Spring 事务里（如 DataSourceTransactionManager 的 doBegin 方法）里，总是会显式地 con.setAutoCommit(false);（不然哪有事务可言）。3.执行CRUD4.提交事务/回滚事务 con.commit() / con.rollback();5.关闭连接 conn.close(); 本文涉及到的类型的类图 Spring 的事务管理核心类型和流程DataSource不同的数据源诞生不同的 DataSource。默认的 TransactionManager 本身是期待一个名叫“datasource”的数据源的。 FactoryBean不同的 DataSource 装入不同的 FactoryBean，比如 JPA 的 EntityManagerFactory。 PlatformTransactionManager桥接模式的实现端。 不同的 FactoryBean 装入不同的 PlatformTransactionManager，比如 JpaTransactionManager（实际上还可以被细分为 TransactionManager/EntityManager/SessionFactory/PersistenceUnit）。PlatformTransactionManager 管很多东西，如数据库方言、数据源（FactoryBean 也持有这个东西，但某些事务管理器宁愿自己冗余一份数据源方便自己处理）。 这个类型可以当做 API 用，但 Spring 官方推荐应该通过 AOP （所以它要被装入 Interceptor）或者 TransactionTemplate 使用。 它提供三个基本接口： TransactionDefinition事务定义 TransactionDefinition 包含很多属性： 是否只读 事务隔离级别 事务传播级别 超时 通过事务的定义，我们根据定义产生特定的事务实例 - 基本上 @Transactional注解里标记的信息都持有在这里。 TransactionStatus每个事务实例在 TransactionStatus 接口 里，事务管理器通过状态可以知道事务的状态信息，然后进行事务的控制。事务是否完成，是否是新的事务，是不是只能回滚等。 对于 TransactionDefinition 而言，transaction status object representing the new or current transaction。 TxAdviceBeanDefinitionParser基于 xml的配置，由 TxAdviceBeanDefinitionParser 负责生成 TransactionInterceptor 对象。 ProxyTransactionManagementConfiguration基于注解的配置，由 ProxyTransactionManagementConfiguration 负责生成 TransactionInterceptor 对象。 TransactionInterceptorTransactionInterceptor 继承了 TransactionAspectSupport（桥接模式的抽象端）。 它通过装入 PlatformTransactionManager ptm 来扩展 TransactionAspectSupport 的行为，类似桥接模式。 其事务执行关键代码是（注意，这段代码和 TransactionAspectSupport.invokeWithinTransaction是相互回调的关系）： TransactionAspectSupportTransactionAspectSupport 提供了 transaction infrastructure，是 Spring 的一切事务 Aspect 的重要祖先。 它使用一个 NamedThreadLocal 来保存当前的 TransactionInfo（包含了 TransactionStatus），所以每个事务就是线程隔离的。 AbstractPlatformTransactionManager所有的 应该从这个类型里派生出来，它提供了如下便利： 定义了（事务）传播行为 提供了事务同步服务 它的参考实现是JtaTransactionManager和DataSourceTransactionManager。 其中管理事务提交的代码 DataSourceTransactionManagerMyBatis 的数据源实际上使用的事务管理器在这里： MyBatis 的事务边界SqlSessionUtils// 每一段 sql 执行的时候都会执行这个操作 2020-03-31 23:30:30,056 [main] DEBUG (SqlSessionUtils:97) - Creating anew SqlSession 2020-03-31 23:30:30,060 [main] DEBUG(SqlSessionUtils:128) - Registering transaction synchronization forSqlSession[org.apache.ibatis.session.defaults.DefaultSqlSession@2cee1bcf] //这里虽然 closeSession，并没有破坏事务的原子性 2020-03-31 23:30:30,307 [main] DEBUG(SqlSessionUtils:186) - Releasing transactional SqlSession[org.apache.ibatis.session.defaults.DefaultSqlSession@2cee1bcf]2020-03-31 23:31:27,389 [main] DEBUG(SqlSessionUtils$SqlSessionSynchronization:284) - Transactionsynchronization committing SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@2cee1bcf]2020-03-31 23:31:27,398 [main] DEBUG(SqlSessionUtils$SqlSessionSynchronization:310) - Transactionsynchronization deregistering SqlSession[org.apache.ibatis.session.defaults.DefaultSqlSession@2cee1bcf]// 但只有整个事务提交的时候会执行这个操作 commitTransactionAfterReturning -&gt;Connection.commit Spring Boot 的增强设计在 Spring-Boot 的各种 spring-data-* 会根据 TransactionManagementConfigurationSelector 自动激活特定的 DataSource 以及相应的 TransactionManager。 Spring 的声明式事务七个传播性配置 TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。 TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。（注意这里，不要采坑） TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 1 可以保证嵌套事务使用同一个事务。 2 则要考虑嵌套事务时，内层事务挂起外层事务的问题，只有内层事务退出（不管正常还是不正常），外层事务才会逐步进入自己的余下的步骤。2 生成的事务是全新的事务。它拥有自己独立的隔离级别，持有自己的锁。这种传播性是用于某类 sequence 生成 id 的嵌套，让 id 生成的嵌套事务不持有太久的数据库锁-因为数据库两段式提交的方式，如果嵌套事务被大事务套住了，嵌套事务的锁要最后才提交。 7 意味着创建的事务是嵌套的事务，它的提交受外部事务控制，而回滚是否影响外部事务由外部事务自己决定。它会产生 savepoint。默认的情况下，嵌套事务的回滚应该触发外部事务的回滚，但在某些大任务拆解，逐步执行嵌套事务的场景下，个别嵌套事务的回滚可以被吞掉，以有效地保证外部事务的部分成功。 具体说明见 Juergen Hoeller 的说明： PROPAGATION_REQUIRES_NEW starts a new, independent “inner” transactionfor the given scope. This transaction will be committed or rolled backcompletely independent from the outer transaction, having its ownisolation scope, its own set of locks, etc. The outer transaction willget suspended at the beginning of the inner one, and resumed once theinner one has completed. Such independent inner transactions are for example used for idgeneration through manual sequences, where the access to the sequencetable should happen in its own transactions, to keep the lock there asshort as possible. The goal there is to avoid tying the sequence locksto the (potentially much longer running) outer transaction, with thesequence lock not getting released before completion of the outertransaction. PROPAGATION_NESTED on the other hand starts a “nested” transaction,which is a true subtransaction of the existing one. What will happenis that a savepoint will be taken at the start of the nestedtransaction. íf the nested transaction fails, we will roll back tothat savepoint. The nested transaction is part of of the outertransaction, so it will only be committed at the end of of the outertransaction. Nested transactions essentially allow to try some execution subpathsas subtransactions: rolling back to the state at the beginning of thefailed subpath, continuing with another subpath or with the mainexecution path there - all within one isolated transaction, and notlosing any previous work done within the outer transaction. For example, consider parsing a very large input file consisting ofaccount transfer blocks: The entire file should essentially be parsedwithin one transaction, with one single commit at the end. But if ablock fails, its transfers need to be rolled back, writing a failuremarker somewhere. You could either start over the entire transactionevery time a block fails, remembering which blocks to skip - or youmark each block as a nested transaction, only rolling back thatspecific set of operations, keeping the previous work of the outertransaction. The latter is of course much more efficient, inparticular when a block at the end of the file fails. 不同事务传播策略下嵌套事务的行为 使用嵌套事务的场景有两点需求： 需要事务BC与事务AD一起commit，即：作为事务AD的嵌套事务，事务BC只有在事务AD成功commit时（阶段3成功）才commit。这个需求简单称之为“联合成功”。这一点PROPAGATION_NESTED和PROPAGATION_REQUIRED可以做到。 需要事务BC的rollback不（无条件的）影响事务AD的commit。这个需求简单称之为“隔离失败”。这一点PROPAGATION_NESTED和PROPAGATION_REQUIRES_NEW可以做到。 换言之： 默认的传播级别（PROPAGATION_REQUIRED），使得嵌套事务只要失败，外部事务也只能回滚-rollbackOnly。 使用 PROPAGATION_REQUIRES_NEW，嵌套事务会被独立提交，而且一定会发生隔离失败（即使没有发生外部的 catch）。 能够让嵌套事务和外部事务一起提交的，只有 PROPAGATION_NESTED了。PROPAGATION_NESTED在事务AD执行到B点时，设置了savePoint（关键）。而且如果嵌套事务失败，则外部事务不会失败。 设置 savepoint 的关键流程在AbstractTransactionStatus里的 savepoint 是 jdbc 的 Connection 的概念，可被命名也可以不被命名（命名通常是 SAVEPOINT_计数器）。它代表着事务的一个位置，rollback 可以只 rollback 到 savepoint，然后当前事务自己决定是继续 rollback 还是继续 proceed。回滚到 savepoint 可以使用如下语句： 参考：《事务之六：spring 嵌套事务》 事务只读属性 只读事务用于客户代码只读但不修改数据的情形，只读事务用于特定情景下的优化，比如使用Hibernate的时候。 “只读事务”并不是一个强制选项，它只是一个“暗示”，提示数据库驱动程序和数据库系统，这个事务并不包含更改数据的操作，那么JDBC驱动程序和数据库就有可能根据这种情况对该事务进行一些特定的优化，比方说不安排相应的数据库锁，以减轻事务对数据库的压力，毕竟事务也是要消耗数据库的资源的。 但是你非要在“只读事务”里面修改数据，也并非不可以，只不过对于数据一致性的保护不像“读写事务”那样保险而已。 因此，“只读事务”仅仅是一个性能优化的推荐配置而已，并非强制你要这样做不可。 事务超时所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以int 的值来表示超时时间，其单位是秒。 默认设置为底层事务系统的超时值（注解的默认值是-1），如果底层数据库事务系统没有设置超时值，那么就是none，没有超时限制。 其他设置事务超时的方法： 在 jdbc 连接字符串里配置（这个方法最好）。 在数据库层面配置。 在中间件层面配置。 参考： 《Spring事务原理完全解析》 《Spring事务原理分析》 《Transactionality》 "},{"title":"软件方法","date":"2020-07-12T03:37:59.000Z","url":"/2020/07/12/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95/","tags":["系统设计"],"content":"建模带来竞争优势。 前言 “唱曲的名家，唱到极快处，吐字依然干净利落”。 不能站在别人的肩膀上看得更远，只是摘抄别人的观点，无意义。要有足够的积累，和深度的思考。 涉众（stakeholder）往往会做而不会定义，把不同类型的涉众放在一起访谈时，只会剩下在场军衔最高那个人的意见。 需求变更的时候，要注意涉众利益角度分析。 项目的流程步骤： 寻找老大 揣摩愿景 业务建模 系统用例 需求规约 分析模型 设计开发 只有一个领域（核心域）的知识是系统能在市场上生存的理由。 拿来主义要摒除门户之见，不关注流派和风格，着力于细节和应用。 建模与 uml利润 = 需求 - 设计需求：提升销售设计：降低开发维护成本 几种弊习： 从需求直接映射设计，会得到大量的重复代码。 从设计出发来定义需求，会得到一堆假的“需求”。 从涉众视角对系统功能分包会得到需求包。子系统是基于内部视角根据系统部件的耦合和内聚情况进行切割。 需求 设计 卖的视角 做的视角 具体 抽象 产品当项目做 项目当产品做 设计源于需求，高于需求 建模工作流 业务建模：描述组织内部各系统如何写作，使得组织考验为其他组织提供有价值的服务。新系统不过是组织为了堆外提供更好的服务，对自己的内部重新设计而购买的一个零件。组织引进一个软件系统，和招聘一名新员工没有什么本质区别。如果通过业务建模推导新系统的需求，而不是拍脑袋得出。- 产出的工件是对系统协作关系的描述。 需求：哪些是涉众在意的、不能改变的契约，哪些不是-严防“做”影响“卖”。- 产出的工件是涉众视角看到的功能。 分析：提炼为了满足功能需求，系统需要封装的核心域机制。对核心域作研究，可以帮助我们达到核心域的复用。- 产出的工件是核心域机制。 设计：为了满足质量需求和设计约束，核心域机制如何映射到选定平台上实现。- 产出的工件是核心域机制的实现 不要用设计映射需求。要关注核心域的核心价值。不同工作流之间产出的工件的区别不在于形式，而在于内容。要重视建模，要重视建模的工作流（modeling workflow）。 UML 图现代的 uml 图脱始于“三友”（three amigo）的在 rational 的标准化工作。 ![Uml 图.png](Uml 图.png)[Uml 图.xmind](Uml 图.xmind) uml 里的图不必全部用到（正如没有哪本经典小说使用了所有的单词一样），大多数情况下只需要用到类图、序列图和用例图，（在某些时候，可以用活动图带图序列图）。 要达成基本共识的沟通，首先要使用统一的语言。使用潦草的草图，解释权在画图的人手里，别人看得似懂非懂，其实就是在用形式上的潦草，来代替思考上的潦草。简陋的形式是没有想好的结果，也是可以拿来为草率的思考作为开脱的借口。 即使是在数学和音乐领域，每一种符号背后都蕴含了基本共识。不要违反这种基本共识。 UML 模型不是用来跟涉众沟通的，是用来跟组织内部人员沟通的。 建模和敏捷敏捷是一个过程家族，是一套 The New Methodology（Martin Fowler语）。 在现实实施中，建模技能不足，流程知识不够的团队在实施过程中，使用“敏捷过程”来掩盖“没有过程”的事实。 你的系统并不特别见识少的病人总以为自己得了怪病，其实到医院让医生一看，太普通了。 软件开发到了极高境界真的是艺术，恐怕也不是大多数人目前有资格谈的。 模型的组织建模工作流和所用的 UML 元素不是一一对应的。模型可以按照 UML 元素的种类组织，也可以按照工作流组织。 可以先按工作流组织。 UML 组织的模式如下： 业务建模 愿景 业务用例 业务对象 需求 系统用例 分析 实体类 控制类 用例实现 边界类 设计 表示层 领域层 应用层 基础设施层 另一种组织的方式是用试图来做 group。 业务建模之愿景不要在错误的方向上努力，做得越多，错得越多。 没有愿景的支持，所有的口号就是空话。 业务建模之业务用例图开发人员有时会有意无意把自己的系统想得太重要，是一种致命的自负。 开发团队经常发些需求“容易变化”，问题的根源之一是需求来路不正。没有把系统当做一个零件放在组织中来看，靠拍脑袋得出需求，导致得出的系统需求是错的。“需求剧烈变化”只是假象，真正的需求没有变过，只是一开始得到的需求是假的。 业务执行者（Business Actor）以某组织为研究对象，在组织之外和组织交互的其他组织（人群或机构）就是该组织的执行者。因为研究对象是一个组织，所以叫业务执行者。 业务工人（Business Worker）和业务实体组织内的人称为业务工人（Business Worker）。 业务工人可以被其他业务工人替换，也可以被业务实体替换（Business Entity）。业务实体是组织中的非人智能系统。 责任转移的思想对识别带引入系统的需求很有帮助。开发人员说，“我在开发一个新系统”，其实说的就是“我在开发的一个新的业务实体，取代现有业务工人或业务实体的一些责任”。 举个例子，我们要先画出业务序列图，然后把业务序列图中业务工人对业务实体的操作，映射为系统用例里的动宾结构。而业务用例图里没有业务工人和业务实体，只有业务执行者。业务用例图和系统用例图的划分边界在组织边界。 这背后的深刻思想是：类通过协作实现用例。组织的业务工人（actor 为 business worker）和业务实体写作完成业务用例，系统的类（主要的角色为 系统、其他 use case）协作完成系统用例。 其他解释：《业务用例与系统用例》 业务用例：业务部门或组织为其外部客户或内部特定人员（业务主角）提供有价值的服务（业务用例）； 系统用例：用户（角色）使用系统时，进行的一次比较完整的交互，并得到了有价值的结果； 功能用例：功能是站在系统内部的静态概念，没有考虑什么人在什么时候如何使用 识别业务执行者识别业务执行者时，抽象级别应该一致。例如，描述系统之间的抽象，部门应该对部门，而不是部门的员工对部门。 识别业务用例业务用例指业务执行者希望通过和所研究组织交互获得的价值。业务流程是业务用例的实现。这样的思路对改进业务流程提供的帮助是：先归纳出组织对外提供什么价值，在思考如何更好地优化组织内部流程来实现这些价值。 业务用例是组织的价值，不会因为某个人脑系统或电脑系统的存在而消失而改变。所以“这个系统的业务用例是什么”这样的说法是错误的。 不能把业务用例的某个流程也当做业务用例，应该做顶层抽象，作为业务用例。 不要把组织内部的业务工人对业务实体的操作当做业务用例，因为它们不是组织的价值。 阿布思考法另一种角度的以终为始。 先想象一个资源不受限时的完美系统，然后用有限的技术资源来山寨（粗劣模仿）这个系统。-本方法出自《Why Not？：How to Use Everyday Ingenuity to Solve Problems Big and Small》 需求之系统用例图系统边界是责任的边界。 系统用例的定义：系统能够为执行者提供的、涉众可以接受的价值。与业务用例相比，研究对象从组织变成了系统。 系统用例是业务工人和业务实体之间的用例。 用例图不应该出现交叉，不同 actor使用同一用例，可能意味着用例应该拆分。 需求启发 和涉众沟通应该采用视图，而不是模型-介质要产生变化。 和涉众沟通应该聚焦涉众利益，而不是需求。 "},{"title":"FatJar 问题","date":"2020-06-03T08:47:19.000Z","url":"/2020/06/03/FatJar-%E9%97%AE%E9%A2%98/","tags":["Java","Maven"],"content":"什么是 FatJarFatJar 又叫 uber-jar。uber 不是打车的 uber，而是德语里面的 uber，意思是英语里面的 over-勉强可以翻译为超越。 FatJar 是一个 all-in-one 的 jar，它可以让部署和运行更加便利，它让最终部署和运行的环境不依赖于任何 maven 或者 lib 的 classpath。 FarJar 的三种具体类型非遮蔽的（Unshaded）依赖于maven-assembly-plugin。 descriptorRef 有： bin 只打包编译结果，并包含 README, LICENSE 和 NOTICE 文件，输出文件格式为 tar.gz, tar.bz2 和 zip。 jar-with-dependencies 打包编译结果，并带上所有的依赖，如果依赖的是 jar 包，jar 包会被解压开，平铺到最终的 uber-jar 里去。输出格式为 jar。 src 打包源码文件。输出格式为 tar.gz, tar.bz2 和 zip。 project 打包整个项目，除了部署输出目录 target 以外的所有文件和目录都会被打包。输出格式为 tar.gz, tar.bz2 和 zip。 所有的 jar 都被 unpack，然后 repack。 和 java 的缺省类加载器一起工作。 遮蔽的（Shaded）依赖于maven-shade-plugin。 所有的 jar 都被 unpack，然后 repack，而且被刻意 rename（所以叫 shade），以避免 dependency version clashes。这种 rename 会产生字节码级的变动，使得类的 package 变化。 和 java 的缺省类加载器一起工作。 shaded jar 依然有可能导致版本冲突，所以需要依赖 class-relocation 解决类重定位的问题，依赖 Resource Transformers 解决资源重定位的问题。 JAR of JARs只是把 jar 打包在一起，jar 里有 jar。 我们常见的 maven package 无插件操作打出来的 jar 就是这种 jar。 默认的 fatjar 里不一定包含所有的依赖，所以需要使用插件： 其他 jar 的分类 Skinny – Contains ONLY the bits you literally type into your code editor, and NOTHING else. Thin – Contains all of the above PLUS the app’s direct dependencies of your app (db drivers, utility libraries, etc). Hollow – The inverse of Thin – Contains only the bits needed to run your app but does NOT contain the app itself. Basically a pre-packaged “app server” to which you can later deploy your app, in the same style as traditional Java EE app servers, but with important differences. Fat/Uber – Contains the bit you literally write yourself PLUS the direct dependencies of your app PLUS the bits needed to run your app “on its own”. Spring Boot 与 FatJar实际上 Java 的原生类加载器处理普通的 Jar 里面的嵌套 class 是友好的，但处理嵌套的 jar 是不友好的。 Spring Boot 的 jar 就是 fatjar，这种 fatjar 携带所有依赖，而且有专有的类加载器来处理嵌套 jar 的依赖问题。这种 fatjar 是最简单的，运行起来最友好的。 分析依赖本来要逐层解压这种 jar-of-jars，但很多解析工具只解析一层的话，反而会被其他问题触发。例如，有时候为了解决依赖版本 冲突而指定 jar 的版本，而直接在一个多模块的 parent pom 里面短路地指定了一个依赖版本，反而会触发解析工具的检测规则。 这样会打印出两个 jar，一个 jar 是普通 jar，另一个 jar 是 jar.original。第二个 jar 是原始 jar，而第一个 jar 则是大而全的真正的 fat-jar。 参考文献： 《Java 打包 FatJar 方法小结》 《What is an uber jar?》 《可执行的uberJar (fatJar)》 "},{"title":"交易系统模型设计","date":"2020-06-01T09:59:55.000Z","url":"/2020/06/01/%E4%BA%A4%E6%98%93%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1/","tags":["系统架构"],"content":"交易系统.xmind"},{"title":"Spring 概览","date":"2020-04-20T07:45:39.000Z","url":"/2020/04/20/Spring-%E6%A6%82%E8%A7%88/","tags":["Java","Spring"],"content":"Spring 起源于 2003 年，它作为 Java EE 平台规范的补充，而不是完全拥抱 specification。 Spring 可以指的是 entire family of projects。也可以单指 Spring Framework（换言之，Spring Framework 本身也只是 family 的一部分）。 Spring Framewo 被模块化了，它的核心只包括 core container（主要解决依赖注入问题）。但是针对不同的应用架构，它提供不同的支持，包括 messaging、transactionl、persistence 和 web。这些模块原本命名为 “spring-core” 和 “spring-context”，在 Java 9 的 jigsaw 项目来临之时，也开始支持 module path，生成“自动模块名”清单项，并且定义语言级别的模块名，如”spring.core”、”spring.context”。 Spring 支持的 JSR 有： Servlet API (JSR 340) WebSocket API (JSR 356) Concurrency Utilities (JSR 236) JSON Binding API (JSR 367) Bean Validation (JSR 303) JPA (JSR 338) JMS (JSR 914) TA/JCA setups for transaction coordination Dependency Injection (JSR 330) Common Annotations (JSR 250) !(spring-framework-architecture.png)[spring-framework-architecture.png]!(spring-modules.png)[spring-modules.png]"},{"title":"Maven 全局配置文件settings.xml","date":"2020-04-18T08:07:27.000Z","url":"/2020/04/18/Maven-%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6settings-xml/","tags":["Java","Maven"],"content":"xml 小知识 xmlns:xsi xmlns:即为别名 &lt;settings xmlns=”; xmlns:xsi=”; xsi:schemaLocation=”; settings.xml 的功能settings.xml 是maven的全局配置文件。而pom.xml文件是所在项目的局部配置。Settings.xml中包含： 本地仓储位置 修改远程仓储服务器 认证信息 settings.xml文件位置settings.xml文件一般存在于两个位置：全局配置（通常被我们忽略的更全局的配置）: ${M2_HOME}/conf/settings.xml用户配置（通常被我们使用的配置）: ${user.home}/.m2/settings.xmlnote：用户配置优先于全局配置。${user.home} 和和所有其他系统属性只能在3.0+版本上使用。请注意windows和Linux使用变量的区别。 配置优先级需要注意的是：局部配置优先于全局配置。配置优先级从高到低：pom.xml&gt; user settings &gt; global settings如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。 顶级元素 LocalRepository作用：该值表示构建系统本地仓库的路径。其默认值：~/.m2/repository。 InteractiveMode作用：表示maven是否需要和用户交互以获得输入。如果maven需要和用户交互以获得输入，则设置成true，反之则应为false。默认为true。 UsePluginRegistry作用：maven是否需要使用plugin-registry.xml文件来管理插件版本。如果需要让maven使用文件~/.m2/plugin-registry.xml来管理插件版本，则设为true。默认为false。 Offline作用：表示maven是否需要在离线模式下运行。如果构建系统需要在离线模式下运行，则为true，默认为false。当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。 PluginGroups作用：当插件的组织id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins和org.codehaus.mojo。 Servers作用：一般，仓库的下载和部署是在pom.xml文件中的repositories和distributionManagement元素中定义的。然而，一般类似用户名、密码（有些仓库访问是需要安全认证的）等信息不应该在pom.xml文件中配置，这些信息可以配置在settings.xml中。 Mirrors作用：为仓库列表配置的下载镜像列表。 Proxies作用：用来配置不同的代理。 Profiles作用：根据环境参数来调整构建配置的列表。settings.xml中的profile元素是pom.xml中profile元素的裁剪版本。它包含了id、activation、repositories、pluginRepositories和 properties元素。这里的profile元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是settings.xml文件的角色定位），而非单独的项目对象模型设置。如果一个settings.xml中的profile被激活，它的值会覆盖任何其它定义在pom.xml中带有相同id的profile。 一个完整的远程仓库，需要配置至少如下四类 repo 来管理 jar： release snapshot thirdParty-release thirdParty-snapshot 两个具体的例子： Activation作用：自动触发profile的条件逻辑。如pom.xml中的profile一样，profile的作用在于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。settings.xml文件中的activeProfile元素可以包含profile的id。profile也可以通过在命令行，使用-P标记和逗号分隔的列表来显式的激活（如，-P test）。 properties作用：对应profile的扩展属性列表。maven属性和ant中的属性一样，可以用来存放一些值。这些值可以在pom.xml中的任何地方使用标记${X}来使用，这里X是指属性的名称。属性有五种不同的形式，并且都能在settings.xml文件中访问。 注：如果该profile被激活，则可以在pom.xml中使用${user.install}。 Repositories作用：远程仓库列表，它是maven用来填充构建系统本地仓库所使用的一组远程仓库。 pluginRepositories作用：发现插件的远程仓库列表。和repository类似，只是repository是管理jar包依赖的仓库，pluginRepositories则是管理插件的仓库。maven插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginRepositories元素的结构和repositories元素的结构类似。每个pluginRepository元素指定一个Maven可以用来寻找新插件的远程地址。 ActiveProfiles作用：手动激活profiles的列表，按照profile被应用的顺序定义activeProfile。该元素包含了一组activeProfile元素，每个activeProfile都含有一个profile id。任何在activeProfile中定义的profile id，不论环境设置如何，其对应的 profile都会被激活。如果没有匹配的profile，则什么都不会发生。例如，env-test是一个activeProfile，则在pom.xml（或者profile.xml）中对应id的profile会被激活。如果运行过程中找不到这样一个profile，Maven则会像往常一样运行。 参考： 《Maven 全局配置文件settings.xml详解》 《xsi:schemaLocation有何作用》 "},{"title":"Spark SQL 原理","date":"2020-04-16T10:06:24.000Z","url":"/2020/04/16/Spark-SQL-%E5%8E%9F%E7%90%86/","tags":["Java","Scala","Spark"],"content":"Spark SQL的发展历程为了给熟悉的 RDBMS 但又不理解 MapReduce 的技术人员提供快速上手的工具，Hive 应运而生，他是当时唯一运行在 Hadoop 上的SQL-On-Hadoop 工具。 但是 MapReduce 计算过程中大量的中间磁盘落地过程消耗了大量的 I/O，降低的运行效率，为了提高 SQL 的执行效率，大量的 SQL-On-Hadoop工具开始产生，而 Shark 是其中一个表现较为突出的项目。 Shark是伯克利实验室 Spark 生态环境的组件之一，它主要修改了内存管理，物理计划和执行三个模块，值得它能运行在 Spark 的引擎上，从而提高 SQL 查询的效率。 但是随着 Spark 的发展，Shark 对 Hive 过多的依赖制约了 Spark 的设计理念和各个组件之间的相互继承，所以 Spark 团队停止了对 Shark 的开发，提出了 SparkSQL 项目。 因为摆脱了Hive 的过度依赖，Spark SQL在数据兼容性，性能优化和组件扩展等各个方面都得到了极大的方便和发展。 提出了 SparkSQL 项目之后，SQL On Spark 发展出了两条支线，SparkSQL 和Hive on Spark。 Spark SQL 解析流程Spark SQL 对 SQL 语句的处理和关系型数据库类似，即词法/语法解析，绑定，优化，执行。 Spark SQL 会先将 SQL 语句解析成一棵树，然后使用各种规则对 Tree 进行绑定和优化等处理。 使用SessionCatalog保存元数据在解析 SQL 语句之前，会创建 SparkSession，在 Spark2。0版本之后，SparkSession封装了 SparkContext 和 SQLContext 创建，也不再区分 SQLContext 和 HiveContext。 涉及到诸如表名，字段名称和字段类型等元数据都会保存在 SessionCatalog 中。 此外，创建临时表或者试图的过程，其实就会往 SessionCatalog 注册。 解析 SQL: 使用 ANTLR 生成未解析的逻辑计划只要是在数据库类型的技术里面，比如传统的 MySQL，Oracle 或者现在大数据领域的Hive。 它的基本的 SQL 执行的模型，都是类似的，首先都是要生成一条 SQL 语句的执行计划。 当调用 SparkSession 的 sql 或者 SQLContext 的 sql 方法时，就会使用 SparkSqlParser 进行解析 SQL。 使用的 ANTLR 进行词法解析和语法解析。 它分为词法分析和构建分析树或者语法树 AST 2个步骤来生成UnresolvedLogicalPlan。 使用分析器 Analyzer 解析逻辑计划在该阶段，Analyzer 会使用 Analyzer Rules，并结合 SessionCatalog，对未解析的逻辑计划进行解析，生成已解析的逻辑计划。 使用优化器 Optimizer 优化逻辑计划优化器也是会定义一套 Rules，利用这些 Rules 对逻辑计划和 Expression 进行迭代处理，从而使得树的节点进行优化。 在传统的 Oracle 等数据库中，通常都会生成多个执行计划，然后根据优化器针对多个计划选择一个最好的计划。 而SparkSQL中，是对一个已生成的执行进行优化生成一个新的执行计划。 比如，一个 SQL 语句 此时，在执行计划解析出来的时候。 其实就是按照sql 原封不动的样子来解析成可以执行的计划的。 但是Optimizer会对执行计划进行优化。 在这个例子中的 where 条件是可以放入子查询中的，这样子查询的数据量大大变小，可以优化执行速度。 相应的执行计划就会变为 使用SparkPlanner生成物理计划SparkPlanner使用 Planning Strategies，对优化后的逻辑计划进行转换，生成可以执行的物理计划SparkPlan。 生成的物理计划区别于逻辑计划的是执行计划在这里已经非常清晰了。 从哪个文件读取什么数据，从哪里读取数据，如何操作等等都已经明确了。 使用 QueryExecution 执行物理计划此时调用 SparkPlan 的 execute 方法，底层其实已经在触发创建并执行 Job 了，然后返回相应结果。 三 SparkSQL中物理计划的执行Spark 的根基: RDD与许多专有的大数据处理平台不同，Spark 建立在统一抽象的 RDD 之上，使得它可以以基本一致的方式应对不同的大数据处理场景。 也就是说，要理解SparkSQL，首先要理解 SparkRDD。 RDD的全称是 Resilient Distributed Datasets，是一个容错的，并行的数据结构，可以让用户显示的将数据存储到磁盘和内存中。 同时，RDD 还提供了一组丰富的操作来操作这些数据。 在这些操作中，诸如 map，flatMap，filter 等转换操作实现了monad模式，很好地契合了Scala的集合操作。除此之外，RDD还提供了诸如join、groupBy、reduceByKey等更为方便的操作（注意，reduceByKey是action，而非transformation），以支持常见的数据运算。 RDD提供了两方面的特性persistence和patitioning，用户可以通过persist与patitionBy函数来控制RDD的这两个方面。RDD的分区特性与并行计算能力(RDD定义了parallerize函数)，使得Spark可以更好地利用可伸缩的硬件资源。若将分区与持久化二者结合起来，就能更加高效地处理海量数据。 既然 RDD 是 spark job 的根基，所有 Spark 的计算都是基于 RDD 的相应Transformation 和 Action 操作。 Spark的整个生态系统与Hadoop是完全兼容的,所以对于Hadoop所支持的文件类型或者数据库类型,Spark也同样支持。 Spark提供了可以读取 Hadoop 文件的接口，对于外部存储创建而言，hadoopRDD 函数是最常用的在 Spark 中创建 RDD 的接口。 也就是说用户可以用这个接口读取集群中的数据并转换成相应的 RDD，然后接入 spark 计算引擎中。 从物理执行计划到 RDD经过 Spark 的 Catalyst 解析优化器对于 sql 的分析之后，已经生成了相应的物理执行计划，而对于已经可以开始执行的 SparkSQL的 Physical Plan，其执行目标就是调用 action 算子之后的 RDD。 SparkPlan主要包含四种操作类型: BasicOperator Join Aggregate Sort 对于 SparkSQL 的物理执行计划，基本可以通过这四种操作类型来完成。 Spark 会以这四种操作为基础创建出相应的 task来分别执行。 这四种操作类型的详细介绍这里不做过多阐述。 SparkSQL中任务的执行模式在介绍了 SparkSQL 如何生成相应的物理执行计划以及物理执行计划是如何执行之后，SparkSQL 任务就进入了具体的执行阶段。 SparkSQL 具体任务的执行方式和普通 Spark 任务的执行方式并无差别。 Spark 任务运行时的角色可以分为三种: driver，executor(worker) 以及cluster manager。 Spark中的driver其实和yarn中Application Master的功能相类似。主要完成任务的调度以及和executor和cluster manager进行协调。 在YARN中，每个Application实例都有一个Application Master进程，它是Application启动的第一个容器。它负责和ResourceManager打交道，并请求资源。获取资源之后告诉NodeManager为其启动container。如果对 MapReduce 比较熟悉的话，一定不会对 Applicaiton Master 陌生。 在 Spark on Yarn 中，任务的执行模式可以分为 yarn-client 和 yarn-cluster 两种。 从深层次的含义讲，yarn-cluster和yarn-client模式的区别其实就是Application Master进程的区别，yarn-cluster模式下，driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行。然而yarn-cluster模式不适合运行交互类型的作业。而yarn-client模式下，Application Master仅仅向YARN请求executor，client会和请求的container通信来调度他们工作，也就是说Client不能离开。看下下面的两幅图应该会明白（上图是yarn-cluster模式，下图是yarn-client模式）： SparkSQL 中任务的具体执行了解了 Spark 任务的执行模式之后，相应的 job 还不能马上开始运行。 这是因为一个完整的执行计划可能比较复杂，完整的数据量也比较大，直接完整执行不太现实。 通常情况下，一个分布式计算引擎都会将一个完整 job 进行切割分批运行，spark 也是这么做的。 在 Spark 中，task 是一个 Job 进行切割后运行的最小运算单元，一般情况下，一个 rdd 有多少个 partition，就会有多少个 task，因为每一个 task 只是处理一个 partition 上的数据。 当在YARN上运行Spark作业，每个Spark executor作为一个YARN容器(container)也就是 executor运行。Spark可以使得多个Tasks在同一个容器(container)里面运行。这种情况在 spark 中通过核数来控制，这也是一个与 MapReduce 较大不同的地方。 而 task 进行组合分批后，通常称为 stage。 也就是说一个Job会被拆分为多组Task，每组任务被称为一个Stage就像Map Stage， Reduce Stage。Stage的划分在RDD的论文中有详细的介绍，简单的说是以shuffle和result这两种类型来划分。在Spark中有两类task，一类是shuffleMapTask，一类是resultTask，第一类task的输出是shuffle所需数据，第二类task的输出是result，stage的划分也以此为依据，shuffle之前的所有变换是一个stage，shuffle之后的操作是另一个stage。 Spark 会为不同的 stage 以及不同的 task设好前后依赖，来保证整个 job 运行的正确性和完整性。 当最后一个resultTask 的上游 task 全部运行完之后即可开始运行，该resultTask 的结束也意味着 job 的成功运行。 至此，一个 SparkSQL 的任务从解析到生成逻辑计划，生成物理执行计划，再到具体执行返回结果的完整运行原理介绍完毕。"},{"title":"gradle 总结","date":"2020-04-11T02:37:59.000Z","url":"/2020/04/11/gradle-%E6%80%BB%E7%BB%93/","tags":["Java","Gradle"],"content":"常用命令"},{"title":"《枪炮、病菌和钢铁》札记","date":"2020-04-10T02:30:05.000Z","url":"/2020/04/10/%E3%80%8A%E6%9E%AA%E7%82%AE%E3%80%81%E7%97%85%E8%8F%8C%E5%92%8C%E9%92%A2%E9%93%81%E3%80%8B%E6%9C%AD%E8%AE%B0/","tags":["读书笔记"],"content":" 先发未必先到，关键性的因素可能在中后半段才起作用。 代差很可怕，代差带来的结果是压倒性的，难以逆转和抗拒的。 直接因素是什么，终极因素是什么？点在哪里，面是什么？ 地久天长的力量：群体的理解是深刻的，但对更大的事物的理解是盲目的-更地久天长的东西往往更大，而更大的东西越需要接力赛式的理解。这就是得天独厚的意义。 天造地设的差异，往往影响非常深刻。有些东西的潜力很大，有些东西的潜力很小。有些东西的潜力易于发觉，因为盲区很小；而有些东西的潜力难于发觉，需要更长的时间来观察-如果这一过程没有被外来的其他力量所中断的话。 两拨农民，都是文盲。一拨农民的祖先长期和从驯化动物得来的病菌作斗争，带有免疫力和另一拨农民作者，对另一拨农民是灭顶之灾-欧洲的拓殖者就是这样消灭美洲的原住民的，这样的军队才是最可怕的。从这个角度来看，被保护得很好的群体，未必能够在历史长河中获胜，因为他们不知道竞争力差异也许来自一个意想不到的维度。 安娜卡列尼娜法则：关注导致失败的因素更重要，导致失败的因素比想象中多。 熊不可养太大，养到一岁就就可以小心为妙了-俄罗斯人恐怕不同意。 纬度对生物的影响，比经度要大，从最南到最北传播，穿越中间有极端气候的地带的时候最难。巴拿马的海峡，安第斯山脉，都是意想不到的阻隔，特别是有些适合产生农业社会的品种，在他们偏南或者偏北的一侧的时候。 东西向发展的阻碍，来自于干旱的草原，和高耸的山脉-这也是中国文明独立发展的屏障。海拔、梯度变化，也能起到重大的阻隔作用。 有些病是细菌的福气，是人的灾难。有些病只有人口少的地方才有，有的病只有人口多的地方才有-拥挤的城市对这样的病菌而言是天堂。 疾病和饥饿对士气的破坏才比简单地杀伤人口更加厉害。在多数情况下，侵略者靠疾病打击原住民，如欧洲人在大航海时代以后做的事情一样；在少数情况下，原住民靠疾病来抵抗侵略者，如同远东和南亚的疾病阻止欧洲人东进一样。 字母只产生过一次，是闪族人而不是腓尼基人。 发明是需要之母，而不是相反。 技术会自我催化，导致技术爆炸。这并不是必然发生的，必须有足够多的技术相互融合，技术总是会越来越重要的。技术发展的速度起初慢得看不出来，最后快得跟不上去。 定居的生活方式不一定会导致农业（种植 + 畜牧业的物种驯化组合），也可能是狩猎采集和农业的混合经济，游牧民族也可以定居。农业是一种风险投资，对远古人而言，它的好处是不可能事先预见到的-没有人见过真正的农业是什么样的。发展农业实际上是一种风险对冲。澳大利亚过于干旱，发展农业划不来，所以农业永远没有发展起来。于是澳大利亚永远没有进入农业社会，没有产生高密度的人口，和灿烂的文明。只有一些介于使用原始石器的部落人群-维持在狩猎采集的状态，人类社会无论如何再也不会就此倒退了。 新月沃土和中国，是两个独立发展的文明中心。中国可能存在多个独立发展的农业起源，以此产生多个文化中心。 在农业社会，农业和人口密度相互决定。人口密度决定社会分化程度，高度分化的社会，有专门进行集约化农业生产的农民，有集中统一的行政机关追求统一的效率，有专门思考抽象问题的人才担任首领和行政长官，有专门生产武器的工艺人，和专门进行残酷战争的士兵，这种形态的社会，对不具有这种形态的社会具有碾压性优势。 旧石器时代 -&gt; 新石器时代 -&gt; 农村公社（从族群到部落）-&gt; 奴隶社会 -&gt; 封建社会 -&gt; 资本主义社会。农村公社时代的首领如果不集权和世袭，无法进入国王时代。早期的贵族社会，是从氏族社会演变出来的（如黄帝的儿子，犹太人的十二支）。 意识形态是盗贼统治者为了保障统治而发明的辩护工具。 病菌、文字、技术和政府+宗教，是历史最广泛模式的四种推动力。 文字是书写系统的一部分，印刷术是另一部分。文字最初并不打算用来叙事和抒情，只是统治阶级用来记账用的。文字意味着权力，所以统治阶级要垄断它。 简单的社会分工里，猎人、樵夫、种田人和诗人，相互交换劳动产品。复杂的社会分工里，出现专门的经济团体-公司、商社、行会、政府部门。 政府宣扬意识形态，是为了控制人民。 人多了以后，社会变得不稳定，为了维护秩序，需要中央集权。否则无法化解没有亲属关系的人群之间的冲突问题，以及经济交换的效率问题-小的社会人人都是亲属，反而无这样的问题。但这样的社会形成，人类的不平等就出现了-因为机会的不对称，最终会造成所得、占有、积累的不平等。 社会契约论假定，人们意识到大社会更复杂更强大也会对个人更好，所以自愿放弃了小社会-但历史上大社会通常是通过征服的方式来迫使其他人放弃小社会的。即使是当代的现代化，农村城镇化进程里，依然存在这个现象。 因果链可以顺着读，也可以逆着读。有时候我们读到了一个链条，以为顺着读是对的，其实逆着读更是对的。 人类在石器时代是没有农业的，狩猎技巧高度成熟；在有了农业以后，大部分人的狩猎技能反而退化了-驯化植物使得植物进化而人类退化；人类进入工业社会以后，农业技能反而退化了；进入信息化社会以后，我们丢弃了什么呢？ 美洲一直都没有合适的驼兽可以驯服，所以它文明里缺失拖、拉、犁、战争的工具，以致于他们的农业比其他大陆的农业缺乏效率，也并没有大规模战争的技术。 农业并不一定由定居者产生，可以由外部人带来，外部交流，其实是一种加速。没有经过加速而自然发展的社会，不会有技术跃迁、爆炸，在现代人看来，成为了一种孑遗。 独特的环境带来独特的生活，独特的生活带来独特的文化：雕刻、绘画和建筑。 没有统一的中央政府，部落之间的冲突简直无日无有，酋长管辖地是一种飞跃。 有定居的生活才有固定的财产，才会有技术进步。 只有几百人的群体，在完全隔绝的情况下不可能无限期生存下去，注定灭绝（塔斯马尼亚人的一些支系）；几千人的群体，可以生存 10000 年，但文化上要失去很多东西（澳大利亚的一些土著人连回力标都不会用了）-因为失去规模，就失去了维持势能的方法，就会失去分工，所有人都会渐渐平凡化-由这个结论推出来，现代社会反而容易诞生个人的奇迹。 巨大的地理条件差异产生的分隔，可以让文明之间的距离，远得好像望着月亮上的山一样 坚决的移民政策，会带来疾病之间的战争-永远不停歇地进入当地的传染源，最先被消灭干净，是占据富饶土地的高发展的原住民，因为那些土地最适合殖民，最后留下来的，只有居住在无用之地的居民；不坚决的移民政策，对原住民而言是好事。 大一统在世界历史上是异数、少数，中国是异数、少数。中国汉语文化体系通过征服，使得其他民族变得“文化上更加劣等”，以此打破人种的隔离，使得各少数民族放弃了自己的语言，迅速地单一化。 纸往西方传播完全是一个偶然，因为高仙芝在怛罗斯之战被偷袭失败，唐朝的工匠被阿拉伯帝国所俘虏。 中国古代的两条河流既贯通东西，也能够加速南北的交流，极大地便利了农业文明在全国的发展。但，水利产生国家是一种幻想，国家产生水利是文明的伟大成就。 象形文字、楔形文字、闪族字母文和中文，是大相径庭的书写系统。 新大陆里有古老的悠久文化，属于欧洲人祖先的那种文化，欧洲人称它为新大陆；而旧大陆里占统治地位的是近四千年来才诞生的文化，甚至有其他区域带来的文化，欧洲人称它为旧大陆。因为欧洲人眼里新大陆的原住民不是文明的人，新大陆尚处于一个等待 civilized 的阶段，是一片需要拓殖的处女地。 客从何处来？华北人从华北来，华南人从华南来，热带东南亚的晚近住民（现在也已占大多数），也从华南来。澳大利亚的人大部分从欧洲来，而只有赤道新几内亚的少部分地区，还有当年划着小船来的原始亚洲人的后裔。 美洲和澳洲不受上天宠爱：他们的大型哺乳动物灭绝得太快了，没有留下适合驯化的品种；美洲的玉米的祖先-蜀黍，最初一个棒子只有拇指大小。但有一点例外，全世界所有的社会，都不约而同地在大概在 10000 年前驯化了狗-即使不是作为食物。 新月沃土曾经领先于全球，因为他们拥有最好的可驯化物种和最好的农业环境，因此最早期的帝国皆称雄于此。但后来衰落了。因为他们自己挖自己的墙角，过度发展摧毁了他们的生态体系。在欧洲人学足了新月沃土的技能以后，权力西移了。 欧洲是分裂的，所以它始终是活跃的，不可能自我封锁，所以进化更快；但中国是统一的，所以一旦有若干决策失误，就可能大大错过某些很偶然地发明创造的时机-即使中国一直是世界上最优越的农业大国之一。这个解释有点牵强。只能解释欧洲一连串的爆炸和跃迁-文艺复兴、地理大发现、工业革命、科学革命、政治革命和哲学革命。 极其容易被忽略的是，即使客观环境已经改变，但精神上骨子里还有强国的文明系统的国家，依然拥有成为强国的潜力。所以（又要引用斯大林说的一句话），希特勒来了又去了，德意志是永存的；所以周虽旧邦，其命维新。那么先发和后发，早达和晚成，哪一个更重要呢？ 越宏观，历史越有其确定性，越微观，历史的变化越难以预测。这不得不让人对研究历史学科的人饱含同情。某种意义上，物理学也有同样的困境，星星的轨迹是易于理解和预测的，但微观粒子的运动是难以理解和预测的。 日本人和韩国人，带着虚伪神话和累累暴行的有色眼镜，观察对方的历史，真有吴越同舟的感觉。 最终影响文明成就高低的四个因素：粮食作物、文化和作物大陆内传播速度、大陆间传播的速度和人口密度。 地理决定论里充满了令人着迷的细节。比如中国实际上是欧亚大陆相对孤立的孤岛。 扩张和征服，总是使一些民族和文明更加进步，并带来其他民族的牺牲甚至毁灭。戒之慎之。 复杂的制度，高度发展的制度的，才有可能是良好的制度，良好的制度，才可能带来各方面的成功。从这点来说，中国制度的某些不健全，可能会阻止它成为一个真正的富强文明。 跳出旧思维来看，可以得到一些有益处的结论，但因为新的框架没有形成，所以用处的体现，要到更晚的时候。 "},{"title":"Unix 常用命令","date":"2020-04-08T06:28:59.000Z","url":"/2020/04/08/Unix-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","tags":["Linux","Unix"],"content":""},{"title":"Spring AOP 笔记","date":"2020-04-05T04:17:29.000Z","url":"/2020/04/05/Spring-AOP-%E7%AC%94%E8%AE%B0/","tags":["Java","Spring"],"content":"AOP 的基本概念Aspect: A modularization of a concern that cuts across multiple classes. 方面，横跨多个类的模块化关注点。如果只是简单地横跨多个类，可以考虑使用继承 + 组合 + 设计模式。如果使用某种模式匹配来横跨多个类，才需要考虑使用 Aspect。 Join point: A point during the execution of a program, such as the execution of a method or the handling of an exception. In Spring AOP, a join point always represents a method execution. 结合点是我们最需要关注的东西，既包括了方法执行过程，也包含了异常处理过程。 Advice: Action taken by an aspect at a particular join point. 方面针对结合点采取的行动。对 Advice 而言，join point 经常是他们的参数（至少 Advice 对应的 Interceptor 里包装了这些参数）。 Pointcut: A predicate that matches join points. Advice is associated with a pointcut expression and runs at any join point matched by the pointcut (for example, the execution of a method with a certain name). The concept of join points as matched by pointcut expressions is central to AOP, and Spring uses the AspectJ pointcut expression language by default. 切点（英文是点切）实际上是对 Join point 进行判定的谓词。切点把 Join point 和 Advice 实际上结合起来了。默认的切点表达式来自于 AspectJ pointcut expression。 Advisor：Base interface holding AOP advice (action to take at a joinpoint) and a filter determining the applicability of the advice (such as a pointcut). This interface is not for use by Spring users, but to allow for commonality in support for different types of advice.Spring AOP is based around around advice delivered via method interception, compliant with the AOP Alliance interception API. The Advisor interface allows support for different types of advice, such as before and after advice, which need not be implemented using interception. Advisor 不是给 Spring 用户用的。它包含一个 advice，是 一个 advice 的容器 - 相应地，Aspect 是包含很多 advice 的容器，这是个 Spring 用户用的。 Introductions：Declaring additional methods or fields on behalf of a type. 类似混型（mixin），在不打开原有类型以改变原有类型的内容的前提下（类似 Ruby 的元编程或者 C# 的 partial class），为类型增加新的功能。 Target object: An object being advised by one or more aspects. Also referred to as the “advised object”. Since Spring AOP is implemented by using runtime proxies, this object is always a proxied object. 目标对象、建议对象，即原始对象。 AOP proxy: An object created by the AOP framework in order to implement the aspect contracts (advise method executions and so on). In the Spring Framework, an AOP proxy is a JDK dynamic proxy or a CGLIB proxy. Interceptor、Proxy，aspect contracts 的实现。 Weaving: linking aspects with other application types or objects to create an advised object. This can be done at compile time (using the AspectJ compiler, for example), load time, or at runtime. Spring AOP, like other pure Java AOP frameworks, performs weaving at runtime. 织入，即把方面和 advised object 联系起来的过程。可以在编译时（性能最好）、装载时（容易被忽略）和运行时（所有的 pure java AOP framework 的默认选项）执行。大多数情况下，Spring AOP 已经够用了。 可以看出 Spring 的设计里面是尽可能地在 IOC 的基础上提供强大的auto-proxying服务，所有的增强功能，都是在代理里实现的，已解决企业级开发中常见的问题，而不是提供强大而完备的 AOP 实现（尽管它已经很强大了）。 所有声明、配置（不管是注解还是 xml 配置）：aspect、advice、pointcut、advisor、自己实现的 Interceptor、其他 proxies 可以混合使用，即 Mixing Aspect Types。 到底应该使用哪种代理呢？Spring 默认使用 Java 动态代理，任何接口实现都可以被代理。但这种代理只能拦截接口方法。最终产生的 object 是 Proxy 的 instance 且 Interface 的 implementation。 当一个对象没有实现一个接口的时候，Spring 会退而求其次，使用 cglib 代理。当然，我们也可以（实际上经常）强制使用 cglib 代理。这种代理可以拦截一切可以覆写的方法（而不只是接口声明的方法）。最终产生的 object 是原类型的 subclass 的 instance。 It is perfectly possible to mix @AspectJ style aspects by using the auto-proxying support, schema-defined aop:aspect aspects, aop:advisor declared advisors, and even proxies and interceptors in other styles in the same configuration. All of these are implemented by using the same underlying support mechanism and can co-exist without any difficulty. 如果默认生成 JDKDynamicProxy，则以下的注入会出错： 声明各种基础类型激活 @Aspect 注解的方式使用 @Aspect 注解的风格被称为 @AspectJ style。@AspectJ refers to a style of declaring aspects as regular Java classes annotated with annotations. 以下两种流程都能激活 @Aspect 注解的解析。注意，即使第二种方法使用 了 xml，也只是激活了对 @Aspect 注解的解析。真正的配置还是放在 @Aspect 里。 注意，这种注解本身的定义来自于 AspectJ 项目（哪怕实际上是 Spring AOP 在起作用），这也要求类路径里存在aspectjweaver.jar。 声明 Aspect Aspect 可以是普通的 class，只是里面可以有 advice、pointcut 和 introduction。 Spring AOP （proxy-based）的切点里 this 总是指代理，而 target 指的是被代理对象；AOP （type-based）里都指代理和被代理对象。 Spring AOP 里的 join point 专指 method execution，其他 AOP 框架不只是拦截方法执行。 详解 pointcut切点有自己的 PCD（pointcut designators ），来自于 pointcut expressions（主要来自于 AspectJ），完整的表达式语法见《Appendix B. Language Semantics》： execution: For matching method execution join points. This is the primary pointcut designator to use when working with Spring AOP. 方法执行连接点，这是最常用的。 within: Limits matching to join points within certain types (the execution of a method declared ** within a matching type ** when using Spring AOP) 以只在特定类型里的方法执行作为切点。execution 的阉割版本。 this: Limits matching to join points (the execution of methods when using Spring AOP) where the bean reference (Spring AOP proxy) is an instance of the given type. 这里的 this 是 proxy 的意思，限制 proxy - 当我们使用 JDK dynamic proxy 的时候，推荐使用这个 PCD（并不必然）。 target: Limits matching to join points (the execution of methods when using Spring AOP) where the target object (application object being proxied) is an instance of the given type. 限制目标类型。当我们使用 cglib proxy 的时候，推荐使用这个 PCD（并不必然） args: Limits matching to join points (the execution of methods when using Spring AOP) where the arguments are instances of the given types. 限制参数。 @target: Limits matching to join points (the execution of methods when using Spring AOP) where the class of the executing object has an annotation of the given type. 限制 target 有特定注解。这种切点配合特定的类注解特别有用！ @args: Limits matching to join points (the execution of methods when using Spring AOP) where the runtime type of the actual arguments passed have annotations of the given types. 限制参数有特定注解。 @within: Limits matching to join points within types that have the given annotation (the execution of methods declared in types with the given annotation when using Spring AOP). 限制在类型有特定注解。 @annotation: Limits matching to join points where the subject of the join point (the method being executed in Spring AOP) has the given annotation. 限制连接点方法有特定注解。这种切点配合特定的方法注解特别有用！ bean 特定的 bean 名称/名称模式引用的，类似 BeanNameAutoProxyCreator。 更多例子： 切点表达式会在编译时被优化，被冲写成 DNF 范式形式，并且会被重排序，以提升性能。 注意，可以混合使用任何地方定义的切点：Java config 里的 bean 可以引用 xml 里定义的切点；反过来也可以。 切点表达式分为三类： Kinded designators select a particular kind of join point: execution, get, set, call, and handler. Scoping designators select a group of join points of interest (probably of many kinds): within and withincode Contextual designators match (and optionally bind) based on context: this, target, and @annotation 好的切点应该使用两种以上的表达式，性能才好，如： 详解 adviceadvice 的类型Advice 可以分为： before 申请资源适合放在这里 After returning After throwing（不怎么常见，但 Spring MVC 的 Controller Advice 就是这样实现的）。PCD 里是不包含对于 exception 的定位的，只能通过 PCD 里定位方法，然后使用这个 advice。这是 Spring 对异常处理的唯一设计。 After (finally) advice = returning + throwing，隐式包含 finally。释放资源适合放在这里。 around（大部分的 advice 都可以这样用，因为它兼容 before、after（实际上囊括了上面所有的 advice）， 而且管控范围最广）适合申请资源、释放资源、权限管理、日志，它因为是栈封闭的，所以是在方法执行前后，线程安全地共享状态（ share state before and after a method execution in a thread-safe manner） - timer 的合理方式。 如果要使用 args 和 argName 配合，则不能指定切点的类型。 通常意义上的 Advice 被建模为 interceptor（所以 Advice 的实现是一个方法，映射到 Spring 的内部不是一个方法，而是一个类型，因为一个MethodInterceptor 只有一个 invoke 点）。围绕着 Join point 串起来一系列 interceptor（aspect 对 advised object 可以多对一，但彼此之间并不能相互 advised）。 我们通常会使用 around，但 Spring 推荐尽量用 less powerful 的 advice 以避免出错。 advice 的优先级有最高优先级的 advice 在 advice 嵌套的最外层，before 最先执行而 after 最后执行。 可以通过实现 org.springframework.core.Ordered 或者使用 Order 注解给 Aspect - advice 的优先级跟着 aspect 的优先级走。 详解 introduction对于 this proxy 而言，introduction 引入了混型（mixin）；而对于调用者而言，这个新的 proxy 实际上是个 adapter。 这个功能在 Spring 内部实际上非常悠久，在 2003 年开发的代码里，就留有 IntroductionAdvisor 的痕迹了。 高级主题 - AOP （其他）初始化模型缺省的情况下，全局只有一个单例 aspect， AOP 把它称作“singleton instantiation model”。 这样的设计允许某些局部状态被限定起来，不再是全局共享。现实中并不太实用 - TransactionInterceptor 本身管理复杂的事务和连接，它却是靠 threadlocal 实现的，并没有依靠多个拦截器。 激活 schema-based approach解析 xml 标签的模式，被 Spring 称为 schema-based approach 。 这种解决方案的表达能力不如基于注解的表达能力强（有些切点表达式可以用注解表达，无法用 xml 表达，，比如 xml 可以表达 id pointcut，却无法表达由 named pointcut 组成的 composited pointcut）。 它基于新增加的 aop schema，需要使用的时候引入一个 schema： 注意：这个&lt;aop:config/&gt;依赖于auto-proxying机制，因而与AutoProxyCreator如BeanNameAutoProxyCreator是相互冲突的，所以两者不要混用-与 Mixing Aspect Types 的观点稍微有点冲突。换言之，&lt;aop:config/&gt;与&lt;bean class=&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt;或者手动创建的DefaultAdvisorAutoProxyCreator互斥。从优先级来讲，恐怕 aop:config/ 更适合大多数场景。 AdvisorAdvisor 是 Spring 特定的概念，AspectJ 里没有。 Advisor 是一个自包含的 aspect，只包含一个 advice - 类似 Java8 引入的函数式接口，而且它本身是一个平凡的 bean（废话），必须实现以 Spring 的官定 advice interface。advisor 适用于内部的 advice，普通的 advice 应该使用 aspect。 到底应该使用哪种 AOP？AspectJ 实际上包含了 Compiler 和 weaver，不如 Spring AOP 开箱即用。根据 Spring 文档： 只做 container managed bean interception 可以只用 Spring AOP，否则考虑 AspectJ AOP（如某些领域对象，我想这里指的是 JPA 取出的 entity）。 如果只做 method interception，可以只用 Spring AOP，否则考虑 AspectJ AOP（如 field set 和 get）- 这决定了实际上这种 aspect 的增强比 proxied-based 的方案强，self-invocation 依然可以被拦截。 当场景里需要大量使用 Aspect + 拥有 Eclipse AJDT 插件的时候，使用 AspectJ language syntax （code style）；否则使用 AspectJ 的注解（比如Aspect 很少）。 使用 xml 或是 @AspectJ 注解 xml 的优点是： 它可以独立变化（不同的人对这一点持不同看法），所以比系统里的切面配置更清晰。 xml 的缺点是： 它违反 DRY 原则，造成了重复； 它表达能力有限：它只有 singleton instantiation model；它不能表达 composite pointcut； 代理机制手动调用代理工厂提供 jdkDynamicProxy 和 cglib 的 proxy 之外的统一抽象。 从外部调用 proxy，会调到 advice。self-invocation （大多数情况下）不会-因为，Finally, it must be noted that AspectJ does not have this self-invocation issue because it is not a proxy-based AOP framework，AspectJ 还是很强大的。 如何在被代理的 bean 里调用 proxy 要求暴露了代理，如&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; expose-proxy=&quot;true&quot;/&gt;或者 @EnableAspectJAutoProxy(exposeProxy=true)或者&lt;aop:config proxy-target-class=&quot;true&quot; expose-proxy=&quot;true&quot;&gt;或者 factory.setExposeProxy(true)。 使用AopContext：((Service) AopContext.currentProxy()).callMethodB();这里的callMethodB 是一个需要被代理增强的方法。这样做是不好的，因为这个类感知到了它正在被 proxied，而且直接耦合 Spring API。 它基于一段命名线程局部对象： @AspectJ 代理的创建方法注意，这里产生的还是 proxy，适用于注解 bean： 使用真正的 AspectJApsectJ 提供一个 compiler 和一个 weaver，可以实现 compile-time weaving 和 load-time weaving - 所以一共有三种织入 aspect 的方法，pure java framework（Java 动态代理 + cglib 代理）都是 runtime，AspectJ 则是更前置的语言特性。Spring 交付一个专门的库spring-aspects.jar，来提供以上功能。 通常编译期的织入，由一个特定的 compiler 来实现。可以由 ant tasks 来实现，基于 ajc。对性能的影响。 load-time 的织入则依赖于 LTW 机制。对性能的影响比 pure java aop 小。 使用 AspectJ 来进行领域对象的依赖注入（Dependency Injection）所谓的领域对象，指的是 new 出来的、orm 框架创建出来的-带有 id 的对象，符合 ddd 里对 domain entity 的定义。 但我们可以使用 AspectJ，让被 new 出来的对象，也被 config。在 Spring 里，有一类类型如果被标记为@Configurable的，Spring 就会改写它的行为，使他隐式地成为一个 bean。这种支持是用在“容器控制之外的对象”上的，实际上建立了一种 “AspectJ 控制的对象”。 AspectJ在类加载时，将AnnotationBeanConfigurerAspect切面将织入到（weaving）标注有@Configurable注解的类中。 AnnotationBeanConfigurerAspect将这些类和Spring IoC容器进行了关联，AnnotationBeanConfigurerAspect本身实现了BeanFactoryAware的接口。 实际上，大量的单元测试的 mock 对象，如果这种注入不生效，手动地注入 stub 和 skeleton 也是可以生效的。 AnnotationBeanConfigurerAspect 是一个单例切面，每一个类加载器拥有一个单例。 如果在一个类加载器里定义了多个 Spring Context，要考虑清楚在哪个 Context 里配置 @EnableSpringConfigured bean，并放置 spring-aspects.jar。 如果一个父的 spring context 和多个子 spring context （特别是多个 servlet 容器场景下）共用一些基础 service，应该在父 context 里激活 @EnableSpringConfigured 配置，在它的类路径（WEB-INF/）里放置 spring-aspects.jar。 一个例子： 需要准备的 jar： spring-core，spring-beans，spring-context，spring-instrument，spring-aspects，aspectjweaver。实际执行的的 LTW 是 spring-context 的InstrumentationLoadTimeWeaver 在@Configuration上加上@EnableLoadTimeWeaving和@EnableSpringConfigured 运行前（有可能要涉及改动launch script）加上-javaagent:/path/to/spring-instrument.jar这个 jvm 参数（如：-javaagent:/Users/magicliang/.m2/repository/org/springframework/spring-instrument/5.2.5.RELEASE/spring-instrument-5.2.5.RELEASE.jar）；理论上还可以加上 aspectjweaver.jar 的路径（例如：-Xset:weaveJavaxPackages=true -javaagent:/Users/magicliang/.m2/repository/org/aspectj/aspectjweaver/1.9.5/aspectjweaver-1.9.5.jar，-Xset 这段可以去掉），但实际上没有尝试成功 work 过。 要让 AnnotationBeanConfigurerAspect 被织入到特定 bean 里面，强行使特定的对象和 Spring 容器被关联起来。 待确定用途的功能： 使用自定义的 aspect + 工厂方法 bean： 上面的例子不成功，这个例子会成功参考《spring-boot-aspectj》 基础的配置： resources/org/aspectj/aop.xml 启动的时候加上这个 vm args（暂时不要使用 spring-instrument.jar）： * -javaagent:${HOME}/.m2/repository/org/aspectj/aspectjweaver/1.9.5/aspectjweaver-1.9.5.jar 只要有这个 javaagent，@Configurable + @EnableSpringConfigured 的自动注入就会生效 - 这个注解强依赖于这个 jave agent。 而如果有了 aop.xml 的 aspect，怎样的 public 方法都可以被增强。 Spring Boot 提供的 @EnableLoadTimeWeaving 和 spring-instrument.jar 理论上应该一起生效，但不知道怎样搭配才能生效还不可知。 compile time weavingcompile time weaving 需要给 maven 增加以下配置： 然后不用 javaagent 就能启动增强了。 但是 @Configurable 不生效，要生效，还是要加上 javaagent： 被编译增强的类，debug 起来非常困难，因为增加了很多代码。还是普通的 spring aop 就足够了。 Spring 允许每个类加载器有细颗粒的 LTW待研究这样做的用处是什么 Spring 的 AOP API切点相关 API切点负责让 advices 指向特定的类和方法。 Spring 用切点 API，使得切点成为一个框架特性，而不是一个语言特性-语言特性需要编译器支持。 但是，大多数情况下，我们应该只使用一个切点表达式就足够了，不要直接使用切点 API。 切点的 api 还可以分为两个部分（用于 union 其他 method matcher）： ClassFilter 用于限制一个目标类的切点。 而 MethodMatcher 更重要： 双参数的 matches(Method, Class) 方法可以确认一个目标类上的特定方法是否符合切点要求。这个求值可以在 AOP proxy 被创建时发生，而不是每一次方法调用时发生。它返回 true，则 isRuntime 返回 true，然后三参数的 matches 每次方法执行会被调用。 大多数 MethodMatcher 被实现为静态的，isRuntime 返回 false，则 三参数的 matches 永不会被执行。这是被 Spring 鼓励的，这样 Spring 可以在 AOP proxy 被创建的时候，缓存 pointcut evaluation 的结果。 除此之外，并集和交集的 API 可以参考org.springframework.aop.support.Pointcuts和ComposablePointcut。 大多数情况下，使用一个静态切点（即只关注 target class 上的方法特征，而不关注真正的运行时 arguments）就最好了 一些有用的切点实现使用切点作为 bean，然后关联 bean 和 advice。 JdkRegexpMethodPointcut RegexpMethodPointcutAdvisor ControlFlowPointcutControl Flow Pointcut 通用的静态切点父类 advice 相关 APISpring 的 advice 主要分为 per-class 和 per-instance 两类。 per-class 最常用，比如 transaction advisor； per-instance 通常用来作为 introduction 支持混型的基本技术，它会给 proxied object 增加状态。 尽量使用 Alliance-compliant AOP advice 的拦截器，这样可以保证拦截器可以被其他 AOP 框架使用（如 google guice）。 interceptor 自己会产生一个 interceptor chain，这个 chain 是会被破坏的。 各种 advice、advisor 可以在一套 proxy 配置里生效。 Interception Around Advice最常用的拦截器，能够完全控制方法的执行。在方法前后，完全环绕： Before Advice只在方法前执行，所以不需要MethodInvocation，只要能够引用到 Method 即可： 它如果挂了，方法执行就会挂掉。而且会抛出一个异常给 client 调用端-如果异常 match client 的异常，可以抛原始异常给 client，否则会抛出一个包装器。 这个 advice 可以配合切点使用。 Throws Advice这是一个 tag interface，所以本身不包含任何的实际方法。但 Spring 又支持 typed advice，所以可以自由组织各种 advice 的实现方法。 这个 advice 可以配合切点使用。 After Returning Advice可以获取返回参数和抛出异常： 这个 advice 可以配合切点使用。 Introduction Advice 这个 advice 不可以配合切点使用。 ProxyFactoryBean一个 bean 引用一个 ProxyFactoryBean，其实不是引用它的 instance，而是在引用它的 getObject() 产生的对象（它的 getObject 接口是 convention over configuration 的典范，总是会被自动调用）。ProxyFactoryBean 有一个优点，因为由他搞出来的 advices 和 pointcuts 本身都是 IoC 容器管理的 bean。在大多数情况下，我们可以用 xml 配置相关 bean，但有些时候我们需要动态生成 bean，这时候就可以用到 ProxyFactoryBean 了。 Spring 框架里各种 EntityManagerFactory 都是各种 FactoryBean，factory bean 在 ioc 里再谈。 这个类型被 AbstractBeanFactory 使用（另一个被 BeanFactory 经常使用的扩展点是 BeanPostProcessor）。我们的系统中经常出现使用的扩展的其实不是 ProxyFactoryBean，而是 FactoryBean。它的用意是“（使用 xml）动态地给现存的 bean 增加切面”。 几个基础属性： proxyTargetClass: true，强制使用 CGLIB 代理。proxy-based vs interface-based（jdk-based proxy）。如果 interface-based 不可能正确生成，即使是这个值是 false，也会强制使用 CGLIB 代理。principle of least surprise。 optimize：可以对 CGLIB 代理施以激进优化。 frozen：是否允许变动配置（如增加 advice）。 exposeProxy：是否把代理放在线程里，允许 AopContext.currentProxy() 生效。 proxyInterfaces：接口列表。如果什么都不提供，使用 CGLIB 代理，提供了，有可能使用 jdk 动态代理。 interceptorNames：拦截器、advice 列表。名字的顺序实际上决定了 interceptor chain 的生效顺序。这个列表本身不是 name-ref 的模式，是为了允许 prototype 模式生效。 singleton：是否单例，大部分的 FactoryBean 的实现的这个值都是 true。 如果有可能，Spring 会顺着接口列表生成 JdkDynamicProxy；否则，会退而求其次生成 cglib proxy。 我们也可以使用一个内部类声明，使全局的 bean 能够藏住一个不可被引用的被代理的 target，而且也无法从全局的其他地方被引用。 interceptorNames 支持通配符模式： 程序化地创建 AOP 代理的方法使用 ProxyFactory（注意，不是 xml 使用的ProxyFactoryBean）； 所有的 proxy 都可以转化为org.springframework.aop.framework.Advise接口，其包含这些方法： 可以看出来 advice 和 advisor 的区别还是很大的： 下面是一个例子，可以把 proxy 的 advisor 都取出来： 注意，以上操作还是会受 frozen 的影响。 使用自动代理设施（auto-proxying facility）这种自动处理机制，很多系统都喜欢用。它的本质是对 bean definition 进行操作，使用 proxy 代理特定模式的 bean definition（targets eligible），依赖于 bean 后处理器的基础设施。 BeanNameAutoProxyCreator这是最常见的做法： 它对于 bean 名称的模式匹配，应该可以被 PCD 完全取代。它本身是一个 BeanPostProcessor，它会给每个 bean 专门生成一个 proxy。 DefaultAdvisorAutoProxyCreator这个东西会自动地把 advisor 和 target 关联起来，所有需要做的事情只是： 声明一系列 advisor。 声明一个 DefaultAdvisorAutoProxyCreator。 从这里看出来 advisor 和 advice、interceptor 的显著区别，advisor 天然就有 pointcut，可以自动被识别。 TargetSource API可热替换（hot-swappable）的 target sourceSpring 提供一个 API，可以让代理暴露自己的目标源： 池化 target sourceSpring 可以和各种 pooling api 配合使用，如以下的例子： 相关的关键类是：org.springframework.aop.target.AbstractPoolingTargetSource。 如果做了以下操作，可以把目标 bean 内部的 pool 配置读出来（比如对象池大小）： 能够被池化复用的对象，应该是无状态的对象，比如 EJB 对象，所以这个功能到底是不是真的有用，还要看业务场景。Spring 文档说无状态对象是线程安全的，只是把这个类型当做 transaction service 而已-如此说，prototype 和 singleton 又有什么区别。 原型化 target source还有原型化的 target source api。原型化的 api 一般都很不好用，因为它意味着每次方法调用都会产生新对象。产生新对象的成本并不高，装配（wiring）依赖的成本会很高。 相当于 bean 还要被套在 TargetSource 里，所以 TargetSource 本质上只是一种 proxy 而已。 ThreadLocal target source ThreadLocal 在多线程和多类加载器的场景下，会导致内存泄漏。 定义新的 Advice 类型Spring 的 AOP 框架本身是支持类型扩展的，自定义的扩展可以通过一套 SPI 机制进行扩展。见org.springframework.aop.framework.adapter文档。 总结一下 AOP 的初始化和使用方法![如何正确使用 AOP.png](如何正确使用 AOP.png) 基本结论，越使用自动机制，越要使用 aspect；越是使用内部机制，越是使用 advisor。 一般的继承关系 spring-aop 模块的 jar 里包含 org.aopalliance.intercept package。 常见的 AOP 实现包括但不仅限于： AspectJ：源代码和字节码级别的编织器，需用使用 Aspect 语言 AspectWerkz：AOP框架，使用字节码动态编织器和 XML 配置 JBoss-AOP:基于拦截器和元数据的AOP框架，运行在JBoss应用服务器上 BCEL(Byte-Code Engineering Library):Java字节码操作类库 Javassist：Java字节码操作类库 代表单一方法的一等公民类型 Advice/Interceptor，他们是围绕 joinpoint/invocation 进行操作。 Advice（marker interface，不带有方法） -&gt; Interceptor（marker interface，不带有方法） -&gt; MethodInterceptor（带有一个很重要的invoke(MethodInvocation invocation)方法，注意，这里要使用 aop 联盟的方法拦截器，而不能使用 cglib 的方法拦截器） -&gt; XXXInterceptor（比如 TransactionInterceptor） 对于每一个 bean 的 proxy 而言，interceptor 是有 interceptor chain 的。 MethodInvocationproxy 方法里使用的方法调用抽象，可以 getMethod() 来获取方法。可以被认为是 joinpoint 的 getStaticPart() 的友元实现。 JoinPoint 设计Spring 自己的方法闭包执行点。 有了连接点，首先封装了 proxy，其他封装了 target，再次描述了方法的签名，最后封装了参数（这点特别重要，使得我们不需要直接使用 Object[]）。 连接点使用 PCD 的表达式，可以实现 data binding - 指定参数名称和类型。 JoinPoint一般的 advice 的参数使用 JoinPoint。 ProceedingJoinPointAround Advice 使用 ProceedingJoinPoint。 ProceedingJoinPoint 的 proceed 可以被执行 0 次、1 次、无数次。 常见的例子就是缓存 API 在校验了 cache 了以后可以执行底层方法，也可以不执行底层方法。 如果按顺序绑定 ProceedingJoinPoint 的参数到 advice 方法上，可以先处理那个参数，再把参数回传去再 proceed 来代替之前被处理的参数。如下面的例子，find 方法的第一个参数是 accountHolderNamePattern，被处理以后就出现新 pattern 来调用。 解析 spring aop 标签的流程我们常见的 xml 标签如下： 在 jar 下存在一个路径可以配置类似 SPI 的加载路径.m2/repository/org/springframework/spring-aop/5.2.3.RELEASE/spring-aop-5.2.3.RELEASE.jar!/META-INF/spring.handlers。 其激活的AopNamespaceHandler 为： 如果我们使用的 aop 配置是： 则对应的 Parser 是ConfigBeanDefinitionParser，关键方法是 parse： beandefinition 里的配置，会最终导致某个 AopProxyFactory 创建的 bean 产生差异。 除此之外，还有其他我们常见的 xml 配置，而且他们对 proxy creator 的影响是相互的、全局的（只要有一个指定 AspectJ，就会导致全局 AspectJ）： To be clear, using proxy-target-class=”true” ontx:annotation-driven/, aop:aspectj-autoproxy/, or aop:config/elements forces the use of CGLIB proxies for all three of them. 由 Spring 自己根据上下文，决定生成 还是 ，当然，这个行为实际上是受proxy-target-class=&quot;true这一属性控制的。引述官方文档如下： If the target object to be proxied implements at least one interfacethen a JDK dynamic proxy will be used. All of the interfacesimplemented by the target type will be proxied. If the target objectdoes not implement any interfaces then a CGLIB proxy will be created.如果要代理的目标对象实现至少一个接口，则将使用JDK动态代理。 目标类型实现的所有接口都将被代理。如果目标对象未实现任何接口，则将创建CGLIB代理。 proxy-target-class 的语义，恰好与 jdkDynamicProxy 的 proxy targe interface 的语义对应过来。 我们可以不再显式地引入 cglib 相关的 jar，从 Spring 3.2 开始，cglib 相关的 jar 已经被自动打包进 spring-core.jar 里面了。 基本的 proxy 工厂DefaultAopProxyFactory ProxyFactory再看一个编程声明 ProxyFactory 的例子： ProxyFactory的构造函数是空方法 setTarget时，将target对象封装成TargetSource对象，而调用的setTargetSource是AdvisedSupport的方法。 setInterfaces，赋值的也是AdvisedSupport中的interfaces属性，但是是先清空再赋值。 addAdvice方法则是直接调用AdvisedSupport，将Advice封装成Advisor然后添加到advisors集合中。 上述的Advice都被封装成 DefaultPointcutAdvisor，可以看下其构造函数 Pointcut.TRUE表示支持任何切入点。 创建代理准备工作做完了，直接通过getProxy方法获取代理对象。 这里的createAopProxy()返回的是 AopProxy 类型，方法是 final，并且加了锁操作。 注意，生成 proxy 的方法显示，ProxyFactory 自己还委托 AopProxyFactory，生成了AopProxy 以后，还要再取一层 Proxy。 可以清晰地看出，AopProxyFactory-&gt;AopProxy-&gt;Proxy之间的结构。 缺省的 AopProxyFactory 是 DefaultAopProxyFactory，它的关键方法是： JdkDynamicAopProxy 的关键代码是： DefaultAdvisorChainFactory 的内容如下： AopUtils 的内容如下： AopProxyUtils 的内容如下： CglibAopProxy 生成代理的流程，使用了 cglib 的 enhancer。 它的 enhancer 注册了很多的 Callback 方法，最重要的方法是 DynamicAdvisedInterceptor，它即是代理实际操作的回调类，回调方法为intercept。 ObjenesisCglibAopProxy 不需要依赖于构造器，在高版本（ 4.0 以后）Spring 上，是 CglibAopProxy 的替代品，而且不完全调用 super 的函数。 参考： 《Introduction to Pointcut Expressions in Spring》 《Spring @Configurable基本用法》 《Spring源码-AOP(三)-Spring AOP的四种实现》 "},{"title":"ThreadLocal 的设计模式","date":"2020-04-01T12:29:29.000Z","url":"/2020/04/01/ThreadLocal-%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","tags":["Java","设计模式"],"content":"基础版本 用 map 来取消第一层工具类的方案（map 容易腐化） 对这个 map 的加强版本 绑定一个容器到线程上，并重建上一个状态-状态里还带有另一个 previous。 ThreadLocal 变策略模式 带名字的 ThreadLocal 其他问题如何正确使用 ThreadLocalThreadLocal 其实可以当做和 guava cache 一样的缓存，但它最好的用法是做一个 request scope 的缓存，在线程里复用其实极度危险。 当然 guava cache 也有额外的问题。 像 SOFA 里的方案，每个 request 开头 setThreadLocal，执行完以后 clear，是最正确的做法。其他做法，都非常危险，在容器的线程里，维护一个 ThreadLocal 的缓存，很危险。 weakhashmap 的实用意义利用下一次操作，来触发 clear，好像有一个线程来维护 map 一样。"},{"title":"Java 注解和配置","date":"2020-03-29T15:12:07.000Z","url":"/2020/03/29/Java-%E6%B3%A8%E8%A7%A3%E5%92%8C%E9%85%8D%E7%BD%AE/","tags":["Java","JPA","Spring"],"content":"Java 的原生注解@Inherited@Inherited 是一个元注解（annotations applied to other annotations），也是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。 @Inherited annotation类型是被标注过的class的子类所继承。类并不从它所实现的接口继承annotation，方法并不从它所重载的方法继承annotation。其查找过程是：反射 API 会在查找 @Inherited 标注的注解的时候，自底向上往继承树上方查找。 其他元注解还包括： @Target: Describes the targets to which an annotation can be applied; this directly corresponds to the nine contexts above @Retention: Describes how long the annotation should be retained by the compiler @Inherited: Denotes that an annotation should be inherited by a subtype if applied to a supertype @Deprecated: Denotes that an annotation (or any other type) should no longer be used @Repeatable: Denotes that an annotation can be applied multiple times in the same context; i.e. a class can have the same annotation applied to it two or more times 这一种注解最有意思，但平时没有什么用例，其大部分使用场景可以被一个复合值的 values 代替。 注意，直接在注解上加入注解，实际上就产生了组合注解，会让配置集体生效，但这和继承元注解不一样。 Spring 原生的功能xml 的模式spring 的配置总是： 固定值的w3c 的 xsi beans ns 它属于 spring org 的 schema 的一个子目录 多个 attribute ns （它实际上是一个目录） 一个 attirbute schemaLocation（它是目录里面的真正方定义的地方） 它也属于 spring org 的 schema 的一个子目录，通常是一段 xsd 带有 name 的注解 @Configuration@Configuration 注解本质上还是 @Component，但又不同于 @Component，详见《Spring @Configuration 和 @Component 区别》。@Configuration 里的 @Bean 方法可以嵌套使用，而@Component 里的 @Bean 方法不可以。它天然可以被加载，还可以触发其他 bean 的加载。它只能被放置在类型上。 @EnableAsync激活异步拦截器，类似美团的 mole。 参考《How To Do @Async in Spring》： 对应的 xml @EnableScheduling激活任务调度。 对应的 xml @EnableTransactionManagementTransactionInterceptor 是被 proxy 或者 advice 加入到调用栈中： Please note that proxy mode allows for interception of calls through the proxy only; local calls within the same class cannot get intercepted that way. Note that if the mode() is set to AdviceMode.ASPECTJ, then the value of the proxyTargetClass() attribute will be ignored. Note also that in this case the spring-aspects module JAR must be present on the classpath, with compile-time weaving or load-time weaving applying the aspect to the affected classes. There is no proxy involved in such a scenario; local calls will be intercepted as well. aspectj 的织入可以增强本地调用，默认的 proxy mode 不可以。 AdviceMode.PROXYAdviceMode.ASPECTJ 各种 mode 的解释见《Optimal @EnableTransactionManagement Configuration》，必须配合proxyTargetClass配置使用： This configuration says how the transaction aspect will be applied.Briefly: adviceMode=proxy, proxyTargetClass=true Cglib is used as proxymechanism. If you use this, cglib must be on classpath, your proxiedclasses must have nonparametric constructor and they can’t be final(cglib creates a child class as the proxy). adviceMode=proxy, proxyTargetClass=false Jdk proxy mechanism is used.You only can proxy classes that implements a interface for methodsthat should be transactional. Jdk proxy can be type casted to theinterfaces but can’t be type casted as the original proxied class. So, for adviceMode=proxy, the decision relies more on how are yourcode standards and what constraints result from used proxy mechanism. adviceMode=aspectJ uses aspectJ library, which does byte codeintrumentation instead of proxying. adviceMode=aspectJ, compile-time weaving You should incorporateaspectJ instrumentation during a build process in your build scripts. adviceMode=aspectJ, load-time weaving Instrumentation is performed onruntime. You have to put the aspectj agent as jvm parameter. Using aspectJ is more powerful and probably more performant. It isalso less invasive in terms of restrictions put on the classes youwant to be transactional. However, proxy mode is simple Spring’s outof the box solution. 基本上静态织入的 AspectJ 的性能最好（我们大多数时候都习惯使用 compile-time-weaving，但其实 AspectJ 还支持 load-time-weaving），但平时我们用得最多的还是 cglib 生成的 proxy（因为 Spring 会自动帮我们决策最优的方案）。 @EnableAspectJAutoProxy web application context 和 DispatcherServlet application contexts 是两个 context，需要单独声明 @EnableAspectJAutoProxy at multiple levels。 @EnableWebMvc ContextConfigurationspring-test特有,ContextConfiguration 要和@Configuration或者@Component配合使用。 @PropertySourceproperty 跨上下文继承的关系见《Properties with Spring and Spring Boot》。《官方的列表》。 @ComponentScan它指定的扫描属性依赖于 basePackageClasses()/basePackages() (or its alias value()。 环境 API环境 API 意味着对 properties 和 profile 的建模，Environment接口扩展了PropertyResolver接口。 参考《Spring的Property配置加载和使用过程及Environment的初始化过程》： 首先，PropertySource其实就是包装的具体配置，跟Properties差不多。 而PropertyResolver，就是用于对PropertySource进行特殊处理，比如解析holder、转换值的类型等。 Spring启动时，默认会new一个StandardEnvironment，这个类里面就默认添加了两个PropertySource（SystemProperties和SystemEnvironment，分别对应System.getenv和System.getProperty） 注意，可能是为了使用方便，Environment实现了PropertyResolver接口。 每一个参数，但凡可以用-D 动态传入，也应该可以使用环境变量，甚至 JNDI 的配置，其相对顺序参考《Spring Boot Configuration Priority order》： command-line arguments. The Java system parameters obtained through System.getproperties (). Operating system environment variables. The JNDI attribute obtained from java:comp/env. The “random.*” property generated by Randomvaluepropertysource. Apply the properties file outside of the Jar file . (via spring.config.location parameter) Apply the properties file inside the Jar file. A property file that is declared through the “@PropertySource” annotation in the application Configuration Java class (the Java class that contains the “@Configuration” annotations). The default property declared by the “Springapplication.setdefaultproperties”. 在 java 中获取环境变量：环境变量System.getenv() 或者 environment.getenv()System.getenv() 方法是获取指定的环境变量的值。它有两种方法，一种是接收参数为任意字符串，当存在指定环境变量时即返回环境变量的值，否则返回null。另外一种是不接受参数，那么返回的是所有的环境变量。 在 java 中获取属性：System.getProperty() 或者 environment.getProperty()获取系统的相关属性，包括文件编码、操作系统名称、区域、用户名等，此属性一般由jvm自动获取，不能设置。这个必须接受一个String类型的参数，返回值的类型也是String，如果想获取所有的系统的相关属性值可以使用System.getProperties（） java.version Java 运行时环境版本java.vendor Java 运行时环境供应商java.vendor.url Java 供应商的 URLjava.home Java 安装目录java.vm.specification.version Java 虚拟机规范版本java.vm.specification.vendor Java 虚拟机规范供应商java.vm.specification.name Java 虚拟机规范名称java.vm.version Java 虚拟机实现版本java.vm.vendor Java 虚拟机实现供应商java.vm.name Java 虚拟机实现名称java.specification.version Java 运行时环境规范版本java.specification.vendor Java 运行时环境规范供应商java.specification.name Java 运行时环境规范名称java.class.version Java 类格式版本号java.class.path Java 类路径java.library.path 加载库时搜索的路径列表java.io.tmpdir 默认的临时文件路径java.compiler 要使用的 JIT 编译器的名称java.ext.dirs 一个或多个扩展目录的路径os.name 操作系统的名称os.arch 操作系统的架构os.version 操作系统的版本file.separator 文件分隔符（在 UNIX 系统中是“/” ）path.separator 路径分隔符（在 UNIX 系统中是“:” ）line.separator 行分隔符（在 UNIX 系统中是“/n” ）user.name 用户的账户名称user.home 用户的主目录user.dir 用户的当前工作目录 对应的命令行用法是java -jar jarName -DpropertyName=value，如java -Djavadoop.database.password=admin4321 -jar app.jar。 参考《System.getenv()和System.getProperty() 的区别》。 profile 的定义 a named, logical group of bean definitions to be registered with thecontainer only if the given profile is active 和 Configuration 类似，用来聚合 bean。与之相对应地，maven 中的 profile 就是用来聚合配置用的。一旦被注册进了某个 profile，则 bean 不会轻易地被默认激活。 properties 的例子 properties files, JVM system properties, system environment variables,JNDI, servlet context parameters, ad-hoc Properties objects, Maps, andso on. 所有的 properties 都由PropertySourcesPlaceholderConfigurer对$&#123;&#125;进行注入。 Aware 接口 ApplicationContextAware ApplicationEventPublisherAware BeanClassLoaderAware BeanFactoryAware BeanNameAware BootstrapContextAware EmbeddedValueResolverAware EnvironmentAware ImportAware LoadTimeWeaverAware MessageSourceAware NotificationPublisherAware ResourceLoaderAware SchedulerContextAware ServletConfigAware ServletContextAware PropertySourcesPlaceholderConfigurer其中PropertyPlaceholderConfigurer是Spring3.1之前使用的。PropertySourcesPlaceholderConfigurer是Spring3.1之后使用的。 有了这个机制，才能让特定的 .properties 注入到特定的 xml 占位符里面。 PropertySourcesPlaceholderConfigurer本质上是一个BeanFactoryPostProcessor。解析XML的流程在BeanFactoryPostProcessor之前， 优先将配置文件的路径以及名字通过Setter传入PropertySourcesPlaceholderConfigurer。 如上BeanFactoryPostProcessor的优先级又优于其余的Bean。因此可以实现在bean初始化之前的注入。 参考： 《Spring PropertySourcesPlaceholderConfigurer工作原理》 《Spring 常用的两种PropertyPlaceholderConfigurer》 基本还是 MergedProperties 那一套。 《Spring Properties Loader》 xml 配置annotation-config等字符串实际上指的是一个 element 的 attribute。 @ResponseBody表示该方法的返回结果直接写入HTTP response body中，一般在异步获取数据时使用，在使用@RequestMapping后，返回值通常解析为跳转路径， 加上@responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中；比如异步获取json数据，加上@responsebody后，会直接返回json数据； @RequestBody参数前加上这个注解之后，认为该参数必填。表示接受json字符串转为对象 List等； @Qualifier当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用 @Autowired按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。(通过类型匹配找到多个candidate,在没有@Qualifier、@Primary注解的情况下，会使用对象名作为最后的fallback匹配)。 @Resource 默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。 @RequestMappingRequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径； params:指定request中必须包含某些参数值是，才让该方法处理。headers:指定request中必须包含某些指定的header值，才能让该方法处理请求。value:指定请求的实际地址，指定的地址可以是URI Template 模式method:指定请求的method类型， GET、POST、PUT、DELETE等consumes:指定处理请求的提交内容类型（Content-Type），如application/json,text/html;produces:指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回。 它还有其他语法糖：@GetMapping、@PostMapping @RequestParam用在方法的参数前面。相当于 request.getParameter； @PathVariable路径变量。如 RequestMapping(“user/get/mac/{macAddress}”) ； public String getByMacAddress(@PathVariable(“macAddress”) String macAddress){ //do something;}参数与大括号里的名字相同的话，注解后括号里的内容可以不填。 @ControllerAdvice@ControllerAdvice是一个特殊的 @Component，用于标识一个类，这个类中被以下三种注解标识的方法：@ExceptionHandler，@InitBinder，@ModelAttribute，将作用于所有的@Controller类的接口上。这三种方法，可以被认为是三种 advice。 DelegatingFilterProxy过滤器，它指向一个bean，这个bean在spring中的名字为testBean，testBean也必需实现javax.servlet.Filter。 JPA 特性@Table@Table(name=”“)表明这是一个实体类。一般用于jpa ，这两个注解一般一块使用，但是如果表名和实体类名相同的话，@Table可以省略； @MappedSuperClass用在确定是父类的entity上。父类的属性子类可以继承； @NoRepositoryBean一般用作父类的repository，有这个注解，spring不会去实例化该repository； @Column如果字段名与列名相同，则可以省略； @Id表示该属性为主键； @GeneratedValue 表示主键生成策略是sequence（可以为Auto、IDENTITY、native等，Auto表示可在多个数据库间切换），指定sequence的名字是repair_seq； 参考《JPA 的 id 生成策略》。 @SequenceGeneretor name为sequence的名称，以便使用，sequenceName为数据库的 sequence 名称，两个名称可以一致； 要底层的 RDBMS 能够支持 sequence 功能。 @Transient表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性. 如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic； @Basic(fetch=FetchType.LAZY) 标记可以指定实体属性的加载方式； @JsonIgnore作用是json序列化时将java bean中的一些属性忽略掉,序列化和反序列化都受影响 @JoinColumn(name=”loginId”) 一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 表之间的映射对应Hibernate配置文件中的一对一，一对多，多对一。 哪一边是 owning side 很重要。 OneToOneImplementing with a Foreign Key in JPA Implementing with a Shared Primary Key in JPA Modeling with a Join Table @OneToManyAs stated in the JPA specification under section 2.9, it’s a good practice to mark many-to-one side as the owning side. 平凡解决方案 Cart as the Owning Side @ManyToOne缺，来日补上 @ManyToMany普通映射 Joining Table Spring Boot 特性Spring Boot 在扫描类路径的时候扫到特定的包的时候，会自动激活事务管理、Spring MVC 等功能。 @SpringBootApplication自带其他自动化配置： @EnableAutoConfiguration打开这个配置后，可以通过扫描类路径、配置文件自动打开某些配置。必须配合 @Configuration 使用。 TransactionAutoConfigurationspring-boot 不需要打开 @EnableTransactionManagement。 org.springframework.boot.autoconfigure.condition这个包下面的注解都带有一个元注解： Spring 自己有一套条件体系： 《自定义 condition 的例子》 这些注解可以放在 @Bean、@Component、乃至于一堆 bean （@Configuration）上。 @ConditionalOnBean在早期版本有 bug，参考《深入Spring Boot：那些注入不了的Spring占位符（${}表达式）》。 仅仅在当前上下文中存在某个 bean 时，才会初始化一个 Bean。 @ConditionalOnClass只有类路径里存在特定的 class 的时候，才会初始化一个 Bean。 @ConditionalOnCloudPlatform只在特定的云平台是活动的时候，才会初始化一个 Bean。 @ConditionalOnExpression当表达式为true的时候，才会初始化一个 Bean。 @ConditionalOnJava只有遇到特定的 JVM version，才会初始化一个 Bean。 @ConditionalOnJndi只有 jndi 路径上有特定的资源的时候，才会初始化一个 Bean。 @ConditionalOnMissingBean仅仅在当前上下文中不存在某个 bean 时，才会初始化一个 Bean。 @ConditionalOnMissingClassclass不存在时，才会初始化一个 Bean。 @ConditionalOnNotWebApplication只有 application context 不是一个 web application context 时，才会初始化一个 Bean。 @ConditionalOnProperty特定的属性有特定的值的时候，才会初始化一个 Bean。 @ConditionalOnResource只有特定的（非 JNDI）资源存在的时候，才会初始化一个 Bean。 @ConditionalOnSingleCandidate类似 ConditionalOnBean，但要求全局只有一个 bean，或者可以决策出 primary bean 的时候，才会初始化一个 Bean。 @ConditionalOnWebApplication和 @ConditionalOnNotWebApplication 正相反。只有 application context 是一个 web application context 时，才会初始化一个 Bean。 @ConditionalOnClass只有存在一个特定的类的时候，才会初始化一个 Bean。 @ConfigurationPropertiesSpring Boot 有个更复杂的属性加载顺序，见《2. Externalized Configuration》： Devtools global settings properties in the $HOME/.config/spring-boot folder when devtools is active. @TestPropertySource annotations on your tests. properties attribute on your tests. Available on @SpringBootTest and the test annotations for testing a particular slice of your application. Command line arguments Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property). ServletConfig init parameters. ServletContext init parameters. JNDI attributes from java:comp/env. Java System properties (System.getProperties()). OS environment variables. A RandomValuePropertySource that has properties only in random.*. Profile-specific application properties outside of your packaged jar (application-{profile}.properties and YAML variants). Profile-specific application properties packaged inside your jar (application-{profile}.properties and YAML variants). Application properties outside of your packaged jar (application.properties and YAML variants). Application properties packaged inside your jar (application.properties and YAML variants). @PropertySource annotations on your @Configuration classes. Please note that such property sources are not added to the Environment until the application context is being refreshed. This is too late to configure certain properties such as logging.* and spring.main.* which are read before refresh begins. Default properties (specified by setting SpringApplication.setDefaultProperties). 惰性加载 By default, ApplicationContext implementations eagerly create andconfigure all singleton beans as part of the initialization process.Generally, this pre-instantiation is desirable, because errors in theconfiguration or surrounding environment are discovered immediately,as opposed to hours or even days later. When this behavior is notdesirable, you can prevent pre-instantiation of a singleton bean bymarking the bean definition as lazy-initialized. A lazy-initializedbean tells the IoC container to create a bean instance when it isfirst requested, rather than at startup. 随机值"},{"title":"Mac 使用技巧","date":"2020-03-29T03:08:19.000Z","url":"/2020/03/29/Mac-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","tags":["Mac"],"content":"修复文件不能打开的问题《应用程序不能打开？一条命令就搞定！》 显示隐藏文件在 macOS Sierra，我们可以使用快捷键： command + shift + . 来快速（在 Finder 中）显示和隐藏隐藏文件。 Mac 出现正在运行安装包脚本或等待其他安装完成的解决办法Mac 出现正在运行安装包脚本或等待其他安装完成的解决办法 打开 Mac 触控板的三指拖移功能打开 Mac 触控板的三指拖移功能 macOS 修改 HostsmacOS 修改 Hosts 显示隐藏文件夹Mac系统如何显示隐藏文件？ Command+Shift+. 可以显示隐藏文件、文件夹，再按一次，恢复隐藏； "},{"title":"Optional 的正确用法\n","date":"2020-03-23T10:04:17.000Z","url":"/2020/03/23/Optional-%E7%9A%84%E6%AD%A3%E7%A1%AE%E7%94%A8%E6%B3%95/","tags":["Java"],"content":"Optional 的不正确实践首先，不要直接拿来做if-else的判定条件，这肯定是错的： 而且get()要配合isPresent()才安全。 其次，尽量不要用 Optional 拿来做成员变量，特别是 pojo 的成员变量，这很容易让读 pojo 的框架出问题。 再次，不要拿来做方法参数，因为很可能写成 if (user.isPresent()) &#123;&#125;式的代码。 最后，Optional 的关注点在它的 value 的后续处理身上，如果这个 value 只是一个 flag，还是要乖乖地用if-else；如果这个 value 被用在多路返回里，也不能使用 Optional。 正确的用法选对构造器Optional.of(T value)如果需要断言值不为空，使用这个构造器。 该方法通过一个非 null 的 value 来构造一个 Optional，返回的 Optional 包含了 value 这个值。对于该方法，传入的参数一定不能为 null，否则便会抛出 NullPointerException。 Optional.ofNullable(T value)如果这个值可以为空，使用这个构造器。 该方法和 of 方法的区别在于，传入的参数可以为 null , 但是前面 javadoc 不是说 Optional 只能包含非 null 值吗？原来该方法会判断传入的参数是否为 null，如果为 null 的话，返回的就是 Optional.empty()。 Optional.empty()最好搭配其他构造器使用这个方法。 该方法用来构造一个空的 Optional，即该 Optional 中不包含值,其实底层实现还是 如果 Optional 中的 value 为 null 则该 Optional 为不包含值的状态，然后在 API 层面将 Optional 表现的不能包含 null 值，使得 Optional 只存在 包含值 和 不包含值 两种状态。 选对返回值要用orElse、orElseGet、map + collect来打扁结构，注意这几个方法是休止方法。很适合拿来配合 supplier 一起使用。 选对消费者ifPresent可以用来接受闭包，实现 cps 风格，很适合搭配 consumer 一起使用。 Java 9 对Optional的增强or方法or 方法的作用是，如果一个 Optional 包含值，则返回自己；否则返回由参数 supplier 获得的 Optional ifPresentOrElseifPresentOrElse 方法的用途是，如果一个 Optional 包含值，则对其包含的值调用函数 action，即 action.accept(value)，这与 ifPresent 一致；与 ifPresent 方法的区别在于，ifPresentOrElse 还有第二个参数 emptyAction —— 如果 Optional 不包含值，那么 ifPresentOrElse 便会调用 emptyAction，即 emptyAction.run() streamstream 方法的作用就是将 Optional 转为一个 Stream，如果该 Optional 中包含值，那么就返回包含这个值的 Stream；否则返回一个空的 Stream（Stream.empty()）。举个例子，在 Java8，我们会写下面的代码： 而有了 Optional.stream()，我们就可以将其简化为 参考文献： 《使用 Java8 Optional 的正确姿势》 《Java高级（三）：Optional的巧用》 "},{"title":"缓存的套路","date":"2020-03-23T06:17:03.000Z","url":"/2020/03/23/%E7%BC%93%E5%AD%98%E7%9A%84%E5%A5%97%E8%B7%AF/","tags":["系统架构","缓存"],"content":"什么时候应该使用缓存？所有高耗时，需要吞吐量，而不太严格依赖强一致性的场景-不管是计算密集型还是 io 密集型，都可以使用缓存加速。 多级缓存问题大多数情况下不要使用多级缓存。多级缓存要严格设计差异化的冷热数据分离策略，还要考虑分布式的缓存失效+更新的问题，很复杂。 勉强可用的多级缓存应该是远端一级缓存，近端二级缓存。 本地多级缓存非常容易出一致性问题-慎用 MyBatis 和 Hibernate 的二级缓存。 外部缓存设计思路外部缓存通常指的是分布式缓存组件或者中间件。 内文直接参考《缓存更新的套路》 缓存更新的设计模式.xmind Redis内部缓存的用法内部缓存通常指的是进程内缓存，in-memory-cache。 Spring Cache 依靠一个 CacheManager SPI 机制，来跟不同的 cache 实现打交道。大多数时候我们应该用 CacheManager 封装好的 wrapper api 来跟缓存打交道，极少数情况下我们应该 getNativeCache 来使用专有 API。 Guava Cache 就是给 ConcurrentHashMap 加上了大量的 LRU 等 evict 操作和相应的管理策略。Guava在每次访问缓存的时候判断cache数据是否过期，如果过期，这时才将其删除，并没有另起一个线程专门来删除过期数据-类似 WeakHashMap。内部维护了2个队列 AccessQueue 和 WriteQueue 来记录缓存中数据访问和写入的顺序。访问缓存时，先用key计算出hash，从而找出所在的segment，然后再在segment中寻找具体问题，类似于使用ConcurrentHashMap数据结构来存放缓存数据。 Guava在每次访问缓存的时候判断cache数据是否过期，如果过期，这时才将其删除，并没有另起一个线程专门来删除过期数据。 ECache 支持本地磁盘缓存，甚至支持集群模式-使用到集群的时候，是不是可以考虑改用 Redis 更好。 Ecache 有内存占用大小统计，Guava Cache 没有。 Ecache 提供全面的缓存支持，Guava Cache 提供基本的缓存支持。 Ecache 允许 value 为 null；而 Guava Cache 允许 value 为 null，因为它根据value的值是否为null来判断是否需要load，所以不允许返回为null。这就意味着 Guava Cache 不易处理缓存穿透的问题，需要使用使用空对象替换 null。 Caffeine 是用 Java8 对 Guava Cache 的一种重写。 在更多的时候，一个简单的全局的 ConcurrentHashMap（注意，它作为全局可访问的状态，天然就应该做线程安全设计）就可以解决大部分缓存问题。只有加上各种细致的操作的时候，才有必要专门引入特定的缓存包。Guava Cache 实际上是由一个开源的 one-man project concurrentlinkedhashmap 衍生出来，交给一个 dedicated team 维护的。 Guavaspring 的 cache 用的是 cachemanager。guava 的 cache 用的是 cachebuilder。 Spring + Guava 一般的短路器式的用法 只需要覆盖 load 方法load 和 evict 逻辑是解耦的。 带权重的缓存配置 指定过期时间 弱引用和软引用 key 定时触发 load 方法 主动预热 必须使用 optional 来应对 null 值 订阅删除事件 Cache Statistic可以 logging cache statistic data Cache Stats= CacheStats{hitCount=3296628, missCount=1353372,loadSuccessCount=1353138, loadExceptionCount=0,totalLoadTime=2268064327604, evictionCount=1325410} Cache Stats=CacheStats{hitCount=3334167, missCount=1365834,loadSuccessCount=1365597, loadExceptionCount=0,totalLoadTime=2287551024797, evictionCount=1337740} Cache Stats=CacheStats{hitCount=3371463, missCount=1378536,loadSuccessCount=1378296, loadExceptionCount=0,totalLoadTime=2309012047459, evictionCount=1350990} Cache Stats=CacheStats{hitCount=3407719, missCount=1392280,loadSuccessCount=1392039, loadExceptionCount=0,totalLoadTime=2331355983194, evictionCount=1364535} Cache Stats=CacheStats{hitCount=3443848, missCount=1406152,loadSuccessCount=1405908, loadExceptionCount=0,totalLoadTime=2354162371299, evictionCount=1378654} 参考：recordStats ECacheSpring4 + ECache 2整个 namespace 的说明见这里。 具体的配置选项见： name：缓存名称。 maxElementsInMemory：缓存最大个数。 eternal：缓存中对象是否为永久的，如果是，超时设置将被忽略，对象从不过期。 timeToIdleSeconds：置对象在失效前的允许闲置时间（单位：秒）。仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大。 timeToLiveSeconds：缓存数据的生存时间（TTL），也就是一个元素从构建到消亡的最大时间间隔值，这只能在元素不是永久驻留时有效，如果该值是0就意味着元素可以停顿无穷长的时间。 maxEntriesLocalDisk：当内存中对象数量达到maxElementsInMemory时，Ehcache将会对象写到磁盘中。 overflowToDisk：内存不足时，是否启用磁盘缓存。 diskSpoolBufferSizeMB：这个参数设置DiskStore（磁盘缓存）的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区。 maxElementsOnDisk：硬盘最大缓存个数。 diskPersistent：是否在VM重启时存储硬盘的缓存数据。默认值是false。 diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是120秒。 memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。 clearOnFlush：内存数量最大时是否清除。 对应的 java code： Spring Boot 2 + ECache3ECache 是 Hibernate 中的默认缓存框架。 要引入 javax 的 cache api（JSR-107）： 对应的缓存注解： 具体的其他 cache 操作的注解： 可以考虑，定义自己的 KeyGenerator 另外，可以用的 key 的缓存专用 SPEL 表达式，在这里。 Caffeine它几个特别有意思的特性：time-based eviction、size-based eviction、异步加载、弱引用 key（不考虑 referenceQueue 的特性，WeakReference 是最适合我们用的）。 automatic loading of entries into the cache, optionally asynchronously size-based eviction when a maximum is exceeded based on frequency and recency time-based expiration of entries, measured since last access or last write asynchronously refresh when the first stale request for an entry occurs keys automatically wrapped in weak references values automatically wrapped in weak or soft references notification of evicted (or otherwise removed) entries writes propagated to an external resource accumulation of cache access statistics 不搭配 Spring 搭配 Spring 相关的配置文件： initialCapacity: # 初始的缓存空间大小 maximumSize: # 缓存的最大条数 maximumWeight: # 缓存的最大权重 expireAfterAccess: # 最后一次写入或访问后经过固定时间过期 expireAfterWrite: # 最后一次写入后经过固定时间过期 refreshAfterWrite: # 创建缓存或者最近一次更新缓存后经过固定的时间间隔，刷新缓存 weakKeys: # 打开 key 的弱引用 weakValues: # 打开 value 的弱引用 softValues: # 打开 value 的软引用 recordStats: # 开发统计功能 如何应对缓存 miss 的问题cache miss 在中文的语境里经常被人分为缓存击穿、缓存雪崩和缓存穿透，这三种类型并不完全互斥穷举，在概念上极其容易造成混淆。在这一段总结的时候姑且依照这三种类型分别加以论述。 如何应对缓存击穿缓存击穿，指的是某个 key 应该访问缓存，却没有访问到，导致缓存通过兜底的策略去更下游的冷存储加载内容，给下游的系统造成了读压力。 应对这个问题的基本思路有： 事前： 在可能热点数据的访问高峰到达以前，提前把数据预热。 永远不要让缓存失效-这样缓存 stale 以后，怎么保鲜是个巨大的问题，只能靠一个后端的主动更新机制来尽最大努力来更新缓存。这种方案是一致性最差的。 在缓存击穿以前，主动更新缓存，即不让缓存击穿发生，即同时才有 expireAfter(t1) + loadAfter(t2) 的策略。 极端热的数据，不允许缓存被动失效，必须使用主动更新的模式。 并发操作下更新缓存一定要注意顺序！如果有消息来更新更要注意顺序！ 定时任务和广播刷新有时候可以互相补充-定时任务是超时的补充。 事中： 在缓存击穿的时候，严格限制读冷存储 + 预热缓存的流量，即有限降级，有损服务。 如果缓存更新是同步读写（Cache Aside 或者 Read/Write Through）的模式，则引入各种限流工具（限制线程数的线程池/信号量/SLA/Rhino/Redis 计数器/线程内计数器/Hystrix/Web 容器的限流器），保障可用性的同时保障吞吐量。 如果缓存更新可以异步主动更新，则考虑单线程执行或者使用消息队列进行低流量更新。能怎样在事中限制这个问题，取决于缓存和读写接入层之间本来的架构关系是如何设计的。 某类特别热的 key 可能一旦失效会导致大量的读，这种 key 的实际更新流程还要加上分布式锁-而且还要使用试锁而不能使用阻塞锁-facebook 的论文里没有提到这种策略，不知道是不是数据很均匀。 事后： 如果系统无法自愈，熔断拒绝服务以后（所以熔断、降级限流每一手准备都要准备好，可以用限流为 0 来制造熔断），手工预热缓存。 如何应对缓存雪崩雪崩问题，指的是：大规模的缓存失效，再加上大规模的访问流量，造成对后端非高可用的冷存储（通常是 RDBMS）的大规模读写，导致 RDBMS 可用性下降，甚至整个系统级联崩溃。 从某种意义上，单一缓存的击穿并不可怕，缓存雪崩才是最可怕的。 应对缓存雪崩问题，基本思路是大规模使用应对缓存击穿的基础策略的基础上，把缓存预热的行为模式打散。 基于超时时间的思路是：不同的 key 设置不同的超时时间，让缓存失效不同时到来。但这样并不能完全解决问题，因为缓存并不是失效以后就直接可以被加载上，除非缓存自带异步自加载的机制（很多 in-memory cache 有，但 Redis 没有），否则不均匀的流量还是可能到达缓存后导致大规模击穿。对超时时间的方案的加强版是，采用一套主动更新缓存的机制。 基于预热的思路是：缓存一开始分好集群。允许某些集群的上游准备好熔断，然后集体停下流量以后，使用脚本批量预热整个集群数据。 如何应对缓存穿透缓存穿透不同于缓存击穿。 缓存穿透指的是试图查询不存在的缓存数据。 可以针对缓存穿透来刷冷数据，导致整个集群频繁查询冷存储而崩溃。 解决方案有： 对明显不符合要求的请求，直接返回 null。 使用一个大的 bitmap 或者布隆过滤器来拦截可能不存在的请求，直接返回 null。 缓存穿透一次，就在 cache 中存上 null - 允许使用 null 的缓存能够天然抵挡缓存穿透问题。Guava 的缺点就在这里被体现出来了 以上措施混合使用的话，必须考虑缓存里的 null。 必须有超时时间，而且应该有对应的无 null。 以后主动更新的机制，否则这个空值就被污染了。 远端缓存与近端缓存的辨析缓存在哪端，哪端就能定制它的行为，但要供应它消耗的资源。近端缓存通常简单，但也就意味着没有什么功能。 远端缓存的好处自带广播、同步和共识功能，能够对接写入服务。自带独立的集群，有专业的运维人员，适合存储海量数据。 远端缓存的坏处制造了复杂的依赖，比如接入变复杂、流程变复杂。所有的服务都依赖于一个服务，配置和流程不易于差异化，冲突比例增多。 近端缓存的好处接入简单。自己可以把控自己的缓存使用逻辑。 近端缓存的坏处相对于广播同步一致性难度大，通信成本高-易引起通信风暴。占用内存变大，无法解决海量数据存储。 参考文献： 《Guava Cache》 美团技术团队的《缓存那些事》 例子很多：《caffeine vs ehcache》 "},{"title":"5why分析法","date":"2020-03-21T04:03:54.000Z","url":"/2020/03/21/5why%E5%88%86%E6%9E%90%E6%B3%95/","tags":["思维模式"],"content":"所谓5why分析法，又称“5问法”，也就是对一个问题点连续以5个“为什么”来自问，以追究其根本原因。 虽为5个为什么，但使用时不限定只做“5次为什么的探讨”，主要是必须找到根本原因为止,有时可能只要3次，有时也许要10次，如古话所言：打破砂锅问到底。5why法的关键所在：鼓励解决问题的人要努力避开主观或自负的假设和逻辑陷阱，从结果着手，沿着因果关系链条，顺藤摸瓜，直至找出原有问题的根本原因。 介绍这种方法最初是由丰田佐吉提出。后来，丰田汽车公司在发展完善其制造方法学的过程之中，也采用了这一方法。 作为丰田生产系统（Toyota Production System）的入门课程的组成部分，这种方法成为其中问题求解培训的一项关键内容。丰田生产系统的设计师大野耐一曾经将五问法描述为：“……丰田科学方法的基础……重复五次，问题的本质及其解决办法随即显而易见。” 目前，该方法在丰田之外已经得到了广泛采用，并且现在持续改善法（Kaizen），精益生产法（lean manufacturing）以及六西格玛法之中也得到了采用。 关键点 5why的”5“并不是问题的数量 5why的”5“指的是问题的深度，即不断地针对上一个问题的答案问问题，如果一直能问到第5层（依然可以继续），那往往才是问题真正的原因 5why追求的是寻找问题的根本原因，即”问题的问题“ 经典案例丰田汽车公司前副社长大野耐一曾举了一个例子来找出停机的真正原因： ★问题一：为什么机器停了？ 答案一：因为机器超载，保险丝烧断了。 ★问题二：为什么机器会超载？（针对答案一提问题） 答案二：因为轴承的润滑不足。 ★问题三：为什么轴承会润滑不足？（针对答案二提问题） 答案三：因为润滑泵失灵了。 ★问题四：为什么润滑泵会失灵？（针对答案三提问题） 答案四：因为它的轮轴耗损了。 ★问题五：为什么润滑泵的轮轴会耗损？（针对答案四问问题） 答案五：因为杂质跑到里面去了。 经过连续五次不停地问“为什么”，才找到问题的真正原因和解决的方法，在润滑泵上加装滤网。 如果员工没有以这种追根究底的精神来发掘问题，他们很可能只是换根保险丝草草了事，真正的问题还是没有解决。 实施方法如果面对一个事故，不知道该如何入手，5why建议从三个层面来实施： 一、为什么会发生？从“制造”的角度。 二、为什么没有发现？从“检验”的角度。 三、为什么没有从系统上预防事故？从“体系”或“流程”的角度。 每个层面连续5次或N次的询问，得出最终结论。只有以上三个层面的问题都探寻出来，才能发现根本问题，并寻求解决。 截选自百度百科，有改动。 "},{"title":"Java 线程状态切换","date":"2020-03-13T05:47:47.000Z","url":"/2020/03/13/Java-%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%88%87%E6%8D%A2/","tags":["JVM","Java","未完成"],"content":"Java 线程状态 NEW没有启动过的线程。 RUNNABLE1 正在执行的线程。2 可以被执行但没有拿到处理器资源。 BLOCKEDblocked 其实是 blocked waiting1 等待 monitor，进入 synchronized method/block2 或者等 wait()/await()以后再次进入 synchronized method/block（注意这一点，解除 wait 以后以后不是直接 runnable，而是进入 blocked，但这一步非常短暂，几乎不可能用程序观察到）。 WAITING在调用这三种不计时方法以后，线程进入 waiting 态： Object.wait Thread.join LockSupport.park waiting 意味着一个线程在等待另一个线程做出某种 action。wait 在等其他对象 notify 和 notifyAll，join 在等其他线程终结。 如：java.util.concurrent.LinkedBlockingQueue.take -&gt; java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await -&gt; java.util.concurrent.locks.LockSupport.park reentrantlock 的 lock 接口的栈帧则是： jstack 总会告诉我们 waiting 的位置，比如等待某个 Condition 的 await 操作。 对这个程序进行 thread dump，可以看出 ReentrantLock 就是依赖于 park 导致的 waiting： 如果使用 synchronized，则会显示 object monitor： 所以 waiting 可能是在条件变量上等待，也可能是在 synchronizer 本身上 上等待，不可一概而论。 按照 jvisualvm 的分类方法，线程还可以分为：等待驻留（park）监视（monitor） TIMED_WAITING调用了计时方法，等待时间结束后才或者被其他唤醒方法唤醒结束等待。 Thread.sleepObject.waitThread.joinLockSupport#parkNanosLockSupport.parkUntil 如： java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take -&gt; java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos -&gt; java.util.concurrent.locks.LockSupport.parkNanos -&gt; sun.misc.Unsafe.park 除了 sleep 以外，jstack 总会告诉我们 time_waiting 的位置，比如等待某个 Condition 的 await 操作。 TERMINATED终结的线程，执行已经结束了。 中断退出也是一种结束。 几种线程状态的对比 blocked：线程想要获取锁进入临界区之前，会求锁，求不到锁会进入 wait_set，然后放弃 cpu。高并发时 blocked 会增多。 工作线程池开始伸缩，扩容的时候：jvm.thread.waiting.count 的数量会变少，这意味着等待从 blockingQueue 里面 take 任务而阻塞的工作线程在变少。 工作吞吐变多，而调用下游的工作线程在阻塞的时候，jvm.thread.time_waiting.count 会变多，因为 rpc 框架自带超时，而这些超时是会让工作线程进行计时等待的。 流量变大的时候，2 和 3 可能同时发生。 特别的切换方法LockSupport.parkcondition 的 await 底层调用的是 LockSupport.park。 wait从 wait 中醒来会有伪唤醒的 case，所以醒来的时候一定要先检查唤醒条件是否已经得到满足。原理见《为什么条件锁会产生虚假唤醒现象（spurious wakeup）？》 join"},{"title":"认证要素","date":"2020-03-13T01:28:42.000Z","url":"/2020/03/13/%E8%AE%A4%E8%AF%81%E8%A6%81%E7%B4%A0/","tags":["金融"],"content":"个人二要素个人银行卡三要素个人银行卡四要素个人运营商三要素企业二要素企业三要素企业四要素企业验卡二要素"},{"title":"Java Logging","date":"2020-03-11T09:46:29.000Z","url":"/2020/03/11/Java-Logging/","tags":["Java","Logging"],"content":"log 历史 阶段 阶段 阶段 阶段 阶段 log4j apache commons logging（JCL） log4j2 JUL simple log logback + slf4j 多个项目使用不同的 logging 库 + 传递依赖等于依赖管理不规范，日志库泛滥以至互斥。 具体框架与门面所谓的日志框架，指的是日志输出的具体实现，常见的日志框架包括但不仅限于 JUL（Java Util Logging）、Log4j、Log4j2 和 Logback。这些框架的功能不尽相同，比如有些框架支持友好地打印异常，有些不支持，有些框架不支持，不同的框架的日志级别也各有差异。 因此，诞生了日志门面。所谓的门面，就是“使用一个中间层解耦”这一具体思想的应用。使用了门面，可以屏蔽日志使用者对于具体差异的依赖，既让代码变得整洁，而且可以简单地切换实现而不需要修改代码。没有日志门面，不足以统一日志框架的使用。 log facade（定义 interface，早期的 JCL 时代，facade 也被叫做接口）-&gt; log implementation 最上层表示桥阶层，下层表示具体的实现层，中间是接口层，可以看出这个图中所有的jar都是围绕着slf4j-api活动的 JCLJCL 全称 Jakarta Commons Logging。由于历史原因，Spring最开始在core包中引入的是commons-logging（JCL标准实现）的日志系统，官方考虑到兼容问题，在后续的Spring版本中并未予以替换，而是继续沿用。如果考虑到性能、效率，应该自行进行替换，在项目中明确指定使用的日志框架，从而在编译时就指定日志框架。 因为这一错误的设计决定，Spring 后悔了： The mandatory logging dependency in Spring is the Jakarta CommonsLogging API (JCL). We compile against JCL and we also make JCL Logobjects visible for classes that extend the Spring Framework. It’simportant to users that all versions of Spring use the same logginglibrary: migration is easy because backwards compatibility ispreserved even with applications that extend Spring. The way we dothis is to make one of the modules in Spring depend explicitly oncommons-logging (the canonical implementation of JCL), and then makeall the other modules depend on that at compile time. If you are usingMaven for example, and wondering where you picked up the dependency oncommons-logging, then it is from Spring and specifically from thecentral module called spring-core. Spring中强制使用的是Jakarta Commons Logging API(JCL)日志系统。我们基于JCL进行编译，构建JCL日志对象，这些同时也对扩展自Spring类可见的。对于使用者而言，确保不同版本的Spring使用相同的日志系统是非常重要的–代码迁移需要确保逆向兼容性。我们之所以这样做，是为了在Spring的一个包中明确的依赖于commons-logging（JCL权威实现），而其他包就基于这个包进行构建编译。如果你使用maven，你可以发现commons-logging以来自Spring-core包。 The nice thing about commons-logging is that you don’t need anythingelse to make your application work. It has a runtime discoveryalgorithm that looks for other logging frameworks in well known placeson the classpath and uses one that it thinks is appropriate (or youcan tell it which one if you need to). If nothing else is availableyou get pretty nice looking logs just from the JDK (java.util.loggingor JUL for short). You should find that your Spring application worksand logs happily to the console out of the box in most situations, andthat’s important. 使用commons-logging的好处是，你不需要做其他额外事情就可以让程序正常工作。它有运行时的发现算法，能够在运行时从classpath自动发现其他日志框架，并自行挑选其中一个合适的，或者你自行指定一个。如果在运行时没有发现任何其他日志框架，则commons-loggin会直接使用JDK的日志系统（java.util.logging或JUL）。 Unfortunately, the runtime discovery algorithm in commons-logging,while convenient for the end-user, is problematic. If we could turnback the clock and start Spring now as a new project it would use adifferent logging dependency. The first choice would probably be theSimple Logging Facade for Java ( SLF4J), which is also used by a lotof other tools that people use with Spring inside their applications. 非常不幸的是，对于终端用户而言，commons-logging的运行时发现算法是合适的，但对于其他使用场景，却是问题重重。如果时间可以重来，让我们重新选择一个不同的日志系统，我们可能会选择SLF4J。 Spring 专门有个 spring-jcl 项目来支持 spring 项目通过 LogAdapter 来切换不同的日志实现。其具体使用步骤是： 使用 SLF4J-JCL 桥接（ bridge Spring to SLF4J）包替换commons-logging包。 使用 SLF4J 来调用 LogBack、Log4j 等 API。 老的调用关系：spring log -&gt; apache commons-logging -&gt; log4j新的调用关系：spring log -&gt; SLF4J-JCL -&gt; slf4j -&gt; log4j2 SLF4J-JCL 支持的日志框架有： SLF4J、Log4J2、JUL。 common-loggingJava 界里有许多实现日志功能的工具，最早得到广泛使用的是 log4j，许多应用程序的日志部分都交给了 log4j，不过作为组件开发者，他们希望自己的组件不要紧紧依赖某一个工具，毕竟在同一个时候还有很多其他很多日志工具，假如一个应用程序用到了两个组件，恰好两个组件使用不同的日志工具，那么应用程序就会有两份日志输出了。 为了解决这个问题，Apache Commons Logging （之前叫 Jakarta Commons Logging，JCL）粉墨登场，JCL 只提供 log 接口，具体的实现则在运行时动态寻找。这样一来组件开发者只需要针对 JCL 接口开发，而调用组件的应用程序则可以在运行时搭配自己喜好的日志实践工具。 所以即使到现在你仍会看到很多程序应用 JCL + log4j 这种搭配，不过当程序规模越来越庞大时，JCL的动态绑定并不是总能成功，具体原因大家可以 Google 一下，这里就不再赘述了。解决方法之一就是在程序部署时静态绑定指定的日志工具，这就是 SLF4J 产生的原因。 common-logging是apache提供的一个通用的日志接口。用户可以自由选择第三方的日志组件作为具体实现 - common-logging 也是个日志门面。 commons-logging日志系统是基于运行发现算法（runtime-discovery）- 常见的方式就是每次使用org.apache.commons.logging.LogFactory.getLogger(xxx)，就会启动一次发现流程，获取最适合的日志系统进行日志记录，其效率要低于使用SLF4J。 动态查找原理：Log 是一个接口声明。LogFactory 的内部会去装载具体的日志系统，并获得实现该Log 接口的实现类。 寻找org.apache.commons.logging.LogFactory 属性配置。 否则，利用JDK1.3 开始提供的service 发现机制，会扫描classpah 下的META-INF/services/org.apache.commons.logging.LogFactory文件，若找到则装载里面的配置，使用里面的配置。 否则，从Classpath 里寻找commons-logging.properties ，找到则根据里面的配置加载。 否则，使用默认的配置：如果能找到Log4j 则默认使用log4j 实现，如果没有则使用JDK14Logger 实现，再没有则使用commons-logging 内部提供的SimpleLog 实现。 common-logging通过动态查找的机制，在程序运行时自动找出真正使用的日志库。由于它使用了ClassLoader寻找和载入底层的日志库， 导致了象OSGI这样的框架无法正常工作，因为OSGI的不同的插件使用自己的ClassLoader。 OSGI的这种机制保证了插件互相独立，然而却使Apache Common-Logging无法工作。 SLF4J类似于Apache Common-Logging，是对不同日志框架提供的一个门面封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。但是，他在编译时静态绑定真正的Log库。 slf4j-api 会去调用StaticLoggerBinder这个类获取绑定的工厂类，而每个日志实现会在自己的jar中提供这样一个类，这样slf4j-api就实现了编译时绑定实现。 slf4j在编译时静态绑定（compile-time bindings）真正的Log库,因此可以再OSGI中使用。另外，SLF4J 支持参数化的log字符串，避免了之前为了减少字符串拼接的性能损耗而不得不写的if(logger.isDebugEnable())，现在你可以直接写：logger.debug(“current user is: {}”, user)。拼装消息被推迟到了它能够确定是不是要显示这条消息的时候，但是获取参数的代价并没有幸免。 最佳实践： 总是使用Log Facade，而不是具体Log Implementation。具体来说，现在推荐使用 Log4j-API 或者 SLF4j，不推荐继续使用 JCL。 只添加一个 Log Implementation依赖 具体的日志实现依赖应该设置为optional和使用runtime scope。如： 设为optional，依赖不会传递，这样如果你是个lib项目，然后别的项目使用了你这个lib，不会被引入不想要的Log Implementation 依赖； Scope设置为runtime，是为了防止开发人员在项目中直接使用Log Implementation中的类，而不适用Log Facade中的类。 如果有必要, 排除依赖的第三方库中的Log Impementation依赖 这是很常见的一个问题，第三方库的开发者未必会把具体的日志实现或者桥接器的依赖设置为optional，然后你的项目继承了这些依赖——具体的日志实现未必是你想使用的，比如他依赖了Log4j，你想使用Logback，这时就很尴尬。另外，如果不同的第三方依赖使用了不同的桥接器和Log实现，也极容易形成环。 这种情况下，推荐的处理方法，是使用exclude来排除所有的这些Log实现和桥接器的依赖，只保留第三方库里面对Log Facade的依赖。 比如阿里的JStorm就没有很好的处理这个问题，依赖jstorm会引入对Logback和log4j-over-slf4j的依赖，如果你想在自己的项目中使用Log4j或其他Log实现的话，就需要加上excludes: 避免为不会输出的log付出代价。注意使用 lambda 来惰性求职（optional 风格的求值）。 Log4j2现在有了更好的 SLF4J 和 Logback——你会想事情到这里总该了解了吧，让他们慢慢取代JCL 和 Log4j 好了。 然而维护 Log4j 的人不这样想，他们不想坐视用户一点点被 SLF4J /Logback 蚕食，继而搞出了 Log4j2。 Log4j2 和 Log4j1.x 并不兼容，设计上很大程度上模仿了 SLF4J/Logback，性能上也获得了很大的提升。 Log4j2 也做了 Facade/Implementation 分离的设计，分成了 log4j-api 和 log4j-core。 参考文献： 《java日志组件介绍（common-logging，log4j，slf4j，logback ）》 《Spring 切换日志系统》 《Java 日志框架解析(上) - 历史演进》 《java日志系统详解》 《Bridging legacy APIs》 "},{"title":"maven-enforcer-plugin 解决包冲突设计方案","date":"2020-03-11T07:45:23.000Z","url":"/2020/03/11/maven-enforcer-plugin-%E8%A7%A3%E5%86%B3%E5%8C%85%E5%86%B2%E7%AA%81%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88/","tags":["Java","Maven"],"content":"执行时机生命周期validate环节。 dependencyConvergence执行逻辑通过访问maven dependency tree生成的依赖树，存入map中，key是groupid和artifactId组合，value是依赖对象list，通过判断每个list里的版本号是否相同来判断所有依赖是否为同一个版本。 配置实例 快速检验在自己分支开发完成后，执行mvn validate命令即可查看冲突信息 移除冲突jar登陆线上机器确认冲突jar的版本，移除不是对应版本的jar，方法：Dependency Analyzer 中搜索冲突jar名，右键选择移除即可自动生成exclude内容。 参考《重新看待Jar包冲突问题及解决方案》"},{"title":"JMX 深度历险","date":"2020-03-08T05:14:53.000Z","url":"/2020/03/08/JMX-%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9/","tags":["JVM","Java"],"content":"JMX 常见指标JVM 指标系统指标 System 相关指标 描述 system.load.average 系统load，如果是docker，此指标收集的物理机的load cpu.system.load.percent 系统所有进程占用cpu的百分比 cpu.jvm.load.percent jvm占用cpu的百分比 system.process.used.phyical.memory 系统使用的物理内存 system.process.used.swap.size 系统使用的swap内存 JVM 内存指标 JVM相关指标 描述 jvm.gc.count GC的次数 jvm.gc.time GC的时间，单位毫秒 jvm.younggc.count 年轻代GC的次数 ，包括的GC算法（Copy，ParNew，PS Scavenge，G1 Young Generation） jvm.younggc.time 年轻代GC的时间，单位毫秒 jvm.fullgc.count 年老代GC的次数，包括的GC算法 jvm.fullgc.time 年老代GC的时间，单位毫秒 jvm.memory.used 内存使用总量 jvm.memory.used.percent 内存使用总量占比 jvm.thread.count JVM的线程数 jvm.thread.deadlock.count deadlock线程数 jvm.memory.nonheap.used nonheap使用总量 jvm.memory.nonheap.used.percent nonheap使用总量占比 jvm.memory.oldgen.used oldgen使用总量 jvm.memory.oldgen.used.percent oldgen使用总量占比 jvm.memory.oldgen.used.percent.after.fullgc 触发fullgc之后使用oldgen的内存使用占比,此时基本剩下不可以回收对象 jvm.memory.eden.used eden使用总量 jvm.memory.eden.used.percent eden使用总量占比 jvm.memory.survivor.used survivor使用总量 jvm.memory.survivor.used.percent survivor使用总量占比 jvm.memory.perm.used perm使用总量 jvm.memory.perm.used.percent perm使用总量占比 jvm.nio.directbuffer.used directbuffer使用总量,这个一般是nio一些框架会用到 jvm.nio.mapped.used mapped使用总量，这个一般是使用java内存文件映射用到 线程指标 JVM Thread 相关指标 描述 vm.thread.count 线程 jvm.thread.daemon.count daemon线程数 jvm.thread.totalstarted.count totalstarted线程数 jvm.thread.new.count new线程数 jvm.thread.runnable.count runnable线程数 jvm.thread.blocked.count blocked线程数 jvm.thread.waiting.count waiting线程数 jvm.thread.time_waiting.count time_waiting线程数 jvm.thread.terminated.count terminated线程数 jvm.thread.deadlock.count deadlock线程数 jmx bean"},{"title":"安全系统设计指南","date":"2020-03-05T11:22:20.000Z","url":"/2020/03/05/%E5%AE%89%E5%85%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97/","tags":["信息安全"],"content":"系统内部设计准则 不要把开发者个人信息硬编码进系统中。 不要带着调试代码上线。 该脱敏的数据不能打在日志和写在 db 列中-可以存在于内存中。 应使用KMS保存密码等信息。 接口设计指南 敏感接口，涉及敏感信息查询，资金流信息流修改的接口应该有鉴权机制。应该接入统一的 SSO 鉴权，或使用统一的 UPM/UAC 服务。 在高并发的场景要加锁或者使用信号量（内部也试用了锁）机制来防止接口大量重入。 接口的参数里涉及可遍历数据的要进行混淆操作-这和一般的 RESTful API 的设计思路相抵触。所有涉及敏感信息的地方都要根据敏感信息进行分类，防止泄露、篡改、越权。 防止篡改，要单独使用非对称算法进行签名和验签。 "},{"title":"Java 平台历代特性","date":"2020-03-01T07:06:31.000Z","url":"/2020/03/01/Java-%E5%B9%B3%E5%8F%B0%E5%8E%86%E4%BB%A3%E7%89%B9%E6%80%A7/","tags":["Java"],"content":"Java 9 模块化，JDK 只依赖于 PATH 不依赖于 CLASSPATH。"},{"title":"汉语","date":"2020-02-28T07:07:35.000Z","url":"/2020/02/28/%E6%B1%89%E8%AF%AD/","tags":["汉语"],"content":"|中文|读音|含义||颟顸|[mān hān]|糊涂而马虎||攻讦|[gōng jié]|揭发别人的过失或阴私而加以攻击（多指因个人或派系利害矛盾）。|"},{"title":"余光中：怎样改进英式中文","date":"2020-02-28T02:15:19.000Z","url":"/2020/02/28/%E4%BD%99%E5%85%89%E4%B8%AD%EF%BC%9A%E6%80%8E%E6%A0%B7%E6%94%B9%E8%BF%9B%E8%8B%B1%E5%BC%8F%E4%B8%AD%E6%96%87/","tags":["文学"],"content":"一自五四新文化运动以来，七十年间，中文的变化极大。一方面，优秀的作家与学者笔下的白话文愈写愈成熟，无论表情达意或是分析事理，都能运用自如。另一方面，道地的中文，包括文言文与民间文学的白话文，和我们的关系日渐生疏，而英文的影响，无论来自直接的学习或是间接的潜移默化，则日渐显著，因此一般人笔下的白话文，西化的病态日渐严重。 一般人从大众传媒学到的，不仅是流行的观念，还有那些观念赖以包装的种种说法；有时，那些说法连高明之士也抗拒不了。今日的中文虽因地区不同而互见差异，但共同的趋势都是繁琐与生硬，例如中文本来是说“因此”，现在不少人却爱说“基于这个原因”；本来是说“问题很多”，现在不少人却爱说“有很多问题存在”。 对于这种化简为繁、以拙代巧的趋势，有心人如果不及时提出警告，我们的中文势必越变越差，而道地中文原有的那种美德，那种简洁而又灵活的语文生态，也必将面目全非。 中文也有生态吗？当然有。措词简洁、句式灵活、声调铿锵，这些都是中文生命的常态。能顺着这样的生态，就能长保中文的健康。要是处处违拗这样的生态，久而久之，中文就会被污染而淤塞，危机日渐迫近。 目前中文的一大危机是西化。我自己出身外文系，三十多岁时有志于中文创新的试验，自问并非语文的保守派。大凡有志于中文创作的人，都不会认为善用四字成语就是创作的能事。反之，写文章而处处仰赖成语，等于只会用古人的脑来想，只会用古人的嘴来说，绝非豪杰之士。但是，再反过来说，写文章而不会使用成语，问题就更大了。 写一篇完全不带成语的文章，不见得不可能，但是很不容易；这样的文章要写得好，就更难能可贵。目前的情形是，许多人写中文，已经不会用成语，至少会用的成语有限，显得捉襟见肘。一般香港学生目前只会说“总的来说”，却似乎忘了“总而言之”。同样地，大概也不会说“一言难尽”，只会说“不是一句话就能够说得清楚的”。 成语历千百年而犹存，成为文化的一部分。例如“千锤百炼”，字义对称，平仄协调，如果一定要说成“千炼百锤”，当然也可以，不过听来不顺，不像“千锤百炼”那样含有美学。同样，“朝秦暮楚”、“齐大非偶”、“乐不思蜀”等成语之中，都含有中国的历史。成语的衰退正显示文言的淡忘，文化意识的萎缩。 英文没有学好，中文却学坏了，或者可说，带坏了。中文西化，不一定就是毛病。缓慢而适度的西化甚至是难以避免的趋势，高妙的西化更可以截长补短。但是太快太强的西化，破坏了中文的自然生态，就成了恶性西化。这种危机，有心人都应该及时警觉而且努力抵制。 在欧洲的语文里面，文法比较单纯的英文恐怕是最近于中文的了。尽管如此，英文与中文仍有许多基本的差异，无法十分融洽。这一点，凡有中英文互译经验的人，想必都能同意。其实，研究翻译就等于研究比较语言学。以下拟就中英文之间的差异，略略分析中文西化之病。 二比起中文来，英文不但富于抽象名词，也喜欢用抽象名词。英文可以说“他的收入的减少改变了他的生活方式”，中文这么说，就太西化了。英文用抽象名词“减少”做主词，十分自然。中文的说法是以具体名词，尤其是人做主词：“他因为收入减少而改变生活方式”，或者“他收入减少，乃改变生活方式”。 中文常用一件事情 （一个短句）做主词，英文则常用一个名词（或名词词组）。“横贯公路再度坍方，是今日的头条新闻”是中文的说法。“横贯公路的再度坍方，是今日的头条新闻”就是英文语法的流露了。同理，“选购书籍，只好委托你了”是中文语法。“书籍的选购，只好委托你了”却是略带西化。“推行国语，要靠大家努力”是自然的说法。“推行的国语，要靠大家的努力”却嫌冗赘。这种情形也可见于受词。例如“他们杯葛这种风俗的继续”，便是一句可怕的话。无论如何，“杯葛继续”总嫌生硬。如果改成“他们反对保存这种风俗”，就自然多了。 英文好用抽象名词，其结果是软化了动词，也可以说是架空了动词。科学、社会科学与公文的用语，大举侵入了日常生活，逼得许多明确而有力的动词渐渐变质，成为面无表情的词组。下面是几个常见的例子： apply pressure: pressgive authorization: permitsend a communication: writetake appropriate action: act 在前例之中，简洁的单音节动词都变成了含有抽象名词的片词，表面上看来，显得比较堂皇而高级。例如press变成了apply pressure，动作便一分为二，一半驯化为静止的抽象名词pressure，一半淡化为广泛而笼统的动词apply。巴仁（Jacques Barzun）与屈林（Lionel Trilling）等学者把这类广泛的动词叫做“弱动词”（weak verb）。他们说：“科学报告不免单调而冷淡，影响之余，现代的文体喜欢把思路分解成一串静止的概念，用介词和通常是被动语气的弱动词连接起来。” 巴仁所谓的弱动词，相当于英国小说家奥韦尔所谓的“文字的义肢”（verbal false limb）。当代的中文也已呈现这种病态，喜欢把简单明了的动词分解成“万能动词+抽象名词”的片词。目前最流行的万能动词是“作出”和“进行”，恶势力之大，几乎要吃掉一半的正规动词。请看下面的例子： （一）本校的校友对社会作出了重大的贡献。 （二）昨晚的听众对访问教授作出了十分热烈的反应。 （三）我们对国际贸易的问题已经进行了详细的研究。 （四）心理学家在老鼠的身上进行试验。 不管是直接或间接的影响，这样的语法都是日渐西化的现象，因为中文原有的动词都分解成上述的繁琐词组了。前面的四句话本来可以分别说成： （一）本校的校友对社会贡献很大。 （二）昨晚的听众对访问教授反应十分热烈。 （三）我们对国际贸易的问题已经详加研究。 （四）心理学家用老鼠来做试验。（或：心理学家用老鼠试验。） 巴仁等学者感慨现代英文喜欢化简为繁、化动为静、化具体为抽象、化直接为迂回，到了“名词成灾”（noun-plague）的地步。学问分工日细，各种学科的行话术语，尤其是科学与社会科学的“夹杠”，经过本行使用，外行借用，加上“新闻体”（journalese）的传播，一方面固然使现代英文显得多彩多姿，另一方面却也造成混乱，使日常用语斑驳不堪。英国诗人格雷夫斯（Robert Graves，1895—1986）在短诗《耕田》（“Tilth”）里批评这种现象说： Gone are the sad monosyllabic daysWhen “agricultural labour” still was tilth；And “100% approbation”, praise;And “pornographic modernism”, filth-And still I stand by tilth and filth and praise. “名词成灾”的流行病里，灾情最严重的应该是所谓“科学至上”（scientism）。在现代的工业社会里，科学早成显贵，科技更是骄子，所以知识分子的口头与笔下，有意无意，总爱用一些“学术化”的抽象名词，好显得客观而精确。有人称之为“伪术语”（pseudo-jargon）。例如：明明是first step，却要说成initial phase；明明是letter，却要说成communication，都属此类。 中文也是如此。本来可以说“名气”，却凭空造出一个“知名度”来，不说“很有名”，却要迂回作态、貌若高雅，说成“具有很高的知名度”，真是酸腐可笑。另一个伪术语是“可读性”，同样活跃于书评和出版广告中。明明可以说“这本传记很动人”、“这本传记引人入胜”，或者干脆说“这本传记很好看”，却要说成“这本传记的可读性颇高”。我不明白这字眼怎么来的，因为这观念在英文里也只用形容词readable而不用抽象名词readability。英文会说：The biography is highly readable，却不说The biography has high readability。此风在台湾日渐嚣张。在电视上，记者早已在说“昨晚的演奏颇具可听性”。在书评里，也已见过这样的句子“传统写实作品只要写得好，岂不比一篇急躁的实验小说更具可看性？” 我实在不懂那位书评家以不能说“岂不比一篇……更耐看（更动人）？”同理，“更具前瞻性”难道真比“更有远见”要高雅吗？长此以往，岂不要出现“他讲的这件趣事可笑性很高”一类的怪句？此外，“某某主义”之类抽象名词也使用过度，英美有心人士都主张少用为妙。 名词分单数与复数，是欧语文的惯例。英文文法的复数变化，比起其他欧洲语文来，单纯得多。请看“玫瑰都很娇小”这句话在英文、法文、德文、西班牙文、意大利文里的各种说法： The roses are small.Les roses sont petites.Die Rosen sind klein.Las rosas son chiquitas.Le rose sono piccole. 每句话都是四个字，次序完全一样，都是冠词、名词、动词、形容词。英文句里，只有动词跟着名词变化，其他二字则不分单、复数。德文句里，只有形容词不变。法文、西班牙文、意大利文的三句里，因为做主词的名词是复数，其他的字全跟着变化。 幸而中文的名词没有复数的变化，也不区分性别，否则将不胜其繁琐。旧小说的对话里确有“爷们”、“娘们”、“ㄚ头们”等复数词，但是在叙述的部分，仍用“诸姐妹”、“众ㄚ鬟”。中文要表多数的时候，也会说“民众”、“徒众”、“观众”、“听众”，所以“众”也有点“们”的作用。但是“众”也好，“们”也好，在中文里并非处处需要复数语尾。往往，我们说“文武百官”，不说“官们”，也不说“文官们”、“武官们”。同理“全国的同胞”、“全校的师生”、“所有的顾客”、“一切乘客”当然是复数，不必再画蛇添足，加以标明。不少国人惑于西化的意识，常爱这么添足，于是“人们”取代原有的“人人”、“大家”、“大众”、“众人”、“世人”。“人们”实在是丑陃的西化词，林语堂绝不使用，希望大家也不要使用。电视上也有人说“民众们”、“听众们”、“球员们”，实在累赘。尤其“众、们”并用，已经不通。 中文词不分数量，有时也会陷入困境。例如“一位观众”显然不通，但是“观众之一”却嫌累赘，也欠自然。“一位观者”毕竟不像“一位读者”那么现成，所以，“一位观众来信说……”之类的句子，也只好由它去了。 可是“……之一”的泛滥，却不容忽视。“……之一”虽然是单数，但是背景的意识却是多数。和其他欧洲语文一样，英文也爱说one of my favorite actresses、one of those who believe…、one of the most active promoters。中文原无“……之一”的句法，现在我们说“观众之一”实在是不得已。至于这样的句子： 刘伶是竹林七贤之一。作为竹林七贤之一的刘伶…… 目前非常流行。前一句虽然西化，但不算冗赘。后一句却是恶性西化的畸婴，不但“作为”二字纯然多余，“之一的”也文白来杂，读来破碎，把主词“刘伶”压在底下，更是扭捏作态。其实，后一句的意思跟前一句完全一样，却把英文的语法as one of the Seven Worthies of Bamboo Grove, Liu Ling…生吞活剥地搬到中文里来。 所以，与其说“作为竹林七贤之一的刘伶以嗜酒闻名”，何不平平实实地说“刘伶是竹林七贤之一，以嗜酒闻名”？其实前一句也尽有办法不说“之一”。中文本来可以说“刘伶乃竹林七贤之同侪”、“刘伶列于竹林七贤”、“刘伶跻身竹林七贤”、“刘伶是竹林七贤的同人”。“竹林七贤之一”也好，“文房四宝之一”也好，情况都不严重，因为七和四范围明确，同时逻辑上也不能径说“刘伶是竹林七贤”，“砚乃文房四宝”。目前的不良趋势，是下列这样的句子： 红楼梦是中国文学的名著之一。李广乃汉朝名将之一。 两句之中，“之一”都是蛇足。世间万事万物都有其同俦同类，每次提到其一，都要照顾到其他，也未免太周到了。中国文学名著当然不止一部，汉朝名将当然也不会祇有一人，不加上这死心眼的“之一”，绝对没有人会误会你孤陋寡闻，或者挂一漏万。一旦养成了这种恶习，只怕笔下的句子都要写成“小张是我的好朋友之一”、“我不过是您的平庸的学生之一”、“他的嗜好之一是收集茶壸”了。 “之一”之病到了香港，更变本加厉，成为“其中之一”。在香港的报刊上，早已流行“是听王家的兄弟其中之一说的”或者“戴维连一直以来都是我最喜欢的导演其中之一”这类怪句。英文复数观念为害中文之深，由此可见。 这就说到“最……之一”的语法来了。英文最喜欢说“他是当代最伟大的思想家之一”，好像真是精确极了，其实未必。“最伟大的”是抬到至高，“之一”却稍加低抑，结果只是抬高，并未真正抬到至高。你并不知道“最伟大的思想家”究竟是几位，四位吗？还是七位？所以弹性颇大。兜了一个大圈子回来，并无多大不同。所以，只要说“他是一个大名人”或“他是赫赫有名的人物”就够了，不必迂而回之，说什么“他是最有名气的人物之一”吧。 三在英文里，词性相同的字眼常用and来连接，例如 man and wife、you and I、back and forth。但在中文里，类似的场合往往不用连接词，所以只要说“夫妻”、“你我”、“前后”就够了。同样地，一长串同类词在中文里，也任其并列，无须连接，例如“东南西北”、“金木水火土”、“礼乐射御书数”、“柴米油盐酱醋茶”皆是。中国人绝不说“开门七件事，柴、米、油、盐、酱、醋以及茶”。谁要这么说，一定会惹笑。同理，中文只说“思前想后”、“说古道今”。可是近来and的意识已经潜入中文，到处作怪。港报上有过这样的句子： 在政治民主化与经济自由化的发展道路，台北显然比北京起步更早及迈步更快，以致在政经体制改革的观念、行动、范围及对象上，更为深广更具实质…… 这样的文笔实在不很畅顺，例如前半句中，当作连接词的“与”、“及”都不必要。“与”还可以说不必要，“及”简直就要不得。后半句的“更为深广更具实质”才像中文，“起步更早及迈步更快”简直是英文。“及”字破坏了中文生态，因为中文没有这种用法。此地一定要用连接词的话，也只能用“而”，不可用“及”。正如slow but sure在中文里该说“慢而可靠”或者“缓慢而有把握”，却不可说“慢及可靠”或者“慢与有把握”。“而”之为连接词，不但可表更进一步，例如“学而时习之”，还可表后退或修正，例如“国风好色而不淫，小雅怨诽而不乱”，可谓兼有and与but之功用。 目前的不良趋势，是原来不用连接词的地方，在and意识的教唆下，都装上了连接词；而所谓连接词都由“和”、“与”、“及”、“以及”包办，可是灵活而宛转的“而”、“并”、“而且”等词，几乎要绝迹了。（但也不要不当而而而！） 四介词在英文里的用途远比中文里重要，简直成了英文的润滑剂。英文的不及物动词加上介词，往往变成了及物动词，例如look after、take in皆是。介词词组（prepositional phrase）又可当作形容词或助词使用，例如a friend in need、said it in earnest。所以英文简直离不了介词。中文则不尽然。“扬州十日、嘉定三屠”两个词组不用一个介词，换了英文，非用不可。 “欢迎王教授今天来到我们的中间，在有关环境污染的各种问题上，为我们作一次学术性的演讲。”这样不中不西的开场白，到处可以听见。其实“中间”、“有关”等介词，都是画蛇添足。有一些圣经的中译、牧师的传道，不顾中文的生态，会说成“神在你的里面”。意思懂，却不像中文。 “有关”、“关于”之类，大概是用得最滥的介词了。“有关文革的种种，令人不能置信”、“今天我们讨论有关交通的问题”、“关于他的申请，你看过了没有？”在这些句子里，“有关”、“关于”完全多余。最近我担任“全国学生文学奖”评审，有一篇投稿的题目很长，叫“关于一个河堤孩子的成长故事”。十三个字里，“关于”两字毫无作用，“一个”与“故事”也可有可无。 “关于”有几个表兄弟，最出风的是“由于”。这字眼在当代中文里，往往用得不妥： 由于秦末天下大乱，（所以）群雄四起。 由于好奇心的驱使，我向窗内看了一眼。由于他的家境贫穷，使得他只好休学。 英文在形式上重逻辑，喜欢交代事物的因果关系。中文则不尽然。“清风徐来，水波不兴”，其中当然有因果关系，但是中文只用上下文作不言之喻。换了是英文，恐怕会说“因为清风徐来，所以水波不兴”，或者“清风徐来，而不兴起水波”。上列的第一句，其实删掉“由于”与“所以”，不但无损文意，反而可使文章干净。第二句的“由于好奇心的驱使”并没有什么大毛病，可是有点啰嗦，更犯不着动用“驱使”一类的正式字眼。如果简化为“出于好奇，我向窗内看了一眼”或者“为了好奇，我向窗内看了一眼”，就好多了。第三句的不通，犯者最多。“由于他的家境贫穷”这种词组，只能拿来修饰动词，却不能当做主词。这一句如果删掉“由于”、“使得”一类交代因果的冗词，写成“他家境贫穷，只好休学”，反觉眉清目秀。 五英文的副词形式对中文为害尚不显著，但也已经开始了。例如这样的句子： 他苦心孤诣地想出一套好办法来。老师苦口婆心地劝了他半天。大家苦中作乐地竟然大唱起民歌。 “苦”字开头的三句成语，本来都是动词，套上副词语尾的“地”就降为副词了。这么一来，文章仍然清楚，文法上却主客分明，太讲从属的关系，有点呆板。若把“地”一律删去，代以逗点，不但可以摆脱主客的关系，语气也会灵活一些。 有时这样的西化副词词组太长，例如“他知其不可为而为之地还是去赴了约”，就更应把“地”删掉，代之以逗点，使句法松松筋骨。目前最滥的副词是“成功地”。有一次我不该为入学试出了这么一个作文题目：《国父诞辰的感想》，结果十个考生里至少有六个都说：“国父孙中山先生成功地推翻了清政府。”这副词“成功地”在此毫无意义，因为既然推而翻之，就是成功了，何待重复。同理，“成功地发明了相对论”、“成功地泳渡了直布罗陀海峡”也都是饶舌之说。天下万事，凡做到的都要加上“成功地”，岂不累人？ 六白话文一用到形容词，似乎就离不开“的”，简直无“的”不成句了。在白话文里，这“的”字成了形容词除不掉的尾巴，至少会出现在这些场合： 好的，好的，我就来。是的，没问题。快来看这壮丽的落日！你的笔干了，先用我的笔吧。也像西湖的有里外湖一样，丽芒分为大湖小湖两部分。他当然是别有用心的。你不去是对的。 喜欢用“的”或者无力拒“的”之人，也许还有更多的场合要偏劳这万能“的”字。我说“偏劳”，因为在英文里，形容词常用的语尾有-tive、-able、-ical、-ous等多种，不像在中文里全由“的”来担任。英文句子里常常连用几个形容词，但因语尾变化颇大，不会落入今日中文的公式。例如雪莱的句子： An old, mad, blind, despised, and dying king── 一连五个形容词，直译过来，就成了： 一位衰老的、疯狂的、瞎眼的、被人蔑视的、垂死的君王── 一碰到形容词，就不假思索，交给“的”去组织，正是流行的白话文所以僵化的原因。白话文之所以啰嗦而软弱，虚字太多是一大原因，而用得最滥的虚字正是“的”。学会少用“的”字之道，恐怕是白话文作家的第一课吧。其实许多名作家在这方面都很随便，且举数例为证： （一）月光是隔了树照过来的，高处丛生的灌木，落下参差的斑驳的黑影，峭楞楞如鬼一般；弯弯的杨柳的稀疏的倩影，却又像是画在荷叶上。 （二）最后的鸽群……也许是误认这灰暗的凄冷的天空为夜色的来袭，或是也预感到风雨的将至，遂过早地飞回它们温暖的木舍。 （三）白色的鸭也似有一点烦躁了，有不洁的颜色的都市的河沟里传出它们焦急的叫声。 第一句的“参差的斑驳的黑影”和“弯弯的杨柳的稀疏的倩影”，都是单调而生硬的重迭。用这么多“的”，真有必要吗？为什么不能说“参差而斑驳”呢？后面半句的原意本是“弯弯的杨柳投下稀疏的倩影”，却不分层次，连用三个“的”，读者很自然会分成“弯弯的、杨柳的、稀疏的、倩影”。第二句至少可以省掉三个“的”。就是把“灰暗的凄冷的天空”改成“灰暗而凄冷的天空”，再把“夜色的来袭”和“风雨的将至”改成“夜色来袭”、“风雨将至”。前文说过，中文好用短句，英文好用名词，尤其是抽象名词。“夜色来袭”何等有力，“夜色的来袭”就松软下来了。最差的该是第三句了。“白色的鸭”跟“白鸭”有什么不同呢？“有不洁的颜色的都市的河沟”，乱用“的”字，最是惑人。此句原意应是“颜色不洁的都市河沟”（本可简化为）“都市的脏河沟”，但读者同样会念成“有不洁的、颜色的、都市的、河沟”。 目前的形容词又有了新的花样，那便是用学术面貌的抽象名词来打扮。再举数例为证： 这是难度很高的技巧。他不愧为热情型的人。太专业性的字眼恐怕查不到吧。 “难度很高的”是什么话呢？原意不就是“很难的”吗？同理，“热情型的人”就是“热情的人”；“太专业性的字眼”就是“太专门的字眼”。到抽象名词里去兜了一圈回来，门面像是堂皇了，内容仍是空洞的。 形容词或修饰语 (modifier) 可以放在名词之前，谓之前饰，也可以跟在名词之后，谓之后饰。法文往往后饰，例如纪德的作品La Symphonie pastorale与Les Nourritures terrestres，形容词都跟在名词之后；若译成英文，例如The Pastoral Symphony，便是前饰了。中文译为“田园交响乐”，也是前饰。 英文的形容词照例是前饰，例如前引雪莱的诗句，但有时也可以后饰，例如雪莱的另一诗句：One too like thee——tameless, and swift, and proud。至于形容词片或子句，则往往后饰，例如：man of action、I saw a man who looked like your brother。（此例极佳，请注意！） 目前的白话文，不知何故，几乎一律前饰，似乎不懂后饰之道。例如前引的英文句，若用中文来说，一般人会不假思索说成：“我见到一个长得像你兄弟的男人。”却很少人会说：“我见到一个男人，长得像你兄弟。”如果句短，前饰也无所谓。如果句长，前饰就太生硬了。例如下面这句：“我见到一个长得像你兄弟说话也有点像他的陌生男人。”就冗长得尾大不掉了。要是改为后饰，就自然得多：“我见到一个陌生男人，长得像你兄弟，说话也有点像他。”其实文言文的句子往往是后饰的，例如司马迁写项羽与李广的这两句： 籍长八尺余，力能扛鼎，才气过人。广为人长，猿臂，其善射亦天性也。 这两句在当代白话文里，很可能变成： 项籍是一个身高八尺，力能扛鼎，同时才气过人的汉子。李广是一个高个子，手臂长得好像猿臂，天性就会射箭的人。 后饰句可以一路加下去，虽长而不失自然，富于弹性。前饰句以名词压底，一长了，就显得累赘、紧张、不胜负担。所以前饰句是关闭句，后饰句是开放句。 七动词是英文文法的是非之地，多少纠纷都是动词惹出来的。英文时态的变化，比起其他欧洲语文来，毕竟单纯得多。若是西班牙文，一个动词就会变出七十八种时态。 中文的名词不分单复与阴阳，动词也不变时态，不知省了多少麻烦。《阿房宫赋》的句子：“秦人不暇自哀，而后人哀之。后人哀之而不鉴之，亦使后人而复哀后人也。”就这么一个“哀”字，若用西文来说，真不知要玩出多少花样来。 中文本无时态变化，所以在这方面幸而免于西化。中国文化这么精妙，中文当然不会拙于分别时间之先后。散文里说：“人之将死，其言也善”；“议论未定，而兵已渡河。”诗里说：“已凉天气未寒时”。这里面的时态够清楚的了。苏轼的七绝：“荷尽已无擎雨盖，菊残犹有傲霜枝。一年好景君须记，最是橙黄橘绿时。”里面的时序，有已逝，有将逝，更有正在发生，区别得准确而精细。 中文的动词既然不便西化，一般人最多也只能写出“我们将要开始比赛了”之类的句子，问题并不严重。动词西化的危机另有两端：一是单纯动词分解为“弱动词+抽象名词”的复合动词，前文已经说过。不说“一架客机失事，死了九十八人”，却说“一架客机失事，造成九十八人死亡”，实在是迂回作态。 另一端是采用被动词语气。凡是及物动词，莫不发于施者而及于受者。所以用及物动词叙述一件事，不出下列三种方式： （一）哥伦布发现了新大陆。 （二）新大陆被哥伦布发现了。 （三）新大陆被发现了。 第一句施者做主词，乃主动语气。第二句受者做主词，乃被动语气。第三句仍是受者做主词，仍是被动，却不见施者。这三种句子在英文里都很普遍，但在中文里却以第一种最常见，第二、第三种就少得多。第三种在中文里常变成主动语气，例如“糖都吃光了”、“戏看完了”、“稿写了一半”、“钱已经用了”。 目前西化的趋势，是在原来可以用主动语气的场合改用被动语气。请看下列的例句： （一）我不会被你这句话吓倒。 （二）他被怀疑偷东西。 （三）他这意见不被人们接受。 （四）他被升为营长。 （五）他不被准许入学。 这些话都失之生硬，违反了中文的生态。其实，我们尽可还原为主动语气如下： （一）你这句话吓不倒我。 （二）他有偷东西的嫌疑。 （三）他这意见大家都不接受。 （四）他升为营长。 （五）他未获准入学。 同样，“他被选为议长”不如“他当选为议长”。“他被指出许多错误”也不如“有人指出他许多错误”。“他常被询及该案的真相”也不如“常有人问起他该案的真相”。 目前中文的被动语气有两个毛病。一个是用生硬的被动语气来取代自然的主动语气。另一个是千篇一律只会用“被”字，似乎因为它发音近于英文的by，却不解从“受难”到“遇害”，从“挨打”到“遭殃”，从“轻人指点”到“为世所重”，可用的字还有许多，不必套一个公式。 八中文的西化有重有轻，有暗有明，但其范围愈益扩大，其现象愈益昭彰，颇有加速之势。以上仅就名词、连接词、介词、副词、形容词、动词等西化之病稍加分析，希望读者能举一反三，知所防范。 常有乐观的人士说，语言是活的，犹如河流，不能阻其前进，所谓西化乃必然趋势。语言诚然是活的，但应该活得健康，不应带病延年。至于河流的比喻，也不能忘了两岸，否则泛滥也会成灾。西化的趋势当然也无可避免，但不宜太快、太甚，应该截长补短，而非以短害长。 颇有前卫作家不以杞人之忧为然，认为坚持中文的常规，会妨碍作家的创新。这句话我十分同情，因为我也是“过来人”了。“语法岂为我辈而设哉！”诗人本有越界的自由。我在本文强调中文的生态，原为一般写作说法，无意规范文学的创作。前卫作家大可放心去追逐缪思，不用碍手碍脚，作语法之奴。 不过有一点不可不知。中文发展了好几千年，从清通到高妙，自有千锤百炼的一套常态。谁要是不知常态为何物而贸然自诩为求变，其结果也许只是献拙，而非生巧。变化之妙，要有常态衬托才显得出来。一旦常态不存，余下的只是乱，不是变了。 "},{"title":"hive 汇总","date":"2020-02-27T07:38:03.000Z","url":"/2020/02/27/hive-%E6%B1%87%E6%80%BB/","tags":["Java","hive"],"content":"hive 操作符和函数汇总"},{"title":"计算机数学","date":"2020-02-27T07:35:14.000Z","url":"/2020/02/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E5%AD%A6/","tags":["数学"],"content":"precision vs scalesql 中的 decimal 函数的签名如下：DECIMAL[(precision[,scale])] DECIMAL with no precision or scale values is equivalent to DECIMAL(9,0). precision represents the total number of digits that can be represented by the column, regardless of the location of the decimal point. This value must be between 1 and 38. For example, representing integer values up to 9999, and floating-point values up to 99.99, both require a precision of 4. You can also represent corresponding negative values, without any change in the precision. For example, the range -9999 to 9999 still only requires a precision of 4. precision 表示总位数。 scale represents the number of fractional digits. This value must be less than or equal to precision. A scale of 0 produces integral values, with no fractional part. If precision and scale are equal, all the digits come after the decimal point, making all the values between 0 and 0.999… or 0 and -0.999… scale 表示小数点后的位数。 在 sql 中转化字符串为数字的方式：select cast(recurr as decimal(19, 9)) 同比环比 环比是由month-on-month翻译过来的 同比是由year-on-year翻译过来的 环比：是连续2个单位周期内的量的变化比。 同比：是一个单位周期内和另一个更大周期的同一个段周期内的变化比。环比只有一个，同比则因参照量（另一个更大周期）不同而不同，有多个。例如我今天（12.25日，星期日）步数是1000步，昨日800步，则环比为 1000/800=1.25；同比有多个，例如上周日为700步，上月25日900步，则上周同比为1000/700，上月同比为1000/900。有人遇到上月同比和上周同比时，把上周同比当成环比来理解了。记住一个重点，环比是连续（无任何时间间隔）周期内变化。 ceil vs floorceil 是 the smallest (closest to negative infinity) floating-point value that is greater than or equal to the argument and is equal to a mathematical integer。即向上取整。 floor 是 the largest (closest to positive infinity) floating-point value that less than or equal to the argument and is equal to a mathematical integer. 即向下取整。 round 是四舍五入。"},{"title":"Java Collections Framework","date":"2020-02-23T10:47:18.000Z","url":"/2020/02/23/Java-Collections-Framework/","tags":["Java"],"content":"UML 图overview-of-java-collections-framework-api-uml-diagram Collection-Hierarchy.html 队列的六个操作add(E e)Inserts the specified element at the tail of this queue if it is possible to do so immediately without exceeding the queue’s capacity, returning true upon success and throwing an IllegalStateException if this queue is full. offer(E e)Inserts the specified element at the tail of this queue if it is possible to do so immediately without exceeding the queue’s capacity, returning true upon success and false if this queue is full. put(E e)Inserts the specified element at the tail of this queue, waiting for space to become available if the queue is full. peek()Retrieves, but does not remove, the head of this queue, or returns null if this queue is empty. poll()Retrieves and removes the head of this queue, or returns null if this queue is empty. take()Retrieves and removes the head of this queue, waiting if necessary until an element becomes available. 平时最常用的 put 和 take 是阻塞操作。非阻塞操作可以加一套限时参数变成部分阻塞操作。 Code ExamplesCopyOnWriteArrayListCopyOnWriteArrayList的读操作有最终一致性问题： 由于所有的写操作都是在新数组进行的，这个时候如果有线程并发的写，则通过锁来控制，如果有线程并发的读，则分几种情况：1、如果写操作未完成，那么直接读取原数组的数据；2、如果写操作完成，但是引用还未指向新数组，那么也是读取原数组数据；3、如果写操作完成，并且引用已经指向了新的数组，那么直接从新数组中读取数据。 普通的 list在迭代的时候用 list.remove 会失败，iterator.remove 在单线程下回成功。而 CopyOnWriteArrayList 实际上是在一个 immutable 的 snapshot 上进行迭代，所以连 iterator.remove 都会 fastfail。 它是 ArrayList 的一个并发替代品，通过读写分离提高性能，但一致性问题和复制问题是一个潜在的性能和业务问题。 EnumSetenumset 的限制： It can contain only enum values and all the values have to belong to the same enum It doesn’t allow to add null values, throwing a NullPointerException in an attempt to do so It’s not thread-safe, so we need to synchronize it externally if required The elements are stored following the order in which they are declared in the enum It uses a fail-safe iterator that works on a copy, so it won’t throw a ConcurrentModificationException if the collection is modified when iterating over it - fail-safe 意味着不是 immutable 的，而且可能被并发修改。 JDK 提供两个默认参考实现： RegularEnumSet JumboEnumSet EnumMap Using Enum as key makes it possible to do some extra performance optimization, like a quicker hash computation since all possible keys are known in advance. 因为枚举的顺序已经被事先知道了，所以可以进行某些极致的优化。 EnumMap is an ordered map, in that its views will iterate in enum order. EnumMap 是一个有序 map，但 LinkedHashMap 和 TreeMap 也可以提供类似的行为。 IdentityHashMapIdentityHashMap 的用法和HashMap的用法差不多，他们之间最大的区别就是IdentityHashMap判断两个key是否相等，是通过严格相等即（key1==key2）来判读的，而HashMap是通过equals()方法和hashCode（）这两个方法来判断key是否相等的。 用途： 需要比对独一无二的的对象，如全局的 class，可以用 IdentityHashMap 来控制唯一性（注意这一点 Set 接口应该也做得到）。 深拷贝的时候需要容忍相同的值不同引用的对象。 Sorted 接口since 1.2 SortedMap、SortedSet 都要求包含的元素实现了 Comparable 接口，这样它们可以被集合排序（当然只有迭代或者顺序查询的时候才能体现出这种顺序来），这被称为provides a total ordering on its keys。 这种 order 可能是 natural order，也可能是由创建集合时传入的 comparator 决定的，却绝不是 LinkedList 等数据结构保持的插入顺序。 Java 中提到 order，默认都是 ascending （类似于指定了 order by 的 MySQL）。 SortedMap 非有序 map 也可以转成有序 map： Range view — performs arbitrary range operations on the SortedMap subMap(K fromKey, K toKey): Returns a view of the portion of this Map whose keys range from fromKey, inclusive, to toKey, exclusive. headMap(K toKey): Returns a view of the portion of this Map whose keys are strictly less than toKey. tailMap(K fromKey): Returns a view of the portion of this Map whose keys are greater than or equal to fromKey. Endpoints — returns the first or the last key in the SortedMap firstKey(): Returns the first (lowest) key currently in this Map. lastKey(): Returns the last (highest) key currently in this Map. Comparator access — returns the Comparator, if any, used to sort the map comparator(): Returns the Comparator used to order the keys in this Map, or null if this Map uses the natural ordering of its keys. SortedSet近于 SortedMap，也能维护自己内部元素的顺序。可以提供各种基于大小比对得到视图（View）的 API。 Navigable 接口since 1.2 NavigableSet扩展了 SortedSet，具有了为给定搜索目标报告最接近匹配项的导航方法。方法 lower、floor、ceiling 和 higher 分别返回小于、小于等于、大于等于、大于给定元素的元素，如果不存在这样的元素，则返回 null。 类似地，方法 lowerKey、floorKey、ceilingKey 和 higherKey 只返回关联的键。所有这些方法是为查找条目而不是遍历条目而设计的。 可以按照键的升序或降序访问和遍历 NavigableMap。descendingMap 方法返回映射的一个视图，该视图表示的所有关系方法和方向方法都是逆向的。升序操作和视图的性能很可能比降序操作和视图的性能要好。subMap、headMap 和 tailMap 方法与名称相似的 SortedMap 方法的不同之处在于：可以接受用于描述是否包括（或不包括）下边界和上边界的附加参数。任何 NavigableMap 的 Submap 必须实现 NavigableMap 接口。 此外，此接口还定义了 firstEntry、pollFirstEntry、lastEntry 和 pollLastEntry 方法，它们返回和/或移除最小和最大的映射关系（如果存在），否则返回 null。 AbstractList它的迭代器是不可变的 ListIterator, 只有 hasNext()，hasPrevious()，next()， previous()， 还有几个获取位置的方法 - 没有增删改查的操作。 AbstractSequentialList抽象线性表，就是数据结构里的线性表，是顺序表和链表的基类型，但在 Java 里只是 LinkedList。 它的迭代器在 ListIterator 基础上增加了，add、remove 等操作。"},{"title":"泛型拾遗","date":"2020-02-23T07:48:31.000Z","url":"/2020/02/23/%E6%B3%9B%E5%9E%8B%E6%8B%BE%E9%81%97/","tags":["Java"],"content":"Java 泛型类型系统![java 类型系统.png](java 类型系统.png) 基本语法 java 的泛型没有 template 关键字。 类型形参叫作 type variable，可以在类/方法里当具体类型如 String 使用，类型实参叫作 type parameter。也有些场景下，String 是 type argument。在甲骨文文档中的描述如下： Type Parameters: K - the type of keys maintained by this map V - thetype of mapped values 是否需要使用 type witness 取决于 compiler 是否有 enough information 来 infer 编译结果 - 又见 type inference。 泛型方法的 type variable 在 modifier（public static）和 return value 之间。 List 是 generic type。List 是 Parameterized type。 绑定类型（bounding type） 明确要绑定 type variable 到某个类型，才可以在接下来的方法里调用那个类型的方法，如需要 compareTo 方法，就必须&lt;T extends Comparable&lt;T&gt;&gt;。extends本身可以后接多个绑定类型，用&amp;分隔。 类型擦除（type erasure） 类型擦除的结果的是将 type variable 替换成绑定类型（bounding types）的 ordinary class（或者说使用 raw type 的 class）。 有了类型擦除，所有的泛型表达式都是可以被翻译的。带有泛型的代码被编译器翻译后通常分为两个部分：1. ordinary class，带有 bounding type，2. casting code，带有类型转换的代码。 cast code 是为了保证类型安全而存在的。 假设 B extends A，我们调用calc(new C())的时候，父类型的相关方法总是会被擦除到 bounding type（假定 C 的擦除类型是 Object），所以子类的方法也带有这个 bounding type 的方法实现calc(Object object)，但为了保持多态，编译器又生成了一个calc(C c)（相当于做了一次重载），真正要使用多态，就必须产生一个 synthesized bridge method，执行calc(Object object) &#123;calc((C)object);&#125;。这个东西是为了保持多态（preserve polymorphism）。泛型集成对比点 1。 为了兼容性（compatibility）考虑，A a = new A&lt;String&gt;() 之类的赋值（从泛型到擦除类型的赋值总是会成立的）总是会成立，但编译器总是会报 warning。猫插入狗列表中问题，只有在真实地 set 和 get 操作时才会发生。在 Jackson 中经常遇见如下问题：实际反序列化的生成 class 是 LinkedHashMap，但 Entity&lt;A&gt; = JsonUtil.toObject(str)等还是会赋值成功（此处 实际得到的是 A）。 泛型不能做什么所有泛型的 bug 都与一个基本假设有关，在虚拟机里运行的类型实际上使用的是 raw type，不注意这一点就可能出错。paramerized type vs raw type。 不能使用基本类型实例化 type parameters。 动态类型识别只能在 raw type 上工作，也就是 instanceof、Class ==、getClass() 这类操作都只能当做 raw type 工作。 不能创建 paramerized type 的数组（Pair&lt;Sring&gt;[] a = new Pair&lt;String&gt;[1]是不可能的） - 但可以赋值到泛型数组，见下一条。 类型参数可以和 vargargs 一起工作，如果使用@safevarargs 连警告都不会有。也就是说这样的语句是成立的Pair&lt;String&gt;[] pair = makePairs(pair1, pair2)（这一条破坏了第三条规则）。但泛型数组还是危险的，因为它是协变（covariant）的。泛型数组适合被写，但不适合被读。尽量避免使用它，否则会出现很奇怪的运行时错误。 不能初始化 type variables，最常见的非法写法是new T()（但 T t 是很常见的）。一个 workaround 是在使用 T 的地方都使用 Class，然后借反射来生成对应的对象。 不能创建泛型数组（T[] a = new T1）。 泛型类的 type variables 不能在它的 static 上下文里工作。但静态方法自己可以有 type variables。-各有各的泛型。 不能抛出和捕获异常类。 巧妙地使用泛型，可以破坏 checked exception 的限制 因为每个泛型方法都有一个兜底的 raw type 方法兜底，如果兜底方法和父类的非泛型方法相冲突（clash），编译会报错。举例，永远不要写boolean equals(T object)，因为编译器会擦除出 boolean equals(Object object)，制造同签名的方法，连重载都算不上。 泛型能够做什么 type variable 可以拿来做目标参数，如T t = get()和(T)。 通配符（wildcard）？是通配符。？ extends T 作为一个 type parameter 证明可以在此处读。Pair&lt;? extends Employee&gt;意味着它的子类 可以是 Pair 和 Pair。？ super T 作为一个 type parameter 证明可以在此处写。Pair&lt;? super Employee&gt;意味着它的子类 可以是 Pair 和 Pair。 LocalDate是ChronoLocalDate的子类（顺序就是这样，没有反过来），但 ChronoLocalDate 已然实现了 comparable&lt;ChronoLocalDate&gt;。这时候 LocalDate 的比较方法就应该声明成&lt;T extends Comparable&lt;? super T&gt;&gt;- 这是 comparable 的标准泛型方案。从 A 派生出 B，则 B 的 comparable 方法必须声明为可以支持 super 的类型，这样对 A 的 compare 才能同时兼容 A、B - 而不只是 B，Lists 的 removeIf 方法的谓词同理。（泛型集成对比点 2） 通配符的存在实际上是为了放松“泛型不能支持协变”，而需要让程序员灵活使用多种实际类型做的一个妥协。 举例，Java 8 中的ArrayList 有个 removeIf 的方法，它的参数是个 predicate，但这个 predicate 的实参可以是，比如 Employee，也可以是 Object（用上了 super）。 Pair 是个没用窝囊（wimpy）的类型，它的 setFirst(? object) 方法甚至无法被使用（试想，setFirst 怎样确定它的设值是兼容某个类型的？，？实际上近于 ? extends）。 但如果有些场景只是从某类 Pair 内部读值，那么 Pair 比 Pair 更加简洁易读。 通配符捕获? 不是 type variable，是 wildcard variable。 ? a = Pair.getFirst() 是不合法的。引入一个 T 来捕获通配符，就可以执行这个方法： 在这里，T 捕获了通配符。T 不知道 ？ 的具体类型，但知道它是某个确定类型。 编译器只有在确定 T 可以捕获确定的通配符的时候才允许编译通过。例如 List&lt;Pair&lt;?&gt;&gt; 多了一个间接层，一个 list 可能有不同的 pair，持有不同的具体类型，编译器不会允许 List&lt;Pair&gt; 产生捕获。 泛型与反射泛型与 classString.class 是 Class 的一个 object。 Class 的 type variable 实际上限制了它方法的种种返回值。 反射能够在擦除后知道些什么可以知道的以下东西： 一个方法或者类型有个 type parameter T。 T 有 super 或者 extends 的 bound。 T 有个 wildcard variable。 不可以知道的东西 到底运行时绑定的 type parameter 是什么？ 反射的类型 hiarachy反射的基础类型是 Type 接口，它有五个子类： Class 类，描述具体类型（而不是接口） TypeVariable 接口，描述类型参数，如 T WildcardType 接口，描述通配符，如 ？ ParameterizedType 接口，描述泛型类或接口类型，如 Comparable&lt;? super T&gt; - 奇怪，是 T 而不是 String GenericArray 接口，描述泛型数组如 T[]。 TypeLiteral有一个可以捕获多重泛型的实参的方案。 运行时捕获类型参数的方法方法一 方法二typetools 方法三 这个方法来自于 JDK 5 的作者的博客《super-type-tokens》。 abstract class 保证了这个类型必须通过子类确定，这样 getGenericSuperclass 必定会得到一个 ParameterizedType 而不仅仅是一个 GenericType。 implements Comparable&lt;TypeReference&gt; 并不是真的希望子类覆写一个比较方法，而是希望子类型不要实现成一个 raw type。 保证了这两天 _type 一定是一个 concret class。 各种泛型黑魔法Optional 里通配符转成类型参数可见@SuppressWarnings(&quot;unchecked&quot;) java 的基础库里到处都是。 其他资料angelikalanger 的 JavaGenericsFAQ。"},{"title":"MySQL 基本功","date":"2020-02-19T13:03:17.000Z","url":"/2020/02/19/MySQL-%E5%9F%BA%E6%9C%AC%E5%8A%9F/","tags":["MySQL"],"content":"插件式架构[MySQL 的插件式架构.xmind](MySQL 的插件式架构.xmind)![MySQL 的插件式架构.png](MySQL 的插件式架构.png) 索引问题索引的出现是为了减少单一维度查询时，搜索数据的成本。 索引的基础架构索引的分类不同的存储引擎支持不同的索引数据结构。 MySQL 支持的索引类型至少包括：BTree索引、Hash索引、full-text全文检索、R-Tree索引。 Innodb 支持的索引数据结构只有 B+树。 B+树索引 B 树扩充了二叉平衡树，让每个节点能够存储的数据大大提升。 B+ 树从 B 树演变而来，B 树每个节点都存储数据，但高度高，只有查找离根节点近的数据的速度是快的；B+树所有数据都存储在叶子节点，所以查询到特定的数据必须走完查询路径，也因此 B+树的查找速度稳定，遍历全部数据和范围查找的算法稳定（不用上溯下钻）。两种数据结构，各有所长。 B+树的每个节点可以被认为是一个磁盘块（block）-可以认为 MySQL 的磁盘块等同于 OS 的数据页，大小通常为 4k/8k/16k。磁盘块通常是双层的，第一层表示存储的数据项（data entry），第二层表示指向子节点的指针（pointer）。但 B+树本身只有叶子节点真实数据，非叶子节点存储的数据指引了指针的搜索方向（作为分界符）。 三层的 B+树能够存储的上百万条数据。也就是说，第三层是叶子节点，且叶子节点的数量为百万级。 假设数据总量为 M： 因为分界的关系，所以如果一个磁盘块能够拥有的数据项数量为 n，则可以拥有的指针数量为 n + 1。 则树的高度 height = log(n+1为底)M。 而数据的块大小又是固定的，也就意味着数据项的大小，决定了 n 的大小。所以 int 为 4 字节，bigint 为 4 字节，产生的 key_length 不一样，最终导致的树的形态也就不一样-注意，这就是B+树的数据只放在叶子节点的原因，非叶子节点存有最大限度的小数据（只有索引数据），它的 n 值最大，树的高度越低。反之，如果一个非叶子节点只能存储一个数据，则树退化为线性表。 总结：小数据 + 非叶子节点只存放小索引的设计 = B+树的高度。转换成 B 树则树的高度会变高很多，增加了磁盘 I/O。 一个数据结构可视化地址。 最左匹配原则当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 不不能跳过索引中的列列，否则只能⽤用到索引前⾯面的部分。 但高版本的 MySQL 开始支持跳跃索引（待补充）。 如果查询中有某个列列的范围查询，则其右边所有的列列都⽆无法⽤用到索引优化。 索引列不能参与计算，另当like通配符在最左如:like’%dd’，或者使用负向匹配 not in,!=,&lt;&gt;等运算符都不不会使⽤用索引。 字段加函数则⽆无法使⽤用索引。隐式转换⽆无法使⽤用索引（这其实也是相当于对索引列加函数进行转化）， 同样的问题也存在于 join 查询。 查询优化器对索引的选择多个索引同时存在，也每次只能使用一个索引。有重叠的索引，如 status、status + time 可能导致任一索引不被使用，有时候单一索引反而更简单。因为添加索引的字段一定要有很好的区分度【cardinality】，区分度不够的时候回表的开销不如 all（full table scan）。 数据量小(比如小于2000 时)的时候 type 可能会是 all，即不走索引直接全表扫描，原理是类似 pg 和 oracle 的 cost-based optimizer。 哪些情况要建索引 主键自动建主键索引 频繁作为查询条件的字段应该创建索引 查询中与其他表关联的字段，外键关系建立索引 在高并发下倾向建立组合索引 查询中的排序字段，排序字段若通过索引去访问将大大提高排序速度 查询中统计或者分组的数据 Index Selectivity = count(distinct column = cardinality)/count(*)。在遇到慢查询的时候，应该考虑建立新索引或者更新存量索引的结构，将查询的关键列包含进去。一个常见的问题是，一个单据既有状态，又有时间，时间的区分度是更高的，但常见的最佳实践是在状态上加索引，因为状态上的索引带来的潜在查询结果更小。 server 层通过 executor 调用 engine 的读接口次数会少很多。 哪些情况不适合建索引 频繁更新的字段 where条件用不到的字段不创建索引 表记录太少 经常增删改的表 数据重复太多的字段，为它建索引意义不大（假如一个表有10万，有一个字段只有T和F两种值，每个值的分布概率大约只有50%，那么对这个字段的建索引一般不会提高查询效率，索引的选择性是指索引列的不同值数据与表中索引记录的比，，如果，一个表中有2000条记录，表中索引列的不同值记录有1980个，这个索引的选择性为1980/2000=0.99，如果索引项越接近1，这个索引效率越高）。 与 order by 的关系1、如果你只需要结果集中的某几行，那么建议使用 limit（limit 最好不要配 offset，配 id，要注意 id 滚动的问题）。这样的话可以避免抓取全部结果集，然后再丢弃那些你不要的行。 2、对于 order by 查询，带或者不带 limit 可能返回行的顺序是不一样的。 3、如果 limit row_count 与 order by 一起使用，那么在找到第一个 row_count 就停止排序，直接返回（类似 ES 的提前返回）。limit 的本质是找到足够多的数据的时候才停止，如果只是想限制查询足够多的数据，id &lt; begin + limit 的性能表现会好得多。 4、如果 order by 列有相同的值，那么 MySQL 可以自由地以任何顺序返回这些行。换言之，只要 order by 列的值不重复，就可以保证返回的顺序。 5、可以在order by子句中包含附加列(组合 order by)，以使顺序具有确定性。 6、ORDER BY的索引优化。如果一个SQL语句形如：SELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。相反地，如果 order by 没有命中索引，就会导致 file sort或者错误的索引选择，mysql 5.7 也不例外。但很多时候，没有命中索引，也不一定就会慢，命中索引或多或少都会导致回表，有可能不回表的速度更快 - 这取决于 query optimizer 怎么看待这个查询计划。考虑多方诉求的话，可以打破常规，考虑把 id 加进索引里。所以 order by 的列不是查询优化器选择的索引是最尴尬的。 7、WHERE + ORDER BY的索引优化，形如：SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];建立一个联合索引(columnX,sort)来实现order by 优化。 注意：如果columnX对应多个值，如下面语句就无法利用索引来实现order by的优化SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] IN ([value1],[value2],…) ORDER BY[sort]; 8、WHERE+ 多个字段ORDER BYSELECT * FROM [table] WHERE uid=1 ORDER x,y LIMIT 0,10;建立索引(uid,x,y)实现order by的优化,比建立(x,y,uid)索引效果要好得多。 MySQL Order By 不能使用索引来优化排序的情况 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)SELECT * FROM t1 ORDER BY key1, key2; 在非连续的索引键部分上做 ORDER BY：(key_part1,key_part2建立联合索引;key2建立索引)SELECT * FROM t1 WHERE key2=constant ORDER BY key_part2; 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)SELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC; 用于搜索记录的索引键和做 ORDER BY 的不是同一个：(key1,key2分别建立索引)SELECT * FROM t1 WHERE key2=constant ORDER BY key1; 如果在WHERE和ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现 order by 的优化SELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10; 特别提示:1&gt;mysql一次查询只能使用一个索引。如果要对多个字段使用索引，建立复合索引。2&gt;在ORDER BY操作中，MySQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。 9、如果不指定 ORDER BY，不能指望 mysql 默认返回任何默认顺序。但一旦指定了 order by，MySQL 的 order by 的默认值是 asc。 10、 MySQL 8.0 开始支持索引在磁盘上排序 。 11、Databases can read indexes in both directions. 但，如果走索引的列和 order by 的列正好相反，那么查询会非常非常慢。举例，假设 t 的数据量非常大，select * from t where gmt_create &lt; &#39;2019-08-11 22:00:00&#39; order by id，如果 MySQL 的查询优化器决定使用 id作为索引（MySQL 上每次只有一个索引会生效），那么查询会先从主索引的树的左边往右扫（扫描顺序由 order by 的顺序决定），如果当前时间和 2019-08-11 22:00:00 之间的数据量非常大，会导致非常大的 filtered，查询会异常地慢（这种情况有点类似 index jumping-注意看这个例子的 6.3）。 12、order-by 语句可能会误导查询优化器，选择错误的索引，形成错误的查询计划。这是一个无数的 RD 和 DBA 工作中会遇到的已知 bug。 与 Group By 的关系must appear in the GROUP BY clause or be used in an aggregate function 所有的 group by 里的列必须被select。select 中除了聚合函数，必须放在 group by 里。 group by 的实质是先排序后分组。在 group by 的列没有索引时，考虑使用 order by null（作用是强制对查询结果禁用排序），有时候可以消除 file sort（因为不需要排序了）。 常见的分组逻辑：where 先搜出结果集，group by 对结果进行分组（整张表不一定会分到一组，如果分组键里有唯一索引每一行都是一组，则每一行都是一组，所以有个常见的逻辑谬误，如 max 问题），然后对分组进行 having 过滤。 索引失效_复合索引（避免） 应该尽量全值匹配 复合最佳左前缀法则（第一个索引不能掉，中间不能断开） 不在索引列上做任何操作（计算、函数、类型转换）会导致索引失效而转向全表扫描 储存引擎不能使用索引中范围条件右边的列 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少select *（特别是生成 orm 映射的时候，尽量把所有的列写入select 段中）。 mysql在使用不等于(!=或者&lt;&gt;)的时候无法使用索引会导致全表扫描 is null，is not null也可能会无法使用索引 like 以通配符开头 字符串不加单引号（引发了隐式转化） 少用or（在大多数情况下用 in 代替，in 也不好，有时候会导致全表扫描） null参考《MySQL中IS NULL、IS NOT NULL、!=不能用索引？胡扯！》、《MySQL中NULL对索引的影响》。 对MySQL来说，null是一个特殊的值，Conceptually, NULL means “a missing unknown value” and it is treated somewhat differently from other values。比如：不能使用=,&lt;,&gt;这样的运算符，对null做算术运算的结果都是null，count时不会包括null行等，null比空字符串需要更多的存储空间等。 blob 与 text这两种数据类型不能配置非 null 缺省值（即缺省值可以为 null），所以不适合配 not null 约束。 破除偏见首先，null 列会存在于 MySQL 的索引里。一般传言认为：null 值必然会全表扫描，是不准确的；null 值不会存储在索引里，也是不准确的。 NULL 与 B+ 树的存储一条记录的主键值不允许存储 NULL 值。设置为 NOT NULL 的列也不允许存储 NULL 值。 对于索引列值为NULL的二级索引记录来说，它们被放在B+树的最左边。 We define the SQL null to be the smallest possible value of a field. 在通过二级索引idx_key1对应的B+树快速定位到叶子节点中符合条件的最左边的那条记录后，就可以顺着每条记录都有的 next_record 属性沿着由记录组成的单向链表去获取记录了，直到某条记录的key1列不为 NULL。 是否使用索引的决策依据到底是什么MySQL 的执行计划是由查询优化器产出的。查询优化器在这个场景里最重要的参考因子是成本（cost-based optimizing 的优化策略是数据库领域最常见的优化策略）。 读取二级索引记录的成本。 将二级索引记录执行回表操作，也就是到聚簇索引中找到完整的用户记录的操作所付出的成本。 换言之，回表意味着 IO 被放大了（简单来说，读至少乘以一个系数 2）。如果回表比简单地全表扫描聚簇索引成本还要高，那么查询优化器就会选择不走索引。 比方说对于下边这个查询： 复制代码优化器会分析出此查询只需要查找key1值为NULL的记录，然后访问一下二级索引idx_key1，看一下值为NULL的记录有多少（如果符合条件的二级索引记录数量较少，那么统计结果是精确的，如果太多的话，会采用一定的手段计算一个模糊的值）- 这种在查询真正执行前优化器就率先访问索引来计算需要扫描的索引记录数量的方式称之为 index dive。当然，对于某些查询，比方说WHERE子句中有IN条件，并且IN条件中包含许多参数的话，比方说这样： 复制代码这样的话需要统计的key1值所在的区间就太多了，这样就不能采用index dive的方式去真正的访问二级索引idx_key1，而是需要采用之前在背地里产生的一些统计数据去估算匹配的二级索引记录有多少条（很显然根据统计数据去估算记录条数比index dive的方式精确性差了很多）。反正不论采用index dive还是依据统计数据估算，最终要得到一个需要扫描的二级索引记录条数，如果这个条数占整个记录条数的比例特别大，那么就趋向于使用全表扫描执行查询，否则趋向于使用这个索引执行查询。 理解了这个也就好理解为什么在WHERE子句中出现IS NULL、IS NOT NULL、!=这些条件仍然可以使用索引，本质上都是优化器去计算一下对应的二级索引数量占所有记录数量的比值而已。 MySQL 官方文档的介绍参考《8.2.1.13 IS NULL Optimization》。 对 NOT NULL 的列使用 IS NULL 查询，表达式会被 optimized away，但如果查询的表是由于 outer join 产生的 null 值，则不会发生 optimization。 其他优化建议 批量insert语句最好采用bulk insert的方法，如insert into table(xxx) values (xxx),(xxx),每个批次以执行时间小于100ms为原则。 禁止使用Select ，用所需字段代替。 禁止使用子查询. 避免使用Or（ in 也不那么好），用Union代替. 不要使用大偏移量的分页。 为较长的字符串使用前缀索引。如果alter table table_name add key (long_string(25));，可以起到类似 git 的 commit 前缀的作用。 explain 思维导图MySQL-Explain.xmind"},{"title":"一次大表翻页实验","date":"2020-02-19T10:46:20.000Z","url":"/2020/02/19/%E4%B8%80%E6%AC%A1%E5%A4%A7%E8%A1%A8%E7%BF%BB%E9%A1%B5%E5%AE%9E%E9%AA%8C/","tags":["MySQL"],"content":"explain 的解释 假设慢查询是 100ms。 测试前准备一千万行数据 实验结果测试环境本地硬盘： 不带 id 翻最深的页 18:14:25 select * from tb_ins_pay_order where status = ‘1’ limit 990000, 1000 1000 row(s) returned 3.563 sec / 0.020 sec ‘1’, ‘SIMPLE’, ‘tb_ins_pay_order’, NULL, ‘ref’, ‘idx_status’, ‘idx_status’, ‘3’, ‘const’, ‘2078340’, ‘100.00’, NULL extra 里没有使用 file sort，也没有其他信息，可以认为是 in memory 大翻页的结果。这个 100.00 是 filtered 的结果，证明这是 explain extended 的输出。 使用 id 加速18:29:21 select * from tb_ins_pay_order where status = ‘1’ and id &gt;= 9000000 limit 990000, 1000 1000 row(s) returned 1.572 sec / 0.0039 sec 快了一倍左右 1, SIMPLE, tb_ins_pay_order, , range, PRIMARY,idx_status, PRIMARY, 8, , 2019920, 10.00, Using where 有了 id，进入范围查询，且使用了 primary，且使用了 where。三种查询手段都用上了，性能增大很多。 进一步使用精确 id 来加速18:37:21 select id from tb_ins_pay_order where status = ‘1’ limit 990000, 1000 1000 row(s) returned 0.194 sec / 0.000070 sec ‘1’, ‘SIMPLE’, ‘tb_ins_pay_order’, NULL, ‘ref’, ‘idx_status’, ‘idx_status’, ‘3’, ‘const’, ‘2078340’, ‘100.00’, ‘Using index’ Using index 性能非常高 进一步嵌套（注意这个嵌套不能简化）：select * from tb_ins_pay_order where id in(select id from ( select id from tb_ins_pay_order where status = ‘1’ limit 990000, 1000) a); 18:38:54 select * from tb_ins_pay_order where id in(select id from ( select id from tb_ins_pay_order where status = ‘1’ limit 990000, 1000) a) LIMIT 0, 1000 1000 row(s) returned 0.199 sec / 0.0039 sec 即使加上 id 也会慢查询。 其原理是： ‘1’, ‘PRIMARY’, ‘‘, NULL, ‘ALL’, NULL, NULL, NULL, NULL, NULL, ‘100.00’, NULL ‘1’, ‘PRIMARY’, ‘tb_ins_pay_order’, NULL, ‘eq_ref’, ‘PRIMARY’, ‘PRIMARY’, ‘8’, ‘.id’, ‘1’, ‘100.00’, NULL ‘2’, ‘MATERIALIZED’, ‘‘, NULL, ‘ALL’, NULL, NULL, NULL, NULL, ‘991000’, ‘100.00’, NULL ‘3’, ‘DERIVED’, ‘tb_ins_pay_order’, NULL, ‘ref’, ‘idx_status’, ‘idx_status’, ‘3’, ‘const’, ‘2078340’, ‘100.00’, ‘Using index’ 3 使用 Using index 加速，1 使用 PRIMARY 还是慢查询，因为 in 的数据太多反而导致索引出问题。 一个解决方案是，想办法让 MySQL 自己通过索引给数据排好序，然后只查第一页-更新-然后第二页变成第一页再查询。 覆盖索引是类似 Using index 的效果的。 潜在的 last execution id 方案每次执行的时候记住上一轮的 last execution id。 然后查询条件加入 &gt; id 等语句再进一步执行，用真正的查询条件进行翻页（而不是限制只翻 500 个 id，不然会翻到死），然后真正的查询条件会告诉我们下一页在哪里。"},{"title":"六顶思考帽","date":"2020-02-17T06:32:13.000Z","url":"/2020/02/17/%E5%85%AD%E9%A1%B6%E6%80%9D%E8%80%83%E5%B8%BD/","tags":["思维模型"],"content":"六顶思考帽®是爱德华·德博诺博士开发的一种思维训练工具，它提供了“平行思维”的工具，全面思考问题的模型，避免将时间浪费在互相争执上。 人们参加会议都是抱着解决问题的共同目的而来的，然而发生争吵很多时候吵的并不是事实，而是情绪。人们总是还未真正理解对方的观点就陷入了和对方喋喋不休的争执之中。 所谓“六顶思考帽”是指蓝帽（指挥帽）、白帽（数据帽）、红帽（情感帽）、黄帽（乐观帽）、黑帽（谨慎帽）、绿帽（创新帽）。 六顶思考帽®是爱德华·德博诺博士开发的一种思维训练工具，它是目前全球最有影响力的创新思维训练课程。它提供了“平行思维”的工具，避免将时间浪费在互相争执上。强调的是“能够成为什么”，而非 “本身是什么”，是寻求一条向前发展的路，而不是争论谁对谁错。运用德博诺的六顶思考帽，将会使混乱的思考变得更清晰，使团体中无意义的争论变成集思广益的创造，使每个人变得富有创造性。它运用于会议管理，团队沟通，流程改进，产品研发/设计，制定决策，解决问题和领导力提升等领域。大部分世界500强企业学习使用过六顶思考帽后，都认为六帽帮助他们大大提高了工作效率，并且使会议时间减少了50%。自1984年被发现应用效果后1996年后美国联邦法律大会，美国军方、白宫、联合国的国际创新中心，也认识到德·博诺博士以六顶思考帽为代表创新思维工具的价值，之后开始市场化推广各个领域应用。 帽子定义1.蓝色——指挥帽定义：蓝色思考帽负责控制和调节思维过程。负责控制各种思考帽的使用顺序，规划和管理整个思考过程，并负责做出结论。 说明：一个会议的成败很大程度取决于组织者。作为会议的组织者必须能够充分掌控会议。所以，会议要取得成功首先要有蓝帽——指挥帽。蓝帽必须具有强大的魄力、组织领导能力，能够掌控整个会议。蓝帽必须有顺序地让所有会议参与者戴各种不同的帽子。 2.白色——数据帽定义：白色是中立而客观的。戴上白色思考帽，人们思考的是关注客观的事实和数据。 说明：人们只会为情绪而争吵，并不会为事实而争吵，如果会，那说明并不是事实。会议组织者要组织会议讨论问题，必须先让大家戴上白帽，先说明相关数据，展现事实情况。记住，只说事实数据，不说任何观点，而且数据要越详细越好，不得有任何的隐瞒。很多时候，人们没把信息展示完整就乱下结论，招致大家的猜疑。 3.红帽——情感帽定义：红色是情感的色彩。戴上红色思考帽，人们可以表现自己的情绪，人们还可以表达直觉、感受、预感等方面的看法。 说明：等所有人都把相应的信息展示完毕后，蓝帽才让大家带上红帽，表达各自的观点。我敢保证，当大家戴过白帽之后，那些很喜欢急于片面地表达观点的人就不会这么急迫了，他们会先思考之后再表达观点，这些观点已经不会那么容易招来质疑了。即使还是有人的观点和别人有冲突，蓝帽要做到让大家戴好红帽，表达了观点就停止，并记录下来，不进行评论。 4.黄帽——乐观帽定义：黄色代表价值与肯定。戴上黄色思考帽，人们从正面考虑问题，表达乐观的、满怀希望的、建设性的观点。 说明：蓝帽在掌握了所有人的观点之后，知道了哪些人对某一方案是支持的，哪些人是反对的。接下来就需要让所有人戴上乐观帽，都说一说方案的优点，而且只说优点，尤其是那些持反对意见的人也要说出一些优点，只要这个方案不是一无是处，就绝对有优点。 5.黑帽——谨慎帽定义：戴上黑色思考帽，人们可以运用否定、怀疑、质疑的看法，合乎逻辑的进行批判，尽情发表负面的意见，找出逻辑上的错误。 说明：如果要持反对意见的人说所反对方案的优点有点强人所难，那么这时候让他们戴黑帽，他们肯定是极其乐意的。这时候对于支持方案的人也要说一说方案存在的缺陷，这样才能让大家都能更加客观地去审视方案。但是此时，蓝帽一定要控制好大家的情绪。说优点的时候大家是很难会发生争吵的，但是当人们在说缺点的时候，总会有人是承受不住的，场面容易失控。一切都只点到为止，每个人只要说完自己的看法就行，不进行辩论。除非提反对意见的人的观点是片面的，对信息掌握不清，支持的人想要做解释，那么最好也是让他们一个一个的说，说完即可，不要争吵。 6.绿帽——创新帽定义：绿色代表茵茵芳草，象征勃勃生机。绿色思考帽寓意创造力和想象力。具有创造性思考、头脑风暴、求异思维等功能。 说明：当所有人都掌握了当前讨论的方案的优缺点之后，接下来很重要的工作就是由蓝帽要求所有人都戴绿帽，对当前的方案提出改进意见。记住，必须让大家都提改进意见，而不是去否决方案。除非前面几步之后大家都认为这个方案毫无价值，不然所有人都要从改进方案的出发点去提意见。 场景举例晨会帽子 突发事件帽子.png 战略规划讨论会.png"},{"title":"Maven 的依赖管理","date":"2020-02-04T09:11:44.000Z","url":"/2020/02/04/Maven-%E7%9A%84%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/","tags":["Java","Maven"],"content":"Maven 的配置和依赖是单根继承的Maven 的模块继承是无法进行多继承的，只能使用单根继承。 Maven 中 dependencies 与 dependencyManagement 的区别dependencies 即使在子项目中不写该依赖项，那么子项目仍然会从父项目中继承该依赖项（全部继承） dependencyManagement 里只是声明依赖和它们的版本，并不实现引入，因此子项目需要显示的声明需要用的依赖。如果不在子项目中声明依赖，是不会从父项目中继承下来的；只有在子项目中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且 version 和 scope 都读取自父 pom; 另外如果子项目中指定了版本号，那么会使用子项目中指定的jar版本。 有效 pom 下载依赖中的源码和文档 在 .m2 中这样配置： 在项目中这样主动配置： 附赠一个脚本： 在 idea中这样配置 Preference &gt; Build, Execution, Deployment &gt; Build Tools &gt; Maven &gt; importing。 bom 和 pomBOMBOM定义BOM（Bill of Material），物料清单。将某一个领域相应的jar统一称之为XXX-BOM予以管理（例如inf-bom、spring-framework-bom），并不是Maven的规定，只是一种约定俗成（convention over configuration）。Gradle 也采用了这样的思路。 为什么要使用bom（1）避免开发同学需要关心各个API的版本关系：BOM这种方式在 dependencyManagement 指定了各个依赖的版本，并不会使得这些依赖并被真正引入（仅做版本管理使用）。在dependency中还要按需引入、但省去了需要制定version的麻烦。 （2）便于历史版本API的收归。 （3）可以说逐渐使用 bom 来统一管理某个团队（领域）的 API 版本已成为一种趋势。 scope 的含义scope元素的作用：控制 dependency 元素的使用范围。通俗的讲，就是控制 Jar 包在哪些范围被加载和使用。scope具体含义如下： compile（默认）含义：compile 是默认值，如果没有指定 scope 值，该元素的默认值为 compile。被依赖项目需要参与到当前项目的编译，测试，打包，运行等阶段。打包的时候通常会包含被依赖项目。 provided含义：被依赖项目理论上可以参与编译、测试、运行等阶段，相当于compile，但是再打包阶段做了exclude的动作。适用场景：例如， 如果我们在开发一个web 应用，在编译时我们需要依赖 servlet-api.jar，但是在运行时我们不需要该 jar 包，因为这个 jar 包已由应用服务器提供，此时我们需要使用 provided 进行范围修饰。 runtime含义：表示被依赖项目无需参与项目的编译，但是会参与到项目的测试和运行。与compile相比，被依赖项目无需参与项目的编译。适用场景：例如，在编译的时候我们不需要 JDBC API 的 jar 包，而在运行的时候我们才需要 JDBC 驱动包。 test含义： 表示被依赖项目仅仅参与测试相关的工作，包括测试代码的编译，执行。适用场景：例如，Junit 测试。 system含义：system 元素与 provided 元素类似，但是被依赖项不会从 maven 仓库中查找，而是从本地系统中获取，systemPath 元素用于制定本地系统中 jar 文件的路径。例如： import它只使用在中，表示从其它的pom中导入dependency的配置，例如 (B项目导入A项目中的包配置)： 想必大家在做SpringBoot应用的时候，都会有如下代码： 继承一个父模块，然后再引入相应的依赖。假如说，我不想继承，或者我想继承多个，怎么做？ 我们知道Maven的继承和Java的继承一样，是无法实现多重继承的，如果10个、20个甚至更多模块继承自同一个模块，那么按照我们之前的做法，这个父模块的dependencyManagement会包含大量的依赖。如果你想把这些依赖分类以更清晰的管理，那就不可能了，import scope依赖能解决这个问题。你可以把 dependencyManagement 放到单独的专门用来管理依赖的pom中，然后在需要使用依赖的模块中通过import scope依赖，就可以引入 dependencyManagement。例如可以写这样一个用于依赖管理的pom： 然后我就可以通过非继承的方式来引入这段依赖管理配置 注意：import scope只能用在 dependencyManagement 里面。这么多的 scope 里面，import 也因此是最危险的，因为 import 会把依赖直接展开，而不是用间接传递的方式在新应用中体现，会覆盖 parent 和 dependency（因为寻根路径最短，链接器会最先被链接上），而且无法被 exclude 排除。 这样，父模块的pom就会非常干净，由专门的packaging为pom来管理依赖，也契合的面向对象设计中的单一职责原则。此外，我们还能够创建多个这样的依赖管理pom，以更细化的方式管理依赖。这种做法与面向对象设计中使用组合而非继承也有点相似的味道。 那么，如何用这个方法来解决SpringBoot的那个继承问题呢？ 配置如下： 这样配置的话，自己的项目里面就不需要继承SpringBoot的module了，而可以继承自己项目的module了。 scope的依赖传递A–&gt;B–&gt;C。当前项目为A，A依赖于B，B依赖于C。知道B在A项目中的scope，那么怎么知道C在A中的scope呢？答案是：当C是test或者provided时，C直接被丢弃，A不依赖C；否则A依赖C，C的scope继承于B的scope。 依赖矩阵表格见：《Introduction to the Dependency Mechanism》 scope 与 optional 的区别maven的 scope 决定依赖的包是否加入本工程的classpath下。- 某些 scope 连本项目的 classpath 都会被影响。使用本项目的项目无论如何都不能绕过 scope 的影响，scope 才是最彻底的对传播的隔离（比如 provided）。 optional仅限制依赖包的传递性，不影响依赖包的classpath。- 不影响本项目生成的 jar，影响使用本项目的项目。 scope 与 optional 都可以用重新声明依赖的方式来引入缺失依赖。 比如一个工程中 A-&gt;B, B-&gt;C(scope:compile, optional:true)，B的编译/运行/测试classpath都有C，A中的编译/运行/测试classpath都不存在C(尽管C的scope声明为compile)，A调用B哪些依赖C的方法就会出错。 A-&gt;B, B-&gt;C(scope:provided), B的编译/测试classpath有C，A中的编译/运行/测试classpath都不存在C，但是A使用B(需要依赖C)的接口时就会出现找不到C的错误，此时，要么是手动加入C的依赖，即A-&gt;C，否则需要容器提供C的依赖包到运行时classpath。 对于纯粹作为 lib 来用的 jar，rovided over optional。因为出了 test 这个 phase，连 jar 都不能独立 run 起来。optional 本身是一个可以自己在各种 phase run，但被依赖的时候则会去除打包配置，依然会影响 classpath。 debug 小技巧 在子工程里显式地指定某个依赖版本看是否能够消除错误。 使用 ide 的依赖分析工具，如 mvn dependency 插件（这个分析工具只是运行时分析，有误导性）或者 idea 的 dependency analyzer。 显式地消除依赖： 《Optional Dependencies and Dependency Exclusions》： Optional dependencies are used when it’s not possible (for whateverreason) to split a project into sub-modules. The idea is that some ofthe dependencies are only used for certain features in the project andwill not be needed if that feature isn’t used. Ideally, such a featurewould be split into a sub-module that depends on the corefunctionality project. This new subproject would have onlynon-optional dependencies, since you’d need them all if you decided touse the subproject’s functionality. However, since the project cannot be split up (again, for whateverreason), these dependencies are declared optional. If a user wants touse functionality related to an optional dependency, they have toredeclare that optional dependency in their own project. This is notthe clearest way to handle this situation, but both optionaldependencies and dependency exclusions are stop-gap solutions. optional 是大项目无法被切割成小的子模块的无奈选择，如果项目要使用被依赖模块的可选功能，必须显式地再声明一遍可选依赖，否则会产生调用出错。optional 阻断了传递依赖。 Project-A -&gt; Project-B Project-X -&gt; Project-A A 的类路径里有 B，而 X 的类路径里无 B。 怎样使用 maven 的 version 插件？ 参考：《Use the Latest Version of a Dependency in Maven》 Maven2 also provided two special metaversion values to achieve theresult: LATEST and RELEASE. 但这两个值已经过期了。 参考： 《Maven依赖中scope的含义》 《maven scope-provided 与 optional 区别》 "},{"title":"MyISAM 和 InnoDB 的区别","date":"2020-02-03T05:34:35.000Z","url":"/2020/02/03/MyISAM-%E5%92%8C-InnoDB-%E7%9A%84%E5%8C%BA%E5%88%AB/","tags":["MySQL"],"content":"参考： 区别： InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； 如何选择 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM； 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使用InnoDB。 系统奔溃后，MyISAM恢复起来更困难，能否接受，不能接受就选 InnoDB； MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的。如果你不知道用什么存储引擎，那就用InnoDB，至少不会差。 "},{"title":"Spring 扩展点","date":"2020-02-02T06:31:42.000Z","url":"/2020/02/02/Spring-%E6%89%A9%E5%B1%95%E7%82%B9/","tags":["Java","Spring"],"content":"[Spring 的扩展点.xmind](Spring 的扩展点.xmind)![Spring 的扩展点.png](Spring 的扩展点.png) 关闭顺序：ContextClosedEvent -&gt; @PreDestroy -&gt; DisposableBean -&gt; destroy-method 参考： 《Spring的扩展点》。 《Spring Bean的生命周期（非常详细）》 "},{"title":"代码大全","date":"2019-12-31T10:08:05.000Z","url":"/2019/12/31/%E4%BB%A3%E7%A0%81%E5%A4%A7%E5%85%A8/","tags":["软件工程"],"content":"第 1 章 欢迎进入软件构建的世界第 2 章 用隐喻来更充分地理解软件开发第 3 章 三思而后行：前期准备第 4 章 关键的“构建决策”第 5 章 软件构建中的设计第 6 章 可以工作的类第 7 章 高质量的子程序第 8 章 防御式编程第 9 章 伪代码编程过程第 10 章 使用变量的一般事项第 11 章 变量名的力量第 12 章 基本数据类型第 13 章 不常见的数据类型第 14 章 组织直线型代码第 15 章 使用条件语句第 16 章 控制循环第 17 章 不常见的控制结构第 18 章 表驱动法第 19 章 一般控制问题第 20 章 软件质量概述第 21 章 协同构建第 22 章 开发者测试第 23 章 调试第 24 章 重构第 25 章 代码调整策略第 26 章 代码调整技术第 27 章 程序规模对构建的影响第 28 章 管理构建第 29 章 集成第 30 章 编程工具第 31 章 布局与风格第 32 章 自说明代码第 33 章 个人性格第 34 章 软件工艺的话题第 35 章 何处有更多的信息"},{"title":"JUnit4/JUnit5 注解","date":"2019-12-30T09:53:30.000Z","url":"/2019/12/30/JUnit4-JUnit5-%E6%B3%A8%E8%A7%A3/","tags":["Java","JUnit","测试"],"content":" junit4 junit5 特点 @BeforeClass @BeforeAll 在当前类的所有测试方法之前执行。注解在【静态方法】上。 @AfterClass @AfterAll 在当前类中的所有测试方法之后执行。注解在【静态方法】上。 @Before @BeforeEach 在每个测试方法之前执行。注解在【非静态方法】上。 @After @AfterEach 在每个测试方法之后执行。注解在【非静态方法】上。 "},{"title":"彩色 UML 建模","date":"2019-12-29T15:03:48.000Z","url":"/2019/12/29/%E5%BD%A9%E8%89%B2-UML-%E5%BB%BA%E6%A8%A1/","tags":["系统架构"],"content":"常见的例子 MomentInterval：订单、消费、事务、退款申请 Role：购买对象、供应商、购买人、服务提供商、消费者（这些东西更偏向于元数据）、审核方、发起方。role 按照原书而言是 person 可以 associate 的一些角色，person 可以根据 role 进行一些 action。RBAC 体系即这一思想的实践。 PartyPlaceThing：Role 的具体实现：投保人、被保人、用户、商家、产品、客服。注意，这一类型几乎穷尽了所有的领域实体，也包括各种 person。 Description：订单的附属对象：消费码、数量、联系⼈、游玩人；用户的附属对象：用户 ID；商家的附属对象：商家 ID、商家名称；产品的附属对象：产品名称、产品价格、产品 ID；退款申请的附属对象：场景金额原因 架构型、彩色和领域无关的组件 架构型构造型即 stereotype，架构型即 archetype。 四种彩色的架构型 粉色的时刻时段（MI）架构型，粉色的时刻时段明细（MIDetail）架构型。由业务和法律需求我们需要追踪的一段模型，有先后之分。它自己可以列出本架构型的所有值和相应的数量。MIDetail 聚合成为 MI。 黄色的角色架构型。表示参与某件事的方式。它可以 assess 自己的值和数量，也可以 assess MI。 绿色的参与方地点和事物架构型。参与某件事的参与方、地点和事物。它可以 assess 自己的值和数量，也可以 assess Role。 蓝色的描述架构型。被全局复用的，有限的几个值。它可以 assess 自己的值和数量，也可以 assess PartyPlaceThing。 事实上 Party、Place、Thing可以有三种独立的 archetype，并且分别有自己的独立的 role。 确定一个类的颜色和架构型先看是不是 MI，再看是不是 Role，再看是不是 Description，都不是就是 PartyPlaceThing。 领域无关的组件待补充图 领域无关的组件之间的交互待补充图 组件连接并不是所有的组件都应该用插入的形式，性价比最高的方法应该是让组件之间相互连接起来。 组件内的 plugin-in point 实际上应该是若干的接口。 12 个（组）复合组件待补充细节 本书一共介绍 61 种领域无关的组件。 制造和采购制造与采购.xmind 物料资源管理“物料资源”是一项业务用来完成工作的东西，包括制造产品的原材料和完成业务的日常供应。 范围起点：物料资源要求终止：该要求的完成，包括了“物料的交付”和处理“来自供应商的发票” 步骤 定义“物料类型”和“物料”。 要求物料。可能说明，倾向于选择的供应商。 向供应商发出“询价”（request for quotation，RFQ）。 输入您从那些“供应商”那里得到的“RFQ 回应信息”。 选择中标的“供应商”并发出订单。 接收供应商的“物料交付”。 输入“来自供应商的发票”，让会计组件完成“过账”。 要求并追踪“供应商的服务”。 链接 追踪我们在存储单元（库存管理）中保存的物料资源。 费用过账（会计管理）。 接收请求（来自制造管理、设施管理、项目活动管理）。 镜像 在“物料资源管理”中，我们根据“发票（供应商给我们的）”将“物料资源”投入业务。 在“产品销售管理”中，我们根据“发票（我们给客户的）”将“产品”从业务中提出。 单一组件 物料资源 MaterialResource 物料要求 MaterialRequest 来自供应商的 RFQ RFQFromSupplier 发往供应商的 PO POToSupplier 供应商的交付 DeliveryFromSupplier 供应商的发票 InvoiceFromSupplier 供应商的服务 ServiceFromSupplier 时刻时段 物料请求（MaterialRequest） RFQ RFQ 的回应（RFQAnswer） 给供应商的 PO 供应商的交付 供应商的发票 服务请求 供应商的服务 交互组件之间共同协作以完成工作。 请求的传播顺序： sender -&gt; RFQ -&gt; RFQ answer -&gt; PO -&gt; delivery 报价、下单、交付 扩展扩展点： 供应商的选择 可以管理货物储备建立供应链 物料资源组件物料资源是业务上使用的某种东西（例如一个具体的部件或一个批次），它可以单独标识（它有一个序列号或诸如此类的东西），它是您认为必须单独记录的东西。单独标识是绿色的 thing。 不可以单独标识或不需要单独标识只需要追踪数量的东西，只需要一个分类目录条目似的蓝色描述就可以了。 物料要求组件物料要求组件只有一个时刻时段“物料要求”。 物料要求可能来自一个用户、来自“物料资源描述”中规定的重新采购阈值，或来自一个“总体项目活动要求”，“物料请求”对“总体项目活动要求”起到了支持的作用。 交互：sender -》物料请求 -》物料请求 detail -》物料请求detail 描述（描述数量）。 RFQRFQ 有两个时刻时段- RFQ 和 RFQ Answer。 对于一个 RFQ，它的前驱 MI 是物料请求，对于 RFQAnswer，它的后继 MI 是 PO。 POToSupplier 给供应商的订单POToSupplier 就是本企业组件的核心 MI。 确定了物料资源的数量。 POToSupplier 链接到购买者（Buyer）、供应商（supplier）和连接点（SupplierPointOfContract） POToSupplier明确了物料资源的数量。 DeliveryFromSupplier 供应商的交付DeliveryFromSupplier 就是本企业组件的核心 MI。 DeliveryFromSupplier 确定了收到的数量、接受的数量和拒绝的数量。 它链接PO 明细，也链接到存储单元明细。 InvoiceFromSupplier 供应商的发票InvoiceFromSupplier 就是本企业组件的核心 MI。 它记载了具体的采购信息。 ServiceFromSupplier 供应商的服务本企业组件的核心 MI 包括“ServiceRequest”和“ServiceFromSupplier”。 设施管理 定义：设施是建筑单元（建筑和内部的房间）、设备和车辆，业务利用它们来完成业务目标。设施是业务的固定资产。 例子： 一个通信公司的网络 一个电力公司的电网 汽车出租公司的汽车 银行的分行大楼 一个零售公司的仓库 一个钢铁公司的高炉 一条组装生产线的储备控制点。 范围：设施管理，开始于设施获取，终止于维护。 步骤： 定义设施类型和设施。 取得预算。 计划设施开发。 计划设施开发任务。 为将来或现在的活动任务建立建造合同。 和使用者一起包养和使用设施。 根据使用者的输入和检查所得到的的信息，建立问题报告，生成工作顺序，进行维护。 链接： 用在一个制造过程步骤中（制造管理）。 将物料和产品移入或移出设施的存放位置（库存管理）。 计划和控制维护活动（项目活动管理）。 符合预算（会计管理）。 组件： 设施描述 设施 设施开发 设施开发任务 设施使用 设施维护 时刻时段： 设施开发要求 设施开发 设施开发任务 建设合同 建设合同付费 设施检查 设施使用要求 设施使用（及明细） 设施问题 设施维护要求 设施维护 制造管理 定义：制造是生产产品或文章。制造管理包括建立生产要求、制定过程模板、制定过程计划，以及执行这些过程计划。 范围：制造管理从要求开始，到实际制造过程结束，包括了构建和测试步骤。 步骤： 建立生产请求（输入的物料、输出的物料和输出的产品）。 定义模板和计划（计划包含相对时间，而不是绝对时间）。 利用模板和开始的日期和时间，从模板生成一个计划的过程。 执行该过程，全程记录实际做的工作。这样可以比较计划的过程和实际的过程。 链接： 根据一次或多次销售，或者根据销售预期（销售管理），建立生产请求。 使用来自库存的物料； 为库存生辰物料和产品（物料管理）。 接受项目活动的要求（项目活动管理）。 对制造费用进行过账（会计管理）。 组件： 生产要求 过程模板 过程 监控和数据获取（SCADA）。 时刻时段： 生产要求 制造过程 制造过程测试结果 数据集 数字分析结果 模式匹配结果 库存管理 定义：库存管理是将库存物品移入、移出存储单元，或在存储单元之间移动。 范围：从定义存储单元开始，到库存移动结束。 步骤： 定义存储单元。 接受移动请求。 将这些请求组合成计划的移动。 移动库存物品。 链接： 追踪在存储单元中的物料资源（物料资源管理）。 追踪在存储单元中的产品（产品销售管理）。 镜像：在这里我们物品移入业务。在产品销售管理中，我们将物品移出业务。 组件： 库存单元 移动请求 移动 时刻时段： 保有的数量 移动请求 移动 扩展： 计划车辆移动 自动化库存移动 添加更复杂的库存价值计算 销售产品销售管理 定义：产品可以作为一件物料资源，带有一些附加原则。可以提取任何物料资源，并将它变成一个产品。 范围：以销售为起点，终止于开发票。 步骤： 定义产品类型和产品。 销售给客户。 发送产品。 给客户开发票。 记录产品的交付，追踪并解决交付问题报告。 达成协议并完成评估。 链接： 从库存中扣除数量（链接到物料资源管理，它与库存管理进行交互）。 针对发票总额进行过账。 镜像： 在产品销售管理中，我们根据发票（我们给客户的）将物品从业务中提出。 在物料资源管理中，我们根据发票（供应商）将物品投入业务。 组件： 产品（Product） 对客户的销售（SaleToCustomer） 发货给客户（ShipmentToCustomer） 交付给客户（DeliveryToCustomer） 给客户开发票（InvoceToCustomer） 产品协议（ProductAggrement） 产品评估（ProductAssessment） 时刻时段： 产品价格（ProductPrice） 对客户的销售（SaleToCustomer） 发货给客户（ShipmentToCustomer） 交付给客户（DeliveryToCustomer） 交付问题报告（DeliveryProblemReport） 给客户开发票（InvoiceToCustomer） 折扣协议（DiscountAggreement） 佣金协议（CommissionAgreement） 费用和开销分配（CostAndOverheadAllocation） 市场调研（MarketStudy） 销售预测（SalesForecast） 地理区域指派（GeographicRegionAssignment） 扩展： 添加支持售前活动的组件。 现金销售管理 范围：以“收银机指派”为起吊，终止于“现金销售”（包括销售项、返回项或两者）。 步骤： 创建“收银机指派”。 开始现金销售会话。 创建现金销售。 链接： 记录销售的产品。 针对销售和支付进行过账。 镜像： 在这里，支付是立即进行的。 在产品销售管理中，支付是一段时间之后进行的。 组件： 现金销售会话（CashSaleSession）。 现金销售（CashSale）。 时刻时段： 收银机指派（CashDrawerAssignment） 现金销售会话（CashSaleSession） 现金销售（CashSale） 扩展： 通过允许大量在线现金销售。 客户账户管理 定义：许多业务利用账户来追踪客户在给定的业务交易背景下的借款项和贷款项。租赁公司常常使用账户来最终出租和退回。 范围：以申请为起点，终止于账户交易。 步骤： 接受客户账户申请。 评估申请。 批准或拒绝。 如果批准，生成一个新的客户账户。 创建客户交易，记录借款项、贷款项，或两者。 链接：过账账户交易（会计管理）。 镜像：在客户管理中，我们建立并维护账户，这样可以从客户的角度来追踪和呈现正在发生的业务。在会计管理中，我们建立并维护账户是为了从财务的角度来追踪总体的业务，它的组织方式是管理层规定的，或者是历法机构规定的（在某些国家），或者两种因素都存在。 组件： 产品账户申请（CustomerAccountApplication） 客户账户（CustomerAccount） 客户账户交易（CustomerAccountTransaction） 时刻时段： 产品账户申请（CustomerAccountApplication） 客户账户交易（CustomerAccountTransaction） 关系人力资源管理 定义：人力资源是在企业中的人员。人力资源管理是检查这些人员完成他们的工作并对他们取得的成功进行奖励。 范围：以职位要求为起点，终止于工资单支付和费用报销。 步骤： 创建职位要求。 找到雇员和其他候选者。 雇用新人。 建立薪酬协议。 培养技能。 创建职位任命。 创建任务指派。 追踪雇员的活动。 评估绩效。 计算工资单和报销费用。 链接： 针对项目活动完成人力资源要求。 针对项目活动完成人力资源活动（项目活动管理）。 对工资单支付和费用报销进行过账（会计管理）。 镜像： 在物料资源管理中，我们将物品移入业务。 在人力资源管理中，我们管理完成业务的人员。 组件： 雇佣（Employeement） 职位要求（Position Request） 职位任命（Position Assignment） 工作与支付（WorkAndPayment） 技能习得（SkillAcquisition） 时刻时段： 雇佣，薪酬协议（Employeement，CompensationAgreement） 职位要求（PositionRequest） 职位任命，任务指派，绩效评估（PositionAssignment，TaskAssignment，PerformanceAssignment） 雇员工作，工资单支付和费用报销（EmployeeWork，PayrollPayment，ExpensePayment） 技能习得计划，参与，技能拼缝（SkillAcquisitionProgram，Participation，SkillRating） 扩展： 添加对雇员的薪酬和权益。 关系管理 定义：关系管理涉及人员、组织机构，以及人员或组织机构可能扮演的诸多角色。 范围：涉及参与方、参与方角色、组织机构角色。 链接：关系管理是参与方和角色的集中地。因此，它链接到所有组件。 组件： 参与方（Party） 参与方角色（PartyRole） 人员角色（PersonRole） 组织机构角色（OrganizationRole） 时刻时段： 参与方关系（PartyRelationship） 地址使用（AddressUse） 扩展： 按用法将角色分组打包 协调和支持项目活动管理 定义：项目管理涉及所有需要计划和执行的企业活动。 范围：以项目为起点，终止于活动。 步骤： 建立项目 创建项目活动要求 执行活动 利用资源和活动缓冲池来找到有效的组合 链接： 请求物料资源（物料资源管理）。 请求制造过程（制造管理）。 要求设施开发（设施管理）。 请求设施使用（设施管理）。 请求库存移动（库存管理）。 要求职位（人力资源管理）。 组件： 项目活动要求（ProjectActivityRequest） 项目活动（ProjectActivity） 活动和资源缓冲池（ProjectAndResourcePool） 时刻时段： 项目（Project） 项目活动要求（ProjectActivityRequest） 项目活动（ProjectActivity） 扩展： 添加写作和计划模拟 工作细分结构和其他计划工具 会计管理 定义：追踪预算，聚集来自其他组件的会计过账，生成财务报表。 范围：以账户为起点，终止于这些账户的会计过账。 步骤： 定义会计科目表（一个账户列表，用于追踪财务数据） 建立账户 创建预算要求 建立预算 接受支付 创建账户过账（正式记录财务数据） 链接： 为项目活动要求建立预算要求并进行预算（来自项目活动管理）。 为设施开发建立预算要求并并进行预算（来自设施管理）。 接受会计过账（来自物料资源管理、设施管理、制造管理、库存管理、产品销售管理、会计管理和项目活动管理）。 组件： 账户（Account） 预算（Budget） 支付（Payment） 过账（Posting） 时刻时段： 预算要求（BudgetRequest） 预算（Budget） 支付（Payment） 过账（Posting） 扩展： 添加详细的账户交易和深度的账户分析 文档管理 定义：将研究结果、业务结果和合法交易用文档记录下来。 范围：以文档模板为起点，终止于文档发布。 步骤： 定义文档模板 根据模板生成文档 编写文档内容 记录对文档的访问 构建文档 批准或拒绝文档 发布文档 组件： 文档（Document） 文档活动（Document Activity） 扩展： 添加文档存储 添加文档追踪 "},{"title":"git 难点知识汇总","date":"2019-12-25T07:52:48.000Z","url":"/2019/12/25/git-%E9%9A%BE%E7%82%B9%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/","tags":["git"],"content":"初始化命令 …or create a new repository on the command line …or push an existing repository from the command line …or import code from another repositoryYou can initialize this repository with code from a Subversion, Mercurial, or TFS project. areas staging area 也叫 index。 HEAD 指向的 commit，是当前分支的顶端。哪怕这个 commit 后面还有很多其他 commit，看起来 branch 在最后一个 commit 上，实际上 branch 的顶端，还是在 head 上的。 修改提交用git log可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。这个命令的本质，是找到没有 branch 的 head 指向的悬垂节点。 大部分情况下，我们可以使用git reset --hard commit_id 的方式来调整当前整个 git 仓库内的内容，这个操作会把代码仓库里的多余内容抹掉。**git reset --hard大部分时间没什么用，因为 head 本来已经是 head 了，但它会把 working directory 里的内容给丢掉。** 如果我们想把代码回滚到特定的版本，但保留 commit 之间的修改，则可以使用git -c core.quotepath=false -c log.showSignature=false reset --soft 6ef50b9f2186fbb0f89b100dfe7399c2b918446d 命令，这样特定版本之间的修改，会停留在 staged 区域，等待再次被修改为一个 commit 并提交。同样是保留文件修改，soft 会帮你写好 commit。 ：git -c core.quotepath=false -c log.showSignature=false reset --mixed 6ef50b9f2186fbb0f89b100dfe7399c2b918446d，则 commit 之间的代码会被放到 working directory（而不是 staging area），等待 add 和 commit。同样是保留文件修改，mixed 不会帮你写好 commit。而且，它是 reset 的默认选项。 git -c core.quotepath=false -c log.showSignature=false reset --keep 6ef50b9f2186fbb0f89b100dfe7399c2b918446d 看不出这个命令和hard有什么区别。 签出操作git checkout最简单的用法，显示工作区，暂存区和HEAD的差异。 注意 checkout 本身不是 reset，纯粹的 checkout 会导致 head 指针比 branch 的最后头指针更加 behind。head 会因此进入 detached HEAD STATE。因为 checkout 本来是拿来移动 branch 的。 我们在 detached head 上乱修改，也可以产生提交。但这个提交是不能当做任何一个 branch 的内容的，也就是在一个匿名的 branch 内。但我们可以再做一次 checkout -b，新建出真正的分支。似乎可以这么理解，git checkout 历史版本，是为了在历史版本上创建新分支而不是更正当前版本而存在的。 因为 checkout 总是被用来切换分支，所以它会导致 local modification 被覆盖，所以我们在 checkout 的时候，总是要先 commit 或者 stash 一下我们的修改。 提交回退我们可以用以下的命令，产生某一个 commit 涉及到的文件的反操作，而不是 commit 和 head 之间的反操作。 git -c core.quotepath=false -c log.showSignature=false revert 6ef50b9f2186fbb0f89b100dfe7399c2b918446d --no-commit 这样可以提交反操作，而不丢失正操作的 commit。这样做的好处是，commit 历史是 append only 的，不会被修改。 mergemerge 的用途是把一个分支的内容合入另一个分支。 要把 master 的代码合并入 feature。 git merge 当然会产生一个多余的 commit，而且如果有冲突的话，还必须在这个 commit 里修改，化解冲突。我们在工程上倒是可以规定所有的 merge 都必须是 no conflict 的，这就要求我们合并里的 source 分支，反而要先 merge target 分支，这样所有的 merge 都是 fast-forward 的。 rebaserebase 的用途也是把一个分支的内容合入另一个分支。 作为 merge 的替代选择，它会产生一个非常整洁的提交记录： rebase 的本质，顾名思义，是改变当前分支的 branch out 的位置。即，把当前 feature 整个移动到 master 的 head 之后，即所谓的 rebase onto。 rebase 导致最后的项目历史呈现出完美的线性——你可以从项目终点到起点浏览而不需要任何的 fork。如果你想把 rebase 之后的 master 分支推送到远程仓库，Git 会阻止你这么做，因为两个分支包含冲突。但你可以传入 –force 标记来强行推送。就像下面一样： 它会重写远程的 master 分支来匹配你仓库中 rebase 之后的 master 分支，对于团队中其他成员来说这看上去很诡异。所以，务必小心这个命令，只有当你知道你在做什么的时候再使用。 rebase 因为会修改 branch 的历史，所以 never use it on public branches。因为这会给其他人的开发分支带来分歧。 而如果我们使用交互式的 rebase，就是把git rebase -i master。则会把我们要 branch out 的 commit 做一个整理。 remote commit 特殊技巧怎样把一些 commit 从当前分支（通常是 master）移到另一个分支 怎样把当前分支的提交直接复制到其他分支 基于某一个分支压缩本分支上的修改 怎样彻头彻尾地 ignore 不需要的文件参考gitignore.io。 Edit .gitignore to match the file you want to ignore git rm --cached /path/to/file "},{"title":"IPv6 问题","date":"2019-12-25T06:35:53.000Z","url":"/2019/12/25/IPv6-%E9%97%AE%E9%A2%98/","tags":["计算机网络"],"content":"背景 IPv4 地址枯竭 5G、IOT、SDN/NFV、云计算、边缘计算等新兴技术兴起，需要地址的终端设备变多。 NAT 技术无法支持新兴技术。 各大互联网公（国外的Google、AWS、Apple，国内的阿里、滴滴等公司）司要定期推动本公司业务的 ipv6 技术改造，网信办会定期检查，不达标的公司要问责。 改造要点因为IP地址长度从32位变为128，文本格式从十进制数字变为十六进制（见附录1），为支持两种IP地址，包括但不限于以下改造要点: 客户端（手机APP和浏览器）缓存用户IP 后端服务根据IP做判断的业务逻辑， 比如set化、小流量。 用户IP归属地查询。 用户IP白名单、黑名单。 风控使用到IP段的策略。 存储用户IP到DB或者缓存 IPv4是32位，可以转成int或者long来存储。 IPv6是128位，不能使用long或者bigint来计算存储。 在服务接口之间传递用户IP 内网之间传递，典型的是支付、风控等。 外网之间传递，如第三方微信支付等。 日志处理 后端日志落地为IPv6后，是否有通过日志内容处理的业务逻辑。 依赖nginx日志中的IPv6地址进行分析和处理的业务逻辑。 验证方法service级别验证 一些依赖IP的代码特征，可用于扫描 正则表达式处理IP IP地址转换函数 数据库字段特征 字段名带IP关键字，或者字段值有IP特征 验证一个独立的service兼容IPv6，包括能正确处理传入clientip，以及对使用IPv6地址的场景能正确解析。 域名级别验证验证一个URL请求在客户端IPv6单栈模式下能正常访问。"},{"title":"亚马逊工作方法","date":"2019-12-20T10:47:37.000Z","url":"/2019/12/20/%E4%BA%9A%E9%A9%AC%E9%80%8A%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95/","tags":["亚马逊"],"content":"一、亚马逊14条领导力原则我们的领导力准则不仅仅是非常鼓舞人心的墙帷。这些准则十分有效，就像我们努力工作所取得的成果一样。无论是在讨论新项目的创意、决定应对客户问题的最佳解决方案，还是对求职者进行面试，亚马逊人每天都在使用这些准则。这是令亚马逊独具特色的一个重要因素。 顾客至尚（Customer Obsession）领导者从客户入手，再反向推动工作。他们努力地工作以赢得并维系客户对他们的信任。虽然领导者会关注竞争对手，但是他们更关注客户。 主人翁精神（Ownership）领导者是主人翁。他们会从长远考虑，不会为了短期业绩而牺牲长期价值。他们不仅仅代表自己的团队，而且代表整个公司行事。他们绝不会说“那不是我的工作”。 创新简化（Invent and Simplify）领导者期望并要求自己的团队进行创新和发明，并始终寻求使工作简化的方法。他们了解外界动态，从各处寻找新的创意，并且不局限于“非我发明”的观念。 当我们开展新事物时，我们要接受被长期误解的可能。 决策正确（Are Right, A Lot）领导者在大多数情况下都能做出正确的决定。他们拥有卓越的业务判断能力和敏锐的直觉。 好奇求知（Learn and Be Curious）领导者从不停止学习，并不断寻找机会以提升自己。领导者对各种可能性充满好奇并付于行动加以探索。 选贤育能（Hire and Develop the Best）领导者不断提升招聘和晋升员工的标准。他们表彰杰出的人才，并乐于在组织中通过轮岗磨砺他们。青出于蓝，冰源于水，领导者培养的也是领导者，而且他们严肃地对待自己育才树人的职责。 最高标准（Insist on the Highest Standards）领导者有着近乎严苛的标准——这些标准在很多人看来可能高得不可理喻。领导者不断提高标准，激励自己的团队提供优质产品、服务和流程。领导者会确保任何问题不会蔓延，及时彻底解决问题并确保问题不再出现。 远见卓识（Think big）局限性思考只能带来局限性的结果。领导者大胆提出并阐明大局策略，由此激发良好的成果。他们从不同角度考虑问题，并广泛寻找服务客户的方式。 崇尚行动（Bias for Action）速度对业务影响至关重要。很多决策和行动都可以改变，因此不需要进行过于广泛的推敲。我们提倡在深思熟虑前提下进行冒险。 10.勤俭节约（Frugality）我们尽量不在与客户无关的地方花钱。勤俭节约可以让我们开动脑筋、自给自足并不断创新。在人员数量、预算规模或固定开支方面，没有额外的投入。 11.赢得信任（Earn Trust）领导者会真正敞开胸怀、认真倾听，并愿意谦逊地审视自己最坚定的信念。 12.刨根问底（Dive Deep）领导者深入各个环节，随时掌控细节，并经常进行审核。不遗漏任何工作。 13.敢于谏言 服从大局（Have Backbone;Disagree and Commit）领导者必须要能够不卑不亢地质疑他们无法苟同的决策，哪怕这样做让人心烦意乱，精疲力尽。领导者要信念坚定，矢志不移。他们不会为了保持一团和气而屈就妥协。一旦做出决定，他们就会全身心地致力于实现目标。他们愿意支持不受欢迎或难获理解的意见。 14.达成业绩（Deliver Results）领导者会关注其业务的关键决定条件，确保工作质量并及时完成。尽管遭受挫折，领导者依然勇于面对挑战，从不气馁。 二、设立组织内部高标准的关键（2017年）美国消费者满意指数发布了年度调查结果，亚马逊连续8年排名第一，在英国也有类似的排名，亚马逊英国连续5年排名第一；在Linkedin 2018年美国职业人士最想为之工作的公司排名中，亚马逊名列首位；Harris Poll在几周前发布的年度名誉指数中，对25，000名客户就社会责任、工作环境、产品、服务等各个维度进行了调查，亚马逊连续三年排名第一。 贝佐斯非常喜欢顾客的一点是，顾客是永不满足的，他们的需求永远不是静止的，而是不断向上的，这是人性。人如果容易满足，也就不会从狩猎采集的日子进化到现在。人们对“更好的方式”总有着足够大的胃口，昨天的“wow”在今天就成了寻常。我看到改进的循环正在以前所未有的速度发生的。这可能是因为消费者有着前所未有的获取信息的便捷渠道——几秒钟内，消费者只要在Iphone上打几个字，就能阅读评论，在多个零售商之间比价，查看货物有没有库存，多久能发货等。这些例子都来自零售业，我感觉到这种消费者赋能在亚马逊做的每一件事上都发生着，同样也在其他行业中发生着，你不能躺在你获得的桂冠上休息。 你怎样才能做到比消费者越来越高的期待？没有一劳永逸的方法，这是许多事情的集合。但是高标准（广泛实施并在各个细节方面）肯定是其中很大的部分。几年来我们在满足客户的期待方面取得了一些成功，一路上也有价值十亿美元的失败经验。以这些经验作为背景，我想和你分享我们（迄今为止）学到的关于组织内高标准的关键所在。 内在的还是可传授的。 首先，有个根本性的问题：高标准是内在的还是可以被传授的？如果你要请我加入你的篮球队，你可以教我很多事情，但你不能让我变的更高。所以我们首要关键的事情是选择”高标准“的人吗。如果这样，这封股东信就变成主要讲招聘实践了，但我不这么认为。我相信高标准是可教的，事实上，人们是很善于简单的通过环境接触来学习”高标准“的。高标准是可传染的，让一个新人加入一个高标准的团队，他能够很快的适应。反之亦然，如果低标准占据优势，也是能够很快传播的。尽管环境接触能够很好的传授高标准，我相信通过设计一些高标准的原则，可以加快学习的速度，这正是我想在这封信中分享的。 共通的还是特定范围的。 另外一个重要问题是，高标准是共同的还是在某些特定范围里的？也就是说，如果你在某个方面有着高标准，是不是意味着你在其他领域也自动拥有高标准呢？我认为高标准是局限在特定范围里的，你必须在各个利益相关的方面单独学习高标准。当我刚开始创立亚马逊的时候，我在发明创造、关照客户以及招聘方面有着非常高的标准，但在运营流程：怎样让已被解决的问题不要再发生，如何从根本上减少缺陷，如何监控流程，诸如此类的问题还有很多。我必须在上述所有方面学习和发展高标准。（我的同事就是我的老师） 理解这一点是非常重要的，因为它能让你保持谦虚，你可以认为自己是在总体上拥有高标准的人，但是仍然会存在一些会令人衰弱的盲点。有可能存在某些地方你根本不知道自己的标准是低的甚至不存在标准，这些地方有很大的努力空间，坦诚的面对这种可能性是非常关键的。 认知和范围在某个领域获得高标准，你需要做什么呢？首先，你要知道这个领域的优秀是什么样子的；第二，你要对付出何种努力（需要多少工作）来获取这个好的结果有个实际的预估。 事例1 完美的手倒立我的一个好朋友最近决定学习不倚靠墙的手倒立。她决定先从瑜伽馆参加一个手倒立的课程开始。她练习了一阵子，发现达不到她想要的效果，因此她请了一个手倒立的教练。这个教练給了她十分有用的建议：“大多数人认为，这要她刻苦努力，就可以在两周之内学会手倒立，而现实是，这是需要六个月时间每天练习才可以做到的。如果你认为你可以在两周之内学会，最终的结果只能是你半途而废。”对于范围（scope）不切实际的想法——通常是隐蔽的没有被讨论过的——只会杀死高标准。为了获得高标准，你自己或者作为团队的一份子，你必须形成并对完成这件事情有多难有充分的沟通和交流，这个教练就充分理解这一点。 事例2 六页纸的陈述在亚马逊是不做PPT的陈述的，取而代之的是做一个陈述性的六页纸备忘录。我们在一个类似“学习厅”的地方，先安静的阅读这份备忘录。毫不奇怪的，备忘录的质量参差不齐。 在手倒立的例子中，高标准是可以很直接的被识别出来的，列出所有做好手倒立的要求和如何执行是并不困难的，但写作的例子就非常不同了，一份优秀的 memo 和一份平庸的 memo 之间的差别就没那么显而易见了，你不可能清楚的列出一些详细的要求来说明怎样写一份优秀的memo。尽管如此，我发现当人们读到一份好的 memo 时，反应是类似的，当人们看到它时就知道它是一份好的 memo。标准就在那儿，尽管它是不易被描述的。 如下是我们的发现： 很多时候，一份 memo 写的不怎么好，并不是作者没有认识到好的 memo 的标准，而是对范围的不正确的预估，他们错误的认为一份好的 memo 是可以一两天甚至几个小时内被写出来的，而实际上是需要花一个星期甚至更多的时间的。他们试图在两周之内学会手倒立，说明我们的教练方式是不对的，好的 memo 是写了一遍又一遍，和那些被要求改进工作的同事分享，放那么几天，然后重新用一个新鲜的头脑再去编辑一遍，这个就是没办法在一两天内完成的。这里的关键点是，你可以通过几个简单的教学步骤改进结果——好的 memo 就是应该花一个星期甚至更多时间来写的。 技能除了识别标准以及对范围有一个切实的预估，技能在里面扮演什么角色呢？写出世界一流的 memo 你需要成为一个非常有技能的作家吗？这是另外一个必须的要求吗？我的观点是并非如此。一个橄榄球教练并不需要会扔球，一个电影导演并不需要会演戏，但他们都需要能够识别出高标准是什么，然后教授对于范围的符合实际的预估。在六页 memo 的例子里，这是一个团队工作，团队中需要有人拥有写作技能，但这个人并不一定非要是你 （岔开一笔：在亚马逊，作者的名字并不会出现在 memo 上，memo 是整个小组的共同成果） 高标准的好处建立一个高标准的文化是非常值得努力的，它有非常多的好处。自然并最显而易见的，你能够为客户制造更多好的产品和服务——这个理由就足够了。或许还有一些不那么明显的理由：人是会被高标准吸引的，高标准帮助高聘和留住人才。更微妙一些的:高标准文化保护每一个公司中那些“看不见”的但是至关重要的工作。我说的是没有人看见的工作，那些没人监督下完成的工作。在一个高标准的文化下，把工作做好是本身就是奖励，这是“专业”的表现。最后，高标准是令人愉悦的，一旦你尝到了高便准的好处，便再也回不去了。 所以我们觉得高标准有四个要素：可被教授的，有特定范围的，你必须能识别他们，你必须公开的说明符合实际的预估范围。对于亚马逊来说，这是运用于每个层面每个细节的，任何事从写 memo 到全新的业务的启动，我希望这也能给你带来帮助。 近期的里程碑贝佐斯在股东信中分享了2017年亚马逊达成的目标，每一项都是团队几年来辛苦工作的成果，我们并不会把这些结果当成想当然。 Prime在Prime推出的13年后，亚马逊全球的Prime会员人数超过1亿。2017年通过Prime在全球范围内配送了超过50亿件商品，不论是全球范围还是美国本土，去年新加入Prime会员的人数超过了过往的任何一年。美国的Prime会员现在就超过1亿种商品可以享受无限次免费2天送达服务。我们将Prime服务拓展到了墨西哥、新加坡、荷兰、卢森堡，并将商务Prime配送服务引入美国和德国。我们也在持续为Prime配送提速，现在在超过8000个城市有了免费Prime同日达和次日达的服务。并在全球九个国家超过50个城市推出了Prime Now的服务。2017年的 Prime会员日（在被CyberMonday超过之前），一直是我们最大的购物活动，那一天加入Prime的新会员人数超过了亚马逊历史上的任何一天。 AWS看到AWS这个200亿美金营收的业务仍在不断的健康成长是一件令人振奋的事情。AWS也在创新上不断的加速——尤其在机器学习、人工智能、物联网、无服务器构架这些新领域。在2017年，AWS推出了超过1400项重要的服务和功能，包括Amazon Sage maker——它显著的改进了开发者日常构建精密机器学习模型的可得性和使用的便利程度。成千上万的顾客也在使用AWS的各种服务，得益于Amazon Sagemaker的广泛采用，活跃用户数量较上一年增长了25%。11月，我们举行了第六次Re:发明创新大会，有4万人到现场参会，以及6万名流媒体在线参与者。 Marketplace2017年，在亚马逊发展史上首次亚马逊全球售出的超过50%的商品是来自第三方卖家的——包括中小型商家。2017年，超过三十万在美国的中小型商家开始在亚马逊上出售商品，FBA(Fullfilment by Amazon)为全球中小型商家运送了数十亿件商品。在2017年会员日，消费者从全球中小商家订购了超过4000万件商品，中小商家的收入比2016年会员日增长了60%。我们的“全球售”项目（使得中小商家能够跨境销售），在2017年增长了50%，中小商家的跨境销售占到了全部第三方销售的1/4。 Alexa消费者对Alexa的接受仍在持续，可以使用Alexa的设备在Amazon全部平台上都是畅销货。我们看到其他公司和开发者想要运用Alexa来创造自己的体验。外部的开发者已经为Alexa开发了超过3万种技能，消费者可以通过Alexa控制来自1200个独立品牌的超过4000种智能设备。Alexa自身也在变得越来越智能。我们开发了指纹技术，来防止家中的设备被Alexa电视广告频繁唤醒。远场语音识别在过去一年提高了15%，在美国、英国和德国我们通过增强Alexa的机器学习元件和半监控学习技术，从而提高了Alexa的口语理解能力25%。最后，我们通过机器翻译和转移学习技术，显著的降低了Alexa学习新语言的时间，这使得我们可以服务于更多国家的客户（比如印度和日本）。 Amazon设备2017年是我们销售硬件最好的年份。顾客购买了上千万的Echo设备，Echo Dot以及加载Alexa的Fire TV Stick是亚马逊所有平台上最畅销的商品。 Prime VideoPrimeVideo持续成为吸引新Prime会员，保留老Prime会员的驱动力。去年我们通过增加新的获奖的Prime Video来更好的服务Prime会员——比如了不起的麦瑟尔夫人，两座观众选择奖，两座金球奖以及奥斯卡提名影片——the Big Sick。 Amazon MusicAmazon Music 持续快速增长，现在已经有上千万的付费用户。Amazon Music Unlimited我们的点播的无广告音乐已经在2017年扩展到30多个国家，会员人数在6个月内翻了一番。 Amazon GoAmazon Go是一种新型的无需排队结账的新型商店，于一月份在西雅图正式向公众开放。我们很高兴听到顾客将他们在Amazon Go的购物体验描述成“神奇的”，使这种神奇成为可能的是定制的计算机视觉，传感器融合以及深度学习，这些结合在一起创造了Just walk out购物，通过JWO, 顾客能够更便捷的购买想要的商品。 投资和工作岗位创造自从2011年，我们在全球投资了超过1500亿美元在我们的服务网络，运送能力和基础设施建设，包括AWS数据中心。亚马逊直接和间接的覆盖了全球170万个就业岗位。仅2017年一年，我们就直接创造13万个新的就业岗位（其中不包括收购），这使得我们的全球员工总人数超过了56万。我们的新增就业岗位覆盖了很多工种：包括人工智能科学家，到包装专家到服务助理等。 前方的路今年是亚马逊第一封股东信发出后的20周年纪念，我们的核心价值和路径始终没有变。我们始终希望能够成为全球最以客户为中心的公司，我们深知这是一个并不小也并不容易的挑战，也知道我们可以改进之处很多，我们会在前方的很多挑战和机遇中找到前进的动力。 三、做Day1的公司：永远年轻，永远朝气蓬勃（2016年）“杰夫，Day 2（第二天）看起来会怎样？” 这是我刚刚从全体会议上收集到的问题。我一直提醒人们，Day 1已经持续了几十年。我在名为Day 1的亚马逊大楼内工作，当我搬离这座建筑时，这个名字如影随形。我花了些时间思考这个话题。 “Day 2是停滞期。接踵而来的是远离主业，然后是一蹶不振，业绩痛苦地下跌，然后是死亡。这就是为什么我们总是处于Day 1。”可以肯定的是，这种下降将以极端缓慢的速度进行。一家卓有成就的公司可能要经历几十年的Day 2，但最终结果还是会到来。 我对这个问题很感兴趣，如何应对Day 2？什么是技术和战术？如何保持Day 1的活力，尤其是在一个大的组织里？这样的问题不会有一个简单的答案，它涉及许多因素、多条路径和大量陷阱。我不知道完整答案，但可能知道其中几点。Day 1防御的首要因素包括：客户至上，抵制形式主义，积极适应外部趋势，以及高速决策。 以顾客为中心有许多方法将业务集中于一点。你可以以竞争对手为中心、以产品为中心、以技术为中心、以商业模式为中心。但在我看来，到目前为止，以客户至上为中心是保持Day 1活力的最佳做法。 原因何在？以客户为中心的方法具有很多优势，不过，它存在一大问题：即使客户口头声称他们很快乐，业务是一流的，但在心里，他们有种种不满，非常不满意。甚至连客户自己都不知道，他们总在要求更好的，而你要取悦于客户的愿望将驱使你为他们创造更大利益。亚马逊的高级会员计划并非为了迎合客户的要求，但显然是后者所渴望的，类似的例子还可以举出很多。始终处于Day 1的心态需要你耐心尝试，接受失败，种植种子，保护树苗，并在看到客户的喜悦之际获得双倍回报。客户至上的文化最有可能为上述过程创造可能发生的条件。 抵制形式主义随着公司越来越大，越来越复杂，管理代理的倾向应运而生。它的呈现方式各异，危险而微妙，与Day 2的特征极为相似。 常见的例子是形式主义。良好的服务流程有利于你为客户服务，但是，如果你不加警觉，流程本身就会变成问题，这在大型企业中尤为普遍。工作流程没有为结果服务，而只是走过场。你不再关注结果，只是确保流程是正确的。这就让人倒吸一口凉气了！下面的情况并不少见：某位下级领导以“嗯，我们是在遵守流程”为理由来为一个坏的结果加以辩解。更有经验的领导者则会把它视为调查和改进流程的良机。流程本身不是问题，永远值得提出的问题是：是我们在按照流程操作？还是流程左右了我们的操作？在一个每况愈下的Day 2公司，你可能会发现答案是后者。 另一个例子：市场调研和客户调查可以流于形式。这是特别危险的，尤其当你正在发明和设计产品的时候。“55%的测试人员对这一功能感到满意，比第一次调查中的47%满意率有所上升。”这种结论难以解读，可能会在无意中造成误导。 优秀的发明家和设计师深入了解他们的客户。他们耗费巨大精力发展这种直觉，并通过调查结论获取许多个人感受，而不仅仅只是平均数，并对此加以研究。他们与设计共存。 我不反对beta测试或调查。但你，作为产品或服务的主人，必须了解客户，富有远见，并乐于奉献。然后，beta测试和研究可帮助你找到盲点。卓越的客户体验始于心灵、直觉、好奇心、游戏、胆量和品味。这些在调查中都找不到。 积极适应外部趋势如果你不会或不能迅速追随强大趋势，外部世界会把你推入Day 2。如果你采取对抗的姿态，你可能是在和未来对着干。拥抱趋势，你将顺势而上。 大趋势并非那么难以确定（他们为此谈论和撰写了不少内容），但是对于大型组织来说，迎合趋势却异常困难，令人匪夷所思。眼下，我们正处于一个显而易见的趋势之中：机器学习和人工智能。在过去的几十年里，计算机被广泛用于完成自动化任务，后者往往通过清晰的规则和算法描述出来。如今，现代的机器学习技术允许我们在难以精确描述规则的领域完成同样的任务。 在亚马逊公司，多年来我们一直致力于机器学习的实际应用。这项工作是高度可见的：我们自主设计的Prime Air空中交付无人机；亚马逊Go便利店使用机器视觉消除排队结帐现象线；还有Alexa——基于云的人工智能助理。（尽管我们尽了最大的努力，我们还是难以满足客户度Echo的需求。虽然听上去令人开心，但毕竟是一个问题。我们正在努力解决。） 但我们利用机器学习所做的大部分实践还不为人知。机器学习驱动我们的算法进行需求预测、产品搜索排名、产品和交易推荐、商品配售、欺诈检测、翻译，以及更多服务。虽然效果还不太明显，机器学习的影响大多如此——悄悄地、但有意义地提升核心业务。 保持决策的高速度Day2公司能够做出高质量的决策，但他们的高质量决策速度非常缓慢。为了保持Day 1的能量和活力，你必须以某种方式作出高质量、高速度的决策。无论对于初创企业还是大型组织来说，这都非常具有挑战性。 亚马逊的高管团队决心保持决策的高速度。商业中的速度问题至关重要，如果是高速决策，游戏就更有趣了。我们不知道所有答案，在此只提出一些想法。 首先，决不使用“一刀切”的决策过程。许多决定是可逆的、双向的，对于这些决策，不必在公司内部大动干戈。而对于那些决定公司生死存亡的决定，我在去年的信中曾经更详细地写到了这一点。 其次，当你获得了七成所需信息后，大多数决策都可以成型。如果你要求信息量达到90%，在大多数情况下，你的决策可能就有点慢了。另外，无论运用上述哪种方式，你都需要善于快速识别和纠正坏的决定。如果你擅长自我修正，那么，错误的成本可能比你想象的要低廉，而决策缓慢肯定意味着代价不菲。 第三，采用“保留己见、服从大局”的方式。这句话虽然简短，却能节省大量时间。如果你对某个特定方向有信心，即使没有达成一致意见，你也可以说：“看，我知道我们对此意见不一，但你愿意和我赌一把吗？保留己见、服从大局？”到目前为止，没有人能确切知道答案，但你可能很快得到答案。 这不是一种单向的做事方法，如果你是老板，也应该这样做，我一直在保留己见、服从大局。我们最近开拍了一部亚马逊工作室的原创剧。我告诉团队我的观点：不管它是否足够有趣，制作过程是否复杂，业务条款好不好……一切都可以讨论，我们还有很多其他机会。他们的态度完全不同，希望继续下去。我立刻写道，“我保留意见，服从大局，并希望它成为我们制作过的最具可看性的节目。” 请想一想，如果团队不得不说服我而不是简单地得到我的承诺，这个决策周期会有多么缓慢。请注意，我举这个例子并不是要说：我没有心里想过“嗯，这些人错了，没抓中重点，但这不值得我追究。”这是一次真正的意见分歧，我坦率表明我的意见，团队对我的观点加以权衡，并快速而真诚地承诺，他们要走自己的路。考虑到这个团队已经带回11个艾美奖、6个金球奖，以及3项奥斯卡奖，他们愿意让我留在房间里，已经让我好开心了！ 第四，及早识别真正的错误问题，并立即使之升级。有时候，团队内部存在不同的目标和截然不同的观点，无法调和。缺少大量的讨论和交流，难以解决深层次矛盾。如果问题没有逐步扩大，默认的争端解决机制将导致争议双方筋疲力竭，最终，谁更有耐力，谁就获得决策权。 在过去的几年里，我在亚马逊看到许多意见不合的例子。当我们决定邀请第三方卖家直接在我们自己的产品细节页面与我们竞争时，出现了一次大规模意见分歧。许多聪明的、善意的亚马逊人完全不赞同这一决策。这个重大决定涉及到数百个较小的决策，其中一些需要升级到高级团队。 “你把我拖垮了”是一个可怕的决策过程，进展缓慢，令人疲惫不堪。使矛盾快速升级反而效果更好。那么，你是否只解决了决策质量问题，或者你也在意决策的速度？你的决策符合世界的发展趋势吗？你是工作流程的牺牲品，还是让它们为你服务？最重要的是，你让顾客喜笑颜开吗？我们可以同时具备大公司的业务范围和能力，小公司的精神和初心，但我们必须有所选择。 十分感谢每一位客户让我们为您服务，感谢股东对我们的支持，感谢世界各地亚马逊人的辛勤工作，感谢你们的努力、智慧和激情。一如既往，我附上1997年的一份信。我们仍然处于创业Day 1。 四、勇于试错、拥抱创新（2015年）在2015年，亚马逊成为最快达到了年销售额1000亿美金的公司，亚马逊云服务的营收达到了100亿美金。 究竟发生了什么呢？两者都从一枚种子，在没有并购的情况下，靠自身有机成长发展为庞大又有意义的业务。从表面上看，亚马逊零售和AWS没有什么相同点，一个服务于消费者，一个服务于企业，那么这两块乍看之下迥然不同的业务在同一屋檐下实现快速成长是一个巧合吗？不可否认，在每一次努力中，运气扮演着重要的角色，但除此之外，这两项业务有着千丝万缕的联系——两者共享着组织文化，重视并遵循着一些原则。这里贝佐斯指的是顾客至上（而非紧盯着竞争对手），抱有发明创造的热情，接受失败，有做长远考虑的耐心，对卓越的运营有着职业自豪感。从这个角度，亚马逊零售和AWS并没有什么大区别。 说几句关于公司文化：不论好坏，公司文化是持久的，稳定的，难以改变的。它将会成为公司优势或劣势的来源。你可以把自己的公司文化写下来，但你这么做是在发现公司文化，而非创造它。公司文化是在漫长的时间里由人和事，由那些已经成为公司传说一部分的过去成功和失败的故事构成。如果是一种鲜明的公司文化，它就像一副定制的手套一般适合某些特定人群。公司文化之所以稳定是因为它具有一种自我选择，一些喜欢竞争的人和一些喜欢创造成为先锋的人会选择适合各自的企业文化。幸好，这个世界里有那么多不同的，高绩效的文化。贝佐斯在这里并不是宣称亚马逊选择的路径就是对的，只是这是属于亚马逊的文化。在过去的二十多年里，亚马逊召集了很多志同道合的人加入了团队，这些人认同亚马逊的企业文化，认为这是振奋人心并有意义的。 亚马逊公司文化中的一个突出特点是勇于试错，贝佐斯声称亚马逊是全世界最好的去失败的地方（他们实践过许多次）发明创造和失败是双生子，因为发明创造需要许多的试验，而每次试验是不知道结果是成功还是失败的。很多大公司欢迎创造，却不想承受获得创新所需承受的必要的失败，超额的回报，很多时候是反传统智慧的，而传统的智慧往往是对的。如果有只有10%的机会成功，一旦成功回报是一百倍，你每次都应该去下注，但你仍要承受九次失败。棒球和商业的不同之处在于，棒球的得分服从一个被删截过的分布，因为不论你怎么击打，最高得分只有四分。而商业中，你一旦打出一个本垒打，得分有可能是1000分。回报的长尾分布决定了你应该大胆尝试。大赢家总是做过许许多多次尝试。 亚马逊的AWS, marketplace 和prime 业务都是大胆尝试的产物，这三个业务帮助亚马逊成为一个大公司，毫无疑问有些事是只有大公司才能完成的，就像你不可能在一个车库里造出全套的787飞机，但也要时刻警惕公司规模的扩大可能会延缓甚至消减创新。 Prime两天达的Prime商品品类从100万种到3000万种，增加了周日达，在全球35个城市引入了免费当天达，还增加了音乐、照片存储，Kindle会员的图书馆，以及电影和电视。 Prime-now为会员提供部分重要品类商品的一小时之内的配送。这项服务在创意提出的111天后就上线了。今天，也就是首次上线的15个月后，亚马逊已经在全球30多个城市为会员提供这项服务。 Prime videovideo 独家提供部分全世界最棒的故事片。而亚马逊的原创剧集也是获奖无数。这些 video 对顾客来说是非常棒的，它也提供了Prime的飞轮效应——看 Prime video 的 Prime 会员更倾向于从免费试用变为付费会员，也会更倾向于成为续费会员。 Prime 会员在2015年增长了51%，其中47%来自美国，美国本土之外的会员增长更快，现在亚马逊的 Prime 会员有上千万。 Marketplace在亚马逊上线 Marketplace 之前的过去15年里，有过两个较为失败的产品。亚马逊从失败中学习，并坚持自己的愿景，现在近50%的从亚马逊售出的单品是通过第三方的卖家售出的。 通过FBA (Fullfilment by Amazon), 飞轮转动的更快，卖家的库存变成Prime-eligible,Prime变得更加有价值，卖家卖出更多商品。 推出了Seller Fulfilled Prime选择能够提供高标准快速，稳定的寄送服务的第三方卖家直接提供Prime质量的寄送，从而增加会员的价值。 我们同时推出了亚马逊借贷服务，帮助小商家的成长。从这项服务推出之后，以短期贷款形式总共向美国、英国日本小商家提供了超过15亿美元。 亚马逊除了不断增加自己提供商品的品类之外，正在努力促成Marketplace的全球化，让在世界任何一个角落的卖家可以向全世界的买家出售产品，跨境销售现在占亚马逊第三方销售中的1/4。 AWS许多大公司声称自己是以客户为中心的，但他们只是说说而已并没有实际行动，而且往往是竞争对手为导向，其他公司在做什么，它立马跟进。 而亚马逊则是真正客户至上，AWS服务降价51次，而且大部分是在没有竞争压力的情况下做出降价的，并且不断推出低成本的服务比如 Aurora, redshift 等。 发明机器亚马逊希望自己成为一个大公司的同时，仍然可以是一个发明机器。通过规模优势为客户提供更好服务的同时，仍然保持初创企业那般的快速行动、敏锐、勇于接受风险。 尽管实现上述目标并不容易，但贝佐斯仍然抱有乐观心态，认为亚马逊的组织文化是能够推进团队实现这一目标的。在实现这一目标的过程中，有一些陷阱是需要当心的，其中之一就是一刀切的决策模式。一些决定是不可逆，会产生一些列后果的，这些决定需要谨慎的、缓慢的、征询各方意见以后去做出。这类决定就好比你从一端走到另一端，但发现面前的风景你并不喜欢，但此时你已经不能回到原来的位置了，我们称这类决定为类型1。但大多数的决定并非如此，他们是可逆的、双向的、后果并非长期的，你从一端走到另一端之后还可以回去，这种类型2的决定需要由高判断力的个体或小组快速的做出。 随着组织的壮大，就会产生用做类型1这种决定的流程去做绝大多数决定的倾向（包括很多类型2的决定），这将导致决策的缓慢，不合理的风险厌恶，没做足够多的实验，最终导致创新发明的消减。亚马逊在尽很大努力在避免这种错误的发生。 可持续和社会责任方面的创新AWS100%使用可持续能源推出一系列renewableenergy, frustration-free packaging, Career choice, leave share and ramp back这些都是亚马逊文化中拥抱创新，长远思考的范例。 五、客户体验背后的技术驱动（2010年）随机预测、单纯贝叶斯估计、RESTful服务、Gossip协议、事件一致性、数据sharding、反熵、拜占庭法定人数、纠删码、向量时钟算法….如果你走进亚马逊的某一个会议中，你会误以为自己到了某个科技论坛。 如果你仔细读读现在的教科书，你会发现亚马逊几乎没有运用书里写的方式。我们使用高性能的交易系统，复杂透视图、目标缓存、工作流、排队系统、商务智能和数据分析、机器学习、方式识别、中性网络、概率化决策还有其他各种技术。我们的许多系统是基于最新的计算机科学研究，但这还不够，我们的构架师和工程师不得不在学术上还没探讨的方向进行进一步研究，我们面对很多问题在教科书上还没有给出解决方案，所以我们很高兴地创造出新路径。 我们的科技几乎无一例外的应用于服务。服务导向的算法(Service oriented architecture or SOA)对亚马逊的技术来说是最根本的建造抽象化理论。感谢我们有想法又富有远见的工程师和构架师团队，这个途径早在SOA成为这个行业的商务用语之前就已经开始进行实践。我们的电子商务平台是由成百上千旨在实现推荐、订单服务、到库存追踪等一系列功能的软件服务构成的。比如，要构建一个供顾客浏览亚马逊网页的产品详情页，我们的软件集合了200-300种服务来为客户营造个性化体验。 状态管理对任何需要大规模拓展的系统来说都是核心。许多年以前，亚马逊的要求已经是任何商业解决方法都没办法为我们所用的地步了。为了满足这些要求高又非同寻常的要求，我们自行开发了一些其他的解决方案，在开发的过程中，我们从分布式系统、数据库研究社区中学习了核心原则，然后以这些原则为基础进行发明创造。我们开发的存储系统展现了非常好的规模化能力，同时保持了对性能、可得性、和成本的严格控制。亚马逊工程师开发的数据管理的先进性是云存储计算和AWS提供的数据管理服务的起始点。比如，我们的简单储存服务，弹性书店、以及SimpleDB都是从亚马逊技术中衍生出他们的基础算法。 亚马逊业务的其他领域也面临相似的复杂数据处理和决策问题，比如产品信息分析和归类，需求预测，库存分配，欺诈侦测等。以规则为基础的系统可以被成功使用，但他们很难保持，时间久了也会变得脆弱不稳定的。在许多情况下，高级的机器学习技术提供了更为精确地分类，在不断变化的情况下，能够自我治愈和自适应。比如我们的搜索引擎利用数据挖掘和在后台运行的机器学习算法来创建主题模型，我们应用信息提取算法从没有结构的描述提取主体，识别特征，从而让客户能够缩小他们的搜索范围，很快找到他们想要的产品。我们在搜索相关性上考虑了很多因素，来预测一个顾客兴趣的概率并最优化搜索排名。产品的多样化要求我们利用现代回归技术比如决策树的随机预测，到在排名时间有弹性的包括数千种产品信息。这些幕后软件的最终结果——快速、准确的搜索结果帮助你找到你想要买的东西。 如果我们把技术放到一边，仅仅交给什么研发部门来负责，我们在技术上投入的努力可能就不那么至关重要了，但是我们并没有走这条路。技术弥漫在我们的整个团队中，我们所有的流程中，我们的决策中，我们对每项业务的革新路径中。它是深深的融合在我们做的每一件事上。 一个例子是 Whispersync, 我们的 Kindle 服务旨在保证不论你走到哪里，无论你拿着哪个设备，你可以获取你的图书馆，你所有的标记，笔记和书签，都能与你所有的 Kindle 设备和移动 app 实现同步。这项技术挑战为拥有上亿的书籍，几百种不同设备型号，住在100多个不同国家的百万Kindle用户提供了7*24全天候可靠的服务。Whispersync的核心是事件一致性可重复的数据储存。作为一个 Kindle 用户，我们将这些技术都隐藏在产品和服务背后了。每当你打开你的 Kindle, 它都会同步到同一个页面上。套用 Arthur Clarke 的话来说，任何足够先进的技术，它和魔术没什么区别。 如果一些很负责任阅读这封股东信的股东，看我上述这个观点看的目光呆滞的话，让我用下面的话来敲醒你：在我看来，这些技术并不是我们闲着无聊想到要开发的，它们直接带来自由现金流。 我们生活的时代有着极具扩张的带宽、硬盘容量、和处理能力，所有这些将会很快变得越来越便宜，我们团队有这个世界上最熟练的技术师——帮助解决当今时代最前沿的挑战。我已经讨论过很多次，我们不可动摇的信念是股东的长期利益是和我们的客户利益是一致的。 创造发明是在亚马逊的DNA中的，技术是我们用来改进和进化我们为客户提供的每一种体验的关键工具。我们仍然有很多需要学习，我期待和希望我们仍然能够在学习中获得这么多快乐。我为我的团队感到自豪。 六、以客户体验为战略支柱（2008年）在当今剧烈波动的全球经济环境下，我们的根本性战略始终没变。埋头苦干，聚焦长期，一切为了顾客。长线思考激发了我们的能力，完成了原本不会想到的新的工作。长线思考支撑了创新发明所必须的失败和迭代，它让我们能够自由的探索之前从未探索过的空间。寻找即时的满足，或者对其虚无缥缈的承诺会让你发现在你之前已经有一堆人挤在那里了。而长线取向与聚焦顾客两者是互相促进的。如果我们能够识别出一个客户的需求，进而确认这个需求是持久的有意义的，我们的策略可以让我们耐心的干上好几年来找出一个解决方法。“回到客户需求”的工作往往与“技术推进”的路径形成鲜明对比，技术推进把我们现有的技术和能力用来驱动商业机会。技术推进说的是，我们已经很擅长X了，我们能有X再做些什么呢？这是一个有用而且很有收获的策略。然而，如果只用这个路径的话，那么我们永远不会开发一些新技能了。最终这些现有技能会被淘汰。而“回到客户需求”来工作经常要求我们获得一些新的能力，锻炼新肌肉，不管最初走的几步有多么不舒服多么局促。 Kindle就是对于我们根本性战略的一个很好的例子。四年多前，我们开始了长线的思维，每本印刷出来的书，任何语言写的，都可以在60秒以内获得。我们想见的客户体验不会允许Kindle的硬件和Kindle服务之间存在明显的界限，两者必须无缝衔接的。亚马逊从来没有制造任何硬件，但我们并没有改变我们的远见来适应我们现有的技术，我们雇佣了一群天才的硬件工程师，并开始学习一些新技能，一项我们需要的用来在未来更好服务顾客的技能。 我们心存感激并欢欣雀跃，Kindle的销量超过了我们最好的预期。在2月23日，我们开始配送Kindle2。如果你还没见过Kindle2,它保留了上一代Kindle所有客户喜欢的特点，并且更轻薄，更快速，更长的电池寿命，能够保存1500本书。你能从25万种最畅销的书、杂志、和报纸中进行选择。无线下载是免费的，你能够在60秒内得到你想要的书。 用户体验支柱在我们零售行业中，我们坚信顾客非常看重低价、多的选择，快和便捷的配送，而这些需求是长期保持稳定的。我们很难想象十年后顾客会想要更高的价格，更少的选择，更慢的配送。我们对这些需求的持久性的坚信给我们针对这些需求进行投资所需要的信心。我们知道我们现在投入的精力将在未来给我们丰厚的回报。 我们的定价目标是赢得顾客的信任，而不是最优化短期的的获利。我们相信这样的定价策略将在长期来看给我们赚到很多的美元。我们可能在每件商品上赚的少了一点，但我们不断的赢得客户的信任，从而让我们卖出更多商品。因此我们在我们提供的所有品类商品都用了低价。同样的理由，我们对免费配送进行了大量投资，包括Prime.顾客是消息灵通并且聪明的，他们在做购买决策时，评估总价，包括配送费。在过去12个月中，全世界客户已经通过使用我们的免费配送服务节省了8亿美元。 我们毫无保留的聚焦在增加可选商品的品类上，一是通过在现有品类中增加商品，二是增加新的品类。我们从2007年开始增加了28个新品类。一个快速成长并继续给了我惊喜的业务是我们2007年推出的鞋店——Endless.com 快，可靠的配送服务对我们的客户来说是很重要的。在2005年，我们推出了Prime.79美元的会员年费。Prime会员可以得到无限次的两天免费运，而且只花3.99美元就可以升级为一天免费送。2007年我们推出了Fulfilment by Amazon,一项针对第三方卖家的新服务。通过FBA, 卖家将自己的商品储存在亚马逊的全球仓储体系中，我们来分拣、包装并代表卖家将商品运送到最终的客户手中。FBA商品可以享有Prime的权利和超级省配送服务——就像它是Amazon直营的商品一样。最终FBA在提升了客户体验的同时，推动了第三方卖家的销售。在2008年的第四季度，我们代表使用FBA服务的卖家运送了300多万件商品，这是一个对卖家和客户都双赢的举措。 谨慎的支出我们选择的消费者体验的路径要求我们有一个高效的成本结构。对股东有个好消息是，我们在这个方面看到很多改进的机会。 我们最主要的财务目标就是最大化长期的现金流，并且保持高的资本回报。我们在AWS、第三方销售工具、在中国、在新品类上做了巨大的投资。我们在做这些投资的时候相信他们能够长到有意义的规模，能够达到我们对回报的高要求。 在全球范围，努力工作，力求创新的亚马逊人总是把顾客放在第一位。我非常自豪能够成为其中的一员。感谢我们的股东对我们的支持，鼓励并加入我们后续的冒险旅程。 七、长线战略的价值（2003年）长线思考是真正拥有一个公司所有权的要求和结果。公司股东是不同于租客的。我知道一对夫妇他们把房子租了出去，而搬进来的的那户人家把一颗圣诞树钉在硬木地板上，而不是用一棵真正的树。我想可能是因为图省事儿吧，不可否认这是非常无良的租户，但真正的房屋拥有者是不会这么短视的。同样的，许多投资人就如同短期的租客，总是很快的买卖手里的投资组合，他们这么做真的就是在租用他们暂时“拥有”的股票。 我们在1997年第一封致股东信里就已经在强调我们的长线战略了，因为这个战略确实在驱动很多具体实在的决定。我想讨论几个在客户体验情境中的非抽象决定。在Amazon.com,我们广泛的使用“用户体验”这个词。它包括了我们业务中所有涉及到面对客户的方面——从产品价格，到商品种类，从网页用户界面到我们如何包装配送商品。我们创造的客户体验到目前为止是我们生意最重要的驱动因素。 当我们在设计我们的用户体验的时候，我们确实将长线思考记在脑中。我们尝试将我们所有大大小小的客户体验的决定都包括在这个思维框架下。 比如说，在1995年推出Amazon.com不久之后，我们就给了客户留言写评论的权利。现在当然这已经是Amazon.com的一个惯常的功能了，但在当时我们收到了供应商的抱怨，基本上就是质疑我们是不是懂商业——你是靠卖东西赚钱的——你为什么允许对商品的负面评价出现在网页上？就像一个焦点小组的成员所说，我知道我在亚马逊上购物时，有时在看了客户留下的负面或者冷淡的评价后会改变主意。虽然从短期看，负面评价会让我们丢掉一些销售额，但是帮助顾客做出更好的购买决定最终是会给公司带来好处的。 另一个例子，是我们的订单即时更新功能，它会提醒你已经购买过某一个商品。顾客们平时很繁忙，有时候会忘记自己已经买了某样东西，比如说一年前买的DVD或者CD。当我们推出订单即时更新系统后，我们就能够通过数据显著性测算出，这个功能会稍稍的降低销量。但对客户是好的吗？肯定的。对股东是好的吗？是的，从长期来看。 我们所关注的最昂贵的客户体验提升是我们的每天免费运送服务和我们不断进行的商品降价。减少次品，提升生产效率然后把由此带来的成本节省的好处以低价传递给客户，这是我们的一个长期的决定。然而，全力以赴的驱动“价格-成本结构环”将会带给我们一个更强大更有价值的商业。因为我们的成本比如说软件开放是相对固定的，而我们很多的可变成本也可以在规模起来以后进行更有效的控制，通过我们的成本结构从而驱动更大的销售量，能够降低这些成本占总销售的百分比。举个小的例子，开发像订单即时更新这样的功能供四千用户使用需要的成本远低于为一百万个客户开发同样功能所需成本的四十倍。 我们的定价策略并不旨在净利润率最大化，而是追求给顾客创造最大的价值，从而创造一个大得多的净利润——长期的。比如说，我们设定我们珠宝销售的毛利比行业常规要低很多，因为我们相信从上时间看，顾客们会明白的，这个策略会为我们的股东创造更多的价值。 我们有一个努力工作，充满创新精神的团队来打造 Amazon.com。他们关注客户，关注长期发展。在长时间维度，股东和消费者的利益是一致的。 亚马逊技术团队故事 亚马逊早期创业时昼夜编码开发，为了省钱临时用门板拼装成了桌子。橡木门板桌子至今仍然是亚马逊的一大传统。 在2017年，亚马逊很多技术团队通过架构变革，使用AWS上的DynamoDB、ElasticSearch替换掉传统的关系型数据库。还有团队大胆尝鲜AWS上刚推出不久的Lambda和Kinesis，把系统进化成了Serverless的弹性架构，从而做到了拦腰削减硬件成本。一切只为了“亚马逊十四条领导力准则里的勤俭节约”。 在亚马逊被访问最多的一个网址是code.amazon.com。这相当于公司内部的github，不仅能搜索、浏览所有团队开发代码，还能看到每个工程师具体写了多少代码，审查了多少别人的代码，解决了多少线上的问题。这些数据既有纵向的，你可以看到任何一个人，任何时间范围所有提交的代码。 code.amazon.com上还有横向数据，你可以看到任何一个人的编码、审查、修改等活动占全组所有贡献的百分比。有人看到过因为在过去6个月代码量不足，因而无法晋升为Principle Software Engineer的案例。每次公司绩效考评时，技术团队的经理、总监们都会对着code.amazon.com上的数据左比右看。 那么亚马逊的工程师写文档么？写，而且还大量写，但是不写PPT。写作在亚马逊是必备的硬技能，研发团队也不例外。亚马逊内部最常见的就是6页纸文档（6 pagers），工程师的架构设计就属于这类正式文档。刚加入亚马逊的工程师往往不习惯：“要我写上几千行代码是小菜一碟，要我写上一页文档简直要命。”有人干脆就画了个架构图，再附上一点接口定义敷衍了事。结果第一次的设计评审往往成了“批斗大会”。 亚马逊的所有会议前15到20分钟都鸦雀无声，因为所有人都在闷头读文档。20分钟后开始逐页拷问。你要解决什么问题？哦—这种类型的情况我们目前的系统处理起来性能不佳。那么这些情况占我们系统中所有调用的比例是多少？TP99的latency是多少？为什么这个问题很挑战？为什么你要用DynamoDB而不是Sable？你这个设计的优点是什么？可能的瓶颈再哪里？你考虑了其他候选方案了么？上线后访问量增大一倍哪里会出问题？如果依赖的这个服务出故障了怎么处理？我们从故障中恢复后，怎样回填数据？我们先在北美上线，将来扩展到欧洲、日本和中国时有哪些工作可以避免重复？ “在亚马逊，好的文档里看不到形容词，我们不说性能改进的很好，而要说，系统的SLA在TP99下从500ms提高到240ms，减小了52%的延迟。我们不说工程师张三进步很快，而说工程师张三在过去的5个月内按时上线了3个项目，迄今为止没有发生任何2级以上的故障。” 最奇特（葩）的PPT来自一位高级经理。十几页幻灯片都是白底，每页上只有一个数字。他对着这个PPT讲了20分钟。基本都是这样的话：“1.25，这是我们新系统上线后节省的成本，在过去的1个季度，我们一共节省了125万美元”，“2300，这是我们的新SLA，从检测到仓库中发布的进货消息，经系统处理后更新到ElasticSearch的索引，到可在前端被用户搜索出来，我们从过去的4000ms提升到了2300ms，这里还有很大的改进空间”。 在亚马逊，我们要求技术团队的工程师必须是全栈的。亚马逊没有前端工程师、后端工程师、运维工程师这类划分。统一叫做SDE，英文是Software Development Engineer。有人将其戏称为Somebody Do Everything。 做一个项目，一个工程师通常从前做到后，从界面做到底层。不仅上线功能给最终用户（买家或卖家）使用，把数据导出到业务部门的集群上做商业分析，并且还要开发出供内部仓储物流工作人员使用的工具。工程师要和产品经理一起开发需求、制定技术方案、撰写设计文档、申请开发用的AWS账户、构建持续集成环境、编码、进行各类测试（包括功能测试、数据测试、压力测试等）、灰度上线，并且oncall解决线上的各种问题。 所有这些都可以在亚马逊内部的工具链Brazil，Apollo，Pipeline的支持下由一个工程师独立完成。工程师需要用Java写业务代码、用SQL或者Hive跑数据、用Java写前端、用Python写脚本、用Ruby写内部控制台（console），还需要写各种XML和JSON的配置。 很多情况下，仅仅懂技术还不够，工程师必须完全了解业务部门的细节。比如FBA（Fulfillment By Amazon），工程师们对于现代化物流仓库的设备和流程要了如指掌，看到一个包裹上的条码，就能够如数家珍的说出这个包裹是否是亚马逊自营的、是否是合作伙伴负责物流的、是独家专卖还是卖家混卖的。要能够很快找出这个包裹是自动收货的、还是人工收货的、是亚马逊打的泡沫包装还是卖家自己做的。 2016年的时候，我所在的团队有个小伙子上线了一个新的内部工具给仓库使用，这个工具可以快速纪录处理货物过程中出现的各种缺陷。2017年4月他作为工程师和一大群高级经理和总监去美国加州参观我们的仓库。参观进行到一半的时候，仓库的工作人员得知原来他就是开发这个工具的工程师，于是大伙围了上来，完全无视一边的各种领导，纷纷和他拥抱、握手——原来你就是作者啊！谢谢！这个新工具好用极了！我想，这也是在亚马逊做工程师的一个快乐的时刻吧。 Rapid 决策框架 Input. People with input responsibility provide the data that is the basis of any good decision. They also offer their own judgments about the proposals. They have the right to provide input to a recommendation but not to veto it. Recommend. The person in this role leads the process and is responsible for obtaining and evaluating the relevant facts and proposing alternative courses of action. Agree. People who must agree to a recommendation are those who must sign off on it before it can move forward—executives with legal or regulatory compliance responsibilities, for instance. Decide. Eventually, one person will decide. (RAPID users tend to say that this person “has the D.”) Giving the D to one individual ensures single-point accountability. Perform. The perform role goes to the individual or group that will execute the decision and that is responsible for doing so promptly and effectively. 几个常见的陷阱： 缺乏投入 在两个或更多的人之间做决定。 "},{"title":"微服务相关文献","date":"2019-12-17T08:48:31.000Z","url":"/2019/12/17/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE/","tags":["微服务"],"content":"《提升团队的微服务落地能力》"},{"title":"滚动重启、金丝雀发布、AB testing 和蓝绿部署","date":"2019-12-17T08:03:44.000Z","url":"/2019/12/17/%E6%BB%9A%E5%8A%A8%E9%87%8D%E5%90%AF%E3%80%81%E9%87%91%E4%B8%9D%E9%9B%80%E5%8F%91%E5%B8%83%E3%80%81AB-testing-%E5%92%8C%E8%93%9D%E7%BB%BF%E9%83%A8%E7%BD%B2/","tags":["持续交付"],"content":"本文讨论发布周期（release cycles）里 deployment strategy 的问题，抛开大规模部署的 big bang deployment。 滚动重启、金丝雀发布、AB testing在 martin fowler 的博客里，金丝雀发布和滚动重启和 AB testing 并没有本质区别，都是 phased approach或者 incremental approach，是 ParallelChange 思想的实践。 当我们拥有一个新版本时： 滚动重启（rolling restart）rolling restart 会让新旧版本在环境里长时间共存，逐一使节点部署新版本，这样易于发现问题和回滚。 金丝雀发布（canary release）而金丝雀发布同样允许新旧版本长时间共存，在逐一部署新节点的前提下，逐步利用 LB 之类的基础设施来切分用户，其策略还可以细分为： 先不给新版本，在无流量的情况下在生产环境验证 - 很多大厂的实现都忽略了这点。 尽量让内部用户先使用 - FB 之类的大厂的员工都非常多，使用一个特性开关（名字很多，比如 feature bits, flags, flippers, switches， martin fowler prefers FeatureToggle），单独让内部员工使用，来检查其中的问题。 amazon 使用暗部署（dark launch），而蚂蚁金服使用灰度环境（grey environment） 来将生产的真流量释放到新版本上。 然后逐步开放给新用户使用。这个过程中涉及到的策略和方法是：使用 LB 的路由策略，将流量逐一发布到特定新版本节点上；基于用户选择，只有特定用户的流量可以进入到新版本的机器里。大部分大厂都采用基于节点的流量分配法则，实际上还可以根据源 ip、地理位置和用户人群划分来解决这个问题。 AB testing金丝雀发布因为可以使不同的人群体验不同版本，所以可以被看作 AB testing 的等同 implementation。 但是，金丝雀发布的用意是“发现新版本问题，提供回滚的灵活性”，而 AB testing 的用意是为了验证和比对不同的具体策略的效果。金丝雀发布必然导致软件的新版本代替旧版本（注意软件的版本和代码的版本是不一样的），间接地提供了 AB testing 的能力；而真正厉害的 ab testing 却可以不依赖软件版本更新，只把用户加以区分，并配以不同的策略即可。 蓝绿部署蓝绿部署的特性要求： 1 旧版本存在于蓝集群。 2 新版本部署于绿集群。 绿集群在上线的时候完全没有流量，在充分验证完成以后一下子通过 LB 把流量完全切入绿集群。 金丝雀发布在事实上是在同一套物理环境里实现渐进式替换，优点是要求的节点数量更小，发现 last minute 问题的时候影响面更可控，缺点是出了问题也要逐步回滚，系统是在进行有损服务的。 蓝绿部署要求生产环境有两套环境，优点是可以直接通过 LB 一键回滚，缺点是占用节点数量过多，出现 last minute 问题的时候影响面更大。蓝绿部署的缺点是大部分公司不直接采用它的原因。 特性开关特性开关的细节可以参考Feature Toggles (aka Feature Flags)，不同的开关实际上体现的是不同的精细化程度。 特性开关的要点是解耦 decision point 和 decision 决策逻辑。 维护这些开关的长期性和动态性实际上需要很重的架构权衡。 "},{"title":"部署环境","date":"2019-12-17T06:20:53.000Z","url":"/2019/12/17/%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83/","tags":["持续交付"],"content":"列举环境根据 wikipedia，工业界总是把开发环境和生产环境分离出来，中间还有若干个 stages。 结构化的发布管理允许分阶段部署（rollout），测试和在遇到问题时回滚（rollback）。 常见的环境有： 4-tier architecture is development, testing, model, production (DEV, TEST, MODL, PROD), Quality Control (QC), for acceptance testing; sandbox or experimental (EXP) Another common architecture is development, testing, acceptance and production (DTAP) Development构造对软件的变动的环境，大多数情况下仅仅是开发者的工作站（workstation）。在这个环境里实验变更和进行单元测试。集成环境有时候也可以被认为是开发环境，在集成环境里专门对 repo 里的源代码 copy 进行构建和单元测试。 Testing执行对新代码的自动化或非自动化测试的环境，在这个环境里测试失败需要联系开发者消除错误，在这个环境测试全通过则可以把代码晋升到下一个部署环境。 StagingA stage or staging environment is an environment for testing that exactly resembles a production environment. Staging 环境要尽可能地合生产环境相似，达到 replicate 的程度。它寻求尽可能完全镜像化生产环境，可能会连接生产的服务和数据，比如数据库（大多数公司，生产、预发、staging 使用一套数据库）。这类环境通常处于一套远程服务器上，和 dev 和 testing 有本质区别，会真正影响系统的网络活动。 staging 环境的首要用途是在应用到生产环境之前，测试安装、配置和迁移脚本和过程。 staging 环境可以拿来做性能测试-但这对 staging 环境的物理机条件有一定要求（可能需要完全复制生产环境的物理配置），staging 环境唯一的好处是可以隔离生产流量。 staging 环境也可以被用来预览新特性或者挑选顾客进行新的外部依赖的新版本集成-这一功能事实上就是大家经常用来进行 ab testing 的灰度环境（Gray/Grey/Canary）。 staging 环境没有真实消费者流量。 staging 环境可以直连生产数据库，也可以专做一个 staging db，专门存放 dummy value。 生产环境经常被称作“活/直播”环境，因为它直接和真实的消费者交互。 除非拥有热替换/热部署的能力，否则安装新代码总是会引起重启，这要求应用有被打断的功能，我们要么在 LB 背后逐一重启应用，要么提前重启应用后再切换流量。 为了防止 last-minute problems 能被发现，部署的 fraction 不一样。"},{"title":"CI/CD 方法论","date":"2019-12-13T08:43:25.000Z","url":"/2019/12/13/CI-CD-%E6%96%B9%E6%B3%95%E8%AE%BA/","tags":["软件工程"],"content":"CI/CD 的重要性Martin Fowler说过，“持续集成并不能消除Bug，而是让它们非常容易发现和改正。” 持续集成和持续交付作为敏捷开发的一种最佳实践，通过包括构建、部署、测试、发布流程的自动化，实现质量内建，让质量问题可以快速发现和消除，从而提升软件交付的质量和效率。 基本策略分支模型是CICD落地的源头，研发过程各角色间的协作方式以及研发过程内代码版本的流转方式都取决于分支模型。 首先划分环境。 划分环境后设计分支，注重开发和发布两个场景。 根据分支设计流水线，验证应该发生在全流水线里。 一般的分支模型 参考文献：《在阿里，我们如何管理代码分支？》《What is Trunk-Based Development?》《提升团队的微服务落地能力》"},{"title":"binlog 收集服务","date":"2019-11-27T06:35:42.000Z","url":"/2019/11/27/binlog-%E6%94%B6%E9%9B%86%E6%9C%8D%E5%8A%A1/","tags":["MySQL"],"content":"1 什么是 binlog？binlog是mysql的二进制日志，记录了mysql所有的数据变更(不记录查询操作)，全称是binary log。mysql使用binlog进行主从同步。 2 binlog是怎么收集上来的？binlog收集可以使用阿里巴巴的开源项目 canal，有兴趣的可以参考 。 canal本质上是模拟mysql的主从同步，对mysql发送dump请求，把自己伪装成mysql的一个从库，来同步binlog。 3 我的业务使用mysql集群（一主多从），binlog从那台机器进行同步？会不会对线上服务有压力？为了避免对 mysql 主库造成压力，canal会优先使用从库进行同步（当然，如果没有从库，那么只能从主库上拉取binlog了）。数据组与DBA之间有自动化接口，根据服务组和database，canal会在从库里随机选一个进行同步，如果有统计专用的从库，那么canal会优先使用统计从库。因此，如果你对canal拉取binlog使用的从库有要求，那么请与DBA联系，把允许拉取binlog的从库设置为统计从库。 4 binlog收集是实时的吗？是。只要数据库里有binlog产生，canal就会实时的拉取过来，拉取来的binlog放入kafka消息队列。 5 既然binlog收集是实时的，为什么有时候我获取的数据有延迟（主要针对实时计算的用户）？binlog收集的实时性，是指binlog以流式的方式从mysql流入kafka。收集延迟的现象，一般有两种原因：1). 业务高峰期，mysql大量写入，导致短时间内产生大量binlog，canal“忙不过来了”，会造成一定的延迟。2）. 为了不影响主库的性能，binlog一般都是从mysql从库拉取的，如果某些原因造成mysql主从延迟，那么canal收集binlog自然也会有延迟。 6 binlog区分库，表吗？我只对某个表的变更有兴趣，只希望订阅这个表的binlog怎么办？mysql的binlog，是以mysql实例（server）为单位产生的，一个mysql实例上所有库，表的binlog，都会一起写入同一份binlog文件。当然，某条binlog能够标识出这是哪个库，哪个表产生的binlog。 7 如果数据库表发生了ddl事件，那么应该怎么办呢？数据库表发生ddl事件时，ddl事件会实时的反映到binlog中，从而也会把变更事件实时的收集上来。对于实时消费者，只需要解析ddl事件，做出相应的响应即可。但是mysql2hive的同步流程，是不能够自动响应ddl事件的，hive表的字段并不会自动发生变更。用户需要手工操作一下。 8 实时使用方注意事项：1）binlog收集服务目前对外的承诺是不丢可重。当DBA进行库表迁移等运维操作时，为了保证数据质量，会采取双收一段时间的策略。"},{"title":"如何做全链路压测","date":"2019-11-10T08:26:09.000Z","url":"/2019/11/10/%E5%A6%82%E4%BD%95%E5%81%9A%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/","tags":["性能测试"],"content":"性能测试压测问题.xmind 性能测试的必要性 营销活动周期首先引入一个营销活动周期的概念，它是一个闭环流程： PS：1和2之间再加一个步骤。环境改造和基础数据准备。强调必须在生产环境。 压测环境准备：需要复用真实的线上环境，压测结果和问题暴露才都是最真实情况。可通过压测流量全局识别、透传（数据进入影子区域）。 基础数据准备：以电商场景为例，构造满足大促场景的核心基础相关数据（如买家、卖家、商品信息），以线上数据为数据源，进行采样、过滤、脱敏，并保持同等量级。 阿里实际上是 2013 年才开始做全链路压测的，现在的压测周期更加智能化。可以在白天由几个人值守进行，包含以下活动： 压测环境改造整个阿里经济体的压测环境，包括双十一压测，全部选择的是线上环境，此时需要评估： 如果要进行全链路压测，是否直接可以使用现有环境。 同一个API多次压测是否会被拦截-容易被忽略。 是否会有脏数据影响、如果有影响应该如何改造避免-必须进行的改造项目：1 识别+ 透传流量标，2 构造影子数据区域。 以上这些问题总结下来即为两类问题：业务问题和数据传递问题。问题比较明确，我们就根据这两类问题来做逐一的改造。 改造分为2方面：业务改造和中间件改造，这些在内部全链路压测1.0 时代就已经完成了，对于外部客户来说，可以作为一个技术改造上的参考点。同时我们已经有成熟的产品化方案提供一站式的能力，免去复杂的改造和维护成本。 业务改造业务改造即为了解决压测过程中的业务异常问题，或者压测请求无法正常被执行的问题。举例如下： 流量区分与识别：压测流量和业务流量的区分，并可在全链路系统中识别出来； 流量单一性问题：比如下单，同一个人执行一次下单后再重复执行就会失败； 流量的限流拦截：如果日常有限制，需要改造为接入流量降级能实时生效调整配置； 剔除压测数据对报表的影响 动态校验 业务改造涉及的内容无法一一穷举，需要根据不同的业务模型、业务架构及配置，一一梳理。一般梳理改造之后，后续所有新应用都按照规范去开发，每年的压测前进行基础的查漏补缺即可。- 面向压测设计。 中间件改造中间件作为衔接业务应用之间的组件，在压测中有个至关重要的功能就是将流量标识传递下去，一直到最终的数据库层面。虽然我们在13年开始，从核心应用使用到的中间件已经升级改造完成，中间我们踩过不少坑，诸如改造全面性、改造带来的业务代码修改成本、版本兼容问题等。 数据准备大促活动确定之后，会对业务模型进行一次评审，即确定该业务模式对应的技术架构应用有哪些，需要做压测的业务范围有哪些、以及数据量级、数据形式是什么样的。所以数据准备包括准备业务模型数据和压测流量数据两部分。数据的准备，主要分为两部分：业务模型的建立和基础数据的构造。 业务模型数据业务模型数据，即压测的业务模型相关的数据，包括涉及到哪些API，这些API之间的压测量级是什么样的或者有什么样的比例关系等。业务模型的构造准确度，直接影响了压测结果的可参考性。 模型设计的目的主要是将业务进行采集并抽象成可执行的压测模型，并对各个子模型中的元素进行预测和设计，最终产生可以执行的压测模型。在双十一大促前，我们会确定好相关的业务，进行场景分类。 已有业务场景：采集以往数据并做处理，作为预测数据，形成一个模型雏形，结合新的业务玩法，形成已有业务的模型； 新业务场景：直接按照新的业务，模型配比，形成一个新业务模型。 最终会将两种业务场景类型进行组合，形成最终的终态业务模型。以下图作为示例： 在组装业务模型数据的时候，需要注意一些关键因素，比如修改具体的电商业务模型关键因素： 1对N ：上游业务一个请求对应下游业务接口是否会存在调用多次的情况；业务属性的比例：根据历史数据计算不同类型业务的比例关系； 业务模型组装之后，单一事务中的业务模型，应该是一个漏斗状的。而每层之间的漏斗比例，是根据不同的层级、不同的玩法、不同的规则会有不一样的比例关系。在一次大促活动中，这个比例关系理论上是不会变化的。漏斗模型参考如下： 业务模型在压测时对应的就是压测量级，淘宝大促用的全部都是RPS模式压测，即从服务端角度出发每个API之间是漏斗比例关系、能够很好地应用于容量规划上。商业化产品PTS（性能测试服务，Performance Testing Service）中也很好的支持了RPS模式。 压测基础数据如果说业务模型对应的是确定要压测的接口/API的话，那压测流量数据，就是确定这些压测API到底压测的是什么内容，比如：登录哪些用户、查看哪些商品和店铺、购买哪些商品，甚至是付款价格是什么。 流量数据中，有一部分为上述业务模型对应具体RPS值，模型体现的是比例关系，而流量数据即有每次压测具体的RPS值。 流量数据中最重要的部分，即为真实的压测数据，我们可以称之为基础数据，比如交易的买家、卖家、商品数据等。全链路压测的目的是为了模拟双11，所以模拟的真实性非常重要，基础数据的真实性就是至关重要的一环。全链路压测会以线上数据作为数据源，经过采样、过滤、脱敏等操作，形成可作为压测使用的数据。 线上数据拿出来使用的时候，特别涉及到写数据的时候，避免造成脏数据，我们落地或者读取的时候，采用影子表的形式。当识别到压测流量，则读写影子表，否则就读写线上正式表。影子表的产生为的是压测流量安全。 淘宝内部系统使用的压测体系，数据平台和压测平台是两套平台。数据平台管理/提供压测数据（包括模型数据和流量数据），压测平台提供施压能力，即保证压测请求能够以指定的“协议”、指定的量级速率、从全国各地发送出来。商业化产品PTS（性能测试服务，Performance Testing Service）中提供的数据工厂能力，很好的将内部的数据平台和压测平台结合起来，产出为统一的一个压测系统，只需用户构造好压测数据以文件/自定义的形式定义好参数，在使用处配置即可。 流量安全策略流量安全策略主要是为了保证能够正常的施压流量且数据不错乱，安全地、符合预期地进行。这里面就包括了两层考虑： 测试数据和正常数据的严格隔离，即非法流量的监控和保护机制； 手段：影子表数据。影子表为和线上结构一致，但是处于隔离位置的可写压测数据表。 效果：数据隔离，避免了数据错乱。 压测流量的安全过滤，即不被识别为攻击流量； 手段：将安全相关策略接入流控降级功能；针对压测适当放松安全策略，或根据特殊标记识别； 效果：压测流量不被判定为攻击流量，成功压测的同时保障线上业务的安全性。 此处，涉及到第三方的系统，诸如支付宝、短信等服务，因业务特殊性需要做压测系统的打通。13年淘宝实现了第一次全链路压测，但是未能打通下游业务链路。在14年双十一压测前，和支付宝、物流环节等打通了全面的压测系统。对于外部客户来说，支付宝、短信等都有对应的挡板服务（mock）（测试领域里专门有“挡板测试”的概念）可提供，用来供用户做全链路压测时使用。 压测实施根据最开始介绍到的流程管控，一切准备就绪之后，即可开始进行全链路压测。除常规理解的正式压测之外，我们还有额外的两个预操作：系统预热、登录准备。 关于系统预热 这里说的预热，未包含我们内部提到的预跑（预跑应该是一个低流量的压测小脉冲压测）。预热是为了该缓存的数据提前缓存好，达到大促缓存态的状态，也更好地实现我们缓存的目的。大促缓存的使用应该利用到极致，故需要通过预热来进行。 对外部客户来说，可以通过先一轮、低量级的全链路压测，来提前预热系统，包括在真正大促活动之前也可这样操作，即提前缓存住需要缓存的数据。 登录准备登录准备主要是用于需要长连接保持、秒杀等场景，即用户都是逐步登录上来，然后再进行业务操作的场景。故如果量级特别大的时候，可以提前做登录的准备，一则来模拟真实用户登录场景，二则是对登录系统的保护。 正式压测一般正式压测会按照压测计划，执行多种压测策略。淘宝的双11大促压测，一般包含这样几步： 1）峰值脉冲：即完全模拟0点大促目标峰值流量，进行大促态压测，观察系统表现。 2）系统摸高：取消限流降级保护功能，抬高当前压测值（前提是当前的目标压测值已经达到，则可以进行摸高测试），观察系统的极限值是多少。可进行多轮提升压力值压测，直到系统出现异常为止。 3）限流降级验证：即验证限流降级保护功能是否正常。 （AHAS引入）商业化产品AHAS(应用高可用服务，Application High Availability Service）提供了全面的限流降级能力，可进行全链路的降级保护。 4）破坏性测试：这个主要是为了验证预案的有效性，类似于容灾演练时的预案执行演练。即为持续保持大促态压测，并验证预案的有效性，观察执行预案之后对系统的影响。 对外部客户来说，可以配置不同的压测量级数据，来进行多轮压测，并观察其系统表现。压测不应该是一次性的操作，而应该是反复的、多轮验证的操作。 问题定位分析压测结束之后，会将压测过程中的系统表现、监控数据等整理，进行压测复盘，分析当前系统瓶颈、后续改进修复计划及下一轮压测时间等。在分析定位问题时，因涉及的系统较多、子业务系统的形态不一，需要具体问题具体分析，其中不免需要一线研发的介入。 商业化产品PTS（性能测试服务，Performance Testing Service）的压测报告，有详细统计数据及趋势图数据，采样日志以及添加了的监控数据。后续PTS还会提供架构监控，帮助性能测试执行同学，更好地从系统架构角度判定压测过程中系统是否正常，大致瓶颈点。 总结 压测前要先评估再改造。 评估要从 API 的语义，应对流量的高可用保障措施（限流、熔断）、请求涉及的模型、模型推导出的真实数据进行完整建模。 改造的时候要确保改造能够覆盖到 major case ：流量标能够在各个流程里传递，包括业务系统和中间件和数据库。数据库能够正确存储影子表。 改造的时候要确保能够覆盖到 major case：如何保证影子影子流量标不丢？如果影子流量丢了如何自保？这需要流程做专门的评估和设计，可能还涉及到压测数据的制造。 制造压测数据的时候，尽量录制真实流量，重现真实流量。 环境的预热很重要，特别是预热缓存、连接和登录 session 等系统状态（state）。 测试的过程要有预压测（预跑）的过程，类似一种灰度能力，看看系统各个场景的压测冒烟状况是否正常。 压测本身首先要验证容量是否达到规划要求。 压测的主要目的达到以后，要进行摸高测试和破坏性测试（类似 netflix 的混沌工程）。 压测的环境改造会产出一个压测平台和数据平台，实际上应该也会产生一个全链路跟踪平台和压测分析平台。 压测改造举例如何改造数据源 参考： 《独家揭秘 | 阿里怎么做双11全链路压测？》 《阿里如何做好双11技术保障？大队长霜波分享4点经验》 《全链路压测在网易传媒的落地与实践》 《高德全链路压测——精准控压的建设实践》 "},{"title":"Redis 笔记之十一-集群 Cluster","date":"2019-11-09T11:13:46.000Z","url":"/2019/11/09/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%8D%81%E4%B8%80-%E9%9B%86%E7%BE%A4-Cluster/","tags":["Redis"],"content":"背景在 Redis Cluster 方案诞生以前，在 Redis 集群遇到单机资源和流量瓶颈时，有两种常见分布式解决方案： 客户端方案：需要自己处理分区逻辑、路由、故障转移。 代理方案：减轻了客户端的职责和压力，架构上的负担过重。 Redis Cluster 的出现，极大地降低了架构师的负担，解放了生产力。 数据分布数据分布理论 分区方式 特点 代表产品 哈希分区 离散度好 数据分布业务无关 无法顺序访问 KV型 Redis Cluster Cassandra Dynamo Elastic Search 顺序分区 离散度易倾斜 数据分布业务相关 可顺序访问 表型 Bigtable HBase Hypertable 由于 Redis Cluster 采取哈希分区规则，常见的哈希分区规则有 节点取余使用特定的数据，如 Redis 的键或用户 Id，再根据节点数量 N 使用公式：hash(key) % N（经典的双层 hash），用来决定数据映射到哪一个桶里。这种方案存在一个问题，当节点数量变化时，整个映射关系都要重新计算。 如果使用这种哈希方式，一开始就要规划好分区，保证可以支撑未来一段时间的数据量，扩容时可以天然采用翻倍扩容。 一致性哈希一致性哈希（Distributed Hash Table）的实现思路是为系统中每个节点分配一个 token，范围一般在 0~2 power 32，这些 token 构成一个 hash 环。数据读写执行查找时，先 hash，然后顺时针（向大数方向）选最近一个 bucket。 一致性散列的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。但一致性哈希分区存在几个问题： 加减节点会造成哈希环中部分数据无法命中（取余分区一样存在这个问题），需要手动处理或者忽略这部分数据，因此一致性哈希常用于缓存场景。 当使用少量节点时，节点变化将大范围影响哈希环中数据映射，因此这种方式不适合少量数据节点的分布式方案。 普通的一致性哈希分区在增减节点时需要增加一倍或减去一般节点才能保证数据和负载的均衡。 虚拟槽分区虚拟槽分区兼顾了取余分区和一致性哈希的优点，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个数一般远大于节点数，比如 Redis Cluster 的槽范围是 0 -16383。槽是集群内数据管理和迁移的基本单位。采用大范围的槽的目的是为了方便数据拆分和集群扩展，每个节点负责一定数量的槽。 Redis 数据分区slot = crc16(key) * 16383 注意： crc16 是一种哈希函数 用 * 取余的方法 每个节点负责维护一部分槽以及槽锁映射的键值数据。 ![Redis Cluster 的槽位映射.jpg](Redis Cluster 的槽位映射.jpg) Redis 虚拟槽分区的特点： 解耦数据和几点之间的关系，简化了节点扩容和收缩难度。如果增加一个节点 6，就需要从节点 1 ~ 5 获得部分 槽 分配到节点 6 上。如果想移除节点 1，需要将节点 1 中的槽移到节点 2 ~ 5 上，然后将没有任何槽的节点 1 从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。 支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。 Redis 数据分区限制 只允许对映射到同一个 slot 的 key 进行批量操作，如 mget、mset。 只支持对映射到同一个 node 的 key 进行事务操作。 大数据结构（hash/list）必须映射到同一节点（key 在最小的可分割单位）。 不支持多数据空间，只能使用 db0。有了 Redis Cluster，会推动多数据空间消亡。 复制结构只支持一层，从节点只能复制主节点。 搭建集群准备节点Redis Cluster 至少需要 6 个节点。开启配置redis-enabled yes。 准备配置文件： 要特别注意： dir、log 等目录一定要可写。 cluster-config-file 是会被自动生成的，类似 sentinel 会覆写 sentinel 节点的配置文件。 节点握手注意，配置文件里并没有指明当前任何节点属于什么集群，这些节点可以手动加入任何集群。 节点握手是指一批运行在集群模式下的节点通过 Gossip 协议彼此通信，达到感知对方的过程。节点握手是集群彼此通信的第一步，由客户端发起命令：cluster meet &#123;ip&#125; &#123;port&#125;。 cluster meet 是一个异步命令，执行后立即返回。内部发起与目标节点进行握手通信： 节点1创建节点2的节点信息对象，并发送 meet 消息。 节点2接收到 meet 消息后，保存 6379 节点信息并回复 pong 消息。 之后节点 6379 和 6380 彼此定期通过 ping/pong 消息进行正常的节点通信。 ![cluster meet.png](cluster meet.png) meet、ping、pong 消息是 Gossip 协议通信的载体。它的主要作用是使节点彼此交换状态数据信息。 使用cluster nodes可以获知当前集群的全貌： 其中开头的 40 位 16 进制数是当前集群的节点 id，在节点生成的时候就唯一初始化好了，每次重启都不会变-不同于 runId，runId 每次重启都会变。我们只要在集群内的任意节点上执行 cluster meet命令，握手状态就会通过消息在集群内传播，这样其他节点会自动发现新节点并发起握手流程。 分配槽位这时候集群只是建立起来，还处于下线状态。直接往任意节点写会出现(error) CLUSTERDOWN Hash slot not served错误。 这时候执行cluster info命令，可以看到 cluster_slots_assigned:0意味着当前的集群的槽位没有做过映射，只有节点被分配了槽位，才能响应和这些槽关联的键命令。 首先把所有槽位分配给 3 个节点。 这个时候再执行cluster info，则会看到： 制造主从结构这时候把剩下三个节点作为从节点： 这时候集群就已经开始各司其职了。 ![cluster nodes.png](cluster nodes.png) 简便方案下面的命令可以一键生成集群，如果 Redis 版本不够高，就必须使用redis-trib.rb。 如果当前节点都位于同一个 host 上，就会报[WARNING] Some slaves are in the same host as their master信息。实际上这些节点都处于一个 docker 集群里，但因为共用了127.0.0.1的地址，触发了反亲和性报错。 广播协议。共识协议。发布订阅。流言协议。 搭建一个集群管理平台要回答好几个问题 业务归属地 事业群、业务线：这里主要供运维参考，方便集群的运维管理。 集群部署位置（几个地域、几个中心） 服务等级 是否涉及现金交易：如果涉及到支付场景，请与SRE/DBA联系。 容量预估：需求容量应该事先评估好，减少后续的扩容次数（扩容过程会不会有数据丢失要看存储方案）。 峰值QPS(次/秒)预估 读写分布 客户端类型：根据实际使用情况进行选择，通常是 Redisson。 集群名：应该能准确简介地描述业务的功能或用途。使用“-”分隔（不要出现超过三次），不要出现环境结尾（环境后缀通常会自动被拼进去），不要出现数字。 集群描述：详细描述具体使用场景 是否持久化：redis集群主要提供的是存储功能。如果仅仅是作为缓存来用，持久化功能可以关闭，关闭了持久化功能的集群可以提供更好的性能。 是否可淘汰 可运维周期（星期几、是否工作日）。 可运维时间（通常是业务低峰期）。 怎样隔离 kv？制造名字空间。 一种思路是key等于$&#123;表名&#125;.$&#123;列名&#125;_$&#123;version&#125;。每一个 key 要指定类型为好。 category 表名 template 列名 version 是 redis 内部管理的一个数字，如果这个 category 清一次缓存，那么 version 会加1，这样最后的 key 字符串会变成全新的字符串，应用使用新的 key 之后需要重新从数据源加载数据到缓存-这又要引入事件驱动机制。 集群与集群组在 Set/单元化架构中，一个 cluster group 包含多个 ldc 里的多个 cluster，每个 cluster 服从每个 unit/region/set 的配置。 在 cluster group 里对 category 进行操作最终会同步到各个 cluster 上。 集群的辅助服务 Redis-Keeper 集群间数据同步 Redis-Migrate 扩容/迁移 Redis-Web 管理 Redis-Monitor 监控告警 Redis-Schedule 调度/运营 Redis-HA 集群高可用 "},{"title":"保险专业基本功","date":"2019-11-08T12:23:13.000Z","url":"/2019/11/08/%E4%BF%9D%E9%99%A9%E4%B8%93%E4%B8%9A%E5%9F%BA%E6%9C%AC%E5%8A%9F/","tags":["保险"],"content":"保险行业市场参与者 直保公司（也就是常见的保险公司），如泰康人寿、平安财险。 保险中介（帮直保公司卖保险的机构），如携程保代、慧择经纪、XX银行分行兼业代理。 再保险公司（直保公司将无法独自分摊的风险进行再分摊），如瑞士再保险，中国再保险。 保险公估（帮助保险公司理赔的专业公司），如泛华公估、民太安公估。 保险资管公司（帮助保险公司进行资产管理的公司），如中国人保资产管理。 类目的区别财产险：经营跟财产损失有关的业务，主要是车险。 寿险：经营与人身损失有关的业务，主要是重疾险、健康险及寿险等。 财产险公司及寿险公司均可经营一年期及更短保障期限的健康险及意外险业务，这就是为什么百万医疗虽然是人身相关的保险，但是最早研发推出的是众安在线（一家财产险公司），而支付宝的好医保·长期医疗6年期百万医疗只能由人保健康这类人寿险公司推出。 互联网保险的模式什么是场景保险模式依靠场景销售保险产品，可以是传统的保险产品定制也可以是全新设计的保险产品。 a) 传统的保险产品定制：以携程为代表，机票搭售航意险，以变现为导向。 b) 全新设计的保险产品：以“准时宝”、“退回运费险”为代表，针对互联网场景特有风险，设计保险产品，并在场景中实现快速销售，以解决“客诉”为导向。 什么是人身类保险模式人身保险对于客户而言是一个重要不紧急的事情，很多客户都知道自己需要买一份保险，但是就是迟迟难以决策购买。（主要依靠代理人孜孜教诲。） 什么是互联网模式 1.0版本（无场景纯商城模式）：依靠流量寄希望于客户自己购买，最终全线阵亡，转化率实在太低。 2.0版本（赠险模式）：以赠险为工具筛选目标客户，通过多次触达创造让客户思考是否需要保险的场景，辅助于高性价比百万医疗产品，实现客户购买千元内的健康险。 3.0版本（互助模式）：以平台触达为依托，实现客户转化为互助客户（先享受后付费），通过理赔案例创造让客户知道风险无处不在的场景，加强客户购买保险需求，辅助于高性价比百万医疗产品，实现客户购买千元内的健康险。 4.0版本（线上+人工模式）： 以平台触达为依托，以赠险、互助、内容营销等形式，筛选潜在客户，再通过电话或者线上1对1沟通，实现客户购买年缴3000+的长期保险产品。 "},{"title":"Redis 笔记之十-哨兵 Sentinel","date":"2019-10-30T14:20:55.000Z","url":"/2019/10/30/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%8D%81-%E5%93%A8%E5%85%B5-Sentinel/","tags":["Redis"],"content":"Redis 有若干套高可用实现方案。2.8 开始提供哨兵功能（不要使用更低版本的哨兵，可能有 bug）。 基本概念 主从复制模式的问题Redis 天然就带有主从复制的功能，但主从复制有若干缺点： 需要手工干预，缺乏自动 FO 机制-分布式高可用问题。 单机的写能力有限-分布式容量问题。 单机的存储能力有限-分布式容量问题。 一个经典的高可用场景当一个主从集群的 主节点 失效的时候，经典的恢复步骤如下： 主节点失效 选出新的从节点，slaveof no one。 先更新应用方的连接 再让其他从节点换主 再把恢复好的主节点作为新的从节点复制新的主节点。 3 和 4 的步骤可以互换。 Sentinel 的高可用性Sentinel 方案是在原生的 Master-Slave 集群之外加上一个 Sentinel 集群。 每个 Sentinel 节点会监控其他 Sentinel 节点和所有 Redis 节点。任何一个不可达的节点，它都会将其做下线标识。 如果标识的是主节点，它还会： 1 与其他 Sentinel 节点进行“协商”（negotiate），当大多数 Sentinel节点认为主节点都认为主节点不可达时。2 会先选举出一个 leader Sentinel 节点来完成自动的 FO 工作。3 把集群变化通知 Redis 应用方。 sentinel 的部署和启动单个 sentinel 节点的配置文件 实际上每个 sentinel 节点的配置文件都可以写成这样，但每个文件必须单独存在，因为 sentinel 文件会在启动时重写各自的配置文件。 启动命令 sentinel 本质上只是一种特殊的 Redis 节点。因此可以使用如下的命令查看哨兵的已知信息： sentinel 可以清楚地知道当前监控了多少个集群，集群里有多少个主从节点，一共有几个哨兵节点。 监控多个集群一套 Sentinel 可以监控多个 Redis 集群，只要准备多套sentinel monitor my_redis_master redis1 6379 3里的 master name my_redis_master 即可。 配置调整 需要注意： sentinel set 只对当前节点有效。 sentinel set 命令执行完成以后会立即刷新配置文件，这点和普通节点需要使用config rewrite。 所有节点的配置应该一致。 sentinel 堆外不支持 config 命令 部署技巧 sentinel 节点应该在物理机层面做隔离。 sentinel 集群应该有超过 3 个的奇数节点。 奇数节点对选举的效果是最优的。 可以一套 sentinel 监控多套集群，也可以多套 sentinel 监控多套集群。取舍的时候需要考虑的是：是否 sentinel 节点自身的失败需要被隔离。 API 实现原理Sentinel故障转移的原理.xmind 三个定时任务 每隔 10s，sentinel 往所有 M/S 发 info 获取最新的拓扑结构 从主节点可以实时获知从节点的信息 ![info 任务.png](info 任务.png) 每隔 2s，sentinel 节点会向 Redis 数据节点的 sentinel:hello 频道上发送改 Sentinel 节点对主节点的判断，以及当前 Sentinel 节点的信息。同时每隔 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及它们对主节点的判断。 sentinel 可以通过这个频道获取 sentinel 之间的信息 交换主节点的状态，可以作为后续客观下线和领导者选举操作的依据： 每隔 1s，sentinel 会向M/S和其他 Sentinel 发送一条 ping 命令做一次心跳检测，来确认节点是否可达。 ![ping 任务.png](ping 任务.png) 主观下线和客观下线主观下线任意sentinel ping master 超时（sentinel down-after-milliseconds my_redis_master 3000），就可以单节点认为该节点已失败。 任何一个节点进入主观下线状态时，都会使用new_epoch让当前纪元加一。 客观下线sentinel 一进入主观下线状态，就会发送SENTINEL is-master-down-by-addr &lt;masterip&gt; &lt;masterport&gt; &lt;sentinel.current_epoch&gt; * 命令直接询问其他哨兵节点对主节点的判断，当主观下线的 哨兵数量超过的个数（不一定要超过半数），Sentinel 节点认为主节点确实有问题，这时候 Sentinel 就可以客观下线的决定。第一个进入主观下线状态的节点，往往成为进入客观下线的节点-这点特别像 Raft。 runId等于*时，sentinel 交换的是主节点下线的判定；runId 等于哨兵的runId时，哨兵请求的是其他节点同意它成为领导者。 客观下线必须举行 Sentinel 节点选举主观下线和客观下线本质上只是对 Redis 主节点的一个状态标记，并不会天然将自己标记为领导者，更不会自动故障转移。 确定进入客观状态的 Sentinel 节点会成为一个 candidate，立刻发送一个SENTINEL is-master-down-by-addr &lt;masterip&gt; &lt;masterport&gt; &lt;sentinel.current_epoch&gt; 自己的 runid 每个 sentinel 节点在收到该命令的后，如果没有同意过其他 Sentinel 节点的 sentinel is-master-down-by-addr 命令，将同意该请求，否则拒绝（raft 里每个节点每轮选举只能有一票）。 发起选举的 Sentinel 要么成为领导者，要么进入下一轮选举（或者恢复到主观下线以前的状态？）。 故障转移所有的故障转移其实只是执行命令，把手动步骤编程为自动步骤而已。 具体步骤为： 在从节点列表中选择一个节点作为新的主节点。因为从节点本身是有状态的，所以实际上是使用综合考虑权重、优先级和一致性的类负载均衡选择算法： 过滤不健康节点：主观下线、断线、5s 内没有回复过 Sentinel 的 ping 命令、与主节点失联超过 down-after-miliseconds。 选择 slave-priority 最高的节点（如何配置？）。 选择偏移量最大的从节点-复制最完整。 选择 runid 最小的从节点。 对选出的节点发出 slave of no one 命令，从节点升为主节点。 对剩下的从节点发出命令，让它们成为主节点的从节点，复制规则和 parallel-sync 参数有关。 （最后）Sentinel 节点集合会将原来主节点更新为从节点，（这样线上先止血成功），然后持续对其关注，待其恢复后命令其去复制新的主节点。 全流程![redis 客观下线流程.png](redis 客观下线流程.png) 节点运维节点下线 临时下线：暂时将节点关掉，之后还会重新启动，继续提供服务。 永久下线：将节点关掉不再使用，需要做一些清理工作，如删除配置文件，持久化文件、日志文件。 主节点下线 将一个合适的从节点（如高性能）的 priority 设置为 0。可参考 sentinel 中的 Replicas priority section。 在任意一个 sentinel 上，执行sentinel failover master-name。 从节点或 sentinel 节点下线如果使用了读写分离，要确保读写分离机制能够自动感知拓扑结构的变化。如果只是临时下线（命令下线、kill），sentinel 会对下线节点念念不忘，也就是会不断地对这些节点进行 monitor，浪费硬盘和网络资源，这种时候可以考虑永久下线。 节点上线从节点上线配置节点 slave of [masterIp] [masterPort] 让节点上线。master 收到链接后，主从就会自动相互注册发现，而 sentinel 也会自动发现新的从节点。 Sentinel 节点上线sentinel 只要配了 sentinel monitor，它就会连上 master，进而被 sentinel 网络互相理解发现。"},{"title":"数据库大表问题","date":"2019-10-30T06:19:31.000Z","url":"/2019/10/30/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%A7%E8%A1%A8%E9%97%AE%E9%A2%98/","tags":["数据库"],"content":"什么是大表大表是数据量过大的表，会在实际生产环境下给业务带来的问题。 大表的危害 读写到瓶颈。物理资源不可能无限扩展，数据库层面软件也有支持极限，当业务发展到一定程度，单集群的表是无法满足高速发展的需求。- 性能下降 性能不稳定。当表的量大到了某一个临界值，所以针对表的读写操作都会受到影响，对于正在线上提供读写服务的业务来说，可能是致命的威胁，严重情况下直接导致业务不可用。 - 稳定性下降 改表耗时过程。为了实现改表不影响线上读写，采用gh-ost的改表方案，其中有一个步骤，将表完全考一遍，这个过程与表表大小呈现正相关行。很多表已经大到改不动的水平了。 - 无法变更 表的统计值不准。数据库内部在做优化的过程中，会使用很多统计形式的量对表进行评估，比如行数。这些指标随着表的增加准确度也越来越难得到保证，会直接影响到对表属性的判断。 - 无法观测 简而言之，大表的所有操作都不稳定，性能不好。 业界对大表的定义 阿里云  腾讯云        定义大表的维度 单表尺寸（最主要的指标1）要注意单表过大后，各种操作语句 select/delete/update 不动，会影响 db 的 migration，既影响归档，也影响分库分表，还影响主从延迟。 gh-ost改表工具，一个晚上大概可以完成80G左右的数据。80G的量级不会对改表操作造成额外的负担。 单表行数（最主要的指标 2） 数据行指的是表里面的数据总行数。表行数也是体现表大小的一个重要因素，当数据行数超过一定量级了之后，SQL的扫描行数过多，很容易造成慢查询。 上面说的数据量大并不等同于行数多，因为表总量=表行数*行大小(每一行记录的字节数)，存在一种情况，表的总量不大，因为每一行很小，但是行数很多，这种情况也是需要关注的，是对数据量的一个补充。 表读写QPS 考虑表读写 qps 的时候，要考虑 binlog+databus 之类的数据搬运工具衍生的写放大问题。做压力测试的时候要注意主从延迟一直保持在可以接受的范围内–实际上做任何大规模的写 dml 以前都要考虑对主从延迟的影响。。如果延迟过高，问题不是改变表大小可以解决的，需要反推业务系统改造。 普通的 MySQL 存储引擎只能提供单表 6000 的读写 tps。 慢查询 出现慢查询的时候可能提示出现了大表。 大表的解决方案归档和拆分。归档针对可以删除数据并且QPS没有成为瓶颈的前提；拆分针对的是业务暴增，不能删除数据，并且QPS已经到了单个集群的瓶颈的情况。 数据归档需要不同公司不同团队的 dba 提供工具对数据进行归档。 清理 binlog根据 MySQL 的运维备份策略，binlog 的会占用不同大小的磁盘空间。即使表本身不是很大，但 binlog 占用的空间太大，也会导致磁盘读写响应变慢，进而影响查询性能。这也属于一种间接的“大表问题”。 所以要改变运维策略，定期删除 binlog 存档。 注意，这个操作可能会耗时很久，注意不要因为锁定影响到正常的业务读写和主从延迟。 删除数据空洞当你对InnoDB进行修改操作时，例如删除一些行，这些行只是被标记为“已删除”，而不是真的从索引中物理删除了，因而空间也没有真的被释放回收。 InnoDB的Purge线程会异步的来清理这些没用的索引键和行，但是依然没有把这些释放出来的空间还给操作系统重新使用，因而会导致（文件系统）页面中存在很多空洞 - purge 不等于归还。 如果表结构中包含动态长度字段，那么这些空洞甚至可能不能被InnoDB重新用来存新的行，因为空间空间长度不足。 有些用户可能会使用 OPTIMIZE TABLE 或者 ALTER TABLE ENGINE=InnoDB 来重建这些表，但是这样会导致表的拷贝，如果临时空间不足甚至不足以进行一次 OPTIMIZE TABLE 操作。并且如果你用的是共享表空间方式，OPTIMIZE TABLE 会导致你的共享表空间文件持续增大，因为整理的索引和数据都追加在数据文件的末尾。 InnoDB类型的表是无法使用optimize table命令的。 清除空洞的命令的例子： 注意，这个操作可能会耗时很久，注意不要因为锁定影响到正常的业务读写和主从延迟。 数据空洞的格式参考： online ddl 操作的窍门参考： 分库分表分库分表带来的问题分库分表相比于数据归档，更加偏向于一套完整的解决方案，需要考虑的因素就比较多了。 事务支持 在分库分表后，就成为分布式事务了，如何保证数据的一致性成为一个必须面对的问题。一般情况下，使存储数据尽可能达到用户一致，保证系统经过一段较短的时间的自我恢复和修正，数据最终达到一致。 分页与排序问题 一般情况下，列表分页时需要按照指定字段进行排序。在单库单表的情况下，分页和排序也是非常容易的。但是，随着分库与分表的演变，也会遇到跨库排序和跨表排序问题。为了最终结果的准确性，需要在不同的分表中将数据进行排序并返回，并将不同分表返回的结果集进行汇总和再次排序，最后再返回给用户。 表关联问题 在单库单表的情况下，联合查询是非常容易的。但是，随着分库与分表的演变，联合查询就遇到跨库关联的问题。粗略的解决方法： ER分片：子表的记录与所关联的父表记录存放在同一个数据分片上。参考： 全局表：基础数据，所有库都拷贝一份。字段冗余：这样有些字段就不用join去查询了。 ShareJoin：是一个简单的跨分片join，目前支持2个表的join,原理就是解析SQL语句，拆分成单表的SQL语句执行，然后把各个节点的数据汇集。 其中的 sharejoin 是特别中间件的 advanced 特性。 分布式全局唯一ID 在单库单表的情况下，直接使用数据库自增特性来生成主键ID，这样确实比较简单。在分库分表的环境中，数据分布在不同的分表上，不能再借助数据库自增长特性，需要使用全局唯一ID。 分库分表的原则能不切分尽量不要切分。 切分本身只是手段，切分的目的是为了降低维护成本，提高访问效率等。 如果要切分一定要选择合适的切分规则，提前规划好。 数据切分尽量通过数据冗余或表分组（Table Group）来降低跨库Join的可能。 由于于数据库中间件对数据Join实现的优劣难以把握，而且实现高性能难度极大，业务读取尽量少使用多表Join。 我们切分可以水平切换，还可以垂直切换，这两种配合，我们的原则是先垂直分，后水平分。 水平切分是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中。 水平切分的优点： 拆分规则抽象好，join操作基本可以数据库做。 不存在单库大数据，高并发的性能瓶颈。 应用端改造较少。 提高了系统的稳定性跟负载能力。 水平切分的缺点： 拆分规则难以抽象。 分片事务一致性难以解决。 数据多次扩展难度跟维护量极大。 跨库join性能较差。 大表拆分的方案搜集信息里，多数是根据表的行数多少来定是否需要拆分，而不是表尺寸。 主要原因：通常水平切分力求切分均匀。通常使用取模的方式，通过单表行数，是比较容易计算适合分几张表。 搜集的信息里，大多推荐单表行数在500万条到1500万条之间。 超过2000万行，需要拆分。 超过1000万行，年增长量500万行，需要拆分。 超过500万行，年增长量500万行，推荐拆分。"},{"title":"复式记账法","date":"2019-10-28T11:37:25.000Z","url":"/2019/10/28/%E5%A4%8D%E5%BC%8F%E8%AE%B0%E8%B4%A6%E6%B3%95/","tags":["会计","金融"],"content":"借记和贷记解释一借贷是符号，对于资产和费用，借方是增加，贷方是减少。 对于负债，权益和收入，借方是减少，贷方是增加。 提高，借贷表示价值流向，借方表示价值去向，贷方表示价值来源。 借方资产，表示价值流向资产，资产增加了。 借方负债，表示价值流向负债，偿还了负债，负债减少了。 贷方权益，表示价值来源于权益，权益增加了。贷方收入，表示价值来源于收入，收入增加了。 因为价值的来源和去向必定是相等的，所以有借必有贷，借贷必相等。 解释二复式簿记中，“借”的含义是“借进来”，“贷”的含义是“借出去”，而这个“借进来”和“借出去”又是从对方的视角来看的。复式簿记发展的最初是以记录债权、债务为目的使用的，而且也没有那么多会计科目，基本都是使用人名（或者商店名字）来进行记录的。而这里的“借进来”“借出去”并不一定是借，这是用来表示财产的流向的。下面为了解释借方、贷方的含义，会有很多简化处理。用户A向银行存钱，在银行的账本上，在现金这个会计科目下，会记录从用户A处“借进来”200元；在用户A这个会计科目下，记录“借出去”现金200元。这里的“借进来”对应着现金会计科目下的“借方”，“借出去”对应着用户A会计科目下的“贷方”。用户B的情况和用户A是一样的。 解释三用“借”表示资金占用的增加和资金来源的减少，用“贷”表示资金来源的增加和资金占用的减少。 复式记账法是意大利人发明的1494年方济会教士伯乔尼(LucaPacioli）的《算术、几何、比及比例要》一书出版，被规范后的复式记账法开始逐渐被欧洲各商业组织接受。 借贷记账法采用复式记账法，可以全面地、相互联系地反映各项经济业务的全貌，并可利用会计要素之间的内在联系和试算平衡公式，来检查账户记录的准确性，它是一种比较完善的记账方法，为世界为国所通用。在我国的会计实务中，曾出现过三种复式记账法，即在我国的会计实务中，曾出现过三种复式记账法，即借贷记账法、增减记账法和收付记账法。1993年7月1日开始实施的《企业会计准则》规定，企业记账必须采用借贷记账法。 思维导图 复式记账法.xmind 资金流举例 1举个例子，比如 “公司从银行贷款100块”。 首先，根据会计恒等式公司资产账户增加了100块，那么等式另一边的负债账户也要增加100块。 然后，明确资金流向，这笔资金是从银行流入公司资产的，根据“一次经济行为的出资账户被记为 credited（债务权益类账户增加），获资账户被记为 debited”（资产类账户增加），在债务账户的credit记100，资产账户的debit记100. 对于资产类账户：增加记debit(借方），减少记到credit(贷方) 对于债务权益类账户：增加记为credit(贷方)，减少记为debit(借方)。 （1）2010年公司成立，老板拿出100块钱作为启动资金。 （2）2011年花50块钱购买设备 资金流举例 2账户结构： 会计科目： 1.A公司会计，从公司银行账户中取出了1000元现金。 会计分录： 借：银行存款 1000 贷：库存现金 1000 2.A公司员工小明，报销当月的差旅费用100元。财务通过现金方式，支付100元。 借：库存现金 100 贷：管理费用-差旅费 100 3.A公司购进一批价格30,000元的原材料，其中28,000是以转账的方式支付，还有2,000元未支付（赊欠）。 现金资产减少 + 负债增加 = 另一种设备资产增加 其他理解基本恒等式：有借必有贷，借贷必相等。 发生一起交易至少要记两条账目，也可以不止两条。 表面上看起来：资产等于 = 所得者权益 + 负债。实际上：所得者权益 = 资产 - 负债。但每一种性质的变动，都要有专门的会计条目来记录。 所有者权益和负债都代表了其他人可以对公司行使货币请求权。 另外，所有者权益还可以再细分： 借代表了资金的流出方向，为 debit，贷为资金的流入方向，等于 credit。 对于资产类的账户，增加要记在 debit 里，意味着在交易里，属于进钱一方；而减少要记在 credit 里，意味着在交易里，属于出钱的一方。 对于负债和权益类账户，增加要记在 credit 里，意味着在交易里，属于出钱一方（出钱多了钱就少了，债务也就增多了）；而减少要记在 debit 里，意味着在交易里，属于进钱的一方（进钱多了钱就多了，债务也就减少了）。 以此推论，一般的储蓄卡是借记卡（debit），从银行的视角来看，debit 的落点是银行；而信用卡是贷记卡（credit），从银行的视角来看，credit 的起点是银行。 账户名称 账户性质 debit credit 应付账款——商家款 债务账户 100 其他货币资金-支付宝 资产账户 100 资金流在保险团队保费支出户（credit 代表了这个资金流的源头）到保险公司保费收入户（ debit 代表了这个资金流的入处）。 同类型的账户一方加就要一方减，不同类型的账户可以同加同减。"},{"title":"世界上最简单的会计书","date":"2019-10-28T10:00:26.000Z","url":"/2019/10/28/%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E4%BC%9A%E8%AE%A1%E4%B9%A6/","tags":["财务","会计"],"content":" 世界上最简单的会计书.xmind"},{"title":"常见数学术语中英文对照","date":"2019-10-28T08:22:52.000Z","url":"/2019/10/28/%E5%B8%B8%E8%A7%81%E6%95%B0%E5%AD%A6%E6%9C%AF%E8%AF%AD%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AF%B9%E7%85%A7/","tags":["数学","英语"],"content":"集合与简易逻辑 集合（集） set非负整数集 the set of all non-negative integers自然数集 the set of all natural numbers正整数集 the set of all positive integers整数集 the set of all integers有理数集 the set of all rational numbers实数集 the set of all real numbers元素 element属于 belong to不属于 not belong to有限集 finite set无限集 infinite set空集 empty set包含 inclusion, include包含于 lie in子集 subset真子集 proper subset补集（余集） complementary set全集 universe交集 intersection并集 union偶数集 the set of all even numbers奇数集 the set of all odd numbers含绝对值的不等式 inequality with absolute value一元二次不等式 one-variable quadratic inequality逻辑 logic逻辑联结词 logic connective或 or且 and非 not真 true假 false真值表 truth table原命题 original proposition逆命题 converse proposition否命题 negative proposition逆否命题 converse-negative proposition充分条件 sufficient condition必要条件 necessary condition充要条件 sufficient and necessary condition……的充要条件是…… … if and only if … 函 数 函数 function自变量 argument定义域 domain值域 range区间 interval闭区间 closed interval开区间 open interval函数的图象 graph of function映射 mapping象 image原象 inverse image单调 monotone增函数 increasing function减函数 decreasing function单调区间 monotone interval反函数 inverse function指数 exponentn次方根 n th root根式 radical根指数 radical exponent被开方数 radicand指数函数 exponential function对数 logarithm常用对数 common logarithm自然对数 natural logarithm对数函数 logarithmic function 数 列 数列 sequence of number项 term通项公式 the formula of general term有穷数列 finite sequence of number无穷数列 infinite sequence of number递推公式 recurrence formula等差数列 arithmetic progression ， arithmetic series公差 common difference等差中项 arithmetic mean等比数列 geometric progression， geometric series公比 common ratio等比中项 geometric mean 三 角 函 数 三角函数 trigonometric function始边 initial side终边 terminal side正角 positive angle负角 negative angle零角 zero angle象限角 quadrant angle弧度 radian弧度制 radian measure角度制 degree measure正弦 sine余弦 cosine正切 tangent余切 cotangent正割 secant余割 cosecant诱导公式 induction formula正弦曲线 sine curve余弦曲线 cosine curve最大值 maximum最小值 minimum周期 period最小正周期 minimal positive period周期函数 periodic function振幅 amplitude of vibration频率 frequency相位 phase初相 initial phase反正弦 arc sine反余弦 arc cosine反正切 arc tangent 平 面 向 量 有向线段 directed line segment数量 scalar quantity向量 vector零向量 zero vector相等向量 equal vector共线向量 collinear vectors平行向量 parallel vectors向量的数乘 multiplication of vector by scalar单位向量 unit vector基底 base基向量 base vectors平移 translation数量积 inner product正弦定理 sine theorem余弦定理 cosine theorem 不 等 式 算术平均数 arithmetic mean几何平均数 geometric mean比较法 method of compare综合法 method of synthesis分析法 method of analysis 直 线 倾斜角 angle of inclination斜率 gradient点斜式 point slope form截距 intercept斜截式 gradient intercept form两点式 two-point form一般式 general form夹角 included angle线性规划 linear programming约束条件 constraint condition目标函数 objective function可行域 feasible region最优解 optimal solution 圆 锥 曲 线 曲线 curve坐标法 method of coordinate解析几何 analytic geometry笛卡儿 Descartes标准方程 standard equation一般方程 general equation参数方程 parameter equation参数 parameter圆锥曲线 point conic椭圆 ellipse焦点 focus, focal points焦距 focal length长轴 major axis短轴 minor axis离心率 eccentricity双曲线 hyperbola实轴 real axis虚轴 imaginary axis渐近线 asymptote抛物线 parabola准线 directrix"},{"title":"Docker 命令与场景","date":"2019-10-27T11:23:15.000Z","url":"/2019/10/27/Docker-%E5%91%BD%E4%BB%A4%E4%B8%8E%E5%9C%BA%E6%99%AF/","tags":["Docker"],"content":"常用命令 "},{"title":"进程和操作系统的诊断工具","date":"2019-10-23T09:48:42.000Z","url":"/2019/10/23/%E8%BF%9B%E7%A8%8B%E5%92%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/","tags":["JVM","操作系统"],"content":"ps pstree df du TOP 输出 系统态 cpu 时间片占比高，可能意味着系统中存在 race condition，或者有进程在频繁等待底层设备。 用 top 看 cpu，st 意味着物理机上其他虚拟机占用CPU的时间百分比。 符号 含义 18:52:04 当前时间 up 10days, 3:49 系统运行时间，格式为：天，时:分 1 user 当前登录用户数 load average: 0.00, 0.01, 0.05 系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值 当CPU完全空闲的时候，平均负荷为0；当CPU工作量饱和的时候，平均负荷为1。 如果CPU每分钟最多处理100个进程，那么系统负荷0.2，意味着CPU在这1分钟里只处理20个进程；系统负荷1.0，意味着CPU在这1分钟里正好处理100个进程；系统负荷1.7，意味着除了CPU正在处理的100个进程以外，还有70个进程正排队等着CPU处理（load 可以超过 1.0！）。load 其实是 cpu utilization 的一种具象化表示。load 1.0 大致上等于那段时间里 cpu 的 idle time = 0。注意，如果有 4 核 cpu，实际上 cpu 的满负荷是 4.0。 如果只有1分钟的系统负荷大于1.0，其他两个时间段都小于1.0，这表明只是暂时现象，问题不大。 如果15分钟内，平均系统负荷大于1.0（调整CPU核心数之后），表明问题持续存在，不是暂时现象。所以，你应该主要观察”15分钟系统负荷”，将它作为电脑正常运行的指标。 第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下： 符号 含义 total 进程总数 running 正在运行的进程数 sleeping 睡眠的进程数 stopped 停止的进程数 zombie 僵尸进程数 %Cpu(s) 0.0 us 用户空间占用CPU百分比 0.1 sy 内核空间占用CPU百分比 0.0 ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7 id 空闲CPU百分比; 0.0 wa 等待输入输出的CPU时间百分比 0.0 hi 硬件CPU中断占用百分比 0.0 si 软中断占用百分比 0.0 st 虚拟机占用百分比 最后两行为内存信息。内容如下： 符号 含义 KiB Mem 7993560 total 物理内存总量 207064 free 空闲内存总量 723688 used 使用的物理内存总量 7062808 buffer/cache 用作内核缓存的内存量，TODO待详解： KiB Swap 8257532 total 交换区总量 8257356 free 空闲交换区总量 176 used 使用的交换区总量 6479580 avail Mem 缓冲的交换区总量,内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小,相应的内存再次被换出时可不必再对交换区写入 进程信息区统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比。这个数值是针对单核的 cpu 时间统计，如果 cpu 是多核，这个数值有可能超过 100% l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分**(进程数据段+栈+堆)**占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb。 The amount ofshared memory used by a task. It simply reflects memory that could bepotentially shared with other processes. (一个任务使用共享内存的总数。它只是反映可能与其它进程共享的内存)也就是这个进程使用共享内存的大小。 u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程) x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h VIRT 虚拟内存中含有共享库、共享内存、栈、堆，所有已申请的总内存空间。VIRT 实际上是整个地址空间里被使用的大小，包括物理内存，和被映射进虚拟内存的文件空间。VIRT包含了在已经映射到物理内存空间的部分和尚未映射到物理内存空间的部分总和。比如进程 A 的地址空间大概有 10g，已经切出了 4 个内存块一共 2g正在用，也被映射到了物理内存上，还有8g 的内存块还未映射上去，这部分也算在 VIRT 里。有一些人认为 VIRT = RES + SWAP。RES 是进程正在使用的内存空间(栈、堆)，申请内存后该内存段已被重新赋值。 RSS 是进程占用内存页的数量，RES 是进程使用的内存大小，不包括cache。它们都指进程常驻物理内存的大小，但单位不同。SHR 是共享内存正在使用的空间。实际上指的是多个进程的多个逻辑内存页映射到物理内存的同一个物理内存页里，参考这里。SWAP 交换的是已经申请，但没有使用的空间，包括(栈、堆、共享内存)。DATA 是进程栈、堆申请的总空间。 实际上单纯的 top 是不一定看得见进程里的 swap 消耗的。用以下命令可以看。 查看 top 消耗内存的进程 或者 From inside top you can try the following: Press SHIFT+fPress the Letter corresponding to %MEMPress ENTER 如果 load 高但 cpu 使用率低，则意味着等待磁盘I/O完成的进程过多，导致进程队列长度过大，但是cpu运行的进程却很少，这样就导致负载过大，但cpu使用率低。 free（非常重要） total used free shared buffers cached Mem: 16318880 16202128 116752 0131300 11917768 -/+ buffers/cache: 4153060 12165820 Swap: 8386552 0 8386552 所有的数据默认都是 KB，第一行有六个值： total：物理内存大小，就是机器实际的内存 used：已使用的内存大小，这个值包括了 cached 和 应用程序实际使用的内存 free：未被使用的内存大小 shared：共享内存大小，是进程间通信的一种方式 buffers：被缓冲区占用的内存大小，后面会详细介绍 cached：被缓存占用的内存大小，后面会详细介绍其中有 total = used + free下面一行，代表应用程序实际使用的内存： 前一个值表示 - buffers/cached，即 used - buffers/cached，表示应用程序实际使用的内存 - 后一个值表示 + buffers/cached，即 free + buffers/cached，表示理论上都可以被使用的内存-CentOS 里很多内存会被 cached 提前用掉。不难看出来，这两个值加起来也是 total。第三行表示 swap 的使用情况：总量、使用的和未使用的。 选项可以参考：《10 ‘free’ Commands to Check Memory Usage in Linux》 uptime这个命令的输出基本被 top 覆盖了。 uptime 20:33:31 up 390 days, 3:44, 1 user, load average: 0.25, 0.25, 0.18 netstat lsof iotoppmap smapvmstat strace /proc 目录当代 OS X 里没有这个目录。 /proc 目录是一个 unix 常见的伪文件系统（in-memory pseudo-file system）或者虚拟文件系统（virtual file system）-意味着这里面的内容不存在于磁盘上，而存在于内存里，是 runtime 运行态数据。实际上，它是 procfs 在启动时（at boot time）被 mount 到 /proc 目录的结果。 procfs 是进程文件系统 (file system) 的缩写，包含一个伪文件系统（启动时动态生成的文件系统），用于通过内核访问进程信息。由于 /proc 不是一个真正的文件系统，它也就不占用存储空间，只是占用有限的内存。 通过查询这个文件夹下的内容，用户可以获得： 硬件信息 进程运行态信息 实际上 proc目录下的文件，保存的是整个系统的信息。 用户甚至可以通过修改这个文件夹下的内容来改变操作系统的行为。 这个文件夹下很多文件的内容的大小为 0，但都可以 cat-可以理解为从设备里实时读取数据而无法显示文件大小。 如： 常见的条目信息所有文件的信息可以用这个命令查看： 具体内容： /proc/cmdline – Kernel command line information. 内核命令行参数信息-不同于进程命令行参数信息 /proc/console – Information about current consoles including tty. 当前控制台（包括 tty）信息，不是所有 os 都有。 /proc/devices – Device drivers currently configured for the running kernel. 为内核配置的设备驱动。系统已经加载的所有块设备和字符设备的信息； /proc/dma – Info about current DMA channels. DMA 通道信息。 /proc/fb – Framebuffer devices. 帧缓冲设备。 /proc/filesystems – Current filesystems supported by the kernel. 当前内核支持的文件系统 + 节点（nodev）信息 /proc/iomem – Current system memory map for devices. 当前针对设备的内存映射。 /proc/ioports – Registered port regions for input output communication with device. 输入输出设备的注册端口区。 /proc/loadavg – System load average. 系统负载平均值。其前三列分别表示最近1分钟、5分钟及15分的平均负载。反映了当前系统的繁忙情况。 /proc/locks – Files currently locked by kernel.内核当前锁住的文件。 /proc/meminfo – Info about system memory (see above example). 系统的内存信息。常由free命令使用。 /proc/misc – Miscellaneous drivers registered for miscellaneous major device. 为主要 Miscellaneous 杂项设备注册的 Miscellaneous 杂项驱动 /proc/modules – Currently loaded kernel modules. 当前已加载的内核模块。 /proc/mounts – List of all mounts in use by system. 当前系统的所有挂载文件系统。如 /dev/vda1 / ext4 rw,relatime,barrier=1,data=ordered 0 0 /proc/partitions – Detailed info about partitions available to the system. 系统可用分区。如 vda、vdb。块设备每个分区的主设备号（major）和次设备号（minor）等信息，同时包括每个分区所包含的块（block）数目； /proc/pci – Information about every PCI device. pci 设备信息 /proc/stat – Record or various statistics kept from last reboot. 上次重启以来保存的各种各样的记录。 /proc/swap – Information about swap space. swap 空间的信息。和 meminfo 里信息不同。如 /dev/vdb1 partition 2096440 805472 -1。 /proc/uptime – Uptime information (in seconds). 系统 uptime 信息。uptime 命令并不是直接从这里 cat 信息。 /proc/version – Kernel version, gcc version, and Linux distribution installed. 内核版本。 /proc/kcore 物理内存的镜像，它会显示文件大小的，但是不占用实际的磁盘空间，所以，看到该文件非常大，也不用担心。kcore文件的大小等于已被使用的物理内存的大小加上4k，该文件可以使用gdb工具调试以查看内核中的数据结构。 /proc/diskstats 磁盘设备的磁盘I/O统计信息列表; /proc/net/dev 网络流入流出的统计信息，包括接收包的数量、发送包的数量，发送数据包时的错误和冲突情况等。 /proc/version 当前系统运行的内核版本号，在很多发行版中，还会显示系统安装的gcc版本； /proc/vmstat 当前系统虚拟内存的统计数据。 /proc/crypto list of available cryptographic modules 当前内核可用的加密模块，如 crc32c、md5、sha1。 /proc/kmsg holding messages output by the kernel dmesg是 打印内核启动过程的所有信息的命令，实际上就是读的/proc/kmsg也是打印内核的信息。这里存的是内核日志的信息。 /proc/scsi information about any devices connected via a SCSI or RAID controller 通过 SCSI 或者 RAID 控制器连接的设备的信息。 其他详细解释还可以看这里： 中文详解，很有价值Discover The Possibilities Of The /Proc Directory（注意里面对 net 文件夹的解释）Linux Programmer’s Manual PROC(5)Chapter 1. Linux Filesystem Hierarchy 进程目录进程目录下文件的含义： /proc/PID/cmdline Command line arguments. 类似于 ps aux 里每个进程的详细输出。 /proc/PID/cwd Link to the current working directory. 是一个符号链接，指向进程的运行目录；比如启动 tomcat，本质上是在 tomcat 的 webapps 某个目录里启动 /path_to_java/bin/java + jvm 启动参数的执行结果。 /proc/PID/cpu Current and last cpu in which it was executed. 现在和上一个进程用于被执行的 cpu。 /proc/PID/environ Values of environment variables. 所有环境变量的值，去掉了空格等 delimiter。 /proc/PID/exe Link to the executable of this process. 进程的可执行文件，比如 java。 /proc/PID/fd Directory, which contains all file descriptors. 包含所有打开的文件描述符的文件夹。非常大。 /proc/PID/maps Memory maps to executables and library files.可执行文件和库的内存映射（表）。 /proc/PID/mem Memory held by this process. 进程持有的内存。/proc/PID/root Link to the root directory of this process. 到这个进程的 root 目录的链接 - 对于 Java 就是 Java_HOME 变量。/proc/PID/stat Process status. 进程状态信息。内部信息很重要，见： Process memory status information. 见： Process status in human readable form. stat 的可读形式，应该优先读这里，具体细节再去读 /proc/PID/stat。 重点介绍/proc/PID/status的格式： VmPeak 进程所使用的虚拟内存的峰值 VmSize 进程当前使用的虚拟内存的大小 VmLck 已经锁住的物理内存的大小（锁住的物理内存不能交换到硬盘） VmHWM 进程所使用的物理内存的峰值 VmRSS 进程当前使用的物理内存的大小 VmData 进程占用的数据段大小 VmStk 进程占用的栈大小 VmExe 进程占用的代码段大小（不包括库） VmLib 进程所加载的动态库所占用的内存大小（可能与其它进程共享） VmPTE 进程占用的页表大小（交换表项数量） VmSwap 进程所使用的交换区的大小 jvm 自己的本地栈大小可以通过指标看出来。"},{"title":"Redis 笔记之九：理解内存","date":"2019-10-19T06:02:59.000Z","url":"/2019/10/19/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B9%9D%EF%BC%9A%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98/","tags":["Redis"],"content":"内存是昂贵的资源，要合理地使用内存，首先要做到： 理解 Redis 的内存布局，以及它管理内存的方案 思考调优的方案 理解内存而能优化内存。 内存消耗内存使用统计 used_memory:1050880used_memory_human:1.00Mused_memory_rss:2162688used_memory_rss_human:2.06Mused_memory_peak:1051776used_memory_peak_human:1.00Mused_memory_peak_perc:99.91%used_memory_overhead:1037590used_memory_startup:987792used_memory_dataset:13290used_memory_dataset_perc:21.07%allocator_allocated:1005760allocator_active:2124800allocator_resident:2124800total_system_memory:17179869184total_system_memory_human:16.00Gused_memory_lua:37888used_memory_lua_human:37.00Kused_memory_scripts:0used_memory_scripts_human:0Bnumber_of_cached_scripts:0maxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionallocator_frag_ratio:2.11allocator_frag_bytes:1119040allocator_rss_ratio:1.00allocator_rss_bytes:0rss_overhead_ratio:1.02rss_overhead_bytes:37888mem_fragmentation_ratio:2.15mem_fragmentation_bytes:1156928mem_not_counted_for_evict:0mem_replication_backlog:0mem_clients_slaves:0mem_clients_normal:49694mem_aof_buffer:0mem_allocator:libcactive_defrag_running:0lazyfree_pending_objects:0 其中值得关注的值分别是： used_memory Redis 分配器（allocator分配的内存总量，也就是内部存储的所有数据内存占用量-实际上等于被实际使用的不包含内存碎片的物理内存和物理内存） used_memory_human 以可读的形式返回的 used_memory used_memory_rss 以操作系统角度显示 Redis 进程占用的物理内存总量 used_memory_peak 内存使用的最大值 used_memory_peak_human 以可读的格式返回的 used_memory_peak used_memory_lua lua 引擎锁消耗的内存大小 used_memory_lua_human 以可读的格式返回的 used_memory_lua mem_fragmentation_ratio used_memory_rss/used_memory 的比值，这个值越高，物理内存碎片越高-有时候和内存页对齐有关。这个比值越小，证明有很多内存被调度到了 swap 空间里。 实际上 Linux 系统的很多系统指标都有 _human readable版本，Redis 基本模仿了这个设计。 （主进程）内存消耗划分对象内存对象内存是 Redis 内存中占用量最大的一块，实际上我们存储的所有数据都存在这个内存区域。 对象只分为 key 和 value。这一区域的大小大致上等于 sizeof(keys) + sizeof(values)。 keys 都是字符串。values 就是五种基本类型：字符串、列表、哈希、集合和有序集合（bitmap 和 hyperloglog 本质上是字符串，geo 数据是 zset）。 缓冲内存客户端缓冲内存客户端缓冲包括输入缓冲和输出缓冲。 Redis 的输入缓冲是无法控制的，默认就是每个客户端只能使用最多 1G 内存-Redis 的自保比较严格。 而输出缓冲则通过 client-output-buffer-limit 控制。 普通客户端除了复制和订阅客户端以外的所有客户端。 Redis 的缺省配置是 client-output-buffer-limit normal 0 0 0。注意，0 意味着限制被禁用了，这是因为 Redis 认为普通客户端大部分情况下没有很多的数据输出，所以 normal 客户端相当于会有无限大的输出空间。但实际上有些特殊场景下还是需要限制输出缓冲的大小。比如如果客户端使用 monitor 命令，会有大量的输出堆积在 Redis 里，导致 Redis 的内存飙升。解决这个问题有两种思路：调整 maxclients 或者调整 client-output-buffer-limit。 从（Replica）客户端Master 会单独为每个 slave 建立一条单连接。每个链接的默认配置是 client-output-buffer-limit replica 256mb 64mb 60。 其中 256mb 是硬限制，只要一到达连接就关闭。64mb是软限制，只要达到并持续 60s，则连接被关闭。 订阅（ pubsub）客户端尚不明确到底对于同一个 channel的多个 pubsub 客户端是不是共用一个缓冲区。因为 Redis 没有消费组的概念，所有 client 即使是争抢同一个缓冲区也是有可能的-其实这样设计比较自然，因为多个缓冲区可能导致消息的重复 subscribe。另外，如果一个 pubsub 客户端订阅了多个 channels，也是共用同一个连接，这更增加了多个客户端共用一个缓冲区的可能性。其默认配置为： client-output-buffer-limit pubsub 256mb 64mb 60 如上所述，订阅客户端的缓冲区大小会稍微大一些。 复制积压缓冲区所有的从节点共用一个复制积压缓冲区，这个复制积压缓冲区还可以被重用，其大小默认只有 1mb，可以调整到 100mb。这样有了更大的应付网络闪断的内存余量。 AOF 缓冲区AOF 重写期间，Redis 接收写命令不会停，必须使用 buffer-non-blocking的方案 之一就是使用 buffer，这部分 buffer 不能被定制。 内存碎片（Memory Framentation）常见的内存分配器（allocator）有：glibc、tcmalloc和 jemalloc，Redis 使用 jemalloc。 allocator 为了更好地分配内存，一般总是 fixed-size 地分配对齐的内存块。在 64 位内存空间里，jemalloc 会把内存分为小、大、巨大三个范围。每个范围内有若干种大小不一的内存块。分配器会在分配内存的时候，选择尺寸最接近的大内存块分配内存（5kb 的内存通常会被分配在 8kb 的内存块里）。jemalloc 高度优化过内存碎片问题，通常情况下 mem_fragmentation_ratio 接近 1。 但当存储的 value 长短差异较大的时候，以下操作一样可以导致高内存碎片问题： 频繁做更新操作，比如频繁地执行 append、setrange 等更新操作。 大量过期键操作，会在内存空间里留下大量空洞-实际上批量删除键也一样。 为了解决这个问题，可以采取的潜在措施有： 使用数据对齐的内存。 使用 Sentinel 或者 Redis Cluster 的机制进行定期的主从切换，安全重启。 （子进程）内存消耗划分在进行备份的时候，AOF/RDB 重写会 fork 子进程。因为 COW 机制，大部分情况下子进程和父进程共用一段物理内存，在子进程发生写的时候，子进程单独复制一页出来完成写操作。 THP（透明大页）的存在会导致内存拷贝时产生的页非常大，拷贝代价增多，这在写命令很多的时候会造成过度内存消耗。所以和 JVM 相反，应该关闭大页优化。 除此之外，应该设置 vm.overcommit_memory=1，允许内核充分使用物理内存。 内存管理设置内存上限内存管理的上限是 maxmemory，这个阈值是为了保护 memory exhausted，触发各种 policy 准备的 - 缓存场景下特别重要。 动态调整 maxmemory这个值可以被动态修改，方便扩容缩容-JVM 就不可以。如果不设置，Redis 默认 maxmemory 无限大。 内存回收策略删除过期对象Redis 所有的 Key 都可以 expire，key 会被保存在过期字典中（Redis数据库主要是由两个字典构成的，一个字典保存键值对，另一个字典就是保存的过期键的过期时间，我们称这个字典叫过期字典）。 Redis 为了节省 CPU，并不会精准删除 Redis 中的每个 Key，主要采用两个方案： 惰性删除所谓的惰性删除，其实是只有发生特定的事件（读/写）的时候，才进行删除数据，并返回空值（nil）的一种策略。 这样做实际上避免了维护 ttl 链表（类似 Java 中的 LinkedHashMap），节省了 CPU。 惰性删除的缺点是，事件并不一定发生，或者过了很长的时间才发生，内存容易发生泄漏。这可能是所有事件驱动悬垂事件的缺点。 定时任务删除Redis虽然是个单线程架构，但内部维护一个定时任务，默认每秒运行 10 次（可配置，不知道是不是 event loop 实现的）。 其基本流程为： 以慢模式启动。 每次执行时针对每个 db 空间随机采样 20 个 key，进行超时检验并删除 key，并采样统计。 如果没有 25% 的 key 过期，任务退出。 否则循环执行删除 key 的操作。 如果最终执行超过 25 ms 或者统计数据低于 25%以后，直接退出。 否则每次 Redis 事件发生以前用快模式删除 Key。 快模式和慢模式的流程一样（也就是和上面一样），但超时时间短很多，只有 1ms，且 2 s 内只能运行一次。 内存溢出控制策略内存使用量(实际上应当是去掉缓冲区内存后的对象内存)一旦到达 maxmemory，Redis 就要开始 evict 操作。基于 maxmemory-policy，Redis 一共有 6 种策略： noeviction：默认策略。拒绝写入任何数据而报错。 volatile-lru：根据 LRU 算法删除设置了 expire 的键，直到腾出空间为止。如果没有可删除的对象（了），回退到 noeviction。 allkeys-lru：对全 key 进行 lru 删除，直到腾出空间为止-这也就意味着不设置 expire 也能区分出 lru 的键来，这也意味着 Redis 可以当做准成的 lru cache 用。 volatile-random：随机删除过期键，直到腾出空间为止。 volatile-ttl：根据键值对的 ttl 属性，删除最近将过期的数据。如果（要有 expire 才有 ttl）没有，回退到 noeviction。 每次执行命令时，Redis 都会检查 maxmemory，尝试进行内存回收工作。内存回收造成的 delete 还会被同步到从节点，造成写放大-凡是主从模式都要考虑写放大问题。 因为这个值可以动态调整，所以可以动态触发 Redis 缩容，这是 JVM 做不到的。 内存优化redisObject 对象Redis 中的值对象在内部定义为 redisObject 结构体。 其内容为： type：type 会返回value（not key）的数据类型。 encoding：同一种类型的 value，使用不同的 encoding 差别也会非常大。 lru：记录对象被最后一次访问的时间。这对allkeys-lru 和 volatile-lru 场景下特别有用。 refcount 记录当前对象被引用的次数。refcount=0 意味着对象可以被安全回收。 *ptr 如果是整数则储存整数，否则指向数据内存段。 缩减键值对象应该尽量减少 key 和 value 的长度。 在完整描述业务的情况，key 越短越好。 value 应该被序列化前尽量精简对象，使用最好的序列化算法+压缩算法（考虑 snappy）。 共享对象池共享对象池就是整数对象池，不像 JVM，不存在其他类型的对象池。 类似 Java 中的字符串 intern 池和 wrapper cache，Redis 会自动复用[0-9999]的整数对象池。5 种类型的 value 一旦涉及整数，也会引用整数对象池。 使用 127.0.0.1:6379&gt; set foo 2OK127.0.0.1:6379&gt; object refcount foo(integer) 2147483647 这个对象池的大小可以通过 REDIS_SHARED_INTEGERS 来定义，不能config set。类似 JVM。 如果 maxmemory-policy 为 volatile-lru 或者 allkeys-lru，整数对象池会无效化，否则这两种策略无法好好工作。 字符串优化字符串没有使用 c 语言的字符串类型，而使用了 sds（simple dynamic string： 大量操作时间复杂度O（1）。 可保存字节数组 有预分配机制-会在 append 场景下造成内存损耗。 有惰性删除机制。 某些场景下，使用 hash 来重构字符串类型的数据结构更节省内存。 编码优化Redis 的特点就是“all in memory”。 可以使用config set来调整某些类型的内部编码的阈值，使数据编码从压缩编码（小编码）向非压缩编码转换（大编码）。其中 ziplist 是一种特别优秀、紧凑的数据结构，会使用线性连续的内存。 重点值得用是 ： ziplist（list，hashtable，zset 都可以用），节省内存但规模大了以后消耗 cpu intset 节省内存 "},{"title":"JDK 收费问题","date":"2019-10-18T09:45:30.000Z","url":"/2019/10/18/JDK-%E6%94%B6%E8%B4%B9%E9%97%AE%E9%A2%98/","tags":["JVM","Java","JDK"],"content":" 现有的JDK8，2019.1之前的更新都可以免费获取正常使用。 Oracle JDK11是一个长期支持的版本，用于商业环境需要付费。 OpenJDK11 可免费用于商业环境，但Oracle只提供6个月的更新支持。 Zulu是Azul公司基于OpenJDK发布的Java SE产品，它没有Oracle JDK对使用场景上的诸多限制，可以放心免费下载和使用。它的核心部分就是原汁原味的OpenJDK，没有任何额外的改动——Azul有时候也会对OpenJDK做bug fix，但这些都是通过提交回到OpenJDK去然后再进入到Zulu Java SE产品中的。它与“自己下载OpenJDK源码，自己build”的最大区别是：Azul会在每次发布Zulu产品之前进行充分的测试，build出来的二进制版本符合Java的兼容性测试；同时，Azul有与Oracle签订合作协议，在critical security fix的方面会比公开发布的OpenJDK源码要更早获得补丁，提前做好build与测试工作，基本上可以跟Oracle在同一时间发布打了security patch的版本，解决zero-day漏洞问题。 "},{"title":"Redis 笔记之八：复制","date":"2019-10-07T08:05:24.000Z","url":"/2019/10/07/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%85%AB%EF%BC%9A%E5%A4%8D%E5%88%B6/","tags":["Redis"],"content":"在分布式系统中为了解决单点问题，必须建立副本复制机制，以解决容灾和负载均衡问题。 配置建立复制建立复制共有三种方法： 在配置文件中使用如下的配置：slaveof localhost 6379 在启动时使用如下命令：redis-server –slaveof localhost 6379 在 redis-cli 中对服务端使用 slaveof localhost 6379 而在主节点里可以查看自己的主从信息： 可以看到自己的角色： role:master 而从节点则会看到： role:slave 断开复制可以使用如下命令断掉与 master 的联系： 本节点断开和 master 的连接。 本节点自己上升为 master。 也可以使用如下命令切换 master： 如果新 master 不同于老 master，老 master 的数据会被清理掉。 安全性主节点可以设置 requirepass 参数进行验证，这时所有的客户端访问必须使用 auth 命令进行校验。 只读从节点（默认）使用 slave-read-only = yes 来保证从节点是只读模式的。在生产上最好保持这种不能允许从节点写的模式，否则会导致数据不一致。 传输延迟关闭 repl-disable-tcp-nodelay 可以降低延迟，但整体带宽使用比较大。 拓扑一主一从 这种思路是把 slave 当做 standby，只在从节点打开持久化（RDB 或 AOF）。这种场景如果主节点重启，则主节点会自动清空数据（因为没有打开持久化-实际上如果没有打开 AOF 持久化，Redis 的优雅关闭也会回退到 RDB 持久化），从节点也可能清空数据。为了预防这种情况出现，在主节点重启以前从节点要slaveof no one断开主从复制-但这种措施无法阻挡主节点宕机引起的数据丢失。 这种一主一从的架构设计和 MySQL 的主从复制很相似，但只打开一端持久化的思路还是比较特别的，不那么安全。而且主节点 flush 数据会导致从节点也 flush 数据，本身也是一种很危险的行为 一主多从 这种拓扑又被叫做星形拓扑。这种拓扑比较像 MySQL 的读写分离设计，主节点承担写命令的操作，而从节点也分担读命令的操作，。其中还可以设计一些特殊的读节点，专门执行 keys，sort 操作。但这种操作会占用太多的网络带宽。 树状结构 这种树形架构通过分层架构来分层放大流量，平衡了带宽和冗余复制的需要，但下层的节点的同步时延变大了。 原理[Redis 内存划分.xmind](Redis 内存划分.xmind) 过程1 如果使用配置文件配置主从关系，这一步几乎可以说是一闪而过。这一步只保存 master 的 ip 和 port 。如果这个时候从 master 节点去看 client 信息的话，会看到一个刚刚建立的 client（从主节点的角度来看，从节点实际上也是client，类似某些 kafka 的数据迁移方案迁移的端点把自己伪装成一个 consumer）。 2 从节点内部有个每秒运行的定时任务（大致上是一个定时线程）维护复制相关逻辑，当定时任务发现新的主节点后，会尝试与该节点建立网络连接。从节点会单独打开一个 port（而不是当前从节点的 server 的 port），尝试建立新的 socket。所以 Redis 的主从复制的连接建立是一个拉过程。 34020:S 06 Oct 2019 23:09:28.709 * Connecting to MASTER localhost:637934020:S 06 Oct 2019 23:09:28.712 * MASTER &lt;-&gt; REPLICA sync started 这个过程如果失败，可以在日志中看到以下错误： 34020:S 06 Oct 2019 23:09:38.086 * MASTER &lt;-&gt; REPLICA sync started34020:S 06 Oct 2019 23:09:38.086 # Error condition on socket for SYNC: Connection refused 从节点会无限重试，直到成功或者主从关系被切断为止。 3 从节点会发送 ping，验证： 连接的 socket 是否正常 主节点是否能正确响应命令 如果验证成功，能收到： Master replied to PING, replication can continue… 4 权限验证 如果 master 配置了 requirepass 参数的话，从节点要配置 masterauth 参数来保证密码一致。 5 同步数据集 分为全量同步和部分同步两种策略。6 命令持续复制 数据集同步完成后。主节点会把自己收到的写命令，持续发给从节点。 同步数据集注意，全量复制和部分复制都属于同步数据集的一部分，后续的写命令持续发送不是部分复制。 全量复制（Full resync）在初次复制的场景下，Redis 会使用全量复制策略（对应 Redis 旧版本唯一用于复制的 sync 命令）。主节点的数据会被一次性全部发送给从节点，造成主从节点和网络的很大开销。 一般从节点会打印如下的日志： 34020:S 06 Oct 2019 23:09:39.128 * MASTER &lt;-&gt; REPLICA sync started34020:S 06 Oct 2019 23:09:39.128 * Non blocking connect for SYNC fired the event.34020:S 06 Oct 2019 23:09:39.128 * Master replied to PING, replication can continue…34020:S 06 Oct 2019 23:09:39.129 * Partial resynchronization not possible (no cached master)34020:S 06 Oct 2019 23:09:39.130 * Full resync from master: 3e6a48b3ce0d87851c0882f4120145a0d7611f0d:034020:S 06 Oct 2019 23:09:39.181 * MASTER &lt;-&gt; REPLICA sync: receiving 175 bytes from master34020:S 06 Oct 2019 23:09:39.182 * MASTER &lt;-&gt; REPLICA sync: Flushing old data34020:S 06 Oct 2019 23:09:39.182 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory34020:S 06 Oct 2019 23:09:39.182 * MASTER &lt;-&gt; REPLICA sync: Finished with success 证明了部分复制不可能，必须打开全量复制。注意PID 34020:S意味着当前 节点是个 Slave（M意味着 Master 而 C 意味着子进程）。 其全流程如下： 注意： 主节点和从节点之间的 复制超时时间一般为 60s，如果数据量很大要调高这个超时阈值，否则从节点会放弃全量复制。- 不要复制太大的数据量！否则就要调高超时 主节点在生成 rdb 的过程中，还在不断接受新的命令（因为 bgsave 是由子进程进行操作的），这些新的命令会被保存在一个单独的客户端复制缓冲区里面（注意，和部分复制的replication-backlog 不一样，这里的 buffer 属于未被发送的命令的 buffer）。在 send RDB 以后还要单独再 send buffer 一遍。 从节点得到了一个完整的 RDB 文件以后要先 flush old data，然后再进行 load，这个全过程都是阻塞的-这也是 MySQL 不具有，Redis 独有的。 如果从节点自己开启了 AOF 功能，为了保证同步完成以后 AOF 文件立刻可用，先启动一段 bgrewriteaof，子进程 rewrite 完成以后全量复制才算收尾-增加了阻塞点。 全量复制过程中，子节点的数据可以算是 stale 的。如果关闭了 slave-serve-stale-data，则全量复制过程中从节点是不接受读命令的（写命令更加不会被接受），属于完全阻塞状态。 部分复制（partial replication）在出现网络闪断等情况时，主节点可以只发送一部分数据给从节点以弥补丢失，效率会很高。 普通的主从建立时，会出现若干次部分复制失败的日志，最终会直接通过全量复制成功-Redis 会优先考虑部分复制的策略。 psync命令需要组件支持以下特性： 主从节点各自复制、保存偏移量 主节点复制积压缓冲区 主节点运行 id 复制偏移量主节点在自己完成写入后，会累加并保存自己的本地 offset。从节点每次完成复制后，也会上报自己的 offset 到主节点中。所以主节点保存了所有节点的偏移量。 而同步了写命令后，从节点也会累加并保存自己的 offset。 对比主从节点的 offset 的差值可以知道复制延迟多大，从而判定系统健康程度。 复制写命令到复制积压缓冲区Redis 会针对每个 client 准备一个固定长度的队列- replication-backlog，默认大小为 1mb 作为复制积压缓冲区。所有写命令在被发送给从节点的同时，也会被发送到这个队列里。这个队列实际上记录了已被复制的命令，可以作为日后补偿部分丢失写命令的依据。 注意，这个缓冲区是已被发送的命令数据的缓冲区，只是为了重放闪断数据用的，和全量复制里的 send buffer 用到的 buffer，也不保存复制完以后持续同步的后续命令。 主节点运行 id每个 Redis 节点都会有一个 40 位的 16 进制字符串来唯一识别节点。 如果主节点重启（必然？）替换了 RDB/AOF 文件（比如两种文件的重写？）的时候会导致节点 id 变化，从节点已经不适用老的 offset， 从节点会重新进行全量复制。-所以尽量不要随便重启主节点 psync 命令psync 命令要求 Redis 2.8 以上版本，它同时兼容全量复制和部分复制。 其格式如下： runId 为待复制的主节点 id，offset 为已复制的数据偏移量（如果是全量复制，其值为-1）。 从节点发送 psync 命令给主节点，主节点回复不同内容的响应给从节点： FULLSYCN {runId} {offset} 从节点将开始全量复制 +CONTINUE 从节点触发部分复制 +ERR 主节点的版本低于 2.8，要从 sync 命令开始重新触发全量复制。 全流程 普通的全量复制，一旦遇到网络闪断，肯定会触发超时复制失败，浪费大量的系统开销。但拥有部分复制的流程，在网络中断后，可以尝试用部分复制来修复小部分数据（默认 1MB）。 部分复制只能发送 replication-backlog 里的数据，如果超出了这个缓冲区的范围，复制就会直接像普通的全量复制超时一样失败，然后重启一个新的全量复制。 心跳主从会相互维护心跳监测： 主从会互相模拟成各自的客户端进行通信，也就是会出现在对方的 client list 里。只不过主节点的 flags=M，而从节点的 flags=S。 主节点定时发送 ping 命令到各个从节点。 从节点定时上报自己的复制偏移量（实际上主从节点都会保存很详细的彼此的进度信息，特别lastest、last 之类的信息，这点同 hdfs、 MySQL 一样，值得学习）。 （后续）命令持续（异步）复制主节点接下来响应写命令，直接返回客户端写结果，而不受从节点复制结果的影响-如何防止这一步数据丢失？应该还存在若干 offset 回溯的功能来预防这个问题。 开发运维中的问题读写分离数据延迟这个问题是由架构和网络通信的特性决定的，不可避免。我们能够做的就是设立多种监控措施，不断用轮询的方式来发现超高的 lag 及时报警人工干预。 读到过期数据低版本的从节点不会主动删除数据，除非它收到主节点的 del 命令。高版本的从节点在读取数据的时候也会检查数据是否已经超时，如果没有超时则 主节点删除超时数据有两种策略。实际上现实中的系统必须混合使用两种策略才能安全删除。 惰性删除（用时/读时删除）在收到读命令的时候检查超时阈值，如果已超时则主动删除，且返回 nil 给客户端，并同步 del 命令到从节点。 实际上 Java 的 weakHashMap 也是采用这种策略来维护自己的数据集的。 定时删除主节点内部有一个定时任务循环采样数据，发现采样的键过期执行 del 命令，之后再同步到从节点。 从节点故障如果自己做水平扩展，则故障转移方案（特别是从节点失效的问题）要自己做。所以可以上 Redis-Cluster 这样的现成方案。 主从配置不一致如果主从的配置不一致，从节点可能无法像主节点一样正常工作。特别是从节点的 maxmemory 不如主节点大的时候，从节点可能会发生内存淘汰而丢失部分数据。-主从节点最好有一样的容量。 规避全量复制全量复制非常耗费资源，应该注意几个问题： 首次复制应该与业务高峰期错开。 避免主节点重启导致从节点全量复制，这种情况可以考虑提升从节点为主节点。 合理规划配置，避免挤压缓冲区不足，部分复制失败回退回全量复制。 规避复制风暴Redis 针对主节点做过专门优化，使得多个从节点可以共用针对第一个从节点生成的 RDB 文件。但还存在其他问题，值得注意： 应该尽量避免单一主节点复制多个从节点，使用树形架构来节约主节点的带宽。 打散多个主节点，避免多个节点一起容灾（同时重启开始复制会拖垮CPU、内存、硬盘和带宽）。 "},{"title":"Redis 笔记之七：持久化","date":"2019-10-06T14:46:08.000Z","url":"/2019/10/06/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%83%EF%BC%9A%E6%8C%81%E4%B9%85%E5%8C%96/","tags":["Redis"],"content":"持久化可以避免进程退出而数据丢失。 Redis 的持久化文件主要包括两种格式，RDB 格式和 AOF 格式，这两种格式的生成机制各有不同。 Redis 在重启时优先加载 AOF 文件（因为 AOF 文件颗粒度更细），如果没有 AOF 文件可加载则加载 RDB 文件。 RDBRDB 持久化会把进程内的数据全量快照保存到硬盘上，其触发方式包括手动触发和自动触发。 手动触发 bgsave 的工作流程如下： 注意，RDB 文件本身永远只有一个。子进程产生的都是临时文件，会通过原子替换的方式来维持 RDB 文件的唯一性。 Redis 内部主动生成 RDB 文件的过程都是采用 bgsave 的方式。 自动触发 在 config 里配置save m n。表示 m 内数据集存在 n 次修改时，自动触发 bgsave。 如果从节点执行全量复制操作，主节点自动执行 bgsave生成 RDB 文件并发送给从节点。 执行 debug reload 命令重新加载 Redis 时，也自动触发 save 操作。 默认情况下执行 shutdown 命令时，如果没有开启 AOF 持久化功能，则自动执行 bgsave-Redis 自带的优雅关闭流程。 RDB 文件的存储默认会存在 config set dir &#123;newDir&#125;和config set dbfilename &#123;newFileName&#125;的文件里。也可以动态修改（）比如在硬盘出问题的时候动态修改）。 默认情况下会对 RDB 文件进行 LZF 压缩处理（可以关闭）。压缩会消耗 CPU 性能，但利于网络传输。 RDB 的优缺点优点： 紧凑存储，适于全量保存/恢复。 加载 RDB 的速度远快于 AOF 文件。 缺点： 没有办法强实时/秒级持久化。 版本不兼容 AOF（append only file）以独立的日志（log）记录每次写命令，重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 具有持久化的强实时性，是 RDB 的补充。 配置方式需要设置appendonly yes（默认不开启），开启后就会被自动触发（也就是说无需手动触发）。可以修改文件名和路径。 工作流程aof 的工作流程如下： 其中： append 其实是把写命令写入 aof_buf 中。 sync 是把写入命令从内存持久化到硬盘中。 rewrite 则会压缩重写 AOF 文件使其达到更紧凑的目的。 当 Redis 重启后，可以加载 AOF 文件进行数据恢复。 其中被持久化的命令，是纯文本的格式，遵循 RESP 协议。 文件同步Redis 本身是个单线程架构，如果每次新的写命令都要写入硬盘，则硬盘的负载能力可能成为一个瓶颈。而如果先写入一个 aof_buf，则可以采取多种策略持久化数据到硬盘中。 这提醒我们，对于零散的多次写 IO，我们都要想办法化零为整，通过 buffer-sync 的分段异步写形式充分协调内存和硬盘的写性能。 我们可以采用的策略分别是： always 命令写入 aof_buf 后调用系统 fsync 操作同步到 AOF 文件，fsync 完成后系统返回。等于一个强实时的策略。在 sata 上只有几百的 tps。 everysec 命令写入 aof_buf 后调用系统 write 操作，write 完成后线程返回。fsync 操作由专门线程每秒调用一次。等于一个中等实时的策略。默认策略，最多丢失 1s 的数据 no 命令写入 aof_buf后调用系统 write 操作，而不对 AOF 做 fsync 同步操作， fsync 同步操作由操作系统负责，通常同步周期最长 30 秒。无法保障同步实时性。 write 其实是一种 delaywrite，写入操作系统的页缓冲区以后线程会立即返回（阻塞期很短），依赖于系统的调度（如时间阈值满或者空间阈值满，期间如果系统宕机则数据会丢失）或者 fsync才能真正持久化到硬盘中。fsync 就是强行同步到硬盘的syscall，阻塞时间会稍长，但持久化更彻底。 重写机制重写主要通过有效地去除无用命令、合并多条有效命令的方式使得 AOF 文件变得更小，更利于加载。 重写（只是重写这个过程）也同样包括手动触发和被动触发两种机制。 重写流程： 其中同时存在两个 aof 文件，新的 aof 文件也会进行一个原子替换。 手动触发 自动触发if (aof_current_size &gt; auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size)/aof_base_size &gt;= auto-aof-rewrite-percentage) auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 是配置文件的配置项。 相关问题fork 问题fork 调用会让子进程调用父进程的内存页表，理论上一个进程占用内存越大，它的 fork 命令就越耗时，而且有些虚拟机（如 xen）里 fork 的性能还更差。 性能优化点cpu 不要和其他 cpu 密集型应用部署在一起。 如果部署多个 Redis 实例，保证每个时刻只有一个后台进程在工作。 内存 如果部署多个 Redis 实例，保证每个时刻只有一个后台进程在工作。 不要增加 copy-on-write 的负担，尽可能让子进程少一些后台重写的负担（如何做到？）。 关掉大页（huge page）优化-和 JVM 的优化策略正好相反。 硬盘AOF 对硬盘的写压力更大。 AOF 追加阻塞此外，AOF 体系还存在一个追加阻塞的问题，其流程如下： 可以看到，主线程如果在写入 AOF 缓冲区时如果上次 fsync 成功的时间（所谓的 checkpoint）还在两秒内，则会持续写入 AOF 缓冲区。这时候 AOF 缓冲区是不安全的。所以实际上 AOF 机制最多会丢两秒内的信息。而如果主线程阻塞，则 Redis 的性能会急剧下降。 至此为止，我们至少有三种潜在的性能瓶颈：save、fork 和 AOF 的 append 造成的阻塞。"},{"title":"Redis 笔记之六：客户端","date":"2019-10-06T09:59:44.000Z","url":"/2019/10/06/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%85%AD%EF%BC%9A%E5%AE%A2%E6%88%B7%E7%AB%AF/","tags":["Redis"],"content":"Redis 协议Redis 的客户端和服务器端使用 TCP 直连，基本的协议都是一问一答（request and response） 形式的。但它发送的请求是遵循特定的应用层协议（Redis Serialization Protocal）的。 一个请求如下： *3 代表 3 个参数（SET KEY VALUE）。 $3 代表紧随其后的参数长度为 3 字节。 每一段可见字符都必须以一个CLRF(\\r\\n)结尾。 而返回值也有格式： 状态回复，在 RESP 中第一个字节为“+”。 错误回复，在 RESP 中第一个字节为“-”。 多条字符串回复，在 RESP 中第一个字节为“”。 整数回复，在 RESP 中第一个字节为“:”。 字符串回复，在 RESP 中第一个字节为“$”。 多条字符串回复，在 RESP 中第一个字节为“”。 Jedis 客户端使用的时候要注意配上 try-finally 块，小心连接泄漏。 也可以使用连接池，也要注意规划，连接池一样可以造成连接泄漏。 客户端管理 redis 服务端为每个客户端分配一个输入缓冲区（默认大小为 1G，而且不受 maxmemory 的限制）。输入缓冲区满了以后，客户端可能会被关闭。 与客户端相关的几个参数： tcp-keepalive 默认值为 0，即 Redis 不检查死连接。如果设置为 60，则 Redis 会定期清理死连接，防止僵尸连接占用资源。 tcp-backlog tcp 接受连接的总数的大小，默认值为 511。这个值也受 OS 的内核参数控制，可以修改/proc/sys/net/core/somaxconn。 监控内存过大的思路消耗的内存如果接近了 maxmemory，则可以按照以下步骤来排查问题： 确认各个主从节点的 dbsize 是否一样。 使用info clients来输出内存消耗信息，确认输入输出缓冲区的大小。 使用redis-cli client list | grep -v &quot;omem=0&quot;查找消耗内存比较多的 client。 检查是否有慢查询-注意查询 slowlog，或者遇到 slowlog 的时候直接报警。 "},{"title":"Redis 笔记之五：Redis小功能","date":"2019-10-05T08:31:59.000Z","url":"/2019/10/05/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%94%EF%BC%9ARedis%E5%B0%8F%E5%8A%9F%E8%83%BD/","tags":["Redis"],"content":"慢查询命令执行的典型过程 发送命令 命令排队 命令执行 返回结果 慢查询值统计 step3 的执行时间，即使没有慢查询，客户端也可能超时。 阈值参数相关的阈值参数分别为：slowlog-log-slower-than和slowlog-max-len。 查询结果 (integer) 7 (integer) 1570264725 (integer) 7 “SLOWLOG” “get” “0” “127.0.0.1:49802” “” 慢日志的格式为：1 慢日志id2 日志发生的时间戳3 命令耗时4 命令详情5 客户端地址6 客户端的名称 参考： 最佳实践1 调大 slowlog-log-slower-than 到1毫秒左右，可以保证 1000 的QPS（实际上在单台 mac pro上的 rps 可以达到接近10万）。2 调大 slowlog-max-len，并定期把其中的数据取出来存入其他存储层。3 如果发生客户端超时，注意对照相应的时间点，注意查看是不是存在慢查询导致级联失败。 Redis Shellredis-cli redis-server redis-benchmark pipeline如上所述，Redis 命令执行流程是： 发送命令 命令排队 命令执行 返回结果 1+4 的耗时统称为RTT（Round Trip Time，往返时间）。 当我们把多个命令合并到一个 RTT 里的时候，可以使用 pipeline。 原生批量命令和 pipeline 的差异是： 原生批量命令是原子的，pipeline 是非原子的。 原生批量命令是一种操作针对多个 key，而 pipeline 是更高层的组合，一个流水线组合多个批量命令。 原生批量命令只靠 Redis 服务端即可实现，pipeline 需要服务端和客户端共同实现。 事务Redis 支持简单的事务（multi-exec）以及 lua 脚本。 简单事务（multi-exec）一个基本的例子 放弃提交（而不是回滚）的例子： 被 queue 的命令因为被抛弃所以没有被执行。 除此之外，如果命令本身有语法错误，如把 set 写成了 sset，可以在 queue 的时候被检测出来，则事务整体都不会被执行。我们只能得到 EXECABORT 错误。 但是，如果命令本身有运行时错误，比如对错误类型的value 进行了错误的操作（对 list 执行了 zadd 操作），则已经执行成功的命令是不会被回滚的！ 上面的操作本身会部分操作成功。可见 Redis 虽然声称这个特性是一个 transacion，但并不具备标准的数据库事务的原子性。 乐观锁在 Redis 中使用 watch 命令可以决定事务是执行还是回滚。一般而言，可以在 multi 命令之前使用 watch 命令监控某些键值对，然后使用 multi 命令开启事务，执行各类对数据结构进行操作的命令，这个时候这些命令就会进入队列。 当 Redis 使用 exec 命令执行事务的时候，它首先会去比对被 watch 命令所监控的键值对，如果没有发生变化，那么它会执行事务队列中的命令，提交事务；如果发生变化，那么它不会执行任何事务中的命令，操作结果就是 nil。 我们也可以使用事务来获取多重结果： LuaRedis 提供 eval 和 evalsha 两种方法来调用 Lua 脚本。 lua 脚本拥有以下优点： 可以提供原子执行的能力，执行过程中不会插入其他命令。 可以提供自定义命令的能力。 可以提供命令复用的能力。 我们可以自由建模，然后打包一个组合脚本进行组合之间的运算-所以可以 组合使用各种原子 API 来实现复杂计算。 eval call 如果遇到错误，则脚本执行会返回错误。如果需要忽略错误执行，需要使用 pcall。 除了 redis.call 以外，还可以使用 redis.log 来把日志打印到 redis 的日志文件里，但要注意日志级别。 如果脚本比较长，可以考虑使用外部文件，配合 –eval 选项来执行。 Redis 的高版本里自带 lua debuger。 evalsha这个功能可以实现 lua script 的复用，其基本流程为： 将 lua 脚本加载到服务器端，得到脚本的 sha1 指纹。 evalsha 可以使用 sha1 指纹来复用脚本，避免重复发送脚本到服务器端的开销。 管理 lua 脚本 位图详细的用法见位操作命令。 它的用例比较有意思，一个典型的用例是，统计一个大型社交网站的所有成员的具体登录信息。我们可以统计每天都产生了多少登录，最小的登录 id 是什么，最大的登录 id 是什么。但位图也不是万能的，如果位图很稀疏，则不如转为一个 list 或者 set 会更省内存-这需要做内存测试。 HyperLogLogHyperLogLog 并不是新的数据结构，而是字符串与基数算法（cardinality algorithm）的结合。 HyperLogLog 本身极省内存，但数据量变大后，pfcount 会变得不准，最多有 0.81%的失误率。 HyperLogLog 具有以下特点： 不能取出存入数据。 计数不准，近似准确。 极省内存。 在现实之中，bitmap、HyperLogLog和传统的 set 可以视场景交替使用或者配合使用。比如 bitmap 标识哪些用户活跃，hyperloglog计数。 发布（publish）/订阅（subscribe）在老版本的 Redis 里，开发者可以通过 list 这一数据结构来模拟消息队列中间件，但后来 Redis 提供了发布订阅功能。这一功能清晰地解耦了发布者和订阅者，两者不直接通信，发布者客户端）向指定的频道（channel）发布消息，订阅改频道的客户端都可以收到该消息。 值得注意的亮点分别是： 客户端在执行订阅命令后就进入订阅状态，只能接收 subscribe、psubscribe、unsubscribe 和 punscribe 四个命令。 新开启的客户端，无法收到该频道之前的消息，因为 Redis 不会对发布的消息进行持久化。–消息既无法堆积（accumulate），也无法回溯（backtrace）。 GEO（地理信息定位）Redis 的 GEO 可以用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能。 此外还可以对 geo 集合的成员求geohash。 geohash 的长度越长，精度越精确。 两个 geohash 越相似，距离越近。 "},{"title":"架构整洁之道笔记","date":"2019-09-26T11:49:28.000Z","url":"/2019/09/26/%E6%9E%B6%E6%9E%84%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E7%AC%94%E8%AE%B0/","tags":["系统架构"],"content":"思维导图： 附件下载： xmind"},{"title":"Petroware 的 Unit Testing Guidelines","date":"2019-09-09T13:43:31.000Z","url":"/2019/09/09/Petroware-%E7%9A%84-Unit-Testing-Guidelines/","tags":["Test"],"content":" Keep unit tests small and fast Ideally the entire test suite should be executed before every code check in. Keeping the tests fast reduce the development turnaround time. 让单元测试保持小和快。 最完美的是，整个测试套件应该在每次代码被签入的时候被执行。让测试保持快速减少了开发的周转时间。 点评：小的测试是低成本测试。 Unit tests should be fully automated and non-interactive The test suite is normally executed on a regular basis and must be fully automated to be useful. If the results require manual inspection the tests are not proper unit tests. 单元测试应该是全自动化且无交互的。 单元测试总是被正式运行在常规基础之上，且必须被全自动化才能有用。如果结果需要手动检查，测试并不是恰当的单元测试。 点评：测试应该自动化。 Make unit tests simple to run Configure the development environment so that single tests and test suites can be run by a single command or a one button click. 让单元测试运行简单。 配置开发环境使得单一测试和测试集可以通过一个命令或者一键执行。 Measure the tests 测量测试。 Apply coverage analysis to the test runs so that it is possible to read the exact execution coverage and investigate which parts of the code is executed and not. 对测试运营应用覆盖率分析，这样就可以读到精确的运行覆盖率，并调查哪一部分代码被运行了，哪一部分没有。 点评：测试要带给我们结论。哪里有 bug，哪里没有。那些 code path 是可达的，哪些 code path 是不可达的。 Fix failing tests immediately 立即修复失败测试。 Each developer should be responsible for making sure a new test runs successfully upon check in, and that all existing tests runs successfully upon code check in. If a test fails as part of a regular test execution the entire team should drop what they are currently doing and make sure the problem gets fixed. 每个开发者必须负责使新测试一被签入就运行成功，且所有存量测试也在签入后运行成功。 如果一次常规测试执行中，一个测试失败了，整个团队应该丢下手头的事情，确保问题被修复。 点评：测试要有回归分析。 Keep testing at unit level 保持测试在单元级别。 Unit testing is about testing classes. There should be one test class per ordinary class and the class behaviour should be tested in isolation. Avoid the temptation to test an entire work-flow using a unit testing framework, as such tests are slow and hard to maintain. Work-flow testing may have its place, but it is not unit testing and it must be set up and executed independently. 单元测试是关于测试类的。每个普通的类应该有一个测试，且类的行为应该被隔离测试。要抵御用一个单元测试框架来测试整个工作流的诱惑，因为这样的测试缓慢且难于维护。自有进行工作流测试的地方，而不是在单元测试里，它必须要被独立设置起来执行。 点评：小的测试才是可以维护的。 Start off simple从简单开始 One simple test is infinitely better than no tests at all. A simple test class will establish the target class test framework, it will verify the presence and correctness of both the build environment, the unit testing environment, the execution environment and the coverage analysis tool, and it will prove that the target class is part of the assembly and that it can be accessed.The Hello, world! of unit tests goes like this: 一个简单的单元测试绝对好于没测试。一个测试类会建立目标测试框架，它会校验构建环境/单元测试环境/执行环境/覆盖率分析工具的存在性和正确性，它会证明目标类是集合的一部分，且可以被访问。单元测试的 Hello, world! 如下： 点评：有胜于无，1胜于0。 Keep tests independent 保证单元测试独立 To ensure testing robustness and simplify maintenance, tests should never rely on other tests nor should they depend on the ordering in which tests are executed. 为了保证鲁棒性并简化维护工作，测试绝不可依赖其他测试或者它们彼此之间的执行顺序。 点评：测试要独立。还是为维护性服务。 Keep tests close to the class being tested 让测试紧随被测试类 If the class to test is Foo the test class should be called FooTest (not TestFoo) and kept in the same package (directory) as Foo. Keeping test classes in separate directory trees makes them harder to access and maintain.Make sure the build environment is configured so that the test classes doesn’t make its way into production libraries or executables. 如果被测试类是 Foo，测试类应该叫 FooTest （而不是TestFoo），并且放在同 Foo 的一个包（目录）下。把测试类放在另一个目录树下让它们难以被触达和维护。 保证构建环境被配置过，所以测试类不会被放进生产库或者可执行文件里面。 点评：测试要和被测试的类紧密相连，概念上才连续，更好维护。 Name tests properly 恰当地命名测试。 Make sure each test method test one distinct feature of the class being tested and name the test methods accordingly. The typical naming convention is test[what] such as testSaveAs(), testAddListener(), testDeleteProperty() etc. 确保每个测试方法测试被测试类的一个截然不同的特征，并因应命名测试方法。典型测试惯例是test[什么]，例如 testSaveAs(), testAddListener(), testDeleteProperty() 等等。 点评：测试要和被测试的类紧密相连，概念上才连续，更好维护。同上。 Test public API 测试公共 API。 Unit testing can be defined as testing classes through their public API. Some testing tools makes it possible to test private content of a class, but this should be avoided as it makes the test more verbose and much harder to maintain. If there is private content that seems to need explicit testing, consider refactoring it into public methods in utility classes instead. But do this to improve the general design, not to aid testing. 单元测试可以通过测试类的公共 API 来定义。一些测试工具使得测试类的私有内容变得可能，但不应该让测试变得更加冗长，且更难以维护。如果有需要被显式测试的私有内容，考虑把它重构进工具类的公共方法里为好。但这么做是为了改善整体设计，而不是帮助测试。 点评：私有 API 要被测试，既是一个不当的测试问题，也是一个不当的设计问题。 Think black-box黑盒思考 Act as a 3rd party class consumer, and test if the class fulfills its requirements. And try to tear it apart. 想象成第三方的类消费者，测试类是否满足它的需求。并且试图把它拆解。 点评：单元测试要注意基本测试。 Think white-box白盒思考 After all, the test programmer also wrote the class being tested, and extra effort should be put into testing the most complex logic. 毕竟，测试程序员一样写了被测试，额外的劳动应该被放在测试最复杂的逻辑中。 点评：单元测试要注意复杂测试。 Test the trivial cases too 也要测试琐碎case。 It is sometimes recommended that all non-trivial cases should be tested and that trivial methods like simple setters and getters can be omitted. However, there are several reasons why trivial cases should be tested too:Trivial is hard to define. It may mean different things to different people.From a black-box perspective there is no way to know which part of the code is trivial.The trivial cases can contain errors too, often as a result of copy-paste operations: private double weight_; private double x_, y_; The recommendation is therefore to test everything. The trivial cases are simple to test after all. getter 和 setter 也是要测试的。 Focus on execution coverage first 先关注执行覆盖率。 Distinguish between execution coverage and actual test coverage. The initial goal of a test should be to ensure high execution coverage. This will ensure that the code is actually executed on some input parameters. When this is in place, the test coverage should be improved. Note that actual test coverage cannot be easily measured (and is always close to 0% anyway).Consider the following public method: By calling setLength(1.0) you might get 100% execution coverage. To acheive 100% actual test coverage the method must be called for every possible double value and correct behaviour must be verified for all of them. Surly an impossible task. 要区别执行覆盖率和实际测试覆盖率。一个测试的首要目标应该是高的执行覆盖率。这可以确保代码在某些输入参数下切实被执行了。这一步到位了以后，应该改善测试覆盖率。要注意实际的测试覆盖率不容易被测量（实际上无论如何经常接近于 0%）。 的测试覆盖率是不可能达到百分之百的。 点评：不可穷举的case里面，执行覆盖率尤其重要。测试覆盖率只能用数学归纳法推理保证。 Cover boundary cases 覆盖边界 case。 Make sure the parameter boundary cases are covered. For numbers, test negatives, 0, positive, smallest, largest, NaN, infinity, etc. For strings test empty string, single character string, non-ASCII string, multi-MB strings etc. For collections test empty, one, first, last, etc. For dates, test January 1, February 29, December 31 etc. The class being tested will suggest the boundary cases in each specific case. The point is to make sure as many as possible of these are tested properly as these cases are the prime candidates for errors. 要保证参数的边界 case 被覆盖了。对于数字，要测试负数，0，整数，最大值，最小值，非数字，无限值，等等。对于字符串，要测试空字符串，单字符字符串，非 ASCII 字符串，几兆大小的字符串，等等。对于集合，要测试空集合，单集合，首元素，尾元素，等等。对日期，要测试1月1日，2月29日，12月31日，等等。被测试类会建议每一种独特 case 下的边界条件。关键点是这些case尽可能多地被测试到了，因为这些case是错误的元凶。 Provide a random generator 提供一个随机生成器。 When the boundary cases are covered, a simple way to improve test coverage further is to generate random parameters so that the tests can be executed with different input every time.To achieve this, provide a simple utility class that generates random values of the base types like doubles, integers, strings, dates etc. The generator should produce values from the entire domain of each type. 当边界case被覆盖到以后，提升测试覆盖率的一个简单方法就是生成随机参数，这样测试每次都会被不同的输入执行。 为了达到这一点，提供一个简单的工具类来生成基础类型的随机值。生成器应该从每种类型的整个值域产生值。 If the tests are fast, consider running them inside loops to cover as many possible input combinations as possible. The following example verifies that converting twice between little endian and big endian representations gives back the original value. As the test is fast, it is executed on one million different values each time. 如果测试很快，在循环里执行它们以尽可能多的覆盖输入组合。 Test each feature once 一次只测试一个特性。 When being in testing mode it is sometimes tempting to assert on “everything” in every test. This should be avoided as it makes maintenance harder. Test exactly the feature indicated by the name of the test method. As for ordinary code, it is a goal to keep the amount of test code as low as possible. 在测试的时候，有时候会尝试在每个测试里面测试所有东西。这应该被避免因为它使得维护变难。只测试测试方法名称指示的特性。 对于普通代码，有一个目标是保证测试代码的数量尽可能低。 Use explicit asserts 使用显式的断言。 Always prefer assertEquals(a, b) to assertTrue(a == b) (and likewise) as the former will give more useful information of what exactly is wrong if the test fails. This is in particular important in combination with random value parameters as described above when the input values are not known in advance. 总是选择 assertEquals(a, b) 而非 assertTrue(a == b)（反过来也一样），前者会给出更有用的信息-测试失败了，到底哪里有错。这在上面描述到的随机参数组合的时候尤其有重要，那时候并不是所有参数都事先明了。 Provide negative tests 提供负面测试。 Negative tests intentionally misuse the code and verify robustness and appropriate error handling.Consider this method that throws an exception if called with a negative parameter: Testing correct behavior for this particular case can be done by: try { setLength(-1.0); fail(); // If we get here, something went wrong } catch (IllegalArgumentException exception) { // If we get here, all is fine } 负面测试故意无用代码，并且验证程序的鲁棒性和正确的错误处理。 点评：非常重要，测试的深度就在这里了。 Design code with testing in mind 胸有测试，再设计代码。 Writing and maintaining unit tests are costly, and minimizing public API and reducing cyclomatic complexity in the code are ways to reduce this cost and make high-coverage test code faster to write and easier to maintain. Some suggestions: Make class members immutable by establishing state at construction time. This reduce the need of setter methods.Restrict the use of excessive inheritance and virtual public methods.Reduce the public API by utilizing friend classes (C++), internal scope (C#) and package scope (Java).Avoid unnecessary branching.Keep as little code as possible inside branches.Make heavy use of exceptions and assertions to validate arguments in public and private API’s respectively.Restrict the use of convenience methods. From a black-box perspective every method must be tested equally well. Consider the following trivial example: public void scale(double x0, double y0, double scaleFactor) { // scaling logic } Leaving out the latter simplifies testing on the expense of slightly extra workload for the client code. 写单元测试是很昂贵的，减少公共 API 和代码中的圈复杂度是减轻这种开销的方法，使高覆盖率的测试代码更快被编写且更易被维护。 一些建议： 在构造时就建立不可修改的状态。这会减少 setter 的数量。 减少过分继承和虚函数的使用。 使用友元类（C++），内部域（C#）和包域（Java）来减少公共API。 避免不必要的分支。 分支里的代码尽可能少。 重度使用异常和断言，来验证公共和私有API（相应的）的实参。 限制使用方便方法。 点评：意在笔先，非常重要。 Don’t connect to predefined external resources Unit tests should be written without explicit knowledge of the environment context in which they are executed so that they can be run anywhere at anytime. In order to provide required resources for a test these resources should instead be made available by the test itself.Consider for instance a class for parsing files of a certain type. Instead of picking a sample file from a predefined location, put the file content inside the test, write it to a temporary file in the test setup process and delete the file when the test is done. 不要连接到预先定义好的外部资源上。 单元测试必须在不需要显式了解要被执行的外部环境上下文的前提下被编写，这样它们在何时何地都可以被执行。要提供测试必须的资源，必须让测试自己来干。 考虑通过解析某个类型的文件，实例化一个类，而不是从某个预定义的场所取一个样例文件，把文件内容放进测试里。把文件的内容放进测试里，在测试启动流程里，把它写到临时文件中，测试完了就删掉。 点评：这也是测试的一个独立性问题。 Know the cost of testing 了解测试的开销。 Not writing unit tests is costly, but writing unit tests is costly too. There is a trade-off between the two, and in terms of execution coverage the typical industry standard is at about 80%.The typical areas where it is hard to get full execution coverage is on error and exception handling dealing with external resources. Simulating a database breakdown in the middle of a transaction is quite possible, but might prove too costly compared to extensive code reviews which is the alternative approach. 不只是写单元测试昂贵，而且跑单元测试也昂贵（此处应有）。两者之间有所权衡，考虑到执行覆盖率，工业标准大约为80%。 难以得到完整执行覆盖率的典型领域是处理外部资源的异常处理。在事务执行中仿真数据库垮掉是可以做到的，但比起另一种方案，大量的代码审查，它太昂贵了。 点评：引入不确定性的依赖是最难测试的。 Prioritize testing要为测试制定优先级。 Unit testing is a typical bottom-up process, and if there is not enough resources to test all parts of a system priority should be put on the lower levels first. 单元测试是典型的自底向上流程。如果没有足够的资源测试系统的所有部分，应该以底层测试为重。 点评：比较反一般直觉的是，底层的测试更重要。 Prepare test code for failures 准备失败的代码。 Consider the simple example: Handle handle = manager.getHandle(); assertNotNull(handle); If the first assertion is false, the code crashes in the subsequent statement and none of the remaining tests will be executed. Always prepare for test failure so that the failure of a single test doesn’t bring down the entire test suite execution. In general rewrite as follows: Handle handle = manager.getHandle(); assertNotNull(handle); if (handle == null) return; 点评：测试要跑完，测试也不能crash。测试也要捕获异常。 Write tests to reproduce bugs 写测试来重现 bug。 When a bug is reported, write a test to reproduce the bug (i.e. a failing test) and use this test as a success criteria when fixing the code. 当一个bug被报告，写一个测试来重现这个bug。然后用这个测试当做修复这段代码的成功标准。 Know the limitations 知道极限在哪。 Unit tests can never prove the correctness of code!!A failing test may indicate that the code contains errors, but a succeeding test doesn’t prove anything at all. The most useful appliance of unit tests are verification and documentation of requirements at a low level, and regression testing: verifying that code invariants remains stable during code evolution and refactoring. Consequently unit tests can never replace a proper up-front design and a sound development process. Unit tests should be used as a valuable supplement to the established development methodologies. And perhaps most important: The use of unit tests forces the developers to think through their designs which in general improve code quality and API’s. 点评：测试只能证明有bug，不能证明没有bug。正面的设计，合理的流程不是测试能替代的，测试反而是方法论里有价值的补充。"},{"title":"《应用架构之道》笔记","date":"2019-09-05T08:38:18.000Z","url":"/2019/09/05/%E3%80%8A%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%81%93%E3%80%8B%E7%AC%94%E8%AE%B0/","tags":["系统架构"],"content":"架构师的职责化繁为简。架构师是职责就是把复杂的问题简单化，使得其他人能够更好地在架构里工作。 架构师要努力训练自己的思维，用它去理解复杂的系统，通过合理的分解和抽象，做出合理的设计。 软件架构软件架构是一个系统的草图。软件架构描述的对象是直接构成系统的抽象组件。各个组件的链接则明确和相对细致地描述组件之间的通信。 软件架构为软件系统提供了结构、行为和属性的高级抽象。，由构件的描述、构件的相互作用、指导构件集成的模式以及这些模式的约束组成。软件架构不仅显示了软件需求和软件结构之间的对应关系，而且指定了整个软件系统的组织和拓扑结构，提供了一些设计决策的基本原理。 软件架构的核心价值应该只围绕一个核心命题：控制复杂性。 软件架构分类 业务架构：由业务架构师负责，也可以称为业务领域专家、行业专家。业务架构属于顶层设计，其对业务的定义和划分会影响组织结构和技术架构。 应用架构：由应用架构师负责，他需要根据业务场景的需要，设计应用的层次结构，制定应用规范、定义接口和数据交互协议等。并尽量将应用的复杂度控制在一个可以接受的水平，从而在快速的支撑业务发展的同时，在保证系统的可用性和可维护性的同时，确保应用满足非功能属性要求（性能、安全、稳定性等）。 数据架构：对于规模大一些的公司，数据治理是一个很重要的课题。如何对数据收集、数据处理提供统一的服务和标准，是数据架构需要关注的问题。其目的就是统一数据定义规范，标准化数据表达，形成有效易维护的数据资产，搭建统一的大数据处理平台，形成数据使用闭环。 物理架构：物理架构关注软件元件是如何放到硬件上的，包括机房搭建、网络拓扑结构，网络分流器、代理服务器、Web服务器、应用服务器、报表服务器、整合服务器、存储服务器和主机等。 运维架构：负责运维系统的规划、选型、部署上线，建立规范化的运维体系。 CQRS 架构核心思想是不把应用做成一个 CRUD datastore，而是要把读的操作使用query model，写操作使用 command model，来实现 Responsibility Segregation。 洋葱架构洋葱架构与六边形架构有着相同的思路，它们都通过编写适配器代码将应用核心从对基础设施的关注中解放出来，避免基础设施代码渗透到应用核心之中。这样应用使用的工具和传达机制都可以轻松地替换，可以一定程度地避免技术、工具或者供应商锁定。 不同的是洋葱架构还告诉我们，企业应用中存在着不止两个层次，它在业务逻辑中加入了一些在领域驱动设计的过程中被识别出来的层次（Application，Domain Service，Domain model，Infrastructure等）。 在洋葱架构中，明确规定了依赖的方向： "},{"title":"（转）程序员的成长路线","date":"2019-09-05T07:22:12.000Z","url":"/2019/09/05/%EF%BC%88%E8%BD%AC%EF%BC%89%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%88%90%E9%95%BF%E8%B7%AF%E7%BA%BF/","tags":["职业发展"],"content":"工作这么些年了，看到了各种各样的程序员，也看到了各种各样的成长路线，说说自己的一些观点吧。 作为技术人员，在刚起步阶段时，首先需要拓宽自己的技术宽度，对自己所做的项目/产品所涉及的方方面面的技术都应该有所了解，另外对于就是学习工程化，让自己真正具备开发商业软件的能力。 在工程化和知识宽度达到一定阶段后，需要开始根据自己的兴趣和工作内容有所选择，主要是加强在某一领域的技术深度。 在技术深度达到了一定阶段后，需要对自己做出一个选择，就是偏业务方向，还是偏基础技术方向。 偏业务方向的技术人员，我认为做的好的表现是： 对业务发展的未来有一定的预判，有商业敏感意识； 能对复杂的业务进行合理的抽象； 在系统的设计上能对未来业务的变化有一定的预留处理。 偏基础方向的技术人员，我认为做的好的表现是： 能结合业务的发展趋势对基础技术的方向有一定的预判，避免业务发展受到基础技术的拖累； 对业界的技术发展方向有自己的认知和判断； 在对应的基础技术领域有不错的技术深度。 结合自己的特质以及当前的一些状况，做出一个选择，重点发展。 而再往更高阶走的同学，通常就会出现一种新的角色，就是成为团队leader，做为一个技术团队的leader，无论是业务的还是基础技术的，在技术能力上还是不能差的，尤其是判断力上，另外，作为一个团队leader，就意味着承担了团队方向的判断的职责，一个团队的方向基本会直接影响到团队所有成员的未来，以及所支持的业务的发展状况，所以对于一个团队leader，我觉得最重要的能力就在方向的判断上，然后是根据方向的判断的组织建设（团队搭建，人才识别、培养、招募等）能力。 如果不是往leader方向呢，那基本就是往架构师方向为多，架构师的话，在至少一两个领域的深度外，对广度的要求非常高，还有同样就是判断能力，无论是业务架构师，还是基础方向的架构师，领域的知识宽度是非常重要的，意味着能做多大范围的事，判断能力会体现出一个架构师在做一个架构设计时重点是怎么判断的，在有限的资源和时间情况下取舍是怎么做的，对未来是怎么做铺垫的，以及TA对事情的技术控制能力，一个好的架构师在技术风险的控制能力上必须是非常强的，例如一个强大的基础领域的架构师，应该是可以很好的控制跨多个专业技术领域的技术演进。 还有一种是往专业技术深度领域方向走，例如内核、JVM等，这些领域是真正的需要非常深的技术功底才能hold的住的。 还会有其他例如转型往业务产品方向等发展的就不在这说了。 总而言之，言而总之，我觉得在整个成长过程中，兴趣是最为关键的，所以follow your heart非常重要，只有在有足够的兴趣或梦想的情况下才能产生很强的自驱，没有足够的自驱我觉得在技术领域基本上是不可能走到高阶的，除了兴趣外，自己的优势也要判断清楚，每个不同的方向，我自己认为还是需要一定的天分的，而所谓的天分我觉得就是对个人优势的判断。"},{"title":"技术发展分期","date":"2019-09-05T07:17:13.000Z","url":"/2019/09/05/%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%E5%88%86%E6%9C%9F/","tags":["misc"],"content":""},{"title":"重述双亲委派模型","date":"2019-09-05T06:41:05.000Z","url":"/2019/09/05/%E9%87%8D%E8%BF%B0%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B/","tags":["JVM","Java"],"content":"何时加载类 遇到 new、getstatic、putstatic 等指令时。 对类进行反射调用的时候。 初始化某个类的子类的时候。 虚拟机启动时会先加载设置的程序主类。 使用 dynamic 动态语言支持等相关特性时。 从 Java 到 cpp 源码分析 JVM默认用于加载用户程序的ClassLoader为AppClassLoader，不过无论是什么ClassLoader，它的根父类都是java.lang.ClassLoader。在上面那个例子中，loadClass（）方法最终会调用到ClassLoader.definClass1（）中，这是一个Native 方法。 definClass1（）对应的 JNI 方法为 Java_java_lang_ClassLoader_defineClass1（）。 Java_java_lang_ClassLoader_defineClass1主要是调用了JVM_DefineClassWithSource（）加载类，跟着源码往下走，会发现最终调用的是 jvm.cpp 中的jvm_define_class_common（）方法。 其上的步骤细分下来共三步： 将 class 文件转化为字节流。 求当前线程是否持有锁，并且显式地进入 protection_domain。 将字节流转化成 Klass 的实例（class 文件在 JVM 中的内存代表），注册进 SystemDictionary 里。 Klass 是 JVM 用来定义 Java Class 的数据结构。不过 Klass 只是一个基类，Java Class 真正的数据结构定义在 InstanceKlass 中。 这个类型定义了 Java 类的所有属性，包括注解、常量、内部类、方法、内部方法、字段等信息。这些信息本来被记录在 Class 文件中，，InstanceKlass 是 它的内存形式。 可以和 Class 文件的结构图对比看。 可以看到，在 class 文件里的 constant pool，只能映射到 InstanceKlass 里的 constant 上。 resolve_from_stream 详解判断是否允许并行加载类，并根据判断结果进行加锁 如果允许并行加载，则不会对ClassLoader进行加锁，只对SystemDictionary加锁。否则，便会利用 ObjectLocker 对ClassLoader 加锁，保证同一个ClassLoader在同一时刻只能加载一个类。ObjectLocker 会在其构造函数中获取锁，并在析构函数中释放锁。 允许并行加载的好处便是精细化了锁粒度，这样可以在同一时刻加载多个Class文件。 解析文件流，生成 InstanceKlass 利用SystemDictionary注册生成的 Klass SystemDictionary 是用来帮助保存 ClassLoader 加载过的类信息的。准确点说，SystemDiction并不是一个容器，真正用来保存类信息的容器是 Dictionary，每个 ClassLoaderData 都保存着一个私有的Dictionary，而 SystemDictionary 只是一个拥有很多静态方法的工具类而已。 注册的代码： 如果允许并行加载，那么前面就不会对 ClassLoader 加锁，所以在同一时刻，可能对同一 Class 文件加载多次-但同一个 Class 必须在同一 ClassLoader 里保持唯一，所以先利用 SystemDictionary 查询 ClassLoader 是否已经加载过相同 Class。 如果已经加载过，那么就将刚刚加载的 InstanceKlass 加入待回收列表，并将 InstanceKlass * k 重新指向利用 SystemDictionary 查询到的 InstanceKlass。（允许重复加载，弃新存旧） 如果没有查询到，那么就将刚刚加载的 InstanceKlass 注册到 ClassLoader的 Dictionary 中 中。 如果禁止了并行加载，那么直接利用SystemDictionary将 InstanceKlass 注册到 ClassLoader的 Dictionary 中即可。此时由锁保证数据唯一性。 ClassFileParserresolve_from_stream（）最重要的是第二步，从文件流生成InstanceKlass，这依赖于调用 KlassFactory::create_from_stream（）方法： 这又依赖于 ClassFileParser。 ClassFileParser 加载Class文件的入口便是 create_instance_klass（）。顾名思义，用来创建InstanceKlass的。 create_instance_klass（）主要就干了两件事： 为 InstanceKlass 分配内存： 内存分配代码如下： 这里首先计算了InstanceKlass在内存中的大小，要知道，这个大小在Class 文件编译后就被确定了。 然后便 new 了一个新的 InstanceKlass 对象。这里并不是简单的在堆上分配内存，要注意的是Klass 对 new 操作符进行了重载： 分配 InstanceKlass 的时候调用了 Metaspace::allocate（）： *由此可见，InstanceKlass 是分配在 ClassLoader的 Metaspace（元空间） 的方法区中。从 JDK8 开始，HotSpot 就没有了永久代，类都分配在 Metaspace 中。Metaspace 和永久代不一样，采用的是 Native Memory，永久代由于受限于 MaxPermSize，所以当内存不够时会内存溢出。 分析Class文件，填充 InstanceKlass 内存区域： ClassFileParser 在构造的时候就会开始分析Class文件，所以fill_instance_klass（）中只需要填充即可。填充结束后，还会调用 java_lang_Class::create_mirror（）创建 InstanceKlass 在Java 层的 Class 对象。双层对象。 至此，系统保证了“不同ClassLoader加载的类是互相隔离的”。其基本流程为：每一个 classloader 有一个私有的 Dictionary，在加载类的过程中，Dictionary 有锁机制保证 InstanceKlass 的唯一性。如果存在不同的 ClassLoader 加载同一个 Class 文件，就会在内存里保存多份 InstanceKlass。而不同的 InstanceKlass 之间是不能相互强制转换的。 上述代码运行一定会出错。 那是因为目标 a.b.c 类型存在于当前类加载器中，而 clazz 这个Class实例则存在于 customClassloader 中，它的 clazz.newInstance() 的类型本身不能跨类加载器相互转化。 一种 hack 技巧 注意，这里面并不直接调用 c c = clazz.newInstance()，而是调用 Object object = clazz.newInstance()，并且必须使用反射才能调用 test。因为如果显式地使用了 C 这个类型，进行常量解析时，还是会跑到系统默认的 ClassLoader 加载的 C。"},{"title":"《流水型 FO》笔记","date":"2019-09-02T06:34:00.000Z","url":"/2019/09/02/%E3%80%8A%E6%B5%81%E6%B0%B4%E5%9E%8B-FO%E3%80%8B%E7%AC%94%E8%AE%B0/","tags":["设计模式"],"content":"数据的分类状态型数据，需要三地五中心容灾，需要强一致性，事务延迟较高。对状态型数据的操作实际上是对同一行记录进行反复操作。 流水型数据，对历史数据依赖较少，每一笔业务相对独立。 基于一定的业务理解和假设，我们可以设计出一套新的模型和存储方案，实现流水型 FO。 部署形态通常流水型 FO 要求部署三套库。 主库 LFO 库 同城 FO。承担机房级故障。 RFO 库，异地 FO 库。承担区域 数据格式8 位日期 + 1 位数据版本 + 1 位系统版本 + 3 位系统标识 + 2 位预留 + 2 位 uid + 2 位弹性位 + 8 位 sequence 设计数据格式影响几个问题： 1 当系统发生一笔流水的时候，流水应该落到哪个库里去。2 当我需要一笔流水时，我应该从哪个库里面查询这笔流水。 有关联关系的单据，如果发生弹性切换，要保证正逆向流程的单据都弹到一个库里。 流水型 FO 方案如何做到业务无感知？？？？ 流水型 FO 发生强切的时候如何保证业务业务无损？？？？"},{"title":"《结构化的思考、做事、成长》笔记","date":"2019-09-02T04:01:14.000Z","url":"/2019/09/02/%E3%80%8A%E7%BB%93%E6%9E%84%E5%8C%96%E7%9A%84%E6%80%9D%E8%80%83%E3%80%81%E5%81%9A%E4%BA%8B%E3%80%81%E6%88%90%E9%95%BF%E3%80%8B%E7%AC%94%E8%AE%B0/","tags":["读书笔记"],"content":"能力要素要重点建设的三种能力： 结构化的思维 结构化的工作模式 结构化的能力建设 什么是结构化structured：建立中心（问题、目标）以中心的核心要素对中心进行分解，形成分类子结构。以一定的范式、流程顺序进行分类子结构的合理分类、减少非关键分类结构；对关键分类子结构进行分析，寻找对策，制定行动计划。 同理，按照逆向的顺序，对多种杂乱的内容，进行分类、剪枝、归纳归总成一个中心，也是结构化。 案例建立结构化的中心一个业务需求，通常可以按照两个维度分解为不同的子结构： 1 当前业务需求的目标是什么？（事的维度）。 目标是快速完成上线试一试业务效果：目标事的维度为高效稳定上线。 目标是建立后续业务铺开的基础方案：目标事的维度是强架构设计下的核心与功能拆分方案。 2 为什么需要我来做？（人的维度） 是因为我工作量还有 buffer 所有承担这部分：目标人的维度是完成职能范畴内的工作。 是因为我在这方面技术比较擅长：目标人的维度是利用事情强化自身能力和使用能力把事儿做好。 沿中心上行对单个业务需求而言，从事、人两个维度建立起的中心即其核心，是最主要部分，建立一颗结构树的基础。但我们不应当停止于此，还应当向上推导：这个需求在整个业务的范畴内，是在哪一层次，哪一分类的。即应当更高层面、或整体业务和行业发展，对这方面业务是怎样的期许。（价值的维度） 一个团队接手某项业务或需求，其背后都会有思考。我们是期望借着这个业务打造一个平台，提升整体行业的表现；还是突击这个业务方向，占领局部的商业蓝海。。。 接到一个需求时一定要思考更大层面这事的价值，才能更好的判断优先级、做事模式。 例如：我们做采购系统，当前需求是，提供采购单列表，按总价范畴搜索单据的能力。按结构化的中心建立，它是：高效稳定上线（事）、我职能范围内的工作（人）。 如果止步于单个需求建立的中心，我们后续的分解应当是如何快速搞定、如何更稳定。。。 如果我们继续向上构建树，我们可以和产品、使用者深度沟通下为什么要做价格搜索 管理员期望能看到高价订单的情况。那么这个需求的上一个中心节点应当是：管理提效。 继续向上，是基于什么原因需要做管理提效？因为防止贪腐、提高工作效率。那么上一个中心节点应当是：降低成本。 依次向上，直到抵达整个业务的目标。比如总结觉得，我们的业务是构建一个集成高效的集团采购系统。 再以此反思： 降低成本是不是当前工作的重点？团队是否有足够的架构设计和人员组织来支撑？ 下一步到到管理提效层面，订单的搜索是否真的是当前最佳的提效工具，因为用户如何定义高价格？他执行这种搜索式查阅工作是否真的是有效不遗漏的？查阅到了订单有问题他能做什么？。。。我们会发现这个需求背后更多的问题。我们也可以沿着更大的中心树，去思考是否构建更好的方案可以更根本的解决这个问题。 再回过头来看当前的任务，是否真的是高效稳定上线（事）、我职能范围内的工作（人）。或者当前最紧急的部分（用户直接需求嘛）是高效稳定上线（事）、我职能范围内的工作（人），但后续更要做更多的其他的根本性解决方案。 沿当前的中心向上建立更大的结构化的认知体系 会让我们对当前事情的判断（中心）更加清晰，也有更好的认知基础，极有利于与合作方的沟通碰撞和内容创新。 建立更大结构化认知体系的过程，也是深入业务、扩展认知力的过程。一定要多和老板、业务方交流，从各自认知的差异性上提升自身的认知能力。 此外，构建更大认知体系，对个人和团队发展也是有价值的 很多时候我们忙于业务实现，都没有花时间去思考业务的价值。一部分是因为忙，一部分是因为懒，一部分是因为不懂，一部分是因为我们是来做事拿工资的，而不是带着愿景想把事做好的。这都不是真正能把事情做好的方式。 作为团队的一员，我们不应当只做“花时间、生鸡蛋”的极低人效、技术外包的母鸡模式，而应当积极的尝试做“建机器、铺厂房、出产品”的工厂模式。这对业务和个人的发展才是积极的作用。 中心的分解建立完成中心后，有多种对中心进行分解的方式。其目标在于将中心拆解为多个内聚的子部分。整体思想是MECE（Mutually Exclusive Collectively Exhaustive）原则，即相互独立，完全穷尽不重叠、不遗漏的分类。够借此有效把握问题的核心，并成为有效解决问题的方法。 SWOT 法 AHP 法 进行分解的顺序逻辑： 时间顺序 结构顺序 程度顺序 清理事业是无限的，人力总是有穷、认知高度总是不够的。我们不能把分析出的所有点都做好，也不是分解出的所有层次都真正有价值的。那么针对分解的产出物，应当以数据挖掘的物料准备类似的逻辑进行前期处理，来提高效率、去除噪声。常用的分别为： 泛化：过度细碎的层次应当抽象总结到更高层次，以进行更有效分类。 补漏：针对中心，某些关键决策子层级缺失，应当补充完全。 剪枝：针对中心，与中心紧密度关联较低或无可操作性的部分应当去除，以降低整体分析复杂度。 结论建立中心； 以中心的核心要素对中心进行分解，形成分类子结构； 以一定的范式、流程顺序进行分类子结构的合理分类、减少非关键分类结构； 对关键分类子结构进行分析，寻找对策，制订行动计划。 实践的效果 老板问我当前做的事情怎么样了，我讲了合作中的难点、视觉风格问题、业务情况、代码质量。。。工作的进展，说了半小时，老板还是get不到我做的事情的情况和价值：按照事情核心目标的达成情况，各子部分重点问题和解进行结构化的讲述，两分钟说清楚。 我这一年做了很多事情，都有一定产出，但是跳出细节来看，发现对业务、对团队价值都不大：先建立团队当前业务的核心目标，分解目标达成所需的各个部分，自身努力在某个部分上做深，或者补全当前缺少的部分，或者强力推进将团队目标向上拔高一层更大的目标。 最近流行codeless，我打算研究下可视化搭建；团队业务涉及到流程编排，我打算研究下TMF。。。一年下来折腾了不少成果出来，老板却不提名我晋升：先确定自身技术能力提升的目标，分解到需要提升的各个部分，针对不同部分向老板强求从事相关工作、在当前工作内尝试和深耕，从深入一个部分到横切一个面的能力提升，晋升自然水到渠成。 "},{"title":"《JVM 问题分析处理总结》笔记","date":"2019-09-02T03:08:44.000Z","url":"/2019/09/02/%E3%80%8AJVM-%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93%E3%80%8B%E7%AC%94%E8%AE%B0/","tags":["JVM"],"content":"知识体系图谱 紧急处理原则出现问题应该第一时间恢复，恢复过程中如果有余地则要保留问题现场供后面排查定位问题，其基本步骤是： 打印堆栈信息 打印内存镜像 生成core文件 保留gc日志文件 保留业务日志文件 查看JAVA堆内存运行分配 如果有余地，可以做完以上的操作后再重启应用。 实例实例一1 查看 gc 日志，评估代际问题。2 查看访问日志，看看应用吞吐量。3 用 jstat 查看代际问题。4 把内存 dump 出来，分析数量最多的对象。5 分析代码。6 改善代码。 实例二1 统计线程总数：ps -eLf | grep java -c2 看 ulimit -u3 jstack、gcore4 改善 jvm 参数"},{"title":"《高可用恢复思路》笔记","date":"2019-08-30T11:44:55.000Z","url":"/2019/08/30/%E3%80%8A%E9%AB%98%E5%8F%AF%E7%94%A8%E6%81%A2%E5%A4%8D%E6%80%9D%E8%B7%AF%E3%80%8B%E7%AC%94%E8%AE%B0/","tags":["系统架构"],"content":"遇到线上问题，经常陷入一个误区：一定要找到问题的根因（root cause）。但实际上对线上应用而言，最重要的是恢复可用性，所以在开发设计环境除了完成功能性需求以外，还需要加入非功能性设计的需求： 限流保护。抵挡来自突发流量冲垮整个集群。 降级保护，对调用的服务接口保持警惕，其各种因素导致不可用，可以对齐降级，从而确保核心功能可用。 削峰填谷（traffic shaping），不因突发数据来袭，造成任务消费陡增，造成调用系统的连串抖动。 这些基本的系统保护，是应对未来的各种突发不确定事件的高可用思考。 以上描述的是问题的应对机制设计，问题的发现机制，也需要结构化地考虑，体系化地建设： 发现机制，是我们的眼睛，也是基础。 监控主指标，需要找对业务的主要指标，常见的主指标一般是：RT（响应时间）、总量、成功量、失败量、成功率。 主指标有异常，还要有细分维度（即结果还可以内部 group by aggregation）。 快速恢复 根据监控快速寻找问题发生的方向和位置。 找对恢复的人、恢复的预案。 倾向于选择成本低的恢复手段。—- 并不是所有的恢复都用大招（熔断、限流），大招一定有损且有风险 最后执行恢复 一般我们都会对恢复预案做演练，避免恢复预案失效。或者因执行了预案产生更大的问题。 执行恢复动作要谨慎。一切线上操作都为变更，都有风险。 经验告诉我们：线上问题70%来自变更，找到变更快速回滚是第一优先级，其余30%的问题需要做好预案及防护，快速对应不同的线上突然事件。 "},{"title":"如何进行域划分","date":"2019-08-30T09:44:03.000Z","url":"/2019/08/30/how-to-recognize-domain/","tags":["领域建模","领域驱动设计"],"content":"1 用户需求场景分析，识别业务全景 use case。这一个阶段重点识别 actor 和 use case。 2 分析模型鲁棒图，识别出业务场景中所有的实体对象。识别边界类（类似 ui）、控制类（类似 controller）和实体类（类似model）三种类型。 3 领域划分，将所有识别出的实体对象进行分类。 比如，主订单、子订单对象和归类到交易域；买家、卖家对象可以归类到会员域。 当然，最终所有的对象是归类到十个域还是二十个域，从理论上看，可以看做一次排列组合过程。只是，我们往往可以根据以往的经验、业务知识，做一个初始的域划分（但不见得是靠谱的）。因此，我们可以认为一个域实际上是一个或多个实体对象的信息集合，并对所管理的实体对象的生命周期进行管理。 4 评估域划分合理性，并进行优化。域划分并一定总是能得到唯一的答案，但可以得到最好的答案。评价一个域划分方案是不是足够好，其实是要根据“高内聚、低耦合”的原则进行评分。这一步就要画时序图了。 时序图的泳道，应该先设计到域颗粒度。可以看到域之间的交互，也就可以看到域之间的交互的复杂度。在绘制过程中，我们可以看域与域之间的调用是否过于频繁？甚至是反复调用不同的域服务？如果存在这种情况，就意味着这两个域之间存在比较严重的耦合。这往往通过直观就能有个大致的判断。如果要从定量角度来分析，可以参考代码圈复杂度的度量算法，我们也可以设定一个“域依赖度”算法，来衡量域与域之间的依赖度。对于依赖度比较高的几个域，我们可以采用：1）域合并 2）域拆分 3）提取第三方域做依赖倒置等降低耦合。 合理的域划分，内部的模型是可枚举的，稳定的，也就不易变的。"},{"title":"Redis 笔记之四：常用命令","date":"2019-07-22T15:29:49.000Z","url":"/2019/07/22/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9B%9B%EF%BC%9A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","tags":["Redis"],"content":"全局命令查看所有键 这个命令会不加区别地，做全局的键扫描，返回且只返回键。它的时间复杂度是O（N），线上环境因为无法预测键的数量，应该禁用这个命令。 看起来 redis 并没有做一个全局的 keys 的缓存，所以并没有办法优化局部性能，但即使存在一个全局的 keys 列表，对这个列表进行遍历，其时间复杂度依然是 O(N)。 键总数 这个操作的性能是 O(1)，也就意味着可以直接被线上使用。 它可以作为查询全部数据以前的预优化，至少全局的记录数量可以预先提取出来，以获得分页查询的依据。 检查键是否存在 如果存在返回 1，不存在返回 0。 注1：在存在多个候选返回值的时候，redis会返回语义更加丰富的返回值。如返回成功或失败，可以直接返回true或false，但返回0既可以表示失败，也可以表示操作的操作数（operand）为0，而返回非0不仅可以告诉我们操作成功了，而且还会精确地告诉我们操作了多少个对象，可谓一举两得。这种设计思路遍布 Redis API 中。 问题：估计有个全局优化，能够不返回具体值的情况下得到是否存在某个 key 的结论。 删除键 如果删除成功则返回 1，否则返回 0 键过期 set 是为比较少的返回“OK”的 command。 因为这个命令有复合的EX、PX、NX、XX等选项，所以其他相对的命令（如SETNX）可能会被设为过期，且被移除。 expire 命令的结果也是 0 和 1。 如果使用了 expire 命令，还有一个可以拿来轮询的 ttl 命令，可以告诉我们键的剩余时间： 键的数据结构类型 字符串命令设/取值 批量设/取值 如果使用平凡的取/设值命令，时间开销为： 总开销= n * (一次网络开销 + 一次操作开销) 如果使用批量取/设值命令，时间开销为： 总开销= 一次网络开销 + n * (一次操作开销) redis每秒可以处理上万的读写操作，相当于每次读写操作的开销小于0.1毫秒，而网络开销很难低于1毫秒。根据阿姆达尔定律，网络开销的减少才是性能优化的大头。 加/减值因为 Redis 本身是单线程架构，所以本身不需要其他设计中的悲观锁或者 cas 操作保证操作正确性。返回的自增结果永远是正确的。 注意，java里涉及数字的缺省值都是0，而且只是缺省值，并不是终值。 位操作命令背景见： Redis 并不只是一个平凡的 kv 数据存储，而是一个拥有许多数据类型的服务器。其中有一种类型是用 String 来解释为位图-“Bitmaps are not an actual data type, but a set of bit-oriented operations defined on the String type”。字符串是safe blobs，最大长度是 512 MB，恰好等于一个2的32次方的位图。字符串的英文字符，都符合（comply to）ascii编码。 所谓的位图，可以用紧凑的方式来表示一个大的 true/false 值域，而且这个 true/false 的点还带有 position 信息。 其他命令 哈希命令3.1 设/取值 注意，len 往往是计数，而 strlen 往往是计值。 批量设/取值 对于mset的升级，就是把数据结构写在最前头。set -&gt; mset -&gt; hmset。 数值操作 其他操作 列表命令增删操作 redis里涉及区间的 end，都是闭区间的 end。 阻塞操作 集合命令增删操作 集合操作 有序集合命令增删操作 集合操作 键管理单个键管理 注意，如果字符串的value为string类型，set 操作也会去除过期时间。 Redis不支持二级数据结构（例如列表或者哈希）里元素的过期时间。 迁移键 遍历键 keys命令本身很容易阻塞redis节点，在以下情况下可以考虑使用： 在不对外服务的从节点上使用。但会影响主从复制。 如果确认键值总数比较少，可以使用以下命令 其他情况下，应该考虑使用 scan 命令，渐进式地遍历所有键。 scan的模式为： scan cursor [match pattern] [count number] 其中 cursor 是必须的，从0开始，到0又结束，周而复始。count 默认为10。 数据库管理关系型数据库用字符来区分不同的数据库名不同。Redis只是使用数字来区分不同的数据库。Redis 默认拥有16个数据库，默认选中的数据库的 dbindex 是0。 未来的 redis-cluster 功能默认只使用 db 0。不同的db之间的数据（KV）是相互隔离的。但用不同的 redis instance 一样可以实现这个效果。 "},{"title":"Redis 笔记之三：数据结构和内部编码","date":"2019-07-22T15:26:57.000Z","url":"/2019/07/22/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%89%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E5%86%85%E9%83%A8%E7%BC%96%E7%A0%81/","tags":["Redis"],"content":"如前文所述，Redis 自带数据类型包括：string、hash、list、set 和 zset，但它们实际上只是 redis 的外部数据类型。Redis 还自带一套内部的编码实现，可以通过以下命令查询键的实际内部编码类型： string int(小于8B)/embstr(小于39B)/raw（其他） hash hashtable/ziplist list linkedlist/quicklist/ziplist set hashtable/intset zset skiplist/ziplist ziplist 对复杂数据结构几乎是万能的。他的特点是比较节省内存，但在数据元素较多的情况下性能比较容易下降。"},{"title":"Redis 笔记之二：toolkit","date":"2019-07-22T15:22:37.000Z","url":"/2019/07/22/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8C%EF%BC%9Atoolkit/","tags":["Redis"],"content":"Redis 笔记之二：toolkit标签（空格分隔）： Redisredis-server常用的配置文件内容： port 一般是 6379 logfile 日志文件（redis 的日志文件和 Kafka 不一样，和存储文件是分离的） dir Redis 工作目录（存放持久化和日志文件） daemonize 是否以守护进程的方式来启动 Redis redis 的 minor 版本号如果是奇数，则含有实验性 feature 的非稳定版本；如果是偶数，则是稳定版本。所以我们应该在生产环境使用偶数版本，而在实验性环境里使用奇数版本。 redis-clicli 有两种工作形式：interactive 和 non-interactive。 使用 redis-cli 关闭 redis 的时候，redis 会做优雅关闭的操作，优雅关闭主要包括： 断开客户端连接。 存储数据到 rdb 文件。 所以要尽量用 shutdown 命令，而不要直接 kill（待完成，kill 的分类）。 redis-benchmark基准测试工具 redis-check-aofAOF 持久化文件校验和修复工具 redis-check-rdbredis RDB 持久化文件检测和修复工具 redis-sentinel启动 redis 哨兵 其他 redis 模块neural-redis Online trainable neural networks as Redis data types. 把可训练的神经网络作为 Redis 的数据类型。RediSearch Full-Text search over Redis 在 Redis 之上的全文本搜索引擎RedisJSON A JSON data type for Redis Redis 的 Json 数据类型 rediSQL A redis module that provide full SQL capabilities embedding SQLite 通过嵌入 SQLite 提供全 SQL 支持能力redis-cell A Redis module that provides rate limiting in Redis as a single command. 支持在 Redis 中一键限流。RedisGraph A graph database with a Cypher-based querying language using sparse adjacency matrices 一个使用基于密码的 使用稀疏邻接矩阵查询语言的图数据库RedisML Machine Learning Model Server 机器学习模型服务器RedisTimeSeries Time-series data structure for redis Redis 的时序数据库RedisBloom Scalable Bloom filters Redis 的可伸缩的布隆过滤器cthulhu Extend Redis with JavaScript modules Redis 的 JavaScript 模块redis-cuckoofilter Hashing-function agnostic Cuckoo filters. 哈希函数的不可知布谷过滤器（？）RedisAI A Redis module for serving tensors and executing deep learning graphs 一个提供张量和执行深度图的 Redis 模块redis-roaring Uses the CRoaring library to implement roaring bitmap commands for Redis. 使用 CRoaring 库实现 Redis 的 roaring 位图命令redis-tdigest t-digest data structure wich can be used for accurate online accumulation of rank-based statistics such as quantiles and cumulative distribution at a point. 一个可以被用来精确累积基于排名的统计（诸如分位点或者某一个点的累积分布）的 t 摘要数据结构Session Gate Session management with multiple payloads using cryptographically signed tokens.使用密码学签名的令牌的多重负载的会话管理 countminsketch An apporximate frequency counter一个近似频率计数器 ReDe Low Latancy timed queues (Dehydrators) as Redis data types. 低延迟的计时队列topk An almost deterministic top k elements counter一个有确定性的 topk 元素计数器 commentDis Add comment syntax to your redis-cli scripts. redis 客户端的评论语法"},{"title":"Redis 笔记之一：Redis 特性","date":"2019-07-22T15:05:06.000Z","url":"/2019/07/22/Redis-%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%80%EF%BC%9ARedis-%E7%89%B9%E6%80%A7/","tags":["Redis"],"content":"Redis 高性能的原因Redis 的读写性能达到 10w/s，主要基于以下原因： 数据主要放在内存中。 Redis 使用距离 OS “层次更近”的 C 语言实现。 Redis 使用单线程架构，没有很高的 lock contention。 IO 多路复用技术 Redis 的代码实现得优雅而兼顾性能 Redis 的数据结构Redis 本身是 Remote Dictionary Server 的简称，其中，老的、常见的数据结构有： 字符串 哈希 列表 set（集合） zset（有序集合） 但后来追加了几种新颖的数据机构，包括：bitmap、hyperloglog，更后来更添加了 GEO 地理信息相关的工具。 基于这些数据结构，我们可以实现一些常见的功能： 键过期，可以用来实现缓存，进而实现分布式锁。 发布订阅功能，进而实现消息系统（待尝试）。 Lua 脚本功能，可以实现自定义的 Redis 命令（待尝试）。 实现简单的事务功能，能在一定程度上实现事务特性。 提供流水线功能，能够让客户端一次性把一批命令一次性上传到 Redis 里，能够合并 IO 并减少网络开销（注意，不同于事务特性）。 redis 有一个很优秀的实现，不需要像 memcache 一样依赖于 libevent 之类的类库（值得研究）。 Redis 应用场景 缓存 搭配使用自带的缓存（1）超时时间（2）最大内存控制加内存溢出后的淘汰策略（待验证），可以制造一个稳定的缓存集群。 排行榜（社交网络数据存储） 有序数据集合（sorted set）可以制造各种维度的排行榜。 3.计数器应用（社交网络数据存储） 不要使用 mysql 来制造 counter 4.其他社交网络数据存储 用 8 种数据结构可以比较合理地实现、存储各种社交网络里的踩、赞、粉丝、好友数据。 Redis 自带比较丰富的集合操作。 5、消息队列系统 消息队列可以拿来做业务解耦，非实时削峰。 Redis 有新的 pub/subscribe 和 blocking queue 功能。 Redis 不适合的应用场景Redis 本身是热存储为主，应该存热数据为主，应该尽量区分热数据和冷数据，把冷数据排出在热数据之外，这样才能合理地提高内存利用效率。对于食品网站，视频信息是跨业务线的热数据，而每个电视剧的观众信息，则是偏冷的数据。 Redis 本身不支持传统关系型数据库复杂的 CRUD 复杂查询语句。 关于 Redis 我们不知道的事情不要只把 redis 当做 get、set、del 的黑盒，开发和运维同样重要。"},{"title":"Differences between Proxy and Decorator Pattern","date":"2019-03-13T08:01:10.000Z","url":"/2019/03/13/Differences-between-Proxy-and-Decorator-Pattern/","tags":["设计模式"],"content":"  Decorator Pattern focuses on dynamically adding functions to an object, while Proxy Pattern focuses on controlling access to an object. Relationship between a Proxy and the real subject is typically set at compile time, Proxy instantiates it in some way, whereas Decorator is assigned to the subject at runtime, knowing only subject’s interface. "},{"title":"所谓解耦","date":"2019-02-13T15:01:57.000Z","url":"/2019/02/13/%E6%89%80%E8%B0%93%E8%A7%A3%E8%80%A6/","tags":["软件工程"],"content":"软件设计，必有单元/片段，不管他们叫做系统、层次、模块、类型和方法，都是为了在一个抽象颗粒度上分割复杂度，让我们降低思考的难度，并且进行团队协作。 我们在进行系统交互的时候，要尽量设计单元交叉点通过薄的中间层交互。也就是放弃直接性，拥抱间接性。 间接性的实现，就是契约、接口或者门面/桥接模式。这些实践的使用，可以轻易让我们切换层次之间的实现，而使变动不扩散出去。"},{"title":"正则表达式速记","date":"2019-01-05T09:47:04.000Z","url":"/2019/01/05/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%9F%E8%AE%B0/","tags":["正则表达式"],"content":"字符类或者字符集 字符组（character classes） 字符集（character sets） 元字符 metacharacters [abc] A single character of: a, b or c[^abc] Any single character except: a, b, or c[a-z] Any single character in the range a-z[a-zA-Z] Any single character in the range a-z or A-Z^ Start of line$ End of line 开头结尾：^$，正好对应键盘上的64。 \\A Start of string\\z End of string. Any single character\\s Any whitespace character\\S Any non-whitespace character\\d Any digit\\D Any non-digit\\w Any word character (letter, number, underscore)\\W Any non-word character\\b Any word boundary(…) Capture everything enclosed(a|b) a or ba? Zero or one of aa* Zero or more of aa+ One or more of aa{3} Exactly 3 of aa{3,} 3 or more of aa{3,6} Between 3 and 6 of a .* 任意关键字匹配 前瞻后顾前瞻：exp1(?=exp2) 查找exp2前面的exp1后顾：(?&lt;=exp2)exp1 查找exp2后面的exp1负前瞻：exp1(?!exp2) 查找后面不是exp2的exp1负后顾：(?&lt;!=exp2)exp1 查找前面不是exp2的exp1 这里的括号不是捕获组的意思。可以看出正则表达式是可以嵌套的。 捕获组与命名捕获组另外需要说明的一点是，除(Expression)和(?Expression)语法外，其它的(?…)语法都不是捕获组。 资料网站 例子 "},{"title":"同比环比问题","date":"2018-12-28T05:18:57.000Z","url":"/2018/12/28/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94%E9%97%AE%E9%A2%98/","tags":["统计学"],"content":"同比比较微观，环比比较宏观。 摘自百度： 同比，是指在相邻时段中的某一相同时间点进行比较； 13年和14年是相邻时段，13年3月和14年3月是这两个相邻时段的同一个时间点，都是3月，这两个时段进行数据对比，就是同比； 环比，则相对更简单，就是相邻时间段的对比，不象同比那样，是在相邻时间段内部的某个相同时间点的对比； 14年4月和14年3月是相邻时间段，这两个时间段的数据都比，就是环比；"},{"title":"关键述职","date":"2018-12-15T14:41:44.000Z","url":"/2018/12/15/%E5%85%B3%E9%94%AE%E8%BF%B0%E8%81%8C/","tags":["职场"],"content":"什么是关键述职可以决定自己职场命运的述职，一次汇报，就是一个转折点，就是关键述职。 职场不是比拼正确性，而是比拼说服力。 关键述职的误区 把述职当作做了什么的流水账。做了什么不重要，做了什么带来什么价值才重要。一定要解答这个疑问，“所以呢，然后呢”。 把述职当成了邀功大会。只讲价值。 工作成果固然重要，关键能力要看是否有归因和理性思考能力。 方法So what找出问题的原因。通过没完没了地问自己，逼迫自己对自己的工作进行深度思考，得出结果，措施。不要怕错。 如何产生这个价值，如何复用这种方法论，如何持续地产生这种价值。 So page跟公司的战略同步。 不同阶段，重要性是不一样的。 A 求增长增长期就要看增长率 B 求利润要看真实效率和投入产出比。 C 求生存，求稳节衣缩食，勒紧裤腰带过冬。"},{"title":"正交性","date":"2018-11-28T05:24:12.000Z","url":"/2018/11/28/%E6%AD%A3%E4%BA%A4%E6%80%A7/","tags":["系统架构","API 设计"],"content":"所谓正交性（orthogonal 意为正交的），就是设计的维度与其他维度完全隔离，一个正交的设计/值域设计，其变化绝不会受其他正交维度影响，也不会影响其他正交维度。 我们可以把 API 设计成正交的。这样 API 有独立变化的空间的。 我们可以把问题域切分清楚。问题域之间完全不相互干涉（注意跨问题域问题）。 我们可以把变量、字段、列设计成正交的。这样不同业务场景下，列之间的赋值不会相互覆盖。"},{"title":"数据分析","date":"2018-11-28T05:02:04.000Z","url":"/2018/11/28/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/","tags":["数据分析"],"content":"DW（Data Warehouse）数据仓库存储是一个面向主题的，反应历史变化数据，用于支撑管理决策。 ODS（Operational Data Store）操作型数据存储，存储的是当前的数据情况，给使用者提供当前的状态，提供即时性的、操作型的、集成的全体信息的需求。 ODS 是数据库到数据仓库的一种过渡形式，与数据仓库在物理结构上不同，能提供高性能的响应时间， ODS 设计采用混合设计方式。 ODS 中的数据是“实时值”，而数据仓库中的数据却是历史值。一般 ODS 中储存的数据不超过一个月，而数据仓库为10年或更多。 Data Mart 为特定的应用或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据。在数据仓库的实施过程中往往可以从一个部门的数据集市着手，以后再用几个数据集市组成一个完整的数据仓库。需要注意的就是在实施不同的数据集市时，同一含义的字段定义一定要相容，这样再以后实施数据仓库时才不会造成大麻烦。 DSS（Decision-Support System）以启发的方式对大量的数据单元进行的分析，通常不涉及数据更新。 参考："},{"title":"UML 细节","date":"2018-11-27T06:04:11.000Z","url":"/2018/11/27/UML-%E7%BB%86%E8%8A%82/","tags":["UML"],"content":"用例图泛化(generalization)：泛化关系是一种继承关系，子用例将继承基用例的所有行为，关系和通信关系，也就是说在任何使用基用例的地方都可以用子用例来代替。泛化关系在用例图中使用空心的箭头表示，箭头方向从子用例指向基用例。 扩展(extend)： extend关系是对基用例的扩展，基用例是一个完整的用例，即使没有子用例的参与，也可以完成一个完整的功能。extend的基用例中将存在一个扩展点，只有当扩展点被激活时，子用例才会被执行。 extend关系在用例图中使用带箭头的虚线表示(在线上标注&lt;&gt;)，箭头从子用例指向基用例。 包含(include)： include为包含关系，当两个或多个用例中共用一组相同的动作，这时可以将这组相同的动作抽出来作为一个独立的子用例，供多个基用例所共享。因为子用例被抽出，基用例并非一个完整的用例，所以include关系中的基用例必须和子用例一起使用才够完整，子用例也必然被执行。include关系在用例图中使用带箭头的虚线表示(在线上标注&lt;&gt;)，箭头从基用例指向子用例。 类图依赖和联系的区别 Martin Fowler 的观点： In general, you use an association to represent something like a fieldin a class. The link is always there, in that you can always ask anorder for its customer. It need not actually be a field, if you aremodeling from a more interface perspective, it can just indicate thepresence of a method that will return the order’s customer. 简而言之，一个类中的一个字段，或者一个 getter 意味着联系。 To quote from the 3rd edition of UML Distilled (now just out) “adependency exists between two elements if changes to the definition ofone element (the supplier) may cause changes to the other (theclient)”. This is a very vague and general relationship, which is whythe UML has a host of stereotypes for different forms of dependency.In code terms, such things as naming a parameter type and creating anobject in a temporary variable imply a dependency. You don’t want to show every dependency on a UML diagram - there arefar too many. You need to be very selective and show only those thatare important to whatever it is you are communicating. I tend not to use stereotypes on the dependencies very often. I findthat most of the time the key point I want to show is that adependency exists, and which kind is rather less vital. Associations also imply dependency, if there is an association betweentwo classes, there is also a dependency. But I can’t imagine a casewhere you would show that dependency as an extra line on the diagram.The association implies it, as does a generalization. 模糊地说，client 依赖 supplier，意味着 supplier 的变动会传递到 client 上。 方法参数或者临时变量意味着为依赖。 依赖有很多形式，难以尽述。联系本身也是一种大致的依赖。"},{"title":"分治策略","date":"2018-11-25T12:43:27.000Z","url":"/2018/11/25/%E5%88%86%E6%B2%BB%E7%AD%96%E7%95%A5/","tags":["算法"],"content":"步骤分解（divide）：将问题划分为一些子问题，子问题的形式与原问题一样，只是规模更小。解决（conquer）：递归地杰出子问题。如果子问题的规模足够小，则停止递归，直接求解。合并（Combine）：将子问题的解组合成原问题的解。 递归式递归式（recurrence）可以帮我们刻画整个算法的运行时间。 一个常见刻画递归式的方法是画递归树。通过递归树的枝叶来试图把整个算法的步骤勾勒出来。"},{"title":"日志问题","date":"2018-11-25T08:04:21.000Z","url":"/2018/11/25/%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98/","tags":["SLF4j","Logback","Log4j"],"content":"Log4j 的架构设计  依赖 如果要接入其他日志库、Servlet、JPA，docker，可以使用《Optional Components》。 使用了可选的组件以后，第一可以自动地在某些 api 里打点，其次可以自动理解这些 api 里的环境（如 docker api 可以自动理解 docker 的容器名称）。 Logger、Appender对于常见的 log4j.xml/slf4j.xml 而言： Logger：日志记录器，负责收集处理日志记录。有 name，这个 name 可以被 java class 定义，也可以被引用。它本身没什么用，真正的配置被包在 LoggerConfig 里面。基本的实现在 AbstractLogger 里。 LoggerConfig 里面包含了一系列 Filter 的配置，会在 LogEvent 发送到 Appender 以前进行处理。 Appender：日志追加器，输出目的地（output destination），负责日志的输出（输出到什么地方）。有 name，这个 name 可以被引用。是一个很重要的功能接口。Logger ref appender。 Layout：日志布局。日志格式化，负责对输出的日志格式化（以什么形式展现）。复杂的布局性能会更差-复杂的任何处理器的性能都应该更差，无关紧要。 一个 logger 可以对应多个 appender，一个 appender 只能对应一个 layout。 rootlogger 总是 DEBUG 的 LEVEL。 默认其他 logger 都是从 root logger 里面派生出来的，主要继承了全局的 log level（&lt;root level=&quot;warn&quot;&gt;会直接导致全局的 log level 提升到 warn），而它的additivity 的配置可以禁掉日志在父 logger 里面的重复输出（Once an event reaches a logger with its additivity set to false the event will not be passed to any of its parent loggers, regardless of their additivity setting.日志会在当前的 logger 引用的 appender 里输出，而不会输出到 parent 上）。一套 logger 的例子是： 假设定义一个 APPENDER 是这样的。它与某个 log file 就联系起来了。 其中 ConversionPattern 可用的内容有（这里的 % 不是类型前缀，而是上下文变量前缀。）： %d 意味着当前时间 %m 意味着日志内容 %n 意味着换行符 然后可以定义一个 logger： 然后可以用名字来引用 logger： 我们也可以定义一个到达某个包名的 logger： 然后可以用类名来引用 logger： 一个典型的 log4j2.xml： 一个典型的logback.xml： 配置文件的内容格式log4j.appender.appenderName= appenderName org.apache.log4j.ConsoleAppender（控制台）org.apache.log4j.FileAppender（文件）org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） log4j.appender.appenderName.layout = ?? org.apache.log4j.HTMLLayout（以HTML表格形式布局）org.apache.log4j.PatternLayout（可以灵活地指定布局模式）org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） ConsoleAppender选项 Threshold=DEBUG:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。Target=System.err:默认情况下是System.out,指定输出控制台 FileAppender 选项 Threshold=DEBUG:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。 RollingFileAppender 选项 Threshold=DEBUG:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。MaxFileSize=100KB: 后缀可以是KB, MB 或者是 GB.在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。MaxBackupIndex=2:指定可以产生的滚动文件的最大数。 日志信息格式中几个符号所代表的含义 -X号: X信息输出时左对齐；%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,%c: 输出日志信息所属的类目，通常就是所在类的全名 %t: 输出产生该日志事件的线程名%x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像javaservlets这样的多客户多线程的应用中。 %%: 输出一个”%”字符%F: 输出日志消息产生时所在的文件名称%L: 输出代码中的行号%m 输出代码中指定的消息%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL%r 输出自应用启动到输出该log信息耗费的毫秒数%t 输出产生该日志事件的线程名%n 输出一个回车换行符，Windows平台为“\\r\\n”，Unix平台为“\\n”%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss , SSS}，输出类似：2002年10月18日 22 ： 10 ： 28 ， 921%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：test.main(test.java: 10 ) LevelSLF4Jlevel 值和严重程度正相反。 level 值越高，能越把低 level 的日志打出来 - 低严重程度的日志级别能把高严重级别（more specific，log4j 的文档这样叫很怪）的日志打出来。 Log4j 基础的 log4j 2 配置全解析本文来自于《Configuration》。 因为安全原因，log4j 的配置文件不按照 dtd 来定义各种 element（和 spring、mybatis 通过名字空间定义 element 不同）。 Attribute Name Description advertiser (Optional) The Advertiser plugin name which will be used to advertise individual FileAppender or SocketAppender configurations. The only Advertiser plugin provided is ‘multicastdns”. dest monitorInterval The minimum amount of time, in seconds, that must elapse before the file configuration is checked for changes. name The name of the configuration. packages A comma separated list of package names to search for plugins. Plugins are only loaded once per classloader so changing this value may not have any effect upon reconfiguration. schema Identifies the location for the classloader to located the XML Schema to use to validate the configuration. Only valid when strict is set to true. If not set no schema validation will take place. shutdownHook Specifies whether or not Log4j should automatically shutdown when the JVM shuts down. The shutdown hook is enabled by default but may be disabled by setting this attribute to “disable” shutdownTimeout Specifies how many milliseconds appenders and background tasks will get to shutdown when the JVM shuts down. Default is zero which mean that each appender uses its default timeout, and don’t wait for background tasks. Not all appenders will honor this, it is a hint and not an absolute guarantee that the shutdown procedure will not take longer. Setting this too low increase the risk of losing outstanding log events not yet written to the final destination. See LoggerContext.stop(long, java.util.concurrent.TimeUnit). (Not used if shutdownHook is set to “disable”.) status The level of internal Log4j events that should be logged to the console. Valid values for this attribute are “trace”, “debug”, “info”, “warn”, “error” and “fatal”. Log4j will log details about initialization, rollover and other internal actions to the status logger. Setting status=”trace” is one of the first tools available to you if you need to troubleshoot log4j. (Alternatively, setting system property log4j2.debug will also print internal Log4j2 logging to the console, including internal logging that took place before the configuration file was found.) strict Enables the use of the strict XML format. Not supported in JSON configurations. verbose Enables diagnostic information while loading plugins. 配置可以要么指定在 attribute、要么指定在 element。 配置 logger 日志器每一个&lt;logger&gt;元素对应一个 LoggerConfig，通常指定 name、level 和 additivity： level 默认值是 error -大部分日志都不会打印出来。 additivity 默认值是 true root 本身也是一个 LoggerConfig。 每一个 configuration 一定要有一个 root - 没有 root 就会使用默认的 error level 使用的 console apender root - 这不是什么好事。 root 不能有名字，也没有 additivity，因为它没有 parent。 有名字和 id 的设计，易于设计 entity。 配置 Appender（附加器）appender 本身可以引用插件作为实现，它可以引用 layout（这也是用插件实现的） - 一个 element 的背后是一个插件。 配置多级过滤器 字符串替换模仿 apache 的 StrSubstitutor 和 StrLookup 是个好东西。我们经常可以用到的根对象包括 base64、bundle、ctx、date、env、jndi、jvmrunargs（从 RuntimeMXBean.getInputArguments() 可以取出来）、log4j、main、map、sd、sys。 这些表达式都支持缺省值模式，如$&#123;lookupName:key:-defaultValue&#125;.。 脚本编程log4j2 支持 javascript 脚本编程 - 类似 logstash 对 ruby 的支持： 配置 log4j2 的方法 通过各种配置文件：properties、xml、json、yaml。 程序化地通过 ConfigurationFactory（上面每一种格式都配有一种 factory）。 通过 Configuration 接口的方法。 通过 Logger Class - 动态改变配置和行为。 用 XInclude 来引入其他配置文件 使用 CompositeConfiguration 组合配置用一串逗号分隔的配置文件列表填充 log4j.configurationFile。 程序化地直接使用 log4j2这段还是很复杂，应该直接看《Programmatic Configuration》： 如果没有定位到任何配置文件，log4j2 的行为是 A ConsoleAppender attached to the root logger. A PatternLayout set to the pattern “%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n” attached to the ConsoleAppender 多个 logger 的例子 Filter 详解ThresholdFilterThresholdFilter是临界值过滤器，过滤掉低于指定临界值的日志（换言之 logger 和 appender 都有过滤功能，只不过是在端点上过滤罢了）。当日志级别等于或高于临界值时，过滤器返回NEUTRAL；当日志级别低于临界值时，日志会被拒绝。 每隔 30s 查找一下日志更新级别 关于日志性能的观点low-latency 是重要的。 异步化是应对 event 爆发的利器（使用异步化的数据结构的 Disruptor，十几万的 qps都顶得住，异步化可以说是当前提升性能吞吐的最强方法）。日志异步化要引入独立后台线程 + 一个 queue。这种 queue 往往会带来 lock contention。使用 queue 的话，记录日志的操作被简化为 enqueue 操作，业务线程可以立刻调头回去执行业务逻辑。 AsyncLogger 使用一个 lock-free data structure（实际上就是 LMAX Disruptor）。 而 logback、log4j、log4j2 的 AsyncAppender 使用的是 ArrayBlockingQueue，会带来 lock contention（在 enqueue 操作上产生竞争）。 所有的异步操作都需要关注 queue size，queue size 满了以后服务的性能会回退到同步操作。 使用了优秀的数据结构，线程越多（workload 越大），日志框架的吞吐量越高。但队列总有满的时候，队列满以前的峰值叫作 peak throughput；队列满了以后的吞吐量叫作 maximum sustained throughput。不同的测试标准需要不同的工作负载（workload）。 logger -LogEvent-&gt; filter -&gt; appender 不要使用Location相关属性，例如 C or $class, %F or %file, %l or %location, %L or %line, %M or %method，大概降低 30到100倍。includeLocation要设置为false（默认为false，可以直接不设置）。 推荐使用RollingRandomAccessFile，大概可以视为RollingFileAppender的进化版，没有bufferedIO这个属性，对于RollingRandomAccessFile，缓存是固定开启的。fileName是实时写入的（未归档）文件名，filePattern则是归档文件的命名模式，因为开启了异步日志所以这里immediateFlush设置为false（不过好像不管它也无所谓），bufferSize缓冲区大小暂时默认（默认为8K），最后，TriggeringPolicy和RolloverStrategy是必须有的，没有显示定义就会采用默认的。asyncLogger 使用 asyncLoggerRingBufferSize。 异步日志的使用方法Log4j2提供了两种实现日志的方式，一个是通过AsyncAppender，一个是通过AsyncLogger，分别对应前面我们说的Appender组件和Logger组件。注意这是两种不同的实现方式，在设计和源码上都是不同的体现。 在使用异步日志的时候需要注意一些事项，如下： 不要同时使用AsyncAppender和AsyncLogger，也就是在配置中不要在配置Appender的时候，使用Async标识的同时，又配置AsyncLogger，这不会报错，但是对于性能提升没有任何好处。 不要在开启了全局同步的情况下，仍然使用AsyncAppender和AsyncLogger。这和上一条是同一个意思，也就是说，如果使用异步日志，AsyncAppender、AsyncLogger和全局日志，不要同时出现。 如果不是十分必须，不管是同步异步，都设置immediateFlush为false，这会对性能提升有很大帮助。若是ImmediateFlush=true，一旦有新日志写入，立马将日志写入到磁盘的文件中。当日志很多，这种频繁操作文件显然性能很低下。 如果不是确实需要，不要打印location信息，比如HTML的location，或者pattern模式里的%C or $class, %F or %file, %l or %location, %L or %line, %M or %method, 等，因为Log4j需要在打印日志的时候做一次栈的快照才能获取这些信息，这对于性能来说是个极大的损耗。 AsyncAppenderAsyncAppender是通过引用别的Appender来实现的，当有日志事件到达时，会开启另外一个线程来处理它们。需要注意的是，如果在Appender的时候出现异常，对应用来说是无法感知的（异步化的缺点）。 AsyncAppender应该在它引用的Appender之后配置，默认使用 java.util.concurrent.ArrayBlockingQueue实现而不需要其它外部的类库。 当使用此Appender的时候，在多线程的环境下需要注意，阻塞队列容易受到锁争用的影响，这可能会对性能产生影响。这时候，我们应该考虑使用无锁的异步记录器（AsyncLogger）。 AsyncAppender 采用的是生产者消费者的模型进行异步地将Logging Event送到对应的Appender中。 a、 生产者：外部应用了Log4j的系统的实时线程，实时将Logging Event传送进AsyncAppender里 b、 中转：Buffer 和 DiscardSummary c、 消费者：Dispatcher 线程和 appenders 工作原理： 1） Logging Event进入AsyncAppender，AsyncAppender会调用append方法，在append方法中会去把logging Event填入Buffer中，当消费能力不如生产能力时，AsyncAppender会把超出Buffer容量的Logging Event放到DiscardSummary中，作为消费速度一旦跟不上生成速度，中转buffer的溢出处理的一种方案。 2） AsyncAppender有个线程类Dispatcher，它是一个简单的线程类，实现了Runnable接口。它是AsyncAppender的后台线程。 Dispatcher所要做的工作是： ① 锁定Buffer，让其他要对Buffer进行操作的线程阻塞。 ② 看Buffer的容量是否满了，如果满了就将Buffer中的Logging Event全部取出，并清空Buffer和DiscardSummary；如果没满则等待Buffer填满Logging Event，然后notify Disaptcher线程。 ③ 将取出的所有Logging Event交给对应appender进行后面的日志信息推送。 以上是AsyncAppender类的两个关键点：append方法和Dispatcher类，通过这两个关键点实现了异步推送日志信息的功能，这样如果大量的Logging Event进入AsyncAppender，就可以游刃有余地处理这些日志信息了。 很简单的生产者-消费者，锁 buffer 的模型，但 log-event 和 disruptor 的模型很精妙（ringbuffer 和普通的拥塞队列都值得研究）。 AsyncLoggerAsyncLogger才是log4j2 的重头戏，也是官方推荐的异步方式。它可以使得调用Logger.log返回的更快。你可以有两种选择：全局异步和混合异步。 全局异步就是，所有的日志都异步的记录，在配置文件上不用做任何改动，只需要在jvm启动的时候增加一个参数； 混合异步就是，你可以在应用中同时使用同步日志和异步日志，这使得日志的配置方式更加灵活。因为Log4j文档中也说了，虽然Log4j2提供以一套异常处理机制，可以覆盖大部分的状态，但是还是会有一小部分的特殊情况是无法完全处理的，比如我们如果是记录审计日志，那么官方就推荐使用同步日志的方式，而对于其他的一些仅仅是记录一个程序日志的地方，使用异步日志将大幅提升性能，减少对应用本身的影响。混合异步的方式需要通过修改配置文件来实现，使用AsyncLogger标记配置。 全局异步 在系统初始化的时候，增加全局参数配置： 你可以在你第一次获取Logger之前设置，也可以加载JVM启动参数里，类似 混合异步 无垃圾的日志防止垃圾回收是通过避免创建临时对象来实现的（即尽量复用对象）。 但有要注意避免： 部分被复用的对象保存在 ThreadLocal 区域中。这样的设计对独立的应用程序来说没有问题，但是对于 web 应用可能会引起内存泄漏。 log4j 防止触发垃圾回收的另一个方式是在将文本转换为字符数组的时候复用缓冲区。所有类型的应用程序都可因此受益，且该功能默认是开启的。然而使用同步日志记录器的多线程应用程序可能会有性能影响，因为不同的线程需要竞争共享的缓冲区。如果遇到这种情况，应该优先使用异步日志记录器，或者禁用共享缓冲区。 只有部分追加器已经修改以避免创建临时对象：Console（控制台）、File（文件）、RandomAccessFile（随机访问文件）、上述追加器的回卷追加器、MemoryMappedFile（内存映射文件）。任何其他追加器都会产生垃圾，并且需要被回收。然而需要注意的是，这些追加器本身可以免垃圾回收，仍然会有其他 I/O 相关的因素会影响它们的性能。 GelfLayout（Graylog Extended Log Format）布局只有在压缩选项禁用时才支持免垃圾回收，而 PatternLayout（我们最常用的布局方式） 只支持限定的转换模式，任何其他转换模式都会创建临时对象。 API 本身也已经为避免创建临时对象而修改。除了之前支持简单可变长度参数（这样会创建一个临时数据）的方法之外，log4j 新增了所有方法的重载版本，最多支持 10 个参数。调用方法超过 10 个参数仍然会使用可变长度参数，这将会创建临时数组。这个限制对于通过 SLF4J 使用 log4j 的场景影响较大，因为这个门面库只提供了最多两个参数的非变长参数。用户如果希望使用超过两个参数，并运行在免垃圾回收模式，就需要抛弃 SLF4J。 虽然已经做了向下兼容，以避免开发者更新代码，有一类临时对象的创建和 log4j 框架本身无关：对基本数据类型的自动装箱。为了确保 JVM 不将基本数据类型装换成对应的对象，开发者在给 log4j 传递基本数据类型时，可以使用静态方法Unboxer.box()。该方法可以允许 log4j 直接处理基本数据类型而无需创建不必要的对象。 参考文献：  "},{"title":"疑难汉字","date":"2018-11-25T06:02:16.000Z","url":"/2018/11/25/%E7%96%91%E9%9A%BE%E6%B1%89%E5%AD%97/","tags":["语言","中文"],"content":" 字 读音 含义 刳 kū 从中间破开；破开后再挖空。 「刳竹」 剡 yǎn 削；削尖 [sharpen] "},{"title":"scoop 安装","date":"2018-11-24T16:23:52.000Z","url":"/2018/11/25/scoop-%E5%AE%89%E8%A3%85/","tags":["windows"],"content":"首先要有一个 Powershell 3.0 与 .Net 4.5 以上的环境。 在 PowerShell 中输入： 如果没有网络问题，则可以直接安装成功（可能需要修改一些与 admin 有关的 policy）。如果安装不成功，则删除C:\\Users\\LC\\scoop再试一次。 "},{"title":"MySQL 中的引号","date":"2018-11-15T06:59:10.000Z","url":"/2018/11/15/MySQL-%E4%B8%AD%E7%9A%84%E5%BC%95%E5%8F%B7/","tags":["MySQL"],"content":"标准的 SQL 中只允许用单引号表达字符串类型。有些 SQL 方言允许使用双引号包裹字符串，如 MySQL，有些则不允许，如 Oracle。 反引号是专门用来表达 identifier 的。"},{"title":"MySQL 字符串和数字隐式转换的 pitfall","date":"2018-11-15T06:46:59.000Z","url":"/2018/11/15/MySQL-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E6%95%B0%E5%AD%97%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2%E7%9A%84-pitfall/","tags":["MySQL","未完成"],"content":"Data truncation: Truncated incorrect 不要小看 MySQL，它出 warning 就一定有错误。 不要滥用 MySQL 字符串到decimal，和 decimal 到 string 的转换。这样有时候 MySQL 不只是 warning。"},{"title":"散列算法","date":"2018-11-14T04:56:01.000Z","url":"/2018/11/14/%E6%95%A3%E5%88%97%E7%AE%97%E6%B3%95/","tags":["算法"],"content":" MD5 易于碰撞。 SHA1 是 git 默认的 commit 用的散列算法。 SHA2 是第二代安全散列算法，合共有六种。 SHA256 是其中一种。 参考：  "},{"title":"高级设计和分析技术","date":"2018-11-10T12:50:40.000Z","url":"/2018/11/10/%E9%AB%98%E7%BA%A7%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%88%86%E6%9E%90%E6%8A%80%E6%9C%AF/","tags":["算法"],"content":" 动态规划动态规划的本质，是寻找状态的定义，并基于这个定义给出状态转移的方程。 最优子结构(optimal substructure） 定义我们通常要做出一组选择来达到最优解。 在做每个选择的同事，通常会生成与原问题形式相同的子问题。当多于一个选择子集都生成相同的子问题的时候，动态规划通常就会很有效。其关键技术就是对每个这样的子问题都保存其解。档期重复出现时，可避免重复求解。 programming 其实是一种表格法，而非编程。分治法解决的问题是，互不相交的子问题。 最优解有两种： an optimal solution vs the optimal solution。 步骤 刻画一个最优解的结构特征。 递归地定义最优解的值。 计算最优解的值，通过自底向上的方法。 利用计算出的信息，构造一个最优解。 递归是自顶向下求解。迭代可以自底向上求解。 能够用动态规划来解的问题通常具有两个性质： 最有子结构性质：问题的最优解，是由相关子问题的最优解组合而成，而这些子问题可以独立求解。 子问题重叠性质：最优子结构里可能出现的子问题，可能会产生重叠。 切割钢条问题一般形式要做基本的切割分析，得出切割方案的一般形式（因为对称性，我们总可以去掉一部分解），如： rn = max(pn, r1 + r(n-1),…, rn-1 + r(1)) 更进一步推导出具体形式： rn = max(pn + rn-1) 递归调用树分析 借助递归调用树的节点总数，我们可以估计总调用次数。 需要通过证明，得知 T（n）= 2 的 n 次方（TODO）。 日后可以把它转化为子问题图： 动态规划的两种等价实现方法动态规划仔细安排求解顺序，对每一个重复的子问题只求解一次，并将结果保存下来。 这是典型的时空权衡问题（time-memory trade-off）。 带备忘的自顶向下方法（top-down with memoization）。 贪心算法与动态规划相似，贪心算法通常用于最优化问题。我们做出一组选择来达到最优解。贪心算法的四项，是每一步都追求局部最优解。 贪心选择性质的证明总是：假定一个存在一个最优解。最优解中的第一个选择如果可以被替换，替换成另一个贪心选择而能得到【另一个兼容】的最优解，则这个问题具有贪心选择性质。 只能用 dp 来解的问题，通常子问题的解是不能相容的，一个子问题的部分选择无法替换成另一个选择而让解的其他部分不变。贪心算法可以解决分数背包问题，不能解决0-1背包问题。因为0-1背包问题，把价值最高的解替换成功价值次高的解，有可能造成空间的变化，以至于让子问题的规模也得以变大-子问题的解可能也因此上升。 霍夫曼编码霍夫曼具有贪心算法性质。霍夫曼编码使用了一种前缀编码（prefix code），即没有任何码字是其他码字的前缀。使用这种前缀码，我们得到一串编码后可以唯一地解析出我们想要的信息，不产生二义性。 变长编码本身是一种变长编码（variable-length code），有点类似于 utf-8。核心思想是让拥有更高出现频率的 character 得到更短的码字。 摊还分析（amortized analysis）摊还分析只能拿来分析一类特定的算法。摊还分析并不是通过分析每个操作的实际代价的界，来分析操作序列代价的界，而是直接分析序列整体的代价的界。这种方法的一个好处是，虽然某些操作的代价可能很高，但其他很多操作的代价可能很低。 Progamming Checklist 先写防御性编程方案。 然后写提前截断流程的子问题的答案。 开始用递归或者迭代的方式求子问题的解，并逐渐推导到当前问题。 "},{"title":"checklist","date":"2018-10-26T03:06:51.000Z","url":"/2018/10/26/checklist/","tags":["软件工程"],"content":"写代码 checklist注意位置注意顺序注意初始化注意返回值注意注释注意防御性编程注意数据库性能 上线 checklist代码变更 check 代码配置变更 check 配置系统变更注意上线顺序依赖中间件变更注意配置中间件配置中心配了吗交互所有细节都实现了吗？配监控和埋点数据库变更了吗？安全检查"},{"title":"JDWP 与远程调试","date":"2018-10-22T09:20:14.000Z","url":"/2018/10/22/JDWP-%E4%B8%8E%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/","tags":["JVM","Java"],"content":"JDWP（Java Debug Wire Protocol），它提供了调试器和目标 JVM （target vm）之间的调试协议。 在 target vm 启动时，增加这个 JAVA_OPTS： 在服务器端，增加 remote debuging 的时候使用如下配置： 可以看出 Java agent API 的出现，对 Java 技术体系的影响还是很大的。"},{"title":"Maven 插件配置指南","date":"2018-10-21T07:26:07.000Z","url":"/2018/10/21/Maven-%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/","tags":["Java","Maven"],"content":"本文主要参考了《Guide to Configuring Plug-ins》： maven 实际上有两种插件： 构建插件，需要在&lt;build/&gt;元素里配置。如&lt;build&gt;&lt;pluginManagement/&gt;&lt;/build&gt;，当然也有&lt;build&gt;&lt;plugins/&gt;&lt;/build&gt;。 报告插件，会在“site generation”里被执行，应该在&lt;reporting/&gt;里配置。如&lt;reporting&gt;&lt;plugins/&gt;&lt;/reporting&gt;。 要引用插件至少要有三个元素：groupId，artifactId， version。 mojo 是什么根据《What is MOJO in Maven?》，mojo 是 Maven plain Old Java Object 的意思。实际上是可执行的 goal。 通用配置一个插件通常包含一个以上的mojo，当一个 mojo 被映射到 goal 的时候，则包含多个 mojo（即一个插件可能有多个 goal）。maven 通过 元素来配置 maven 插件， 的子元素，就会映射到 mojo 的字段，或者 setter 里。 假设有一个mojo： 生成的 xml 就如下： 可以看到&lt;configuration/&gt;确实是 schemaless 的。 而且这些 field 上的注释可以注明缺省值，以及与命令行参数一起使用时的表达式： 查看帮助通常插件都带有一个help的 goal，通常可以用以下的方法查看（自行替换插件名称）： 配置参数普通类型基本类型的映射，就使用字面量配置&lt;configuration/&gt;元素： 复杂类型如果有复杂（complex not compoud）类型映射的需要： maven 会以大写首字母的方式，在 mojo 本身存在的包里寻找 person 类，否则，就要指定包名： 列表类型同数组不同，列表类型在 maven 的xml 语法里不是强类型的（换言之，数组是）： 其映射规则是： If the XML element contains an implementation hint attribute, that is used If the XML tag contains a ., try that as a fully qualified class name Try the XML tag (with capitalized first letter) as a class in the same package as the mojo/object being configured If the element has no children, assume its type is String. Otherwise, the configuration will fail. map 类型 Properties 类型和 map 表达嵌套的方式恰好又不一样了，更加工整： 配置构建插件使用&lt;executions&gt;标签 注意，在一个 POM 的一个插件里，execution id 必须是唯一的。 一个 plugin 在多个 phase 多次被执行的例子： 下面这个 mojo，用注释标明了这个 plugin/goal 的默认 phase： 我们可以使用 xml 配置来覆盖初始配置： 曾经，maven 插件的如果处于内部，则无法被命令行 invocation 调用，因为它必须到指定生命周期 phase 才可以被使用。但自 Maven 3.3.1 以后，我们可以直接这样做： 使用&lt;dependencies&gt;标签插件自己也有自己的默认 dependency，我们可以在插件内部自己使用&lt;dependencies&gt;来更换它的依赖。如 Maven Antrun Plugin version 1.2 使用的 Ant version 1.6.5，我们可以这样更新依赖（兼容性自己保证）： 在构建插件里使用&lt;inherited&gt;标签默认的插件配置是会被传播（propagated）到子 pom 里的，所以可以显式地设置&lt;inherited&gt;为 false 来打破这种属性 配置 reporting 插件使用 &lt;reporting&gt; Tag VS &lt;build&gt; Tag&lt;build&gt; 标签里也可以配置 reporting 插件，但大部分情况下&lt;reporting&gt;里的配置都优先被使用。具体细则见 maven 原文档。 使用&lt;reportSets&gt;标签如果我们想要选择性地生成报告，我们可以使用&lt;reportSets&gt;标签，只有被它包括的报告，才被选中生成： 推而广之，一份报告都不生成的时候，我们可以这样做： 在报告插件中使用&lt;inherited&gt;标签同构建插件差不多 "},{"title":"Maven 构建生命周期","date":"2018-10-21T06:05:18.000Z","url":"/2018/10/21/Maven-%E6%9E%84%E5%BB%BA%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","tags":["Java","Maven"],"content":"maven-生命周期.xmind 构建生命周期的基础知识Maven 基于一个“构建生命 周期”的中心概念，也就意味着构建和发布一个特定的工件（也就是工程）的过程已经被清晰地定义了。 有三种内置的生命周期：default，clean 和 site。default 生命周期处理处理项目部署，clean 生命周期处理项目清理，site 生命周期处理项目的站点（site）文档的创建。 实际上这些 lifecycle 只是在（比如 idea 里）对 phase 归类的时候特别有用，我们平时使用 mvn 命令的时候是无法指定这几个生命周期的。 一个构建生命周期是由多个阶段（phases）组成的上面每个生命周期是由不同的 phase 列表组成的。一个 phase 表示一个生命周期的一个 stage（这两者有什么差别？）。 default 里 phases 的顺序大致上是是 validate -&gt; compile -&gt; test -&gt; package -&gt; verify -&gt; install -&gt; deploy。 使用命令行如果我们使用命令： 实际上到 install 为止所有的phases 都会执行，所以我们通常只要指定执行某一个生命周期的最后一个目标 phase 就行了。 如果我们使用命令： maven 会先进行清理，然后再进行部署。如果这是一个多 module 的项目（即有多个子项目），则会遍历每个项目以执行 clean 和 deploy。 每一个构建 phase 是由构建 goal 组成的phase 下面还可以再细分，细分的单元就是 plugin goal。 plugin goal 其实是一个执行的任务（比 phase 更细粒度）一个 goal 可以和一个或者多个 phase 绑定，甚至在生命周期之外通过直接 invocation 运行。 mvn 是一级命令。 clean 和 package 是二级命令，也就是 phase。 dependency 是三级命令，也就是 plugin。 copy-dependencies差不多可以说是参数，也就是 plugin goal。 上面的命令就是执行 clean 及其前面所有的 phases 的所有 goal，单独执行 dependency 插件的 copy-dependencies goal，然后再执行 package 的所有 goal。 一个 goal 被绑定到(bound 是 bind 的过去分词形式)多个 phase，这个 goal 会被执行多遍。 设置你的项目来使用构建生命周期如何把任务分配到构建 phases 里？ packaging第一个方法是使用 packaging，它对应的 POM 元素是&lt;packaging&gt;。它的有效值分别是：jar、war、ear 和 pom（pom 也是一个 packaging 值，证明这个项目是 purely meta data）。默认值就是 jar。 packaging 有不同的值，插件的 goal 对各个 phases 的绑定就不同。 jar 的插件绑定如下： 其他 phases 见这个《Plugin Bindings for default Lifecycle Reference》。 plugins插件是向 maven 提供 goal 的 artifact，即插件虽然自己包含很多 mojo，但它是以 artifact 的形式向外发布自己的能力（capability）的。例如，compile插件提供两个 goal：compile和testCompile（注意看，没有中间的 hyphen，所以不是 phase）。 在添加插件的时候要注意，不是只是加入一个 plugin 就万事大吉了，我们需要指定我们想要在构建的时候运行的 goal。 因为 packaging 本身也含有对插件和 goal 的绑定，所以我们要当心混合使用的时候的顺序问题。我们可以使用&lt;execution/&gt;来进行顺序的控制，如： execution 里还可以指定 phases： 生命周期参考clean 生命周期的 phases phase 含义 pre-clean 在实际的项目清理以前，需要被执行的处理过程（processes） clean 移走前一个 build 生成的所有文件 post-clean 执行所有需要用来终结项目清理的过程 default 的 phases phase 含义 validate 验证项目是正确的，且所有必须信息是可用的（实际上就是整个 pom 文件是 valid 的） initialize 初始化构建状态，即设置 properties 或创建目录。也就是 properties 要在这个阶段被 inject generate-sources 为任何编译中的inclusion（包含）生成源代码。 process-sources 处理源代码，比如过滤某些值 generate-resources 为打包的时候需要的inclusion（包含）生成资源。也就是中间资源（resources/assets）生成。 process-resources 拷贝和处理资源到目标文件夹里，为打包做准备。也就是静态资源准备完毕 compile 编译项目的源代码 process-classes 后处理编译生成的文件，比如对 Java 类进行字节码增强。也就是 generate-test-sources 为编译中的inclusion（包含）生成测试用源代码 process-test-sources 处理测试源代码，比如过滤某些值 generate-test-resources 为测试创建资源。 process-test-resources 复制和处理资源到测试目标目录 test-compile 编译测试源代码到测试目标目录 process-test-classes 对测试编译的结果进行后处理，比如进行字节码增强，需要 Maven 2.0.5 和以上版本。 test 用测试框架中合适的单元运行测试，这些测试不能要求类被打包和部署 prepare-package 进行任何实际打包前必须的准备操作 package 把编译过的远吗装进一个可发布格式，比如 JAR pre-integration-test 进行集成测试前需要的活动，比如设置一个合适的环境 integration-test 处理和部署一个包，如果有必要的话，部署到一个集成测试可以被运行的环境里 post-integration-test 执行集成测试后需要执行的活动，比如清理环境 verify 跑一些校验，来验证包是有效的，而且满足质量标准的 install 把当前的包安装到本地仓库，这样可以作为其他项目的本地依赖 deploy 在集成或者发布环境中执行，把包拷贝到一个远程的仓库，给其他开发者和项目共享 site 的 phases phase 含义 pre-site 执行需要在站点生成（generation）之前执行的流程 site 生成项目的站点文档 post-site 执行需要被用来终结站点生成的操作，来为站点部署做准备 site-deploy 部署站点文档到特定的 web server 里（而不是仓库里） "},{"title":"卡表和 RSet","date":"2018-10-13T08:01:59.000Z","url":"/2018/10/13/%E5%8D%A1%E8%A1%A8%E5%92%8C-RSet/","tags":["JVM","Java"],"content":"上下文卡表和 RSet（Remember Set），是 JVM 为了解决分代收集时，live set 扫描需要穿梭到不同的代的时候的效率问题。 使用缓存表来提高查询效率，是化顺序查找为部分随机查找的一种常用的设计思路。 例如，在传统的计算机体系结构中，当我们把内存分成页以后，会有一个页表，页表又会有一个快表，作为一个中间缓存项，来帮助我们查找我们需要使用的页表项（table entry）。 JVM 在进行垃圾收集的时候，有一项非常重要的工作就是确定这一次垃圾收集的对象到底有多少个，即确定 live set 的范围。 对于新生代垃圾收集器而言，这个问题又有其特殊之处。根据 JVM 的弱分代收集假设（weak generational hypothesis）的存在，每次垃圾收集的时候，新生代的扫描范围可能很大，但新生代的 live set 不应该太大。card table/Remember Set 的设计目的，就是尽量减少无用的垃圾扫描范围，使用类似操作系统或者数据库的脏页表的形式，来做类似快表的查询。 卡表（card table） 卡表是 CMS 的解决方案。 卡表通常在 JVM 中实现为单字节数组。当我们把 JVM 划分成不同区域的时候，每一个区域（通常是4k字节）就得到了一个标志位。每一位为 1 的时候，表明这个区域为 dirty，持有新生代对象，否则，这个区域不持有新生代对象。这样，新生代垃圾收集器在收集live set 的时候，可以通过以下两个操作： 从栈/方法区出发，进入新生代扫描。 从栈/方法区出发，进入老年代扫描，且只扫描 dirty 的区域，略过其他区域。 每次老年代中某个引用新生代的字段发送变化时，JVM就应当将对应的卡表元素设置为适当的值，从而将该字段所在的卡片标记为脏（把读操作的开销用写操作来提前分担，也是一种重要的性能优化手段）。 JVM 在实现卡表的时候，对于所有老年代更新新生代的操作插入了一种写屏障（write barrier），写屏障保证所有更新引用操作能把卡表的脏位设置到最新状态。不仅原生代码拥有这种写屏障，JIT 生成的代码也有这种写屏障。这也使用类似数据库索引/触发器的设计思路，但因为是对于一类操作模式的增强，所以和 AOP 殊途共归。我们实现自己的辅助数据结构也需要引入类似 xxxbarrier 的设计，这样才能保证一致性，这种 barrier 作为 pre 比 post 对一致性的保障要好。 与卡表相关的 JVM 参数是： 在 JVM 中，一个 card 的大小（通常是）512字节。在多线程并行收集时，每个线程可以批量扫描多个 card，一批 card 被称为一个 stride。默认一个 stride 含有 256个 card，即每个线程要每次扫描 512 * 256 = 128 K 的内存区域。stride数量太多就会导致线程在stride之间切换的开销增加，进而导致 GC Pause 增长， strides 太少恐怕也会导致单次扫描的时间增长，进而影响整个 GC Pause 。 网上流传有3个 magic number 作为配置值:32768、4K和8K。 RSet（Remember Set） Remember Set 是从 G1 开始特有的一种数据结构，是卡表的设计思路 + G1 垃圾收集器使用场景的衍生产物。 伴随 Hotspot G1 垃圾收集器的诞生，传统的老年代和新生代都从物理上的连续空间，变成了一个个物理上不连续的空间 region。 JVM 针对这些Region 提供了一个数据结构，也就是 CSet（Collection Set），存储任意年代的 region。 物理上不连续的 region 造成了新生代和老年的引用破碎化，新生代引用老年代，所以产生了 old-&gt;young和old-&gt;old的跨代对象引用，这时候 JVM 只要扫描 CSet 中的 R Set 即可。 传统卡表的特征是 points-out，即记录当前老年代区域区域所指向的新生代的状况。RSet 则更加细致，每个region拥有自己的 RSet，记录所有其他 region 指向它的指针，它的设计特征是 points-into。老年代可以共用一个传统卡表，但 RSet 必定是每个 region 一个的。RSet 其实是一个 Hash Table，Key 是别的 Region 的起始地址，Value 是一个集合，里面的元素是 Card Table 的Index-所以G1的 RSet 是在 Card Table 的基础上实现的，每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 下图是相互引用的三个region。R1 和 R3 的被细分到了card table 级别。R2 被 R1 和 R3的某些区域引用，所以 R2 的 RSet 会记录到 R1 和 R2 的区域索引，即产生某些循环引用的作用。 一个 Region 的 RSet 如果有值，至少可以证明这个区域是有引用的（如果有循环引用另外讲）；一个区域如果无值，则可以认为这个区域不可达，可以不扫描这个区域（Card Table 可以减少 Minor GC 扫描 old 区来理解 young 区的时间，RSet 则可以减少扫描生成 CSet 选取候选 region 的时间）。 在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation（只扫描在 old 里出现的 region，我猜测，young 区里面没有 points-into 的 RSet 对应的 young region 也是可以直接回收的，不必从根出发。）。 而mixed gc的时候，old generation中记录了old-&gt;old的 RSet，young-&gt;old的引用由扫描全部young generation region（的 card table）得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量-old 区总是面积大、碎片多，不宜扫描过多。 上图中有三个Region，可以被看作一个 CSet，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，这就是points-into。 而维系RSet中的引用关系靠post-write barrier和Concurrent refinement threads来维护。 结论卡表只解决 ygc 少扫老年代的问题，而 RSet 则解决了（G1 对）所有 Region 的扫描问题。 卡表通过对外引用提示我们应该扫描什么区域，这样我们可以避开不用扫描的区域；RSet通过对内引用提示我们应该扫描什么区域，这样我们可以避开不用扫描的区域。 不管是卡表还是 RSet，都通过写表 + 查表的方式减少了对堆的扫描，进而减少 GC 的时间。 参考资料： 《jvm的card table数据结构》 《Java Hotspot G1 GC的一些关键技术》 "},{"title":"数据建模名称规范","date":"2018-10-08T09:27:25.000Z","url":"/2018/10/08/%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E5%90%8D%E7%A7%B0%E8%A7%84%E8%8C%83/","content":"综合 NV + DiDi + Ali 的各种命名规范。 DO（ Data Object）：与数据库表结构一一对应，通过DAO层向上传输数据源对象。 DTO（ Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。 BO（ Business Object）：业务对象。 由Service层输出的封装业务逻辑的对象。 AO（ Application Object）：应用对象。 在Web层与Service层之间抽象的复用对象模型，极为贴近展示层，复用度不高。 VO（ View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。 POJO（ Plain Ordinary Java Object）：POJO专指只有setter/getter/toString的简单类，包括DO/DTO/BO/VO等。 Query：数据查询对象，各层接收上层的查询请求。 注意超过2个参数的查询封装，禁止使用Map类来传输。 Entity：JPA 规范下从数据持久层存储里取出来的对等对象。其实相当于 DO 。 Request：RESTful 接口的输入参数。相当于入参特化的 DTO。 Response：RESTful 接口的返回值。相当于返回值特化的 DTO。 "},{"title":"业务分析方法","date":"2018-10-08T06:32:09.000Z","url":"/2018/10/08/%E4%B8%9A%E5%8A%A1%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/","tags":["软件工程"],"content":"背景从 prd 出发，分析业务需求，寻找可以创造价值的方案。 业务分析的价值 全面分析用户的各项需求 告诉我们“做什么” 业务分析的目的 理解产品需求，识别业务范围 分析业务模块的重要程度、优先级 发现产品设计的不足 为后后续测试分析做准备 业务分析方法-整体过程用不同的动作达到不同的产出。 理解 需求背景（必须） 举例：阿里巴巴账户体系要初步阐述：1. 产生什么价值。 2. 需要解决什么问题。3. 甚至要阐明要达到什么目标（比如，基于支付宝账户体系统一账户id）。 现状分析（必须） 产品定位 现有业务架构 产品业务范围 规划业务架构（1. 要有分期的意识，识别产品形态。 2. 要有清洗数据的方案，预测安全风险） 识别（抽象分析建模） 业务角色（实际上就是系统交互的输入方，有多少个角色，就需要关注多少个东西） 自然人 其他系统 业务串联（为了找业务用例。业务串联就是把一堆文字描述串在一起） 业务用例（建模-业务用例图 用例是对场景的概括） 分析业务用例（建模-活动图 活动图是对用例的拆解） 提炼（进一步建模） 关键流程 由活动图的 action 逐一用流程图分析，并且做规则分析。 业务状态流 细化（在模型之上补充完备） 补充流程 ： 又是互联网又是金融 有什么异常分支 有什么反向流程 要搞清楚既有流程的设计逻辑 分析用例价值 如果不做，有什么理由可以说服别人。要思考认可什么，不认可什么。 确定业务边界（就是搞清楚对上下游，四面八方的影响） 明确业务涉众 明确职责划分 推动跨线评估 "},{"title":"系分方法论交流笔记","date":"2018-10-08T03:19:17.000Z","url":"/2018/10/08/%E7%B3%BB%E5%88%86%E6%96%B9%E6%B3%95%E8%AE%BA%E4%BA%A4%E6%B5%81%E7%AC%94%E8%AE%B0/","tags":["软件工程"],"content":"分析、设计和架构的区别系分 = 业务分析 + 系统设计 系分其实就是 Analysis + Design 业务分析才是最重要的大头要理解： 架构约束 项目约束 要有： 权衡 选择的过程 理解业务，要理解业务背后的东西，产出的是模型。一步一步走，推演出来解决方案，要有方法论。 系统设计是很明确的工作了应用设计 + 数据设计 + 技术设计 = 系统方案 要考虑的额外问题： 非功能设计：运行关注点、运维关注点、开发关注点、测试关注点。 项目约束 常见方法论用例驱动设计SOAD 面向服务的分析和设计OOAD 面向对象分析和设计DDD 领域驱动设计 DDD特别适合复杂系统。有一个以不变应万变的对象，才可以在未来承载复杂的业务演进过程。这几种方法论可以混合使用。 需求分析与业务建模把 prd 从薄读到厚，把文档中缺失的部分补全。 __系分做 PRD 评审的时候，影响比较大的点一定要尽早确认。__一些对系统变化可控，可预测的变化，可以暂时放过，后续在补充。 面向服务的业务建模分析主业务服务，设计业务功能域，设计业务功能域边界。这个过程可能不断地螺旋式地重构。 如果用泳道来画流程图，则每一个泳道都可以得到一个服务域。 一组业务功能域要有明确的职责分配。 对业务流程的分析也要很仔细。 要随时停下来思考： 看看是不是交互过于复杂、频繁。要停下来重新设计内聚和耦合关系。 要思考通信协议的影响。 要思考对其他系统的影响。 要思考异常流程的影响。 考虑要不要使用现有的技术平台。 要符合现有应用的架构，技术的标准。 领域建模用科学方法找到系统模式。 寻找到名词和动词，模型客观而抽象地描述了事实，而且带有结构、状态和行为。 OOD 到 OOP 产生的类最少。 SOAD 到 SOAP 产生的类比较多。 DDD 产生的类比较多。 有些地方流程图表达不出来，需要使用状态图表达。 非功能设计与验证可维护性回答一个问题，谁来维护，维护什么？ 要写好注释和文档，把设计的缺陷和原因讲清楚。 分层分层可以让依赖清晰 突破模式 反响依赖 循环依赖 一定要可控，而且有收益。"},{"title":"Docker 与存储","date":"2018-09-21T06:07:06.000Z","url":"/2018/09/21/Docker-%E4%B8%8E%E5%AD%98%E5%82%A8/","tags":["Docker"],"content":"写在前面的话容器的默认状态难以从容器中搬运出来。 容器的默认状态是基于联合文件系统的，也就是需要存储驱动的支持，效率会比直接写到宿主机文件系统里要差一点。 所以此处 storage driver，就正对应 network driver 了。 把数据写入到宿主机上的方法有：volumes 和 bind mounts。如果在 linux 上，还有 tmpfs mount。注意，这些东西不是 storage driver。 他们之间的关系是： Volumes在宿主机文件系统上，Volumes 使用一块专属的路径来存储 docker 文件，如/var/lib/docker/volumes/，其他进程不应该碰这些文件。 Volumes 是 Docker 持久化数据最佳的选择。 常见创造数据卷的方法只能迟至容器创建时把一个数据卷和容器关联起来。 是docker volume create。 容器/服务创建时，使用 -v/--mount 参数 也就是说，不能追加在容器里创建数据卷。 有数据共享需求，可以考虑使用docker cp一类的命令来解决。 数据共享多个容器可以通过共享数据卷的方式来共享数据。即使所有的容器都不在使用卷了，卷对于 docker 进程而言依然是活跃的，除非使用docker volume prune命令来打扫卷。也就是说，卷的生命周期，和容器的生命周期是互不干涉的。 命名与匿名当创造卷的时候，卷可以是命名的，也可以是匿名的。匿名的卷只是没有显式地被命名，但 docker 本身还是会给它起一个随机名字。 远程存储数据卷允许使用卷驱动（volume driver，不是 storage driver），这样我们可以在远程文件系统，或者云系统上存储数据。 常用命令创建容器的时候创建卷，新用户应该使用 mount 选项而不是使用v 选项。 如果是创建容器的时候，容器内部的目录已经有数据，而绑定一个 volume 进去，则会自动把内部容器的数据拷贝到 volume 里面。 bind mounts可以让数据在宿主机文件系统中的所有部分，也可以让其它进程修改。它是 docker 早期就存在的技术。 bind mounts 在宿主机上的路径并不被要求早已存在，它会在需要的时候被创建出来，也就是所谓的pre-populate data。当然这也要求宿主机有一些特定的目录结构存在，如果这个目录结构不存在，那么还是要回来寻求 volume 的帮助，因为 volume 使用的路径完全可以被 docker 守护进程把控。 额外的副作用docker 容器有完全地修改 bind mount 内文件内容的权限。所以如果宿主机里有什么敏感文件的话，不要放在这里面，否则会产生安全隐患。这也是为什么推荐使用 volumes 的原因。 常见命令 volume vs bind mount 如果只是简单地想在把容器的状态持久化到宿主机上，应该直接使用数据卷，这样新的容器也能继承老容器的状态。更抽象地说，如果需要在容器和容器之间转移状态，可以使用数据卷。 如果只是要备份数据，可以考虑停下容器，把数据卷里的内容拷贝出来。 数据卷在不同的宿主系统上是通用的。 如果想进一步在宿主机和容器之间共享状态，那么可以考虑使用 bind mount。 tmpfs mounts这个是在内存里面做 bind mounts。所以本质上是不持久化的。 存储驱动（storage driver）相关分层架构存储驱动总是基于联合文件系统，其基本架构如图： 可以看到，多个容器之所以能够基于一个镜像诞生，是因为镜像的层次是 RO 的，而每个容器的 RW layer 是彼此独立的。 如果有跨镜像的同份数据共享，请使用 volume。 大小计算使用 docker ps -s 命令，我们可以看到两个 size： size。容器的可写层在磁盘上的数据大小。 virtual size。镜像的只读数据加上 size 的大小。 其他更细致的计算请查看《Container size on disk》。 docker 除了 layer 以外，还有其他消耗磁盘的地方。比如写日志，有专门的日志驱动，这需要另外计算大小。 COW 问题为了最大效率地（for maximum efficiency）利用磁盘，跨层之间是使用 COW（Copy On Write）策略来利用文件的。也就是说，当上层（包括可写层在内）的层要使用下层的文件，应该先直接访问，在有需要修改的需求时，才将该文件拷贝一份放到本层里。 通常，应该让容器自己的 writable layer 变得非常薄。 层次存储的位置通常在目录/var/lib/docker/下，例如： 常见的存储驱动 aufs overlay overlay2 btrfs ZFS others docker 选择驱动的优先级列表： btrfs/zfs -&gt; overlay2 -&gt; overlay -&gt; aufs/devicemapper 在当代，默认的存储驱动总是 overlay2，而以前则是 aufs。 选择存储驱动要考虑的因素主要有： 是否零配置。 操作系统是否支持。 稳定性。 "},{"title":"OOM 调查使用到的工具","date":"2018-09-10T03:33:04.000Z","url":"/2018/09/10/OOM-%E8%B0%83%E6%9F%A5%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84%E5%B7%A5%E5%85%B7/","tags":["JVM","操作系统"],"content":" top 与 htop。这两个东西比 free 好用。比较神奇的是，为什么线上还有装了 htop这样的非标准 top。字节跳动自己开源了一个 atop，可以细致地监控线程信息，也可以快速采集系统信息，是一个不错的监控工具。 pmap。这个东西是莫枢自己也用来 dump 详细的内存轮廓的地址，但可能需要使用他提到的一个 Serviceability Agent API 来读才读得懂。这个工具的输出可以看到各段内存的起止，但不经帮助，很难读出各个子线程的栈来。这个命令在非 root/sudo 权限下看到的是 jvm 启动参数，在 root/sudo 权限下看到的是内存轮廓，这时候就需要 Serviceability Agent API 了。 smem。这个东西对内存的 RSS/PSS/USS 分析得很好。但并不能帮助我们直接获知我们最期待的栈内存轮廓，比如当前 JVM 的 stack 到底是怎么分布的，占了多少内存？而且更重要是，线上机器没有这个工具。 直接 cat /proc/pid/smaps 其实其他的进程内存查看工具的信息可能都能在这里看得到，但是需要耐心。而且，这个东西在线上也是看不了的，看来也是需要 root。 ps_mem.py 这是一个对 private ram usage 分析得不错的脚本。但是需要 root。 jstack。 这是目前 thread dump 最详尽的命令行工具了。但线上有时候用不了（为什么用不了呢）。jstack 可以用来分析 core dump（jmap 也可以）。 其他 jmx 客户端。 JConsole/JVisualVM/JMC。全部都连不上线上。JVisualVM 的 mbean 功能没有 JConsole 强大，要搞好 mbean，要在界面上对“函数名”浮层按钮进行点击调用。或者在 JMC 上打开 mbeanserver 的控制台，在诊断命令面板里面点击 GC.class_stats 等高危命令。 飞行记录器。这个东西甲骨文收费非常贵，但好处是可以录下来再在本地回放。目前看来，所有的 JVM 运行时状态分析，只有这个是最完备的了。它还有一个命令行工具 jcmd，可以动态地使用飞行记录器的功能和各种 jmx client 特有的动能。 其他，这里有本书，讲了很多 system tuning 的原理和工具，但对 JVM 的调试好像没有什么特别的好处。 看 jstat -gc PID 也可以看到内存轮廓。其中 MU 是永久代信息。同理，JMX 客户端也可以看到这个值。jstat 相关的 options 可以查看内部的 gc 统计结果，比直接读 gc log 直观。因为 JVM 会直接写一个内部的类似日志的东西，把所有的 gc 记下来，即使没有打开 printGCLog。 directbuffer 和 metaspace 的回收严重依赖 fullgc，ygc 是远远不够的。 查看元空间的尺寸： /usr/local/java8/bin/java -XX:+PrintFlagsFinal -version | grep Metaspace 直接看 gc log 也可以看到 metaspace 的大小。 查看所有的 native memory：jcmd 16200 VM.native_memory scale=MB，这需要使用 Java 8 自带的 nmt 功能。注意，jmc 可以直接看到 direct buffer，比 native memory tracker 优秀，但看不到 thread 内存。nmt 正好反过来，能看到线程消耗的内存，看不到 direct buffer。 jps -lvm 查看实际的 jvm 汇总传入参数。 ps -aux ps -elf查看进程实际的传入参数。java -XX:+PrintFlagsFinal java 命令默认的参数。 heap dump 可能包括 full gc 的时间，也包括写磁盘的时间，大堆的 hang/panic 几乎不可避免。 要仔细思考互为因果的问题里各个因素的相互关系和在时间线上出现的顺序：有 GC 耗时增大、线程 Block 增多、慢查询增多、CPU 负载高四个表象，到底哪个是诱因？如何判断 GC 有没有问题？使用 CMS 有哪些常见问题？如何判断根因是什么？如何解决或避免这些问题？ 真正难的是建立评价 Metric 的方法：当前的系统 performance 应该使用什么样的 metric 来衡量。 基础原理汇总： 聊聊jvm的-XX:MaxDirectMemorySize  Native Memory Tracking in JVM JVM源码分析之堆外内存完全解读 JVM Anatomy Quark #12: Native Memory Tracking 聊聊HotSpot VM的Native Memory Tracking NMT 工具输出表 Java程序在Linux上运行虚拟内存耗用很大 native-mem-tracking.md 说说在Java启动参数上我犯的错 江南白衣 | 关键系统的JVM参数推荐(2018仲夏版) 线程栈的原理 thread 源码 rocketmq 的 jvm 配置 gdb：注意 backtrace 的使用。 vmerr：注意看 jvm 退出的时候线程栈状态，cpp 栈帧从哪里调用又从哪里抛出，调用从哪里来的。 《System.gc()和-XX:+DisableExplicitGC启动参数，以及DirectByteBuffer的内存释放》 《Impact of setting -XX:+DisableExplicitGC when NIO direct buffers are used》 jcmd 实战例子 上面的输出里面的 committed 的意思是已经向操作系统做了 mmaped PROT_READ | PROT_WRITE ，就是正在使用的内存（最初的 committed 等于 xms）；reserved 只是向系统用 mmaped none 申请了的内存，等到 paging error 才真的申请（最初的 reserved 等于 xmx）。 top 排序press shift+m after running the top commandor you can interactively choose which column to sort onpress Shift+f to enter the interactive menupress the up or down arrow until the %MEM choice is highlightedpress s to select %MEM choicepress enter to save your selectionpress q to exit the interactive menuOr specify the sort order on the command line jstack sop 如果存在死锁，输出的开头和末尾都会打出死锁相关的信息，不需要再单独找分析工具。 Profiler 问题本文参考：《JVM CPU Profiler技术原理及源码深度解析》 常见的 profiler 有： JProfiler。这是一个“The Award-Winning All-in-One Java Profiler”，可惜它是商用的。 Uber 开源的 JVM profiler，可以搜集 CPU、Memory、IO 相关的信息。 intellij 集成的穷人版 Profiler。 统一的 profiler 列表。 当代的开源 lowoverhead CPU Profiler 已经超越了 hprof 和 JFR 里的 profiler。 火焰图作为一个二维图片，火焰图的 X 轴代表采样总量，而 Y 轴代表栈深度。每个框就代表了一个栈里的函数，其宽度代表了所占用的 CPU 总时间。因此，比较宽的框就表示该函数运行时间较慢或被调用次数较多，从而占用的 CPU 时间多。通过火焰图，RD 可以轻松观察到各个方法调用占用 CPU 的情况。 找平顶，或者说宽平面。平时人们总是容易注意“宽”，但很少注意“顶”。 热点分析树热点分析树会统计出CPU上调用最频繁的方法，我们把这些方法称为热点，同时树形结构可查看抵达此热点的不同栈路径。和调用堆栈树不同，热点分析树是从自底向上描述调用栈，并做了更深入的继承关系分析，在性能诊断时具有更好的实践指导意义。 日志通常被调用得比较多，但日志并不能被真正称为一个性能热点。就好像字符串虽然在 heapdump 里面出现得比较多，但字符串未必就是性能热点一样。热点分析树能够用聚合的视角让我们看到被调用得最多的底层方法。通常出现得比较多的热点方法有日志调用、协议编解码、加解密、各种客户端 flushBuffer。 调用堆栈树该功能统计了Java进程在一段时间内各个方法占用CPU的情况，通过一颗自顶向下的树式（java method1 → java method2 → … native method…）来呈现耗时信息，树中包含所有在JVM中已记录的访问队列。 通常出现得比较多的底层堆栈有： java.lang.Thread.run java.util.concurrent.ThreadPoolExecutor$Worker.run 各种 io 事件 handler 各种 runnable、future.get Idea 的 Method Merged Callees 和 Method BackTraces Java Agent作为 Java instrumentation 体系的经典工具，它的存在意味着我们可以把一个伴生库 attach 到 JVM 主进程里，通过 JVMTI 机制和 JVM 进行通信，这种通信是 Debugger（JDWP）、Profiler、Monitor、Thread Analyser等工具的统一基础，在主流Java虚拟机中都有实现。 我们可以通过 CPP 编写 Java Agent，也可以通过 Java 来编写 Java Agent。通过 Java 编写的 Java Agent 是一种更友好的方式。 我们应当仔细想清楚 Java Agent 和 Advice 的侵入性和编码难易程度上的差别。因为侵入性特别低，所以业内的流行开源产品都是基于 Java Agent 来实现的。 Java 的 Java Agent 规范 声明一个 在jar包的MANIFEST.MF中将Premain-Class指定为一个入口类。 实现一个这样的方法： 这样打包出来的jar就是一个Java Agent，可以通过-javaagent参数将jar传递给Java进程伴随启动，JVM同样会在启动阶段的合适时机执行该方法。 在该方法内部，参数Instrumentation接口提供了RetransformClasses的能力，我们利用该接口就可以对宿主进程的Class进行修改，实现方法耗时统计、故障注入、Trace等功能。Instrumentation接口提供的能力较为单一，仅与Class字节码操作相关，但由于我们现在已经处于宿主进程环境内，就可以利用JMX直接获取宿主进程的内存、线程、锁等信息。无论是Instrument API还是JMX，它们内部仍是统一基于JVMTI来实现。 一个普通 Profiler 的架构思路使用过JProfiler的同学应该都知道，JProfiler的CPU Profiling功能提供了两种方式选项: Sampling和Instrumentation，它们也是实现CPU Profiler的两种手段。 Sampling vs Instrumentation这个问题的另一种问法是：你的设计是基于 AOP 拦截，还是基于定时采样 dump？ Sampling方式顾名思义，基于对StackTrace的“采样”进行实现，核心原理如下： 引入Profiler依赖，或直接利用Agent技术注入目标JVM进程并启动Profiler。 启动一个采样定时器，以固定的采样频率每隔一段时间（毫秒级）对所有线程的调用栈进行Dump。 汇总并统计每次调用栈的Dump结果，在一定时间内采到足够的样本后，导出统计结果，内容是每个方法被采样到的次数及方法的调用关系。 Instrumentation则是利用InstrumentAPI，对所有必要的Class进行字节码增强，在进入每个方法前进行埋点，方法执行结束后统计本次方法执行耗时，最终进行汇总。二者都能得到想要的结果，那么它们有什么区别呢？或者说，孰优孰劣？ Instrumentation 其实就是一种 AOP，AOP 是一种更广义的编程思想。 Instrumentation 侵入性强，对真实执行环境的影响大，但采集数据详实精确（虽然里面也有很大的时间加成）。 Sampling 的缺点是：到底什么样的采样率能够保证数据真实？我们不知道。JVM 只能进入安全点才能采样，更限制了 Sampling 的活动空间。所以有了一篇这样著名的文章《Why (Most) Sampling Java Profilers Are Fucking Terrible》。 具体到“孰优孰劣”的问题层面，这两种实现技术并没有非常明显的高下之判，只有在分场景讨论下才有意义。Sampling由于低开销的特性，更适合用在CPU密集型的应用中，以及不可接受大量性能开销的线上服务中。而Instrumentation则更适合用在I/O密集的应用中、对性能开销不敏感以及确实需要精确统计的场景中。社区的Profiler更多的是基于Sampling来实现，本文也是基于Sampling来进行讲解。 注意，Sampling 也有它的用武之地，特别是对线上服务的 Sampling 而言，更是不知不觉地使用了很多的 Sampling 功能。 基于Java Agent + JMX实现 一个最简单的Sampling CPU Profiler可以用Java Agent + JMX方式来实现。以JavaAgent为入口，进入目标JVM进程后开启一个ScheduledExecutorService，定时利用JMX的threadMXBean.dumpAllThreads()来导出所有线程的StackTrace，最终汇总并导出即可。 Uber的JVM-Profiler实现原理也是如此，关键部分代码如下： Uber提供的定时器默认Interval是100ms，对于CPU Profiler来说，这略显粗糙。但由于dumpAllThreads()的执行开销不容小觑，Interval不宜设置的过小，所以该方法的CPUProfiling结果会存在不小的误差。 JVM-Profiler的优点在于支持多种指标的Profiling（StackTrace、CPUBusy、Memory、I/O、Method），且支持将Profiling结果通过Kafka上报回中心Server进行分析，也即支持集群诊断。 所以对于 Monitoring 服务而言，大停顿的操作都要小心、小心再小心。 使用Java实现Profiler相对较简单，但也存在一些问题，譬如说JavaAgent代码与业务代码共享AppClassLoader，被JVM直接加载的agent.jar如果引入了第三方依赖，可能会对业务Class造成污染。截止发稿时，JVM-Profiler都存在这个问题，它引入了Kafka-Client、http-Client、Jackson等组件，如果与业务代码中的组件版本发生冲突，可能会引发未知错误。Greys/Arthas/JVM-Sandbox的解决方式是分离入口与核心代码，使用定制的ClassLoader加载核心代码，避免影响业务代码。 所以自定义的 Java Agent 本身并不足够好用，必须要认真思考依赖隔离的问题。 SafePoint Bias问题 基于Sampling的CPU Profiler通过采集程序在不同时间点的调用栈样本来近似地推算出热点方法，因此，从理论上来讲SamplingCPU Profiler必须遵循以下两个原则： 样本必须足够多。 程序中所有正在运行的代码点都必须以相同的概率被Profiler采样。 如果只能在安全点采样，就违背了第二条原则。因为我们只能采集到位于安全点时刻的调用栈快照，意味着某些代码可能永远没有机会被采样，即使它真实耗费了大量的CPU执行时间，这种现象被称为“SafePointBias”。 一定会有高开销的方法会不能在 SafePoint 里读到。 上文我们提到，基于JMX与基于JVMTI的Profiler实现都存在SafePointBias，但一个值得了解的细节是：单独来说，JVMTI的GetStackTrace()函数并不需要在Caller的安全点执行，但当调用GetStackTrace()获取其他线程的调用栈时，必须等待，直到目标线程进入安全点；而且，GetStackTrace()仅能通过单独的线程同步定时调用，不能在UNIX信号处理器的Handler中被异步调用。综合来说，GetStackTrace()存在与JMX一样的SafePointBias。更多安全点相关的知识可以参考《Safepoints: Meaning, Side Effects and Overheads》。 基于JVMTI + AsyncGetCallTrace实现 如上节所述，假如我们拥有一个函数可以获取当前线程的调用栈且不受安全点干扰，另外它还支持在UNIX信号处理器中被异步调用，那么我们只需注册一个UNIX信号处理器，在Handler中调用该函数获取当前线程的调用栈即可。由于UNIX信号会被发送给进程的随机一线程进行处理，因此最终信号会均匀分布在所有线程上，也就均匀获取了所有线程的调用栈样本。 按如上步骤即可实现基于AsyncGetCallTrace的CPU Profiler，这是社区中目前性能开销最低、相对效率最高的CPUProfiler实现方式，在Linux环境下结合perf_events还能做到同时采样Java栈与Native栈，也就能同时分析Native代码中存在的性能热点。该方式的典型开源实现有Async-Profiler和Honest-Profiler，Async-Profiler实现质量较高，感兴趣的话建议大家阅读参考文章。有趣的是，IntelliJIDEA内置的JavaProfiler，其实就是Async-Profiler的包装。更多关于AsyncGetCallTrace的内容，大家可以参考《ThePros and Cons of AsyncGetCallTrace Profilers》。 我们常说的“低开销 profiler”，其实指的是Async-Profiler。 如何实现 Dynamic Attach？ JDK在1.6以后提供了AttachAPI，允许向运行中的JVM进程添加Agent，这项手段被广泛使用在各种Profiler和字节码增强工具中。总的来说，DynamicAttach是HotSpot提供的一种特殊能力，它允许一个进程向另一个运行中的JVM进程发送一些命令并执行，命令并不限于加载Agent，还包括Dump内存、Dump线程等等。 arthas 的例子： async profiler 的 jattach 的例子： 如何实现自己的火焰图？ 现在我们拥有了采样调用栈的能力，但是调用栈样本集是以二维数组的数据结构形式存在于内存中的，如何将其转换为可视化的火焰图呢？ 火焰图通常是一个svg文件，部分优秀项目可以根据文本文件自动生成火焰图文件，仅对文本文件的格式有一定要求。FlameGraph项目的核心只是一个Perl脚本，可以根据我们提供的调用栈文本生成相应的火焰图svg文件。调用栈的文本格式相当简单，如下所示： 将我们采样到的调用栈样本集进行整合后，需输出如上所示的文本格式。每一行代表一“类“调用栈，空格左边是调用栈的方法名排列，以分号分割，左栈底右栈顶，空格右边是该样本出现的次数。 将样本文件交给flamegraph.pl脚本执行，就能输出相应的火焰图了： 总结 Java Agent 很美好，但保证它的 dynamic attach 被良好实现、易用， 是基于它构建的工具能被广泛使用要思考的关键问题。 Intercept 很美好，但不适合做定量分析，因为它对性能影响可能非常大。 很多 JMX api 会 block until SafePoint（比如 GetStackTrace），所以 SafePoint Bias 是客观存在、必须注意的问题。 Sampling 才是对业务友好的采集器，精确度是一个必须迂回解决的问题。 Remote debugger为什么有时候 remote debugger connection refuse？因为上一个 debugging 还在继续，再 debug 上去会被拒绝。 gperftools待续 java 7 的默认 flag"},{"title":"Docker 与网络","date":"2018-09-07T09:07:59.000Z","url":"/2018/09/07/Docker-%E4%B8%8E%E7%BD%91%E7%BB%9C/","tags":["Docker"],"content":"docker 操纵网络是无形的，它通过修改路由规则来让某些包在特定的 network 里面流动。在 Linux 下，它是通过操纵 iptables 来做到这件事的(windows下通过其他机制)。 docker 的网络是可插拔的，因为使用了驱动。默认就自动携带的驱动是: bridge默认的网络驱动。当所有的容器都在一个宿主机的时候，应该使用这个驱动。 在计算机网络的范畴里，一个桥接网络是一个链路层设备，转发网络片段。一个桥可以一个硬件设备或者宿主机内核里的软件设备。在 Docker的范畴里，桥接网络使用一个软件桥来让容器连在同一座桥上，通过桥通信。同一个宿主机里，不同桥网络是不能相互通信的（实际上不同的网络就不应该彼此通信）。 启动 docker 的时候，一个默认的桥接网络就被创建了。如果没有其他网络被创建，则默认大家都使用这个网络。所有新创建的容器，都会自动在这个名称为 bridge 网络里互连。用户也可以创建自定义的桥接网络，自定义的桥接网络拥有更高的优先级。 自定义网络的优势 用户自定义网络在容器化应用程序里，提供了更好的隔离和互操作性。在同一个桥接网络里的容器，默认向彼此打开了所有端口，但却不向网络外开放端口。如果使用自定义的桥接网络，则可以指定开放哪些端口给网络外部，如果使用缺省桥接网络；则开放时必须默认全部开放端口（可以有其他迂回策略做到部分开放）。细想一下，这种网络隔离免去了网络内部容器之间鉴权的必要。 用户自定义的桥接网络提供网络内容器间自动的 DNS 解析。这让我们可以免于使用 –link 这样的遗留选项（这个选项本质上 必须和缺省桥接网络共生），使我们可以用容器名或者别名直接访问网络。我们当然也可以采用 hack 容器内的 /etc/hosts 的方法来解决这个问题。然而，这产生了难以 debug 的问题，特别是容器每次重建这个文件都会被刷新。 可以动态对用户自定义桥接网络添加容器和解绑，而对默认桥接网络这么做，就需要停下整个网络。 可以动态修改用户自定义桥接网络的配置，但缺省网络配置就难以修改，因为又涉及到重启。 使用缺省网络，所有容器共享环境变量。 操纵自定义网络基础的 CRUD： 允许 docker 容器内的流量转发到外部世界： 配置缺省桥接网络，要求 docker 守护进程重启： 容器加入自定义网络： 使用 IP V6需要单独配置。参考《Use IPv6》。 host移除单个容器和宿主机之间的网络间隔，并直接使用宿主机网络。这个驱动只在高于等于版本 17.06 的 swarm 服务上可用。 当网络栈部分不与宿主机隔离，而容器的其他部分需要与宿主机隔离的时候，应该使用这个驱动。 这个驱动只真对 Linux。 使用这个驱动，容器开放的端口和宿主机开放的端口号一致。比如容器内应用绑定了80端口，在宿主机上可以看到是 docker 进程占用了该端口： 创建网络： overlay层叠网络虽然最被我们所熟悉，但却不是缺省网络。 层叠网络可以让多个 docker 守护进程（注意，每个 宿主机上实际上只有一个 docker 守护进程）连接到一起，也让 swarm 服务与他们一一通信。 层叠网络可以让 swarm 服务和单独的容器一起通信。 层叠网络可以让多个 docker 守护进程里的单一容器通信。 层叠网络消除了 OS 级别的容器间路由。 当多个宿主机上的容器需要通信，或者需要使用 swarm 服务让多重应用一起工作时，应该使用这个驱动。 层叠网络创建的是一个分布式网络，构建在多个宿主专属网络上。 两个内部网络（这个主题似乎和层叠网络不是很有关系，而和 swarm 本身有关系）当我们初始化一个 swarm，或者让一个已经存在的容器加入一个已经存在的 swarm 服务时，每一个节点（manager 或者 worker 都有）产生了两个内部网络： ingress 负责处理 swarm 相关的流量 docker_gwbridge 这是一个桥接网络，连接不同的 docker 守护进程。 容器和服务可以连接多个网络，但每次只能在一个它们连上的网络里相互通信。 层叠网络操作创建层叠网络先决条件： 打开以下端口 TCP port 2377 for cluster management communications TCP and UDP port 7946 for communication among nodes UDP port 4789 for overlay network traffic 成为 swarm manager 或者加入一个 swarm 集群。这样才能初始化 ingress 网络。 实际上这些操作，还是在 swarm manager 节点上执行最好，详情见《Networking with overlay networks》。 层叠网络里的加密swarm 的管理流量默认就是被 AES 算法 GCM 模式加密过的。 创建层叠网络时使用 –opt encrypted 会让普通的应用流量也加密。 不要让 windows 节点加入加密的 swarm 网络，有错也检验不出来。 定制缺省的 ingress 网络修改有服务存在的 ingress 网络是很麻烦的： docker network inspect ingress，然后移除网络中的服务。 去除现存的 ingress 网络，docker network rm ingress。 使用新的 opption 来创建新的 ingress 网络： 定制 docker_gwbridge 也是类似的操作。 绕过路由网格（routing mesh）swarm 默认会帮我们做服务级的负载均衡，这样应用程序就获得了 VIP。 我们可以关闭这种模式，通过 To bypass the routing mesh, you can start a service using DNS RoundRobin (DNSRR) mode, by setting the –endpoint-mode flag to dnsrr. 让 docker 宿主机成为一个 DNS 服务器，用自己的负载均衡来查询这个 IP 列表。docker 守护进程本身也可以像一个 DHCP server 一样工作。 macvlan这个驱动让容器可以得到一个虚拟的 MAC 地址，让它表现得好像一个物理设备一样。而 docker 守护进程按照 Mac 地址往 docker 容器发流量。 这个驱动是面对要直连物理设备的遗留程序（比如一些网络监控程序）的最好选择。 详情见《Use Macvlan networks》。 none这个驱动必须可以第三方驱动配合使用。 也可以用来完全禁止一个容器的网络栈部分： 其他第三方驱动这些驱动可以在 docker 商店里找到。 创建容器的时候可以指定 ip 地址可以指定网络中的 ip。具体可以看文档： When you connect an existing container to a different network usingdocker network connect, you can use the –ip or –ip6 flags on thatcommand to specify the container’s IP address on the additionalnetwork. "},{"title":"日期与时间","date":"2018-09-07T03:16:39.000Z","url":"/2018/09/07/%E6%97%A5%E6%9C%9F%E4%B8%8E%E6%97%B6%E9%97%B4/","tags":["Java","MySQL"],"content":"JSR 310 Java Date与Time API新旧 API 的更迭旧的 Java API 主要包括java.util.Date和java.util.Calendar 两个包的内容。这两个包的时间类型是可变的。如 Date 的实例可以通过 setYear 来产生变化。 JSR 310 中包括的日期类型主要有： 计算机时间：Instant，对应 java.util.Date，它代表了一个确定的时间点，即相对于标准Java纪元（1970年1月1日）的偏移量；但与java.util.Date类不同的是其精确到了纳秒级别。 人类时间：对应于人类自身的观念，比如LocalDate和LocalTime。他们代表了一般的时区概念，要么是日期（不包含时间），要么是时间（不包含日期），类似于java.sql的表示方式。此外，还有一个MonthDay，它可以存储某人的生日（不包含年份）。每个类都在内部存储正确的数据而不是像java.util.Date那样利用午夜12点来区分日期，利用1970-01-01来表示时间。这些类型的实例是 immutable 的，而且只能通过工厂方法创建。 时区（比如Europe/Paris与America/New_York）和距UTC的偏移量（比如+01:00与-08:00）之间的差别偏移量仅仅是 UTC （基础偏移起点）和本地时间之间的差值。 而时区是一个具名的规则集合，描述了偏移量改如何随着时间的变化而变化。比如说，时区会描述一个特定的区域（比如纽约）在给定的一个时刻具有某个偏移量，之后具有另一个 偏移量（在本地时间线上创建一个间隙或是重叠，如春秋时制的变换）。换言之，时区是比偏移量更复杂的规则集合。 有三个级别的类支持这些概念： LocalDateTime 无需使用偏移量和时区就能表示时间。 OffsetDateTime 额外地指定了偏移量。 ZonedDateTime 则增加了时区规则。 过去，很多应用都喜欢使用时区，但他们真正需要的其实只是偏移量而已（使用偏移量更简单、更快且不易出错）。所以我们更加应该使用偏移量。XML Schema规范就是一个典型，它只支持偏移量而不支持时区。JSR 310可以明确表示出这些差别。 时区规则会随着时间的推移而不断发生变化。就在千禧年之前，一些国家将时区由国际日界线之后改为之前；此外，夏时制也在不断变化。 其他附属类型可以使用Duration界定任意两个Instant之间的范围。 现在有一些具体的概念来表示YearMonth和MonthDay，在适当的时候应该使用这两个类。还有一个Period类来表示任意的时间周期，如“两年、3个月、7天、4小时、50分钟”等。 核心日历是ISOChronology，默认情况下使用它来映射时间，就像目前Java API中的GregorianCalendar一样。然而，我们对其他一些年代也提供了支持，如CopticChronology和ThaiBuddhistChronology。 API 举例操作日期的时候，都会在方法名上让人看出合理的行为模式，模仿自 Joda API： 新式的 DateTimeFormatter，使用字符串来初始化： 与旧 API 的兼容： DateTimeFormatterDateTimeFormatter 是线程安全的，而 SimpleDateFormat 不是。 它的基础用法是： 常见的模式有： Formatter Description Example ofLocalizedDate(dateStyle) Formatter with date style from the locale ‘2011-12-03’ ofLocalizedTime(timeStyle) Formatter with time style from the locale ‘10:15:30’ ofLocalizedDateTime(dateTimeStyle) Formatter with a style for date and time from the locale ‘3 Jun 2008 11:05:30’ ofLocalizedDateTime(dateStyle,timeStyle) Formatter with date and time styles from the locale ‘3 Jun 2008 11:05’ BASIC_ISO_DATE Basic ISO date ‘20111203’ ISO_LOCAL_DATE ISO Local Date ‘2011-12-03’ ISO_OFFSET_DATE ISO Date with offset ‘2011-12-03+01:00’ ISO_DATE ISO Date with or without offset ‘2011-12-03+01:00’; ‘2011-12-03’ ISO_LOCAL_TIME Time without offset ‘10:15:30’ ISO_OFFSET_TIME Time with offset ‘10:15:30+01:00’ ISO_TIME Time with or without offset ‘10:15:30+01:00’; ‘10:15:30’ ISO_LOCAL_DATE_TIME ISO Local Date and Time ‘2011-12-03T10:15:30’ ISO_OFFSET_DATE_TIME Date Time with Offset 2011-12-03T10:15:30+01:00’ ISO_ZONED_DATE_TIME Zoned Date Time ‘2011-12-03T10:15:30+01:00[Europe/Paris]’ ISO_DATE_TIME Date and time with ZoneId ‘2011-12-03T10:15:30+01:00[Europe/Paris]’ ISO_ORDINAL_DATE Year and day of year ‘2012-337’ ISO_WEEK_DATE Year and Week 2012-W48-6’ ISO_INSTANT Date and Time of an Instant ‘2011-12-03T10:15:30Z’ RFC_1123_DATE_TIME RFC 1123 / RFC 822 ‘Tue, 3 Jun 2008 11:05:30 GMT’ 其中 date 和 time 之间的 T 是 ISO 8601 标准。 其他缩写字母的含义见此文档： 以上内容主要参考： 《JSR 310 Java Date与Time API》 《Java8 日期/时间（Date Time）API指南》 MySQL 中的时间类型（Date and Time Types）MySQL 共有5种类型来表示时间值（temporal values），包括 DATE，TIME，DATETIME，TIMESTAMP 和 YEAR。所有的时间类型都有一个 valid range，当你插入 invalid value 的时候，有个 zero value 会被使用。 MySQL 的时间 API 有几个通用的设计考量： 从 MySQL 中获取数据，总是会获取到标准化数据（严出 ）；但对于同一种特定类型，它可以接受并试图解释多种格式的输入。 对于日期，MySQL 倾向于使用年月日的顺序（’98-09-04’），而不是其他顺序。 只有两位数字（two-digit）的年份可能存在二义性，MySQL 的转义规则是： Year values in the range 70-99 are converted to 1970-1999. Year values in the range 00-69 are converted to 2000-2069. 如果日期被用在一个数字上下文，MySQL 会自动帮转化为数字。反之亦然。 改变 SQL MODE，可以让 MySQL 接受一些看起来 invalid 的日期。有些日期是用户故意输错的，MySQL 只检查月份是不是在1-12，而日期是不是在1-31里。 MySQL 允许在月和日里存储零值（zero value）。这可以拿来存储不知道确切日期的生日（类似 null 之于 integer）。要 disable 掉这种行为，启动 NO_ZERO_IN_DATE MODE。’0000-00-00’ 就是这样一个 dummy date。使用这种日期的话，相关的日期函数计算就不能得到正确的结果。 零值在 ODBC 等连接器里面，通常会被转化为 NULL，因为这些连接器不知道怎么处理这些零值。 零值表 数据类型 零值 DATE ‘0000-00-00’ TIME ‘00:00:00’ DATETIME ‘0000-00-00 00:00:00’ TIMESTAMP ‘0000-00-00 00:00:00’ YEAR 0000 时间值通常有两种字面量表达方法，用引号标准起来的字符串，或者纯数字：’2015-07-21’, ‘20150721’ 和 20150721 都是合理的日期。松散的字面量定义见此链接，注意下面的评论，有些断句符本身必须和语言 collation 一起使用。。 取值范围DATE 类型没有时间部分，通用格式为 ‘YYYY-MM-DD’，合理的取值范围为’1000-01-01’ 至 ‘9999-12-31’。 DATETIME 类型既有日期部分，又有时间部分。合理的取值范围为’1000-01-01’ 至 ‘9999-12-31’。这类似 Java 8 的 LocalDatetime，是属于人的形式，不需要理解时区和偏移。 TIMESTAMP 类型既有日期部分，又有时间部分。合理的取值范围为 ‘1970-01-01 00:00:01’ UTC 至 ‘2038-01-19 03:14:07’ UTC。也就是说， TIMESTAMP 这个类型类似 Unix Epoch timestamp，时间范围又窄，基础偏移量又基于 UTC。 这两种类型的字面量里都是没有 T 的。 DATETIME 和 TIMESTAMP 可以包含最多到微秒六位精度的小数部分。 如果加入了小数部分： DATETIME 的取值范围变为 ‘1000-01-01 00:00:00.000000’ 到 ‘9999-12-31 23:59:59.999999’。 TIMESTAMP 的取值范围变为 ‘1970-01-01 00:00:01.000000’ 到 ‘2038-01-19 03:14:07.999999’。 DATETIME 和 TIMESTAMP 的自动初始化和更新行为基本示例 可以从初始值和其他 column 被修改时自动修改值两个维度来设置类型： 但总体来讲不是很好用。还是把缺省初始值设置为某个时间戳比较简单。 具体文档在《Automatic Initialization and Updating for TIMESTAMP and DATETIME》。 DATETIME 和 TIMESTAMP 的其他区别 TIMESTAMP 消耗的存储空间更小。 DATETIME 不能使用缺省值，因为这个 post，以下操作不会生效，插入一个 null gmt_payment_begin_time 依然会收到 jdbc 报错： 时区的影响TIMESTAMP 类型在被存储时，会被转往 UTC 时区（此处 UTC 被当做时区来用），在取值的时候，又会被取成当前时区的时间-所以 TIMESTAMP 可以适应服务器、连接的时区变更，DATETIME不行。 而 MySQL 的时区设置，是针对每一个连接可以单独设置的。这也就意味着，如果时区不是一个常量，一个 TIMESTAMP 被存进去一个值，取出来是另一个值。这个可能存在的问题，是大家都喜欢用 datetime 的原因。时区相关的具体行为，可以通过 time_zone 这个环境变量来修改。 矫正到零值对于不合理的赋值，MySQL 可能把它赋值为各种类型的零值，还可能产生若干警告。 精度定义语法是 type_name(fsp)。type_name 可以是 TIME, DATETIME, 或者 TIMESTAMP，而 fsp 是小数秒精度。 一个例子： 如果定义里面不存在秒数，存值的时候可能会被抹去，比值的时候可能失败。 日期和时间类型的转换这两种类型相互转换有点类似移位。能补零则补零，否则会变成全零值。 具体内容见《Conversion Between Date and Time Types》。"},{"title":"使用 Truffle 来编译、安装智能合约(旧文一篇)","date":"2018-08-29T06:10:10.000Z","url":"/2018/08/29/%E4%BD%BF%E7%94%A8-Truffle-%E6%9D%A5%E7%BC%96%E8%AF%91%E3%80%81%E5%AE%89%E8%A3%85%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%97%A7%E6%96%87%E4%B8%80%E7%AF%87/","tags":["区块链","Ethereum"],"content":"因为官定版本的 solidity 实在编译安装太费力了，放弃，改用 Truffle。 直接用 npm 安装： 创建新目录，初始化新目录： 修改配置文件 truffle.js: 生成必须的智能合约源码和迁移脚本： 迁移脚本 目录下已然有了示例用的 contract 和 migration 文件，接下来： 如果 migrate 失败，可能需要先解锁账户， 并且把配置文件中的 gas 调高点，不知道还有多少 gas 余额的时候，可以考虑用： 进入 console： 退出 console： 使用来查看所有通过 Truffle 部署的代码： "},{"title":"在以太坊网络上使用智能合约 solidity（旧文一篇）","date":"2018-08-29T05:45:08.000Z","url":"/2018/08/29/%E5%9C%A8%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%BD%91%E7%BB%9C%E4%B8%8A%E4%BD%BF%E7%94%A8%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-solidity%EF%BC%88%E6%97%A7%E6%96%87%E4%B8%80%E7%AF%87%EF%BC%89/","tags":["区块链","Ethereum"],"content":"因为一个并不周知的 issue，geth 客户端将不再提供 solc 编译相关功能。我们必须借助外部编译器，比如 solc/remix。 所谓 Contract，只是 Martin fowler 的书里面经常提到的一个富血的类型罢了。 注意，要用高版本的 npm，来安装 solc： 智能合约代码： 用 solcjs 来编译代码： 它会产生 testContract_sol_TestContract.bin 和 testContract_sol_TestContract.abi。结尾应该是 Contract 的类型。 使用以下命令先解锁账户： 在控制台里使用以下命令生成新的合约： 注意看，address 还没有被 transaction 写入确认。如果挖矿了，最终它会被部署上去。 用两种方式来调用只能合约： sendTransaction 的文档在这里。 查看当前合约变量的地址： 通过地址反推代码： 用一个典型的方式来在其他节点定位到这个合约 "},{"title":"在Centos 6.7 上安装并使用web3（旧文一篇）","date":"2018-08-29T05:39:28.000Z","url":"/2018/08/29/%E5%9C%A8Centos-6-7-%E4%B8%8A%E5%AE%89%E8%A3%85%E5%B9%B6%E4%BD%BF%E7%94%A8web3%EF%BC%88%E6%97%A7%E6%96%87%E4%B8%80%E7%AF%87%EF%BC%89/","tags":["区块链","Ethereum"],"content":"不要使用默认 gcc，会编译安装 web3失败。 不能使用全局安装，要尽量本地安装： web3 本身是一系列 nodejs 模块的集合，包括但不限于 web3-eth 针对以太坊区块链和智能合约 web3-shh 针对耳语协议在 p2p 网络中的通信和广播 The web3-bzz 针对 swarm 协议，去中心化的存储 The web3-utils 针对 Dapp 的有用的功能 在 nodejs 中引入和初始化 web3 对象： 要使用的智能合约： 一些基本操作： Calc 的相关 abi 和地址,并以此产生合约调用 ： 最终版本的 calc-node.js: 用一下命令来nohup 执行脚本： 需要使用的 package.json: 用 ab 进行 benchmark: 运维须知： 要千万小心，重启了 node 节点以后，要重新 unlock account，不然还是连不上。koa 应用程序不需要重启。 "},{"title":"在CentOS 6.7上用 geth 搭建以太坊私链网络的全部步骤（旧文一篇）","date":"2018-08-29T05:27:07.000Z","url":"/2018/08/29/%E5%9C%A8CentOS-6-7%E4%B8%8A%E7%94%A8-geth-%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%A7%81%E9%93%BE%E7%BD%91%E7%BB%9C%E7%9A%84%E5%85%A8%E9%83%A8%E6%AD%A5%E9%AA%A4%EF%BC%88%E6%97%A7%E6%96%87%E4%B8%80%E7%AF%87%EF%BC%89/","tags":["区块链","Ethereum"],"content":"生成基本的路径 如果 git 版本是 1.x，卸载旧的 git，安装最新版的 2.x 以上的 git: 执行以下命令，编译以太坊客户端: 如果有“fatal: unable to access ‘;: Failed connect to github.com:443; Operation now in progress”考虑是容器的外网访问权限问题。 把 export PATH=$PATH:/root/go-ethereum/build/bin 加入环境变量: 生成一个叫 datadir 的文件夹来存储账户的私钥和链数据。 生成一个内容为123456的 password.txt。 用这个命令生成一个初始账户： 查看一下生成文件的内容，我们可以看到如下内容： 使用 ll 也可以查看到相似内容： 生成一个私链创世区块配置文件，gas limit 不能超过53bit，也就是13个 f，不然会出现 admin 连不上，合约出问题等种种麻烦事： 其中， chainID 是接下来要用到的网络 id。 alloc 是为了链初始化的时候就先充值的账户 。 coinbase 是 这个节点附带的矿工的私人账户，可以写不正确的账户，反正节点启动的时候，会试图使用当前 keystore 里面的第一个账户 。 difficulty 是这个网络的难度，数字越小，出块的时间越快。据 gitter 上的人说，实际上区块链网络会自动调整网络难度。 extraData 一个个性签名，目前还是用16进制的数好，不要用中文。 gasLimit 当前网络中一个区块可以容纳的 gas 的总数。 初始化链（这是必须的，否则console 可以运行，账户余额为0，挖矿也会出问题）： 启动节点并进入控制台，这个命令可以重复执行，而且可以加上 –verbosity 6 来获取细节的输出： 注意，这里的 –networkid 必须和 genesis.json 里的 chainid 相同 ，否则，可能覆盖前者。查看当前节点信息：admin.nodeInfo 查看当前到底有多少个账户，可以看到预先生成的账户以及导入了： 在 console 查看第一个账户的余额： 查看所有账户余额的函数： 在 console 上查看区块数量： 大部分是空区块的话，一个空区块大概需要 1-2kb 的磁盘空间。按 2kb 一个空区块来看，一年500万个空区块大概需要消耗 10g 的硬盘空间。 在 console 上开始挖矿： 每挖出一个区块来，有5个以太币的奖励。公网有差不多9000万个以太币。 在 node2 上把之前的动作（除了与账户相关的动作）都重做一遍。然后试图重建同一个账户节点的内容： 如果没有相关的目录结构就 mkdir，如果有的话，就直接 touch，然后把 node1 的相同文件下的信息写进去。正如 geth 的官方文档所说：“It is safe to transfer the entire directory or the individual keys therein between ethereum nodes. ” 在 node2 上启动区块节点控制台，在控制台上使用如下得到 node2 的节点信息： 注意，把@和:30303之间的地址换成公网可以访问的 IP 地址。 在 node1 的控制台执行以下命令： 其实可以考虑使用 bootnode，如果 bootnode 不挂的话，倒是有点像超级账本里的 anchor peer。 如果两边都开始挖矿了，可以通过以下两个命令查看网络内的节点： 两边都开始挖矿，block 会逐渐同步到 canonical chain。gas 的计算公式： cost = gas * gasPrice , （ 账户1减少的资产 - 账户2增加的资产）/ gasPrice = 消耗的gas要注意，如果节点重启， peers 有可能会丢失，大家又会在各自的区块链上挖矿，直到重新 addpeer 然后同步，也有自动同步的例子。而且，节点之间的 account 是不能同步的。必须要拷贝 account 的 keystore 文件才行。 尝试着转账： 在这个函数里，可以确认最近 N 个区块里有多少区块是由这个矿工挖出来的： 获取当前的 gas limit: 结果总是 4712388，不管 genesis.json 里面设置得多高。 删除链数据而保留账户数据： 在退出 console 后，用挖矿模式 nohup 静默挖矿： 可以用如下命令查看当前到底有多少可用的 module： 可以用 modules 查看到到底打开了多少个 rpc api： 可以用 modules 查看到到底打开了多少个 rpc api： 通过本地端口 attach 上去： 在本地安装高版本的 nodejs： 目前已知的账户是：bbb 启动 bootnode 节点，让大家都去连 boot node： 从零开始重启动整个矿工节点的脚本： 使用 clique 算法（puppeth 生成出来的 genesis.json）： 从日志里读到事务 hash，找到这个事务的输入数据： "},{"title":"Kibana 速记","date":"2018-07-30T10:13:13.000Z","url":"/2018/07/30/Kibana-%E9%80%9F%E8%AE%B0/","tags":["Kibana"],"content":"基本步骤 安装 ES（注意兼容性）。 安装 Kibana（注意兼容性）。 在 ES 里建索引（如果使用 logstash，可能会自动创建索引）。 在 kibana 里选择 index pattern（注意使用 wildcard）。历史上，索引一共有两种模式可以表达事件时间： 索引的文档里带有时间 field（Index contains time-based events ）。 索引的名字里带有时间戳（Use event times to create index names [DEPRECATED]早已废弃）。 在 discovery 里创建 search，保存 search。 根据 search 创建 visualize。 根据 visualize 创建 dashboard。 search 相关在单行里面，可能适合写单行的 Lucene DSL，而不适合写复杂的 ES 查询体（如果是在程序里，当然还是使用抽象 API 更好）。 常见的查询语法可以参考《Kibana查询语法详解》或者《ELK：kibana使用的lucene查询语法》，实际上底层是由 ES 的查询字符串语法支持的。 discover 页面 注意保存的页面是不包含时间信息的。 visualize 页面y 轴可以选各种聚合函数，比如 sum、count、avg。x 轴选不同的聚合类型（这里不是函数了，而是面向图表聚合），可以选出不同类型的，适合这种聚合的文档 field。有时候还要选 interval。 又如： 这个地方可以选绘图的风格： dashboard 相关注意看 visualize 的配置，如果给予 visualize 的空间太小，可能图是绘制不出来的。 可视化的文字数据： 管理存储的查询、可视化和大盘存储对象的位置："},{"title":"如何做性能测试的问题下的答案","date":"2018-06-19T06:50:50.000Z","url":"/2018/06/19/%E5%A6%82%E4%BD%95%E5%81%9A%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8B%E7%9A%84%E7%AD%94%E6%A1%88/","tags":["Java","性能"],"content":"试着回答一下这个问题。 首先要划分系统类型：有状态还是无状态，业务系统还是存储系统。根据不同的业务场景，设立性能测试的目标：是要测 QPS，还是 TPS 还是 TPS，还是任何其他【性能】-从广义来讲，一个存储系统到底能够以多高的平均时延来管理大多的存储空间，可能也是性能的一种。 有了性能测试的目标，接下来就是拆解用例。如果把性能测试归为测试的话，测试就需要测试用例，测试用例只是用例的形式化表达。把用户的使用场景勾勒出来，把每一步拆解成的流程图或者时序图–我们已经得到了一个纸上的集成测试计划，只是没有跟性能挂上钩。 接下来就进入真正写测试用例的环节了。 我们的测试报告如果要涵盖足够立体的信息，则既要了解每一个环节/接口/API 的性能指标，又要了解整体的性能指标。 这个时候测试工具的覆盖面就很重要了。如果我们选择偏黑盒的测试工具，apache ab /JMeter，则我们的测试用例就要围绕着对外交互的 API写，也只能测到外围接口的性能。这样的测试用例写起来最简单，无需侵入任何内部代码中。 如果我们使用了 JMH 一类的工具，则可以自由编写对任何方法的测试用例。但需要对系统有非常深的理解，知道测试用例应该落在什么调用上，也需要对系统有一定的侵入性（至少对原有的功能/验收/单元/集成测试计划有侵入性）。 我们还可以使用 Profiling/Sampling 工具（不同的语言都有不同的工具），这样的工具甚至都不需要我们怎么写代码来截取各种时间戳，就可以自动地帮我们生成性能剖面图。但这些工具并不是包治百病的，亲身使用过这类工具的朋友一定有所体会，这些工具对性能的绝对性能是有影响的，而且影响的大小难以预测。胆敢直接用这类工具 attach 生产环境的程序员都有可能受到惩罚。而且，使用这样的工具就好像在系统混沌变化的各种性能曲线里寻找一个剖面（profiling 言之不虚），要找到的正确的性能热点，还是需要测试脚本的支持。 当然不管我们用什么样的测试工具，测试用例的衍生，一定要按照上面拆解流程图或者时序图的思路来做。 最后，决定系统的性能因素排名往往是：架构-》算法-》Runtime 性能。 最好保证测试环境和目标环境使用相同的架构，相同的软硬件介质（这个在当前比较混乱的发布环境的团队里很难达到）。这个条件很难做到。 所以现在新的做法就是基于 Sampling 了。直接使用 Dapper/把脉一类系统的带有时间戳的 log，用线上验证+大数据聚合的思路来分析系统性能分布。这是现代的做法，却不能称作测试了。 众所周知，测试对于业务代码是必须如影随形的，是很重的负担，有了线上验证的思路，性能测试还真的有必要吗？"},{"title":"log 的历史","date":"2018-06-06T08:23:39.000Z","url":"/2018/06/06/log-%E7%9A%84%E5%8E%86%E5%8F%B2/","tags":["未完成"],"content":" git DAG 区块链 saga binlog/WAL"},{"title":"JPA 的 id 生成策略","date":"2018-05-29T10:15:25.000Z","url":"/2018/05/29/JPA-%E7%9A%84-id-%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5/","tags":["Java","数据库","MySQL","JPA"],"content":"JPA 有一个@GeneratedValue注解，有一个strategy attribute，如@GeneratedValue(strategy = GenerationType.IDENTITY)。 常见的可选策略主要有IDENTITY和SEQUENCE。 GenerationType.IDENTITY要求底层有一个 integer 或者 bigint 类型的**自增列（ auto-incremented column)**。自增列的赋值必须在插入操作之后发生，因为这个原因，Hibernate 无法进行各种优化（特别是 JDBC 的 batch 处理，一次 flush 操作会产生很多条insert 语句，分别执行）。如果事务回滚，自增列的值就会被丢弃。数据库在这个自增操作上有个高度优化的轻量级锁机制，性能非常棒。 MySQL 支持这种 id 生成策略， 使用 MySQL 应该尽量使用这个策略，即使它无法优化。 JPA 用它生成 id，会一条一条地插入新的 entity。 GenerationType.SEQUENCE数据库有一个所谓的 sequence 对象，可以通过 select （而不是 insert ）来获取下一个数。 它也可以指定一个特殊的 SequenceGenerator，而不是只使用数据库自带的。 MySQL 不支持这种 id 生成方式，Oracle 支持。 *JPA 用它生成 id，会一条一条地 select 出新的 value，然后再 batch insert 新的 entity jdbc 生成的隐藏 sql在使用MySQL时，若表中含自增字段（auto_increment类型），则向表中insert一条记录后，可以调用last_insert_id()（对应的操作就是在事务的 insert 里偷偷插入这样一个语句SELECT LAST_INSERT_ID()）来获得最近insert的那行记录的自增字段值（一个bigint类型的64-bit值）。 jdbc/mybatis 就是用这样一个语句来获取最新的 id 并绑定在最新的 orm 对象上的。 参考文献： 《How to generate primary keys with JPA and Hibernate》 《How do Identity, Sequence, and Table (sequence-like) generators work in JPA and Hibernate》 【MySQL笔记】last_insert_id()函数使用的注意事项 "},{"title":"convention over configuration over programming","date":"2018-05-09T03:00:44.000Z","url":"/2018/05/09/convention-over-configuration-over-programming/","tags":["软件工程"],"content":"convention over configuration over programming in configuration, cmd args &gt; env &gt; configuration file option 是命令可选的参数，可以影响程序的how to do，算是一种特殊的argument，通常与flag同义（flag在很多时候是boolean形态的option）。普通的 argument 则是告诉程序 what to do。如果command是一个动词，option就是一个副词或者形容词，argument则是它的宾语，通常是名词或者代词。 该模型也可以这样理解：APPNAME VERB NOUN –ADJECTIVE或者APPNAME COMMAND ARG –FLAG"},{"title":"重拾TCP/IP协议簇","date":"2018-05-09T02:55:20.000Z","url":"/2018/05/09/%E9%87%8D%E6%8B%BETCP-IP%E5%8D%8F%E8%AE%AE%E7%B0%87/","tags":["未完成","计算机网络"],"content":"TCP/IP 协议簇本质上是 OSI 三层（网际层）和四层（传输层）协议簇的总结，通常包括TCP、UDP、IP、ICMP和ARP等几种协议。 IP 协议 链路层协议和物理层协议解决了点对点通信的问题。 而在大范围的多个子网通信问题则由 IP 协议解决。 IP地址族的分类32 位的地址空间可以分为5 类地址（常用的地址空间只用到A/B/C）。 A 类地址：0.0.0.0-127.255.255.255 B 类地址：128.0.0.0-191.255.255.255 C 类地址：192.0.0.0-223.255.255.255 实际上用二进制来看地址开头的话，还有一种巧妙的分法： 如果 32 位的 IP 地址以 0 开头，那么它就是一个 A 类地址。 如果 32 位的 IP 地址以 10 开头，那么它就是一个 B 类地址。 如果 32 位的 IP 地址以 110 开头，那么它就是一个 C 类地址。 这三类地址是用来做unicast（也就是单播）的。我们常见的环回地址127.0.0.0和本机地址0.0.0.0是A类地址。 IP 协议报文格式 IP 的 header 的整体格式还是定长的字段。值得注意的是TTL字段，这表明这个packet还可以穿过多少个路由，每经过一个路由TTL就会减一。尽管8位的数学空间允许一个 IP packet 最多穿过255个路由，但现实中这个 packet 通常只穿过64或者32个路由。 路由器与路由表packet 在子网中传输通常大部分情况下只经过路由器，只在到达最后一个目标子网以后由那里等路由器跳到目标机器上。 路由器内部会维持一个类似路由表等东西，用高速等缓存机制来确认某几个特定子网的 packet 应该从去往哪个子网。 可靠性IP 协议并不是面向连接的协议，也就不存在纠错和可靠传输问题。 ARP 协议与 RARP 协议ARP 协议大概可以理解为一个子网内的广播协议。就是一个 Host 想知道一个 IP 地址对应的 Mac 地址是多少，向本子网进行一个 broadcasting，寻找答案。配合上面对 IP 协议的解读，基本上就是一个本子网内才会用到的协议。而 RARP 协议则正好反过来。 ICMP（Internet Control Message Protocol） 协议当传送IP数据包发生错误，比如主机不可达/路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。这导致了我们可以通过一些应用来诊断网络状况。 pingping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请 求，受到请求的主机则用类型码为8的ICMP回应。 ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。我们可以看到， ping给出来了传送的时间和TTL的数据。 Traceroute这个工具在不同 OS 上的缩写是不一样的，linux系统中是traceroute,在MS Windows中是tracert。 traceroute 的名称清楚地表明了这是一个追踪路由器工作过程的工具。 它的工作原理是： traceroute 在收到目标地址以后，向目标地址发送一个 TTL 为1的 UDP packet，当第一个路由器收到这个 packet 以后，自动把 TTL 减为0，而TTL为0的 packet 已然无法向前（所以TTL为1的packet一开始能去哪儿呢？），路由器就扔掉它，并返回ICMP Time Exceeded 报文来报告源主机网络不可达。traceroute在收到 ICMP 报文后，又再发送一条 UDP报文，如此循环往复，直到最后一个 packet 到达目标地址，返回ICMP Echo Reply报文。 根据英文维基百科，实际上任意形式的协议报文都可以拿来做这种探针报文，当然通常我们使用 payload 无意义的 UDP packet。 TCP 协议报文结构与协议栈 常见的报文格式无外如上。上层报文格式不需要知道下层的报文格式，下层的报文在拿到上层报文后，直接添加一段首部（在以太网层面还需要加入校验和作为尾部），即成为本层的报文。整体上还是一个 header + body（在网络协议里面通常叫做 payload） 的模型。 报文在发送方的一端，看起来像是一个不断入栈的过程，而走发送方而言，就像是一个不断出栈的过程。虽然因为物理因素，发送方和接收方实际上是在操纵两个栈，但这两个栈理论上应该是对等的，发送方的报文穿过多层栈，接收方也会重建多层栈。 三次握手 首先再来详细看看 TCP 当报文格式： 序号就是我们经常说当seq，占32位，因为 TCP 是面向字节流的（byte stream oriented），所以要给流里中的一个 packet 编号。 确认号就是 Acknowledgment number (if ACK set)，它只有在 ack 标志位被置位以后才生效。它等于 seq + 1。 而标志位的含义是： （A）URG：紧急指针（urgent pointer）有效。（B）ACK：确认序号有效。（C）PSH：接收方应该尽快将这个报文交给应用层。（D）RST：重置连接。（E）SYN：发起一个新连接。（F）FIN：释放一个连接。 三次握手的过程大致上如下： 第一次握手，client 把 SYN 标志位设置为1，然后生成一个随机的 seq 作为通信的起点，发送以后本机进入 SYN_SENT 状态。 第二次握手，server 在收到 SYN 报文以后，知道 client 要建立连接，于是生成一个 SYN 和 ACK 标志位都为1的报文，其中ack号为收到的 seq 值加一（可以看出ack不仅表明了收到的报文的序号，也表明了期待接下来收到的seq的序号），然后随机产生一个值seq=K（client 和 server 使用两个随机数来通信），并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手，Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态（由此可见，只有收到ACK为1的报文，并且ack为自己发送的值加一的报文的时候，一端才算进入Client和Server进入ESTABLISHED状态），完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手 由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 第一次挥手，Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。第二次挥手，Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。第三次挥手，Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。第四次挥手，Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 由上述过程可以看出，握手和挥手都会用到 ACK 标志位和ack 序号。它们 ack 到包到标志位是 SYN 还是 FIN 才是挥手和握手的主要区别。 为什么握手是三次而挥手是四次？双工通信要求了我们建立连接和取消连接，其实是建立和取消两条管道（其实是两个 seq 序列）。 建立连接到时候必然要做成双工的，所以两端的握手必须紧密安排在一起，而第一个 ACK 和第二个 SYN 是可以为了简便而合二为一的。 挥手的时候，可以完全关闭，也可以双工变单工，特别是想要关闭连接的一方没有数据要发送了，不代表另一方的数据已经发送完了，因此不是那么适合把第一次关闭的 ACK 和第二次关闭的 FIN 合二为一。 有些时候，我们不喜欢TIME_WAIT 状态(如当MSL数值设置过大导致服务器端有太多TIME_WAIT状态的TCP连接，减少这些条目数可以更快地关闭连接，为新连接释放更多资源)，这时我们可以通过设置SOCKET变量的SO_LINGER标志来避免SOCKET在close()之后进入TIME_WAIT状态，这时将通过发送RST强制终止TCP连接(取代正常的TCP四次握手的终止方式)。 用 tcpdump 来查看tcp协议通信传输的过程首先用ping 查看tianya的地址： ping tianya.comPING tianya.com (120.24.90.198): 56 data bytes64 bytes from 120.24.90.198: icmp_seq=0 ttl=49 time=40.042 ms64 bytes from 120.24.90.198: icmp_seq=1 ttl=49 time=37.354 ms64 bytes from 120.24.90.198: icmp_seq=2 ttl=49 time=37.271 ms64 bytes from 120.24.90.198: icmp_seq=3 ttl=49 time=39.367 ms64 bytes from 120.24.90.198: icmp_seq=4 ttl=49 time=37.655 ms64 bytes from 120.24.90.198: icmp_seq=5 ttl=49 time=37.335 ms 然后用以下命令开始监控： 得到的全部输出如下： 17:57:13.415883 IP bogon.65290 &gt; 120.24.90.198.http: Flags [S], seq 477782453, win 65535, options [mss 1460,nop,wscale 5,nop,nop,TS val 213769344 ecr 0,sackOK,eol], length 017:57:13.452814 IP 120.24.90.198.http &gt; bogon.65290: Flags [S.], seq 2061846025, ack 477782454, win 14600, options [mss 1386,nop,nop,sackOK,nop,wscale 7], length 017:57:13.452857 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 1, win 8192, length 017:57:13.452949 IP bogon.65290 &gt; 120.24.90.198.http: Flags [P.], seq 1:78, ack 1, win 8192, length 77: HTTP: GET / HTTP/1.117:57:13.490112 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], ack 78, win 115, length 017:57:13.516730 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 1:1387, ack 78, win 115, length 1386: HTTP: HTTP/1.1 200 OK17:57:13.516736 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 1387:2773, ack 78, win 115, length 1386: HTTP17:57:13.516771 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 2773, win 8105, length 017:57:13.516826 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 2773, win 8192, length 017:57:13.517050 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 2773:4159, ack 78, win 115, length 1386: HTTP17:57:13.517053 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 4159:5545, ack 78, win 115, length 1386: HTTP17:57:13.517055 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 5545:6931, ack 78, win 115, length 1386: HTTP17:57:13.517056 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 6931:8317, ack 78, win 115, length 1386: HTTP17:57:13.517058 IP 120.24.90.198.http &gt; bogon.65290: Flags [P.], seq 8317:9001, ack 78, win 115, length 684: HTTP17:57:13.517079 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 5545, win 8105, length 017:57:13.517089 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 8317, win 8018, length 017:57:13.517095 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 9001, win 7997, length 017:57:13.517504 IP 120.24.90.198.http &gt; bogon.65290: Flags [.], seq 9001:10387, ack 78, win 115, length 1386: HTTP17:57:13.517507 IP 120.24.90.198.http &gt; bogon.65290: Flags [P.], seq 10387:11135, ack 78, win 115, length 748: HTTP17:57:13.517523 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 11135, win 7930, length 017:57:13.519626 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 11135, win 8192, length 017:57:13.526151 IP bogon.65290 &gt; 120.24.90.198.http: Flags [F.], seq 78, ack 11135, win 8192, length 017:57:13.563681 IP 120.24.90.198.http &gt; bogon.65290: Flags [F.], seq 11135, ack 79, win 115, length 017:57:13.563735 IP bogon.65290 &gt; 120.24.90.198.http: Flags [.], ack 11136, win 8192, length 0 要注意： 初始的seq数字往往都很大。 ack的结果是下一个希望收到的字节流的第一个字节的序号。比如这一次收到的字节是以10000个字节结尾的，ack显示的结果就需要下一段字节流以10001号字节开头。因为并不是每一个包都每次只发送一个字节，所以ack并不一定等于收到的包的seq加一，而是等于seq加上实际的length加一。 tcpdump 显示的seq号，只有一开始显示syn的时候的seq号是绝对seq号，接下来都是相对seq号。 这个.是ACK的意思。原因见此。缩写的含义是S (SYN), F (FIN), P (PUSH), R (RST), U(URG), W (ECN CWR), E (ECN-Echo) or &#39;.&#39; (ACK)。 "},{"title":"Fabric 文档拾遗","date":"2018-04-10T09:28:06.000Z","url":"/2018/04/10/Fabric-%E6%96%87%E6%A1%A3%E6%8B%BE%E9%81%97/","tags":["区块链","Hyperledger Fabric"],"content":"基本名词解释ledger账本上一系列由事务驱动的状态迁移的记录。状态迁移是链码调用（调用即事务）的结果。这些记录是不可修改顺序的，因此也上抗篡改的。 每个channel有一个账本，但恐怕不只一个账本。 理论上账本是由产生它的链码的命名空间隔离开来的，不能直接被其他链码访问到。 chain由包含一系列 transaction 的 block 通过hash-link（由散列值作为前驱指针的一种连接方式）组成的数据结构。 state database记录各种 key 的 latest value。可以被认为上chain的indexed view，可以随时被从链上重建出来。 所以 Fabric 自己就有双层数据结构。 读写集语义读集和写集搞不好是同一个事务里的数据结构（待查）。 锚节点一个 peer 节点，全 channel 里所有的其他节点都可以跟它交谈。每个组织（Member）都有一个锚节点，Member 里 的所有节点通过它来发现频道中的所有其他节点，通过锚节点和其他组织交换数据。 特别像以太坊中的 bootnode。 leader 节点这个节点代表组织跟 orderer 通信，拉取最新到达的节点以后，通过 gossip 协议向其他节点做同步。 Member法律上分离的实体，拥有独立的网络根证书。 Membership Service Provider一个抽象的插件化组件，可以切换实现。主要用意是提供 credentials 甚至 peers 给 client，让它跟网络交流。理论上每个 Member 应该有个 MSP。 MSP 的本质是一系列证书、私钥和验证算法，实际上就是一堆文件夹。 Membership Services每个 peer 和 orderer 都可能实现 MSP，也就是说 MS 其实是它们的一个服务组件。 BCCSPBlockchain Crypto Service Provider 和MSP一样，是加密服务的提供者。 bin 文件夹下的内容configtxlatorget-byfn.shget-docker-images.shordererpeer 其中 orderer、peer 都会被映射到镜像之内。 初始化的步骤 cryptogen 这个工具根据配置文件生成指定拓扑的 x.509证书材料。 用 configtxgen 工具生成 orderer 创世区块，给 orderer 用。 生成频道配置事务-算是元事务的一种吧，给 channel 用。 生成相关组织的锚节点。 启动脚本的作用 默认的 chaincode 开发语言是 Golang，但也可以切换到 node 上面。 这里的-m是 mode 的意思。 这个命令会消灭掉 docker 网络残余文件，包括密码学文件和链码镜像。 这个大脚本会大量依赖父文件夹的../bin脚本。 transaction 的流程 client 根据 endorsement policy 发送 transaction proposal 到各个 peer。 各个 peer 通过合约容器试算，生成 read-write-set。 client 再根据读写集语义签真正的 transaction，如果不是查询的试算，会把 transaction 发给 orderer。 orderer只负责收集所有的 transaction 打包成区块。 区块发送给 peer，如果 read-write-set 语义还依然满足，则 transaction validate 通过，把区块添加到区块链上。 CA 问题CA 是可选组件。 但如果 CA server 跑起来，我们可以向它发送 REST 请求给组织的 CA 来完成用户注册和登记。 CA 是 PKI 的实现。PKI 可以抗女巫攻击。 CA 可以像 cryptogen 一样，先生成组织里的节点证书和私钥（组织里一定会有 root-ca），然后生成成员（admin 和普通成员）的证书和私钥。 常见端口号这些端口号有先后顺序，适合在同一个 host 编排一系列容器。 orderer：7050peer：7051peer event：7053ca：7054 SDK 问题区块链天然可以用gRPC来通信。 因为各种语言都支持 Protocol Buffers，基于Protocol Buffers over gRPC，我们可以制造各种语言的SDK。 所以理论上我们可以直接通过 gRPC 跟区块链通信。 读写集语义实际上读集（read set）和写集（write set）是分开的。它们共同组成了事务。 configuration block有configtx，就有configuration block，这不奇怪。两者都要经过orderer。 可以通过命令行来获取configuration（peer channel fetch）。peer channel fetch 可以用来获取任意序号的区块。 packaging 这一行命令生成了一个 signedCDS。 有-s（signing的意思）应该有-S，否则再也没有机会让 owner 来签署这个 package 了。-S指出了需要本地 MSP 来 sign 这个 package。 -i是 intantiate policy，指的是只有 OrgA 的 admin 可以初始化这个 package。 实际上不用 package 和 sign 最好了，反正每个peer默认可以初始化链码也只有本 Member 的 admin（这种 admin 在默认的情况下是大多数需要产生变化的 wrtier）。 可见这个初始化策略是针对 package 而不是针对 channel 的。我们只可以组织一个 package 被初始化，不能阻止别人在一个 channel 上安装任意的 chaincode。 这个初始化策略还会进一步限制 upgrade。只有符合策略的 MSP 才能 upgrade 整个lian ma 停止链码目前只能通过停止和删除容器，并删除 peer 上 CDS的方式来做到，对其他组织的机器是个考验呢。 系统链码逻辑上和普通链码是一样的（应该也是通过各种事务驱动的），但只跑在 peer 进程内。 系统链码的目的是为了减少 peer 和 chaincode 容器之间的 gRPC。 要 upgrade 链码只有 upgrade peer 二进制文件（实际上就是跟着 Fabric 版本走）。 架构流程图 "},{"title":"Fabric 中的 peer","date":"2018-04-09T09:55:01.000Z","url":"/2018/04/09/Fabric-%E4%B8%AD%E7%9A%84-peer/","tags":["区块链","Hyperledger Fabric"],"content":"每个 peer 可以拥有若干个 chaincode，也可以拥有若干个 ledger，但并不是一开始就拥有的，而是逐渐被创建出来的。chaincode 一定会定义一个 asset，也就生成了 ledger。一个peer 可以拥有 ledger 而无 chaincode，可见也并不是必然由 chaincode 生成 ledger。比如同一个组织里面多个 peer，只有一个安装了 chaincode（只有这个 peer 可以当作 endorser），其它的peer一样可以拿到 ledger。 peer 的流程架构图大致上是： 为了预防有 peer 的数据不一致，有可能需要 client application 向多个 peer 进行查询。 channel 可以认为是一系列 peers 的逻辑组合，orderer 可以被认为是跨channel的。同一个 channel 的 peers 共享完全一样的账本。 不同的组织完全可以基于同样的账本copy，产生不同的 application。 Fabric 有 identity，identity 有 principal。 transaction 到达 orderer 的顺序，并不一定就是 transaction 在 block 里的顺序。 现在整个共识过程分为proposal-packaging-validation三个阶段。第一步和第三步都是去中心化的，第二步等局部中心化只是为了模块化共识算法的实现，也为了解耦第一和第三步，让它们并行执行。实际上，endorser和commitor在逻辑上还可以进一步分离，又进一步提升了并发性。 在 validation 阶段，不合格的 transaction 会被保留（在区块中？）以备审计，而不会被应用中账本上。 peer并不都要连到 orderer 上，这就要求 gossip 协议出场了。 "},{"title":"Hyperledger Fabric 各个容器内环境","date":"2018-04-09T06:53:18.000Z","url":"/2018/04/09/Hyperledger-Fabric-%E5%90%84%E4%B8%AA%E5%AE%B9%E5%99%A8%E5%86%85%E7%8E%AF%E5%A2%83/","tags":["区块链","Hyperledger Fabric"],"content":"peer 容器/opt/gopath/src/github.com/hyperledger/fabric/peer虽然是WORKING_DIR，什么都没有。这个目录是/bin/bash永远的进入路径，不管在哪个目录退出，重新进入还是会进入这个路径。 /etc/hyperledger/fabric /var/hyperledger/production这个文件夹存放unix系统里面的动态程序数据。 启动命令整个容器内只有一个进程peer node start。完全没有其他命令行参数，所以就是靠环境变量来支持。 这个启动命令被安装只/usr/local/bin/下，里面只有这个命令（精简的ubuntu系统）。 全部环境变量用env命令可以打出来： orderer 容器/opt/gopath/src/github.com/hyperledger/fabric虽然是WORKING_DIR，什么都没有。这个目录是/bin/bash永远的进入路径，不管在哪个目录退出，重新进入还是会进入这个路径。 注意，这个目录没有peer子目录。 /etc/hyperledger/fabric /var/hyperledger/这个文件夹下有专门的两个子文件夹。 orderer 文件夹下有三个文件： production 文件夹下还有一个orderer文件夹： 启动命令orderer 连启动参数都没有。直接启动就会遇到地址被占用的错误。 这个启动命令被安装只/usr/local/bin/下，里面只有这个命令（精简的ubuntu系统）。 全部环境变量 cli 容器/opt/gopath/src/github.com/hyperledger/fabric/peercli容器的这个工作目录倒是有很多文件了： /opt/gopath/src/github.com/hyperledger/fabric/examplescli 容器独有的放置链码的文件夹，也是外部的docker映射进来的。 /etc/hyperledger/fabric这个文件夹可以说也是从标准环境中诞生出来的（标准镜像里就有这些文件夹了么？） /var/hyperledger/没有任何内容，没有production数据需要单独存放。 环境变量 链码容器/etc/hyperledger/fabric/只有一个peer.crt文件，应该是在生成这个镜像的时候，从特定的peer上拷贝过来的。 没有/opt下的gopath，也没有/var下的production目录。 启动命令只有一个启动命令 /usr/local/bin/下只安装了一个命令chaincode。 环境变量"},{"title":"一个滚动重启的状态保存问题","date":"2018-04-02T03:49:41.000Z","url":"/2018/04/02/%E4%B8%80%E4%B8%AA%E6%BB%9A%E5%8A%A8%E9%87%8D%E5%90%AF%E7%9A%84%E7%8A%B6%E6%80%81%E4%BF%9D%E5%AD%98%E9%97%AE%E9%A2%98/","tags":["系统架构"],"content":"很多时候滚动重启，都会导致状态丢失。比较好的设计方法是把服务本身设计成无状态的，然后在上游的服务上做好 failover，然后增加 standby server，让 sticky 数据 transmit 到 standby 机器上，让 request 失败以后可以自己由上游重传到 standby server。然后就可以滚动重启了。 这大部分场景下还要考虑幂等的问题。 这就看得出热配置热替换的重要性了。在大多数情况下，除了发布新的 feature 升级以外，都应该尽量用热配置来避免重启。"},{"title":"重读 Martin Fowler 的微服务论文原文","date":"2018-03-20T08:26:04.000Z","url":"/2018/03/20/%E9%87%8D%E8%AF%BB-Martin-Fowler-%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BA%E6%96%87%E5%8E%9F%E6%96%87/","tags":["微服务"],"content":"微服务也是面向服务的，但 SOA 意味着 ESB。试图把复杂度隐藏在一个庞然大物里面。 几个小标题 组件化（Componentization ）与服务（Services）组件化的好处就是可以独立部署和升级，把变化隔离在组件之内。 缺点就是会引入大量的进程间交互，引入系统交叉点，引入性能下降的瓶颈以及失败的交互。 围绕业务功能的组织不要被 conway 定律左右，按照 feature 组织 team。每个 project 都应该能够独立拥有自己的全部功能–UI、数据库。 产品不是项目产品要有 ownership，要对这个产品的全部生命周期负责。 强化终端及弱化通道弱化 ESB 的复杂协议、集中式的框架。强化各个 end，或者是 client。 两种做法：基于 RESTful 通信，像 Unix 过滤器一样。基于轻量级消息总线。 分散治理这一条的意思大概是，不要考虑用一个技术方案 rule them all。 分散数据管理就是每个服务拥有自己的数据库。 基础设施自动化持续集成都全自动化。 容错性设计监控错误指标，引入断路器和仪表盘。总之提高各种 resilience（韧性）。 设计改进能够持续改进微服务组件。版本只是最后一个手段。"},{"title":"Hyperledger Fabric MSP 相关问题","date":"2018-03-15T08:29:15.000Z","url":"/2018/03/15/Hyperledger-Fabric-MSP-%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","tags":["区块链","Hyperledger Fabric"],"content":"Fabric要求所有的 paticipant 有相关的 identity。identity是由x509证书认证的（大致上也就是各种signcert），每个 identity 有自己的 principal，包含了大量的 property，包括但不仅限于组织名。 PKI 生成 identity，而 MSP 表达治理组织的规则，包括哪些 identity 属于哪些组织，且参与网络中。 PKIPKI 是一种标准，一般由四个元素组成： Digital Certificates Public and Private Keys Certificate Authorities Certificate Revocation Lists 数字证书一个持有一个组织的系列属性的数字文件。常见的数字证书是X509标准的，很像一个国家发放的身份证（有名称，省份，国家，还有组织的名字）。 For example, John Doe of Accounting division in FOO Corporation in Detroit, Michigan might have a digital certificate with a SUBJECT attribute of C=US, ST=Michigan, L=Detroit, O=FOO Corporation, OU=Accounting, CN=John Doe /UID=123456. 注意，这些属性都是这个party的subject attribute的一部分。 注意看，这个 party 的公钥是这个证书的一部分，而私钥则不是。 因为有密码学加持，所以这个证书是抗篡改的，里面的attribute可以被认为是真的，只要别人信任这个证书的签发方的话。因为这个签发方用自己的私钥的方法把这些 attribute 加密写入（secrete writing）了这个证书。注意，签发证书的时候，csr的请求者不需要提供自己的私钥。在CA那里，是证书公钥 + CA 私钥 + CA 证书（当然也包含了CA的公钥）来生成新的证书。 质询和公私钥质询和消息完整性是安全通信的重要概念。 私钥签名，公钥验证签名。 CA现实中的CA是一系列权威。 用自己的私钥给一个party的属性和公钥签名。因为CA是周知的权威，它的签名可以被周知的CA公钥验证。 在区块链里，我们当然希望一个或多个CA可以帮我们定义一个组织里有哪几个成员。 因为根CA的证书，可以帮我们验证某个证书是不是它签发的，所以我们可以通过根CA签发一个中间CA的证书，而这个中间CA一旦被验证了，它也可以产生它签发的证书。这就是CA构成的信任链的本质了。 换言之，任何一个证书，都可以拿来当CA证书来用。 做区块链世界里，理论上不同的组织可以由不同的根 CA 签发证书。 Fabric 的 CA 不能拿来提供 SSL 证书，这点来看就不如 openssl 这样的工具了。而且，实际上我们也可以使用公共的权威 CA 来生成相关的组织证书。 CA 有证书撤销列表（Certificate Revocation Lists），验证的party要验证证书的时候，还要查看撤销列表（在线查看？离线怎么办？）： MSP1.1 文档MSP 的工作方式无非有两个： 列出一个组织里所有的成员。 列出一个CA，声称由这个CA签发的证书都是这个组织的成员。 MSP的实际作用还超过于此，它还规定了很多角色和特权的细节，如果admin，普通user，reader和writer（后面这两项是由某些policy决定的）。 按照1.1的文档，现在Fabric提倡一个组织（这里的组织不同于x.509标准里的组织）使用一个MSP（这也符合gossip协议的要求）。比如ORG1-MSP之于ORG1，特殊情况下才需要ORG2-MSP-NATIONAL和ORG2-MSP-GOVERNMENT之于ORG2。 如上图可以看出，合理的MSP总是由不同的根CA经过若干个ICA单独生成的。 每个组织还可以再分成不同的 OU（organizaional units），用不同的 OU 来区分不同的业务线。这个OU就是 X.509 证书里的那个 atrribute。我们可以靠 OU 这个属性来做权限控制（实际上我们应该可以通过任何属性来做权限控制）。Fabric的原话是，我们可以用同一套 CA 体系，靠不同的 OU 来区分不同的组织成员（为什么不直接用不同的 O ？）。 MSP可以分为两类，频道MSP（频道配置文件）和本地MSP（节点或者user的msp文件夹是必须存在的）。这两种MSP定义了outside channel level和 channel level 的管理和参与权利。因为频道MSP包含了这个 channel 的组织成员配置，只有这些配置里包含进了这些组织的 MSP，这些组织才能参与到频道中。其关系图如下： 从这个图可以看出，每个组织的 MSP，实际上是全局 MSP 的一部分。 似乎频道MSP会被拷贝到各个peer的本地。这样的话是不是网络中的MSP变动（加入新的组织）的时候要动态地滚动重启整个网络呢？ 高级的MSP（频道）管理网络资源，包括加入联盟等问题，低级（本地）MSP管理本地资源，包括这本地部署合约初始化合约等问题。 此外，MSP还可以分为 Network MSP，Channel MSP，Peer MSP，Orderer MSP。 MSP的组成部分无外乎，所以MSP实际上是一大堆文件夹组成的东西： 现实中的结构有： 这里没有把user也列出来，基本上除了本节点或者user私有的证书（包含了公钥）和keystore（包含了私钥）以外，有大量的ca证书，管理员证书和tls证书是整个org共享的。注意，不同组织的ca证书是完全不同的，足以证明cryptogen这个工具生成的不同的组织的组织根ca还是不一样的。 1.0 文档MSP 把签发和验证证书、用户质询（换言之MSP即使是在peer/client上也提供authentication的功能）的过程给抽象化了。MSP 可以完全定制化实体（identity）的记号，和这些实体被治理的规则。实际上对 Peer 而言，MSP 就是他们的一部分，可以被认为是会员相关操作的一部分。 一个 Fabric 区块链可以被一个或多个 MSP 统治。这提供了会员制操作的模块化，和不同会员制标准的互操作性。 在 Fabric 中，签名验证（signature verification）是 authentication。 每一个 peer 和 orderer 都需要局部设置 MSP 配置（实际上就是需要配置证书和 signing keys）。每个 MSP 必须有个 MSP ID 来引用这个 MSP。实际上如果我们仔细观察 crypto-config 这个文件夹，就会发现组织域、peer、admin 和一般 user，凡是有 identity 的，都有 msp 的配置。而 MSP 的全套配置必然包括： admincerts cacerts tlscacerts 如果可以发起和验证签名，还需要有： keystore 这个文件似乎不是私钥本身，而是私钥的集合大概是这种形式的： signcerts 用户可以使用 Openssl（这个大概是没人用的）、cryptogen 和Hyperledger Fabric CA来生成用来配置 MSP 的证书和 signing keys。 在每个节点的配置文件里面（对 peer 节点是 core.yaml 对orderer 节点则是 orderer.yaml）指定 mspconfig 文件夹的路径和节点的 MSP 的 ID。mspconfig 文件夹的路径必须是相对于FABRIC_CFG_PATH的路径，在 peer 上用mspConfigPath参数表示，在 orderer 上用LocalMSPDir参数表示。MSP ID 在 peer 上用localMspId表示，在 orderer 上用LocalMSPID表示（注意大小写不同）。这些参数可以被环境变量给覆写掉，对于 peer 用CORE_PEER_LOCALMSPID，对于 orderer 用ORDERER_GENERAL_LOCALMSPID。当 orderer 启动了以后，必须把“系统 channel”的创世区块提供给 orderer。 只有手动操作才能重新配置一个“本地”MSP，而且要求那个 peer 或者 orderer 进程重启。未来可能会提供在线动态的重配置。 在 mspconfig 文件夹下可以用一个 config.yaml 文件来定义组织化单元。大概是这样： 这些 ou 的定义是可选的，是为了在组织内再进一步按照业务线分权。默认的情况下没有的话，组织里的 identity 就不再进一步分权。 有一种特殊的分类方法，把签发事务、查询 peer 的 identity 称作 client，而把背书和提交事务的节点被称作 peer。问题是默认的情况下一个 peer 容器就是 peer 了，也不需要专门的 config 来配置。所以我想应该只是专门使用 client 来区分、鉴别 identity。 正如我们前面看到的，orderer 在启动的时候，需要得到一个“系统频道”的创世区块，这个创世区块必须包含全网络中出现的所有 MSP 的验证参数。这些验证参数包括：“verification parameters consist of the MSP identifier, the root of trust certificates, intermediate CA and admin certificates, as well as OU specifications and CRLs”。这样 orderer 才能处理频道创建请求（channel creation requests）。 而对于应用程序频道而言，只有治理那个频道的 MSP 的验证组件必须被包含在那个频道的创世区块中。在 peer 加入频道以前，应用程序有义务把正确的 MSP 配置信息包含在创世区块之中。 要修改一个频道里的 MSP，要一个有那个频道 administrator 证书的拥有者，创建一个config_update对象，然后把这个对象在频道里公布。这是通过 configuration block 来实现的吗？ 网络中还可能存在大量的 intermediate CAs。 MSP 的最佳实践有： 一个组织拥有多个 MSP。 这是一个组织下面有多个分支机构的时候才会用到的设计方法。 多个组织共用一个 MSP。 什么情况下会让一个联盟中的多个组织共用一个 MSP 呢？除非它们极为相似吧。 client 要和 peers 分开。怎么做到的呢？ 要有独立的 admin 和 CA 证书。 把中间 CA 放到黑名单里面。 CA 和 TLS CA 放在不同的文件夹下。 "},{"title":"Hyperledger Fabric 的配置文件解读","date":"2018-03-15T06:38:14.000Z","url":"/2018/03/15/Hyperledger-Fabric-%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E8%AF%BB/","tags":["区块链","Hyperledger Fabric"],"content":"Crypto Generatorx.509 相关的文件主要包含两个东西：证书和 signing keys。 cryptogen 使用的配置文件是crypto-config.yaml。 x.509 的根证书是ca-cert。它把 peers 和 orderers 绑定到一个 Org 里面。在这个网络里，每个组织都有签发自己的证书的能力，可以用这个 ca 来签发其他证书给节点和 client。 签发交易用的是私钥（keystore），验证交易用的是公钥（signcerts）。 跑完这个工具生成的材料都在crypto-config这个文件夹下，它总会归属于 ordererOrganzations 和 peerOrganizations。这两个文件夹下的子文件夹就是由拓扑决定的几个域文件夹。每个域下必有 ca、msp、peers/orderers、tlsca 和 users 五个文件夹。每个user，peer和orderer还必然有自己的MSP。 configtxgen 相关configtxgen需要使用的配置文件是configtx.yaml，解说文件大致如下： docker-compose 的配置文件分析服务的定义依赖关系大概是 peer-base.yaml -&gt; docker-compose-base.yaml -&gt; docker-compose-cli.yaml。 常见环境变量前缀Orderer 相关的环境变量开头是ORDERER_GENERAL_。 Peer 相关的环境变量开头是CORE_PEER_。 其他环境变量开头是CORE_。 peer-base.yaml启动 chaincode 容器都是在本网桥网络里启动的。 它的工作目录是/opt/gopath/src/github.com/hyperledger/fabric/peer。二进制的可执行文件应该都在 gopath 下。 它的工作路径里有二进制的 peer 文件，所以可以直接peer node start启动。 它的所谓的 vm enpoint 看起来就是容器服务治理的思路，用 port 来做 endpoint 的端点CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock。 docker-compose-base.yaml docker-compose-cli.yaml在cli 容器内的的Gopath 就是普通的 /opt/gopath。 在容器内有四个已经写好的目录，要映射到本地目录上才能用，映射关系大致是： ./../chaincode/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/：脚本的位置，这里应该可以放一些让容器外的控制命令操纵整个 fabric 的脚本。./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts：当然这就是 channel 的器物所在地了。 本身的相关文件的放置地。 docker-compose-e2e-template.yaml byfn.sh script/script.sh"},{"title":"X.509证书问题","date":"2018-03-13T06:38:20.000Z","url":"/2018/03/13/X-509%E8%AF%81%E4%B9%A6%E9%97%AE%E9%A2%98/","tags":["密码学"],"content":"X.509证书里有一段属性主题，大概是这样： 这些 attribute 的含义是： country (countryName, C), organization (organizationName, O), organizational unit (organizationalUnitName, OU), distinguished name qualifier (dnQualifier), state or province name (stateOrProvinceName, ST), common name (commonName, CN) and serial number (serialNumber). locality (locality, L), title (title), surname (surName, SN), given name (givenName, GN), initials (initials), pseudonym (pseudonym) and generation qualifier (generationQualifier). Distinguished Name (DN)。具体内容可以参考这里。 PEM格式 - Privacy Enhanced Mail,打开看文本格式,以”—–BEGIN…”开头, “—–END…”结尾,内容是BASE64编码. 一个典型的场景，在为 node 设置启用 https 以前。 先要生成 ca 机构： 你需要root或者admin的权限 Unable to load config info from /user/local/ssl/openssl.cnf 对于这个问题，你可以从网上下载一份正确的openssl.cnf文件， 然后set OPENSSL_CONF=openssl.cnf文件的本地路径 然后生成服务端证书： 这里面用到的配置文件有一个特别重要的地方： 然后生成客户端证书： 公私钥除了可以用来加解密信息，还可以用来做数字签名的签署和验证，一个典型流程大概是这样： A 给 B 发信息： 首先 A 用 Hash 函数对要发送的数据实体生成摘要（digest），这个过程是不可逆的。 A 使用自己的私钥对这个摘要进行加密，生成数字签名（signature），并将此签名连同要发送的数据实体一起发送给 B 。 B 收到 A 发送过来的数据后，首先用 A 的公钥对数字签名进行解密，得到摘要，从而证明数据确实来自 A，因为只有 A 有私钥。 B 再对接收到的数据实体进行 Hash 函数，如果得到的结果和上一步摘要一致，则证明数据实体没有被篡改过。 "},{"title":"谢灵点在以太坊中的应用","date":"2018-03-13T03:53:19.000Z","url":"/2018/03/13/%E8%B0%A2%E7%81%B5%E7%82%B9%E5%9C%A8%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","tags":["Ethereum","博弈论"],"content":"Focal point 或者 Schelling point 是博弈论中的一个概念，指的是人们在缺乏沟通的情况下，倾向于使用的解。因为人们拥有一样的常识，所以这些解对他们而言显得特殊、自然或者与他们有关系。这个观点最早是由美国诺贝尔经济学奖得主Thomas Schelling提出的。 警察系统在这几个世纪中已经不自觉地使用这个理论很久了。他们经常把犯人分开审问某件事的具体细节，囚犯想要说得一致以得到释放，唯一的可能就是说真话。 在以太坊中，也有利用谢灵点理论的变种谢灵币来达到一个公允的 data feeds 的实践，其简要的工作过程大致是： 所有人在第一个区块提交一个 value hash。 所有人在接下来的一个区块提交 value。 对 value 进行排序，在25分位和75分位之间的数给予奖励。 这种机制可以做到一个类似预言机的机制：所有人都会尽量提供一个真实值，比如某地的温度，某天的物价。 这个机制要正确运行，防女巫攻击（sybil attack ），要运用 PoW 和 PoS 机制才行。当然，这始终不是百分之百可靠的，还是可能有串谋机制。"},{"title":"以太坊中的事务和消息调用","date":"2018-03-12T03:36:54.000Z","url":"/2018/03/12/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%92%8C%E6%B6%88%E6%81%AF%E8%B0%83%E7%94%A8/","tags":["区块链","Ethereum","Solidity"],"content":"综合What is the difference between a “call” , “message call” and a “message”下的回复，得出此文。 Call 是一个在不同的上下文下含义很混乱的词汇。 Message 是带有数据载荷或价值，在合约到合约之间传递的东西（合约可能有独立账户，也可能没有！）。Message 到达目标账户后，如果目标账户含有代码，则目标账户会产生状态迁移，这时候 Message 就产生了 Message Call。Message 不会因为挖矿延迟，他们本身就是 transaction 执行的一部分。 Transaction 一定是由外部账户签署的，账户到账户之间发送的 Message ，要么它产生了一个合约，要么它是一个 Message Call，而且它可以激发合约之间越来越多的 Message Call。 再引用 Solidity 官方文档原文： A transaction is a message that is sent from one account to anotheraccount (which might be the same or the special zero-account, seebelow). It can include binary data (its payload) and Ether. In fact, every transaction consists of a top-level message call which in turn can create further message calls. 对于已经被创建好的合约而言，它收到的transaction，都是 Message Call，对于很多其他文献而言，Message Call 也叫 internal transaction，但它不像正式的 transaction 一样带有签名，也就无法被 transaction api 查询出来。 我们经常讲的 call 和 transaction 还有是两种调用合约的方式： SendTransation 必然会对链上数据进行修改。所以高层 API 通常只是得到一个 transaction hash，以后再得到 reciept。 call 则当场得到结果，但不会引起链上的数据变化。"},{"title":"精通比特币读书笔记","date":"2018-03-11T07:28:10.000Z","url":"/2018/03/11/%E7%B2%BE%E9%80%9A%E6%AF%94%E7%89%B9%E5%B8%81%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","tags":["区块链","比特币"],"content":"第一章 介绍传统货币的防止双花，必须在一个中心化（centralized）的清算所（clearing house）里清算。比特币则用全局选举的机制达到共识，来清算双花问题。本质上来讲，就是把一个固定的中心化的清算过程，用选举的方式转化为无数个去中心化的局部清算过程。这就弥补了在比特币之前出现的数字货币的缺点。 clearing 在比特币网络里就被称作 mining 。 钱包是保存地址和管理密钥的地方。不要害怕公开自己的钱包地址。 全节点可以获取全部的交易信息，也因此可以验证交易，发出交易。硬件钱包是运转在专有硬件上的节点（树莓派？），冷钱包就是纸一类的东西。离线钱包是非常安全的。 第二章 比特币原理比特币最多可以分割到一亿分之一的大小。 Transaction就像是复式记账法账簿上的行，即每行都有输入和输出。 简单来说，每一笔交易包含一个或多个“输入”，输入是针对一个比特币账号的提款（而不是债务）。 这笔交易的另一面，有一个或多个“输出”，被当成信用点数记入到比特币账户中。这些输入和输出的总额（负债和信用）不需要相等。相反，当输出累加略少于输入量时，两者的差额就代表了一笔隐含的“矿工费”，这也是将交易放进账 簿的矿工所收集到的一笔小额支付。 简而言之，每个交易的输出是下一个交易的输入，意味着交易是编号的。 比特币中的找零（change），是经常会被发送到钱包的新地址里（出于隐私原因），或者返回原地址（出于默认配置）。 化零为整的例子： 化整为零的例子（发工资）： 钱包可以离线生成transaction。 Alice只需要指定目标地址和金额，其余的 细节钱包应用会在后台自动完成。很重要的一点是，钱包应用甚至可以在完全离线时建立交易。就像在家里写张支票， 之后放到信封发给银行一样，比特币交易建立和签名时不用连接比特币网络。只有在执行交易时才需要将交易发送到网络。 钱包只存储与本地址相关 transaction，是所有数据的子集，是 filtered 过的。 大多数钱包应用跟踪着钱包中某个地址的所有可用输出。 查询某个地址的 UTXO，可以看到transaction 的格式，注意看，value的单位是聪（和以太坊一样，以太坊的value最小单位是伟）： 这个格式里的 script就是锁定这个 UTXO的关键。这是一个留给未来使用这个UTXO的使用者的谜题-谁能拿出一个signature，可以和这个script里提供的锁定地址（也就是交易里的价值获得者）相匹配，就可以得到使用这个UTXO的权力。但这个script字段是什么意思呢？ value_hex 是 value 的16进制值。 私钥可以产生公钥，公钥可以散列出地址。交易里应该同时存在地址、签名和公钥。 交易被包在一起放进区块中时需要极大的计算量来证明，但只需少量计算 就能验证它们已被证明。 挖矿在构建区块时会创造新的比特币，和一个中央银行印发新的纸币很类似。 描述挖矿的一个好方法是将之类比为一个巨大的多人数独谜题游戏。一旦有人发现正解之后，这个数独游戏会自动调整 困难度以使游戏每次需要大约10分钟解决。想象一个有几千行几千列的巨大数独游戏。如果给你一个已经完成的数独， 你可以很快地验证它。然而，如果这个数独只有几个方格里有数字其余方格都为空的话，就会花费非常长的时间来解 决。这个数独游戏的困难度可以通过改变其大小（更多或更少行列）来调整，但即使它非常大时验证它也是相当容易 的。而比特币中的 “谜题” 是基于哈希加密算法的，其展现了相似的特性：非对称地，它解起来困难而验证很容易，并且它的困难度可以调整。 新交易不断地从用户钱包和应用流入比特币网络。当比特币网络上 的节点看到这些交易时，会先将它们放到各自节点维护的一个临时的未经验证的交易池中。。当矿工构建一个新区块时， 会将这些交易从这个交易池中拿出来放到这个新区块中，然后通过尝试解决一个非常困难的问题（也叫工作量证明）以 证明这个新区块的合法性。 工作量证明是为了证明这个区块是合法的。 这些交易被加进新区块时，以交易费用高的优先以及其它的一些规则进行排序。矿工一旦从网络上收到一个新区块时， 会意识到在这个区块上的解题竞赛已经输掉了，会马上开始下一个新区块的挖掘工作。它会立刻将一些交易和这个新区块的数字指纹放在一起开始构建下一个新区块，并开始给它计算工作量证明。每个矿工会在他的区块中包含一个特殊的交易，将新生成的比特币（当前每区块为12.5比特币）作为报酬支付到他自己的比特币地址，再加上块中所有交易的交易费用的总和作为自己的报酬。如果他找到了使得新区块有效的解法，他就会得到这笔报酬，因为这个新区块被加入到了总区块链中，他添加的这笔报酬交易也会变成可消费的。 手续费（fee）的排序是存在的。 Alice的交易被网络拿到后放进未验证交易池中。一旦被挖矿软件验证，它就被包含在由Jing的采矿池生成的新块（称为候选块）中。 参与该采矿池的所有矿工立即开始计算候选块的工作证明。大约 在Alice的钱包第一次将这个交易发送出来五分钟后，Jing的ASIC矿机发现了新区块的正解并将这个新区块发布到网络上后，一旦被其它矿机验证，它们就会立即投身到构建新区块的竞赛中。 所谓的候选区块也是存在的。 全索引客户端可以追钱款的来 源，从第一次有比特币在区块里生成的那一刻开始，按交易与交易间的关系顺藤摸瓜，直到Bob的交易地址。 特别地，轻客户端通过确认交易在哪个区块，以及后面还有多少个区块来确认一个支付的合法性。 在大多数情况下，UTXO总是是很难整齐地被拿来支付某些支出。总是很容易出现聚合（aggregating）几个 UTXO 用来支付一笔交易的情况。 第三章 比特币核心最初的中本聪实现已经被吸收进了比特币核心，是其他比特币系统的参考实现。在这里bitcoin core就不是核心团队，而是核心系统了。 比特币核心架构图如下： 不要使用比特币核心的钱包，应该使用支持标准（如BIP-39和BIP-32）的现代钱包。 在18年出，比特币核心需要2g的内存和160g的硬盘。比特币核心的节点会索引交易数据，这样应该可以提升一些搜索交易的速度。在下载完2009年以来全部的交易以前，比特币核心节点无法处理交易和更新余额（查账都做不到？）。 不想依赖其他人而验证交易的人总是需要一个自己的节点。 获取一个交易并且对它进行解码： 交易的实际存储总是十六进制编码。而总能解码为一个 JSON 对象。注意看上面的交易细节，一个输入产生了两个输出，一个是真实转账，一个是找零转账，实际上应该也可以支持多个输入。vin则是上一次交易，可以看到上一次交易也有散列形式的txid。 提示交易ID在交易被确认之前不具有权威性。 在区块链中缺少交易哈希并不意味着交易未被处理。 这被称为“交易可扩展性”，因为在块中确认之前可以修改交易哈希。 确认后，txid是不可改变的和权威的。 这段话的意思，恐怕是赞同交易可扩展性的，但交易可扩展性明明是有问题的。 块可以由块高度或块哈希引用。 用块高度可以得到块散列，用块散列可以得到块内容。 当然除了命令行的方式，也可以有各种各样的客户端来实现比特币的全节点。 第四章 密钥和地址现代密码学的用处： 秘密写作 用签名来证明秘密 用数字指纹来证明数据真实性 具有讽刺意味的是，加密不是比特币的重要组成部分，因为它的通信和交易数据没有加密，也不需要加密来保护资金。 公开通信，公开存储，所以所有人都可以查看。 大多数比特币交易都需要一个有效的签名才会被存储在区块链。只有有效的密钥才能产生有效的数字签名，因此拥有~密钥副本就拥有了对该帐户的比特币的控制权。用于支出资金的数字签名也称为见证（witness），密码术中使用的术语。 比特币交易中的见证数据证明了所用资金的真正归谁所有。 有签名才有见证，隔离见证即隔离签名相关部分。 密钥是成对出现的，由一个私钥和一个公钥所组成。公钥就像银行的帐号，而私钥就像控制账户的PIN码或支票的签名。 一般而言，由公钥生成的地址对应公钥。但比特币地址并不只能代表公钥，它还可以代表其他支付对象，譬如脚本。比特币地址把收款方抽象起来了。 公钥加密发明于上个世纪70年代。 素数幂和椭圆曲线乘法函数，在数学上都是不可逆的。 在比特币系统中，我们用公钥加密创建一个密钥对，用于控制比特币的获取。密钥对包括一个私钥，和由其衍生出的唯 一的公钥。公钥用于接收比特币，而私钥用于比特币支付时的交易签名。 私钥-&gt;公钥-&gt;地址。 公钥和私钥之间的数学关系，使得私钥可用于生成特定消息的签名。此签名可以在不泄露私钥的同时对公钥进行验证，大致是通过OP_CHECKSIG一类操作码。 支付比特币时，比特币的当前所有者需要在交易中提交其公钥和签名（每次交易的签名都不同，但均从同一个私钥生 成）。比特币网络中的所有人都可以通过所提交的公钥和签名进行验证，并确认该交易是否有效，即确认支付者在该时刻对所交易的比特币拥有所有权。 我们通常可以随机选择一个数字(k)作为私钥，然后通过椭圆曲线相乘算法得到一个公钥(K)。然后使用一个单向散列函数得到一个地址（A）。 为什么在比特币中使用非对称密码学？ 它不是用于“加密”（make secret）交易。相反，非对称密码学的有用属性是生成数字签名的能力。 可以将私钥应用于交易的数字指纹以产生数字签名。 该签名只能由知晓私钥的人生成。 换言之，只有非对称加密才能在确保私钥保密的情况下产生签名。私钥就是一个随机选出的数字而已。一个比特币地址中的所有资金的控制取决于相应私钥的所有权和控制权。 你可以用硬币、铅笔和纸来随机生成你的私钥：掷硬币256次，用纸和笔记录正反面并转换为0和1，随机得到的256位二进制数字可作为比特币钱包的私钥。该私钥可进一步生成公钥。 生成一个比特币私钥在本质上与“在1 到2^256之间选一个数字”无异。 更准确地说，私钥可以是1和n-1之间的任何数字，其中n是一个常数（n=1.158 * 10^77，略小于2^256），并被定义为由比特币所使用的椭圆曲线的阶（见椭圆曲线密码学解释）。要生成这样的一个私钥，我们随机选择一个256位的数字，并检查它是否小于n-1。从编程的角度来看，一般是通过在一个密码学安全的随机源中取出一长串随机字节，对其使用SHA256哈希算法进行运算，这样就可以方便地产生一个256位的数字。如果运算结果小于n-1，我们就有了一个合适的私钥。否则，我们就用另一个随机数再重复一次。 要使用比特币核心客户端生成一个新的密钥，可使用 getnewaddress 命令。出于安全考虑，命令运行后只 显示生成的公钥，而不显示私钥。如果要bitcoind显示私钥，可以使用 dumpprivkey 命令。 dumpprivkey 命令会把私钥以 Base58校验和编码格式显示，这种私钥格式被称为钱包导入格式（WIF，Wallet Import Format） 为什么与私钥签名有关的编码都是 Base58 编码？ 通过椭圆曲线乘法可以从私钥计算得到公钥，这是不可逆转的过程：K = k * G 。其中k是私钥，G是被称为生成点的常数点，而K是所得公钥。其反向运算，被称为“寻找离散对数”——已知公钥K来求出私钥k——是非常困难的，就像去试验所有可能的k值，即暴力搜索。在演示如何从私钥生成公钥之前，我们先稍微详细学习下椭圆曲线密码学。 因为所有比特币用户的生成点是相同的，一个私钥k乘以G将 得到相同的公钥K。 比特币的地址总是1开头的。它本质上只是公钥的指纹。公钥的计算方法是双层散列。以公钥 K 为输入，计算其SHA256哈希值，并以此结果计算RIPEMD160 哈希值，得到一个长度为160位（20字节）的数字： A = RIPEMD160(SHA256(K)) 但我们常见的比特币地址还更近一层，使用了一个 Base58Check 的机制，提供了一个可读的、有校验和的版本。 Base58是Base64编码格式的子集，同样使用大小写字母和10个数字，但舍弃了一些容易错 读和在特定字体中容易混淆的字符。具体地，Base58不含Base64中的0（数字0）、O（大写字母o）、l（小写字母 L）、I（大写字母i），以及“+”和“/”两个字符。简而言之，Base58就是由不包括（0，O，l，I）的大小写字母和数字组成。 为了增加防止打印和转录错误的安全性，Base58Check是一种常用在比特币中的Base58编码格式，比特币有内置的检查错误的编码。检验和是添加到正在编码的数据末端的额外4个字节。校验和是从编码的数据的哈希值中得到的，所以可以用来检测并避免转录和输入中产生的错误。使用Base58check编码时，解码软件会计算数据的校验和并和编码中自带的校验和进行对比。二者不匹配则表明有错误产生，那么这个Base58Check的数据就是无效的。一个错误比特币地址就不会被钱包软件认为是有效的地址，否则这种错误会造成资金的丢失。 换言之，比特币地址的最后两个8个字符是校验和？ 为了将数据（数字）转换成Base58Check格式，首先我们要对数据添加一个称作“版本字节”的前缀，这个前缀用来识别编码的数据的类 型。例如，比特币地址的前缀是0（十六进制是0x00），而对私钥编码时前缀是128（十六进制是0x80）。 表4-1会列出一些常见版本的前缀。 接下来，我们计算“双哈希”校验和，意味着要对之前的结果（前缀和数据）运行两次SHA256哈希算法： checksum = SHA256(SHA256(prefix+data)) 在产生的长32个字节的哈希值（两次哈希运算）中，我们只取前4个字节。这4个字节就作为检验错误的代码或者校验和。校验码会添加到数据之后。 为什么头四个字节就可以拿来当校验和并说明数据变化？ 所以比特币的 Base58Check 地址，是一个加头（1字节）加尾（四字节）的数据。 注意，这个图的上半部分是增加Check的过程，加头加尾以后还要 Base58 Encoding才行。 Base58Check编码的比特币地址是以1开头的，而Base58Check编码的私钥WIF是以5开头的。下图展示了一些版本前缀和他们对应的Base58格式： 压缩格式公钥渐渐成为了各种不同的比特币客户端的默认格式，它可以大大减少交易所需的字节数，同时也让存储区块链所需的磁盘空间变小。 BIP0038提出了一个通用标准，使用一个口令加密私钥并使用Base58Check对加密的私钥进行编码，这样加密的私钥就可以安全地保存在备份介质里，安全地在钱包间传输，保持密钥在任何可能被暴露情况下的安全性。这个加密标准使用了AES，这个标准由NIST建立，并广泛应用于商业和军事应用的数据加密。 BIP0038加密方案是：输入一个比特币私钥，通常使用WIF编码过，base58chek字符串的前缀“5”。此外BIP0038加密方案需要一个长密码作为口令，通常由多个单词或一段复杂的数字字母字符串组成。BIP0038加密方案的结果是一个由base58check编码过的加密私钥，前缀为6P。如果你看到一个6P开头的的密钥，这就意味着该密钥是被加密过，并需要一个口令来转换（解码）该密钥回到可被用在任何钱包WIF格式的私钥（前缀为5）。许多钱包APP现在能够识别BIP0038加密过的私钥，会要求用户提供口令解码并导入密钥。第三方APP，诸如非常好用基于浏览器的Bit Address ，可以被用来解码BIP00038的密钥。 以3开头的地址，是P2SH(Pay-to-Script Hash)，有时候被错误地称为多重签名或多重签名地址。它指定比特币交易的受益人，为脚本的散列（hash of script），而不是公钥的主人，也就不同于P2PKH（Pay-to-Public-Key-Hash）。 本质上，谁能解锁一个UTXO，谁就拥有了特定比特币的所有权。解锁的脚本，就是满足UTXO要求的过程。传统的UTXO解锁的过程就是提供pubkeyhash和验证signature。但P2Sh的解锁要求是由脚本决定的。 不同于P2PKH交易发送资金到传统1开头的比特币地址，资金被发送到3开头的地址时，需要的不仅仅是一个公钥的哈希值和一个私钥签名作为所有者证明。在创建地址的时候，这些要求会被指定在脚本中，所有对地址的输入都会被这些要求阻隔。 一个P2SH地址从交易脚本中创建，它定义谁能消耗这个交易输出（后面“P2SH（Pay-to-Script-Hash）”一节对此有 详细的介绍）。编码一个P2SH地址涉及使用一个在创建比特币地址用到过的双重哈希函数，并且只能应用在脚本而不是公钥： script hash = RIPEMD160(SHA256(script)) 产生的脚本哈希由Base58Check版本前缀为5的版本、编码后得到开头为3的编码地址。举例如下： 可以看出这就是把一段解锁代码，放进一个脚本里面，再对脚本进行散列，而不是直接对公钥进行散列求地址的方法。 P2SH函数最常见的实现是多重签名地址脚本，但也可能编码其他类型的交易脚本。多重签名地址脚本，顾名思义，底层脚本需要多个签名来证明所有权，此后才能消费资金。设计比特币多重签名特性是需要从总共N个密钥中需要M个签名（也被称为“阈值”），被称为M-N多签名，其 中M是等于或小于N。 靓号（Vanity）地址包含了人类可读信息的有效比特币地址。 第五章 钱包非确定性钱包只是一把私钥，Just a Bunch Of Keys。JBOK。这种钱包难以备份和保存私钥，因为私钥之间没有相互联系。 而确定性钱包，特别是分层确定性钱包，却可以通过一个最初的种子，还原出全部的钱包结构来。分层确定性钱包一个母扩展就可以产生40亿对密钥（一半普通密钥，一半强密钥），还可以借此衍生出更多孙密钥。生成密钥的方法，还是单项离散方程从公共的种子生成衍生私钥。 第六章 交易 比特币交易是比特币系统中最重要的部分。根据比特币系统的设计原理，系统中任何其他的部分都是为了确保比特币交易可以被生成、能在比特币网络中得以传播和通过验证，并最终添加入全球比特币交易总账簿（比特币区块链）。比特币交易的本质是数据结构，这些数据结构中含有比特币交易参与者价值转移的相关信息。比特币区块链是一本全球复式记账总账簿，每个比特币交易都是在比特币区块链上的一个公开记录。 我们在各种比特币应用程序用户界面中看到的大多数高级结构实际上并不存在于比特币系统中。 一个常见的示例交易脚本如下： 这里的vin是一个数组。它的每个对象的对象的含义如下： 由 txid 和 vout 定位一个被引用交易的 vout。vout如果没有被用过，那它就是一个UTXO。整个区块链上拥有一个动态变化的UTXO集，有新的UTXO产生，UTXO集就会变大，有旧的UTXO被用掉，则UTXO集就会变小。 比特币可以再分，UTXO却不可以再分，UTXO 总是作为一个整体被消耗掉的。所以在支付的时候，钱包会优先地自动选择自己能够碰触到的UTXO来拼凑出交易的输入来。如果不用编程的方式的话，用户无法手动选择要使用的UTXO。交易总是输入 UTXO 而产生 UTXO 的，如果输入的 UTXO 含有的价值超出了真正要支付的价值，则必然产生找零的 UTXO（收入比特币地址依然是转出比特币地址的 UTXO）。如果没有找零的UTXO，则输入和输出的差值全部变成矿工费。 交易费即输入总和减输出总和的余量：交易费 = 求和（所有输入） - 求和（所有输出） 换言之，如果所有的输入和所有的输出的差值为0，怎会产生0矿工费用的交易。矿工会自己决定是否要确认0手续费的交易。实际上区块链的矿工收费的标准并不是按传递的价值来计算的，而是按照产生的交易占用的字节大小来计算的。在现代的矿工节点中，低手续费的交易甚至不会被节点传递（relay）到区块链网络的其他部分中。在Bitcoin Core里，有一个可以被修改的参数 minrelaytxfee，决定了矿工将以什么标准传递交易。事实上，越多散碎 UTXO 的交易越复杂，占用的字节数越多，矿工就倾向于收取越贵的费用。 一个 UTXO 实际上就是 vout 的形式，如： 有意思的是，并不是一定要有 vin 才有 vout，coinbase 交易就是只有 vout 才有接下来的 vin 的。vout 是鸡，vin 是蛋。 好了，来谈谈最关键的解锁脚本和锁定脚本吧。 脚本公钥（scriptPubKey） == “锁定脚本”（locking script）== 见证脚本（witness script） == 加密难题（cryptographic puzzle） 解锁脚本（unlocking script） == 脚本签名（ScriptSig） == 见证（witness） 这些术语在不同的抽象层次上都意味着同样的东西。在transaction的字段里面，这些脚本都是script开头的。 这些脚本都是以类似 Forth 的基于堆栈的逆波兰表达式语言书写的。经过深思熟虑的安全考量，这些脚本被特意设计成不可循环或使用复杂控制流的非图灵完备语言，这就意味着有限的复杂性和可预见的执行次数（可见图灵完备的语言天然就无法抗停机问题）。这样就不可能设计出逻辑炸弹，滥用比特币网络的能力进而进行“拒绝服务攻击”。 所有的脚本都会以去中心化的形式在每个节点上执行，所有执行脚本所需要的信息都包含在脚本中。这实际上就是去中心化共识机制的基石了。 解锁一笔 UTXO 交易的过程，大概就是在一个逻辑栈上先执行解锁脚本，再执行锁定脚本的过程。 栈是先进后出的，所以会先把交易签名和公钥入栈（实际上这就在链上暴露了公钥，所以公钥一定不是秘密）。 然后执行OP_DUP，在栈顶复制一份公钥。然后执行OP_HASH160，进行双层散列，即RIPEMD160(SHA256(K))操作，但没有做加头加尾的BASE58CHECK操作，也就是说离比特币收款地址还有一步之遥。 把这个加密谜题最关键的部分，PubKHash 放入栈上作为第二个操作数。 执行 OP_EQUALVERIFY 操作，如果结果为TRUE，移除两个用来比较的操作数。 此时栈上还是原封不动的sig和 PubK，然后用 OP_CHECKSIG，进行ECDSA的验证签名，把结果的 TRUE 或者 FALSE 留在栈顶，作为验证的最终结果。 这个加密谜题的本质，就是把一个完整的栈上可递归的等式的左半部分撕掉，只留下右半部分作为谜题。而右半部分里的PubKHash还可以拿来 BASE58CHECK 编码一下，作为比特币钱包地址的凭据。 上面描述的解锁过程，是一个典型的 P2PKH（Pay-to-Public-Key-Hash）过程。当然我们还可以在上面再进行更复杂的演化，通过制造更强的P2SH等机制，来支持脚本的可变化锁定脚本，因此产生了可变化的解锁脚本。 不包含P2PKH的交易也可以被确认。 每天都有数百个不包含P2PKH输出的交易在块上被确认。 blockchain浏览器经常向他们发出红色警告信息，表示无法解码地址。以下链接包含未完全解码的最新的“奇怪交易”：https：//blockchain.info/strange-transactions。 这里的sig，是私钥加交易的具体信息的签名。大致是sig(transaction, private key)的结果。数字签名是用于证明数字消息或文档的真实性的数学方案。 有效的数字签名给了一个容易接受的理由去相信：1）该消息是由已知的发送者（身份认证性）创建的； 2）发送方不能否认已发送消息（不可否认性；3）消息在传输中未被更改（完整性）。 区块链钱包或者浏览器维护一个 UTXO 大集合。虽然区块链底层的数据结构是链式的，但并不代表查询每个账户地址的余额的时候，它们会每次都扫描数百万个交易，数万个区块。它们会不断监听区块链网络里的一切，并且保证自己在正确的链上，然后用锁定脚本里的散列值生成特定的地址，以特定的地址不断增量式地扫描自己的存量数据和新数据，挑选出符合要求的交易，放在优化过的，供查询用的数据结构里，生成真正的account balance。换言之，真正的存档数据都是放在链上的，而客户端节点可以通过流式计算的方法，把UTXO的链式读写模型，重构转化为类似account balance的可查询数据结构。例如： 比特币钱包通过扫描区块链并聚集所有属于该用户的UTXO来计算该用户的余额 。大多数钱包维护一个数据库或使用数据库服务来存储所有UTXO的快速参考集，这些UTXO由用户所有的密钥来控制花费行为。 我们总是从更高级的数据结构里面读取真实数据。 第七章 高级交易和脚本特殊的高级交易涉及的脚本是复杂脚本，这涉及到多重签名脚本、P2SH等技术。 多重签名脚本通常会先列出N把密钥，然后再左边列出一个数字M，这样只要收集够M个密钥的签名，就可以执行解锁操作。 P2SH在2012年为简化复杂交易脚本而引入，而作为一种交易类型被引入（P2PKH是基本交易类型）。多重签名脚本太复杂，以至于使用过程太复杂，也更浪费全节点的RAM。P2SH才是complex script的解决之道。 在P2SH 支付中，复杂的锁定脚本被电子指纹所取代，电子指纹是指密码学中的哈希值。P2SH的含义是，向与该哈希匹配的脚本支付（用脚本而不是用公钥来解开加密谜题），当输出被支付时，该脚本将在后续呈现。 数字指纹的对比可以用如下表格来呈现： 没有P2SH的复杂脚本|脚本名|脚本形式||:–:|:–:||Locking Script|2 PubKey1 PubKey2 PubKey3 PubKey4 PubKey5 5 CHECKMULTISIG||Unlocking Script|Sig1 Sig2| 有P2SH的复杂脚本 脚本名 脚本形式 Redeem Script 2 PubKey1 PubKey2 PubKey3 PubKey4 PubKey5 5 CHECKMULTISIG Locking Script HASH160 &lt;20-byte hash of redeem script&gt; EQUAL Unlocking Script Sig1 Sig2 赎回脚本即锁定脚本的原始形式。 可以看出，赎回脚本以指纹的形式被存为锁定脚本。解锁脚本还是完整的解锁脚本，但解锁的过程是把一部分拆出来对照锁定脚本。这也意味着，P2SH只简化了锁定脚本。P2SH的这个形式，还使得 UTXO 的生成者，也就是Transaction 的Sender少生成一些数据（vout占的字节更少），也就少进行一些复杂计算，也少花一些矿工费（还记得矿工费本质上是和交易占用的字节有关吗？）。而 UTXO 的接收者（receipt）就需要填上原长度的解锁脚本了，主要的矿工费用由他们负担。 P2SH的另一重要特征是它能将脚本哈希编译为一个地址（其定义请见BIP0013 /BIP-13）。P2SH地址是基于Base58编码的一 个含有20个字节哈希的脚本，就像比特币地址是基于Base58编码的一个含有20个字节的公钥。由于P2SH地址采用5作为前缀，这导致基于Base58编码的地址以“3”开头。 P2SH的优点： 在交易输出中，复杂脚本由简短电子指纹取代，使得交易代码变短。 脚本能被编译为地址，支付指令的发出者和支付者的比特币钱包不需要复杂工序就可以执行P2SH。 P2SH将构建脚本的重担转移至接收方，而非发送方。 P2SH将长脚本数据存储的负担从输出方（存储于UTXO集，影响内存）转移至输入方（存储在区块链里面）。 P2SH将长脚本数据存储的重担从当前（支付时）转移至未来（花费时）。 P2SH将长脚本的交易费成本从发送方转移至接收方，接收方在使用该笔资金时必须含有赎回脚本。 其实从这里也可以看出来，没有用过的UTXO都是存在内存里的，用过的UTXO就变成 transaction 的隐含引用被放在区块链里了。 P2SH脚本不能递归。 请记住不能将P2SH植入P2SH赎回脚本，因为P2SH不能自循环。虽然在技术上可以将RETURN包含在赎回脚本中，但由于规则中没有策略阻止您执行此操作，因此在验证期间执行RETURN将导致交易被标记为无效，因此这是不实际的。 P2SH脚本的赎回脚本是在使用 UTXO 的时候才第一次出现在网络中的，这也就意味着，有可能Hash填错了，就永远没有正确的赎回脚本能花掉那个 UTXO。 比特币有可能被滥用： 比特币的去中心特点和时间戳账本机制，即区块链技术，其潜在运用将大大超越支付领域。许多开发者试图充分发挥交易脚本语言的安全性和可恢复性优势，将其运用于电子公证服务、证券认证和智能合约等领域。很多早期的开发者利用比特币这种能将交易数据放到区块链上的技术进行了很多尝试 ，例如，为文件记录电子指纹，则任何人都可以通过该机制在特定的日期建立关于文档存在性的证明。 运用比特币的区块链技术存储与比特币支付不相关数据的做法是一个有争议的话题。许多开发者认为其有滥用的嫌疑，因而试图予以阻止。另一些开发者则将之视为区块链技术强大功能的有力证明，从而试图给予大力支持。那些反对非支付相关应用的开发者认为这样做将引致“区块链膨胀”，因为所有的区块链节点都将以消耗磁盘存储空间为成本，负担存储此类 数据的任务。 更为严重的是，此类交易仅将比特币地址当作自由组合的20个字节而使用，进而会产生不能用于交易的UTXO。因为比特币地址只是被当作数据使用，并不与私钥相匹配，所以会导致UTXO不能被用于交易，因而是一种伪支付行为。因此，这些交易永远不会被花费，所以永远不会从UTXO集中删除，并导致UTXO数据库的大小永远增加或“膨胀”。 在0.9版的比特币核心客户端上，通过采用Return操作符最终实现了妥协。Return允许开发者在交易输出上增加80字节的非交易数据。然后，与伪交易型的UTXO不同，Return创造了一种明确的可复查的非交易型输出，此类数据无需存储于UTXO集。Return输出被记录在区块链上，它们会消耗磁盘空间，也会导致区块链规模的增加，但 它们不存储在UTXO集中，因此也不会使得UTXO内存膨胀，更不会以消耗代价高昂的内存为代价使全节点都不堪重负。 比特币需要时间锁。时间锁保证了一笔资金在一定时间过后才能被使用。 比特币从一开始就有一个（有缺陷的）交易级时间锁定功能，由nLocktime实现（这同时也是比特币核心代码里的字段名）。 在大多数交易中将其设置为零，以指示即时传播和执行。如果nLocktime不为零，低于5亿，则将其解释为块高度，这意味着交易无效，并且在指定的块高度之前未被中继或包含在块链中。 如果超过5亿，它被解释为Unix纪元时间戳（自Jan-1-1970之后的秒数），并且交易在指定时间之前无效。指定未来块或时间的nLocktime的交易必须由始发系统持有，并且只有在有效后才被发送到比特币网络。 nLocktime 锁定的是 transaction 生效的时间，也就意味着在那个时间段后transaction才生效，transaction里的 vout 才能被使用。这也就意味着这个 transaction 的发起者可以直接发起双花攻击。 2015年12月，引入了一种新形式的时间锁进行比特币软分叉升级。根据BIP-65中的规范，脚本语言添加了一个名为CHECKLOCKTIMEVERIFY（CLTV）的新脚本操作符。 CLTV是每个输出的时间锁定，而不是每个交易的时间锁定，与nLocktime的情况一样。这允许在应用时间锁的方式上具有更大的灵活性（实际上就是更细粒度的锁定）。 CLTV不会取代nLocktime，而是限制特定的UTXO，并通过将nLocktim设置为更大或相等的值，从而达到在未来才能花费这笔钱的目的（这样说来，到底CLTV会不会把 vout 锁定的同时锁定 vin 呢？）。 一个没有加过时间锁定的锁定脚本（赎回脚本）如下： 而加上时间锁定以后，它就变成这样： nLocktime和CLTV都是绝对时间锁定，它们指定绝对时间点。nSequence 是一种相对时间戳，脚本级相对时间锁定使用CHECKSEQUENCEVERIFY（CSV）操作码实现（具体内容见原文）。 比特币脚本可以实现条件控制语句，实现复杂脚本。但这种复杂脚本是不是图灵完备的，要看操作码的表达能力的范畴了。 隔离见证是对公示规则的升级。在2017年8月1日，由一个 BIP-9 的软分叉在主网上激活。在密码学里，见证就是一个密码学谜题的解。而在比特币中，见证就是对UTXO的密码学条件（cryptographic condition）的满足。一个签名是一种见证，但见证并不仅限于签名，可能有更宽泛的形式。 我们常见的解锁脚本里，签名数据作为至关重要的见证本来是嵌入在vin里面的。隔离见证的简单形式就是把见证从解锁脚本里移出来，放到一个transaction伴侣见证数据结构里。 我们需要隔离见证的原因： 见证数据不再是交易id（也就是散列值的一部分），因为见证数据本身已经不在交易里了。在这之前，见证数据是唯一一个可以被第三方修改的值，因为第三方可以修改签名的值，在不影响交易至关重要属性（输入、输出、数额）的前提下，修改交易的id（可见这个散列算法要求的输入是交易的全部），从而欺骗一些不良实现的认为交易不可更改的钱包，产生拒绝服务攻击。这使得一些依赖于高级交易创建的特性得以实现，特别是闪电网络。 脚本版本化。从隔离见证以后locking script就有了版本，可以在以后通过软升级引入新的操作码。 节省硬盘（扩容本身只是第三个好处）。把见证数据移出transaction，间接地扩大了区块的容量。而且全节点可以在验证交易正确完成以后，删除见证数据，见证数据也不必在所有全节点之间传输和存储。 签名验证优化。之前的计算复杂度可以达到二次方，现在的时间复杂度可以达到线性复杂度。 离线签名改进。 隔离见证不是关于改进如何构造事务的，而是关于如何构造输出的。事务并不分为隔离见证事务和非隔离见证事务，但输出可以分为隔离见证输出和非隔离见证输出。以往的UTXO要求解锁脚本把见证数据内联到input里，但隔离见证可以让见证数据放在input之外。 软分叉总是向后兼容的。对于老客户端，隔离见证的输出就像anyone can spend的output，即一个空的signature也可以解开这个crypto puzzles。 所谓的向后兼容，是一个很有意思的概念，指的是新节点升级以后的语法，依然被老节点所接受，老节点天然支持新节点的语法，老节点在设计之初，就已经给出了新语法的足够的设计空间，即使老节点自己不用新语法，也不妨碍新语法的使用。具体的例子是，含有这种 anyone can spend的 output 的交易是非标准交易，新节点是不验证、不转发也不打包的，但一旦被新节点打包进了区块中，老节点在验证无误的时候，可以接受。 这种anyone can spend的output，如果被老节点试图使用，会通不过新节点的验证，这时候就会变成写两条链。新节点发出的区块，则可以被老节点验证通过。这样如果新节点的算力最终超过了老节点的算力，新链会压倒老链。 我们把一个P2PKH的锁定脚本： 转化成 这个脚本被推入栈顶以后，自然是连签名都不需要就可以解锁的（栈顶的这串数字天然等于true？）。而对于新的客户端，0是隔离见证的版本，而这串数字则是PKH。对于解锁脚本，scriptSig就成为了空字符串（反正对旧客户端，empty signature也可以解锁），而 transaction 外还专门有一个witness的字段，放置scriptSig的内容。这类脚本叫做Pay-to-Witness-Public-Key-Hash (P2WPKH)。 它被spend的时候，本来应该是这样： 因为引入了隔离见证，变成了这样： P2WPKH应该由reciept来生成，不应该由sender从一个已知的公钥生成（岂不是要求频繁换公钥？），而且应该由压缩（compressed）公钥来生成，未来的升级里面，P2WPKH的script可能导致这个output不可花费。P2WPKH应该由reciept的钱包由私钥衍生的压缩公钥诞生。 同理，P2SH的output经过隔离见证的升级以后，产生的输出（锁定脚本）P2WSH会是这样的： 它被使用起来则是这样的，注意看transaction外多出来的witness区域： 而使用P2SH的payment原本应该是这样的： P2WPKH的散列值长度是20字节，而P2WSH的散列值长度则是32字节。他们都是一个版本号加上一个本来的H而略去了所有多余的操作码。 隔离见证的升级，因为以上所述的细节，分为两步，首先钱包要产生隔离见证的输出，然后使用隔离见证的钱包，要被构造进支持隔离见证的交易里。 因为新旧协议的升级有间隙的问题，所以隔离见证的钱包，也可以用隔离见证的交易花费非隔离见证的output，这样可以减轻交易费用。 再谈隔离见证的好处。 引入隔离见证后，scriptSig的部分变空了。也就没有第三方篡改签名，进而影响txid的可能，可以认为txid是不可变的了。也就消除了交易延展性问题。而见证的部分也产生了一个wtxid。wtxid就是transaction + 见证数据后的散列id。由此可以推出两个结论，首先，如果见证数据为空，则wtxid等于txid，其次，wtxid可以被认为是可延展的。 隔离见证可以降低全网的交易费用。 第八章 比特币网络P2P网络要求网络中的节点彼此对等，不存在专门的Client，Server节点，依靠扁平的拓扑结构通信（IP网络就是这样一个结构）。 除了比特币P2P协议之外，比特币网络中也包含其他协议。例如Stratum协议就被应用于挖矿、以及轻量级或移动端比特币钱包之中。网关（gateway）路由服务器提供这些协 议，使用比特币P2P协议接入比特币网络，并把网络拓展到运行其他协议的各个节点。例如，Stratum服务器通过 Stratum协议将所有的Stratum挖矿节点连接至比特币主网络、并将Stratum协议桥接（bridge）至比特币P2P协议之 上。 尽管节点之间的地位完全平等，但角色又有不同。各种节点的结构大致上是： 一些节点保有一份完整的、最新的区块链拷贝，这样的节点被称为“全节点”。全节点能够独立自主地校验所有交易，而不需借由任何外部参照。另外还有一些节点只保留了区块链的一部分，它们通过一种名为“简易支付验证（SPV）”的方 式来完成交易验证。这样的节点被称为“SPV节点”，又叫“轻量级节点”。 挖矿节点通过运行在特殊硬件设备上的工作量证明（proof-of-work）算法，以相互竞争的方式创建新的区块。一些挖矿 节点同时也是全节点，保有区块链的完整拷贝；还有一些参与矿池挖矿的节点是轻量级节点，它们必须依赖矿池服务器维护的全节点进行工作。 换言之轻量级挖矿节点总是矿池全节点的附庸。 越来越多的用户钱包都是SPV节点， 尤其是运行于诸如智能手机等资源受限设备上的比特币钱包应用；而这正变得越来越普遍。 比特币传播网络是一种尝试最小化矿工之间传输块的延迟的网络。原始的比特币传播网络是由核心开发商Matt Corallo于2015年创建的，以便能够以非常低的延迟在矿工之间快速同步块。该网络由世界各地的亚马逊Web服务基础架构上托管的几个专门的节点组成，并且连接大多数矿工和采矿池。 新节点总是要找到第一个比特币对等节点，然后连入比特币网络中。 新节点如何找到对等体？ 第一种方法是使用多个“DNS种子”来查询DNS，这些DNS服务器提供比特币节点的IP地址列表。 其中一些DNS种子提供了稳定的比特币侦听节点的静态IP地址列表。 一些DNS种子是BIND（Berkeley Internet Name Daemon）的自定义实现，它从搜索器或长时间运行的比特币节点收集的比特币节点地址列表中返回一个随机子集。 Bitcoin Core客户端包含五种不同DNS种子的名称。 不同DNS种子的所有权和多样性的多样性为初始引导过程提供了高水平的可靠性。 在Bitcoin Core客户端中，使用DNS种子的选项由选项switch -dnsseed控制（默认设置为1，以使用DNS种子）。 或者，不知道网络的引导节点必须被给予至少一个比特币节点的IP地址，之后可以通过进一步介绍来建立连接。 命令行参数-seednode可用于连接到一个节点，仅用于将其用作种子。 在使用初始种子节点形成介绍后，客户端将断开连接并使用新发现的对等体。 节点必须连接到若干不同的对等节点才能在比特币网络中建立通向比特币网络的种类各异的路径（path）。由于节点可以随时加入和离开，通讯路径是不可靠的。因此，节点必须持续进行两项工作：在失去已有连接时发现新节点，并在其他节点启动时为其提供帮助。节点启动时只需要一个连接，因为第一个节点可以将它引荐给它的对等节点，而这些节点又会进一步提供引荐。一个节点，如果连接到大量的其他对等节点，这既没必要，也是对网络资源的浪费。在启动完成 后，节点会记住它最近成功连接的对等节点；因此，当重新启动后它可以迅速与先前的对等节点网络重新建立连接。如果先前的网络的对等节点对连接请求无应答，该节点可以使用种子节点进行重启动。 并非所有的节点都有能力储存完整的区块链。许多比特币客户端被设计成运行在空间和功率受限的设备上，如智能电话、平板电脑、嵌入式系统等。对于这样的设备，通过简化的支付验证（SPV）的方式可以使它们在不必存储完整区块链的情况下进行工作。这种类型的客端被称为SPV客户端或轻量级客户端。随着比特币的使用热潮，SPV节点逐渐变成比特币节点（尤其是比特币钱包）所采用的最常见的形式。 SPV节点只需下载区块头，而不用下载包含在每个区块中的交易信息。由此产生的不含交易信息的区块链，大小只有完整区块链的1/1000。SPV节点不能构建所有可用于消费的UTXO的全貌，这是由于它们并不知道网络上所有交易的完整信息。SPV节点验证交易时所使用的方法略有不同，这个方法需依赖对等节点“按需”提供区块链相关部分的局部视图。 打个比方来说，每个全节点就像是一个在陌生城市里的游客，他带着一张包含每条街道、每个地址的详细地图。相比之 下，SPV节点就像是这名陌生城市里的游客只知道一条主干道的名字，通过随机询问该城市的陌生人来获取分段道路指示。虽然两种游客都可以通过实地考察来验证一条街是否存在，但没有地图的游客不知道每个小巷中有哪些街道，也不知道附近还有什么其他街道。没有地图的游客在“教堂街23号”的前面，并不知道这个城市里是否还有其他若干条“教堂街 23号”，也不知道面前的这个是否是要找的那个。对他来说，最好的方式就是向足够多的人问路，并且希望其中一部分人不是要试图抢劫他。 简易支付验证是通过参考交易在区块链中的深度，而不是高度，来验证它们。一个拥有完整区块链的节点会构造一条验证链，这条链是由沿着区块链按时间倒序一直追溯到创世区块的数千区块及交易组成。而一个SPV节点会验证所有区块的链（但不是所有的交易），并且把区块链和有关交易链接起来。 例如，一个全节点要检查第300,000号区块中的某个交易，它会把从该区块开始一直回溯到创世区块的300,000个区块全部都链接起来，并建立一个完整的UTXO数据库，通过确认该UTXO是否还未被支付来证实交易的有效性。SPV节点则不能验证UTXO是否还未被支付。相反地，SPV节点会在该交易信息和它所在区块之间用merkle路径（见“ Merkle 树”章节）建立一条链接。然后SPV节点一直等待，直到序号从300,001到300,006的六个区块堆叠在该交易所在的区块之上，并通过确立交易的深度是在第300,006区块~第300,001区块之下来验证交易的有效性。事实上，如果网络中的其他节点都接受了第300,000区块，并通过足够的工作在该块之上又生成了六个区块，根据代理网关协议，就可以证明该交易不是双重支付。 这一段其实没有讲清楚，按照How does an SPV wallet use the headers that it downloads?的观点，SPV节点会询问完整节点，一个特定的transaction在哪里，全节点会给出全部区块头（以显示区块之间的确认性），以及特定的 Merkle 相关路径，以证明，某一个transaction属于某一个区块头，所有的区块头属于canonical chain。 比特币网络中几乎每个节点都会维护一份未确认交易的临时列表，被称为内存池或交易池。节点们利用这个池来追踪记录那些被网络所知晓、但还未被区块链所包含的交易。例如，保存用户钱包的节点会利用这个交易池来记录那些网络已经接收但还未被确认的、属于该用户钱包的预支付信息。 随着交易被接收和验证，它们被添加到交易池并通知到相邻节点处，从而传播到网络中。 有些节点的实现还维护一个单独的孤立交易池。如果一个交易的输入与某未知的交易有关，如与缺失的父交易相关，该 孤立交易就会被暂时储存在孤立交易池中直到父交易的信息到达。 第九章 区块链比特币核心使用谷歌的LevelDB来存储区块（C++版本，Fabric使用Go版本）。 区块链可以被视作一个垂直的栈。 每个区块的散列值，是对区块头二次散列的结果。 一个区块只有一个父区块，但可以暂时拥有多个子区块，即分叉。分叉的出现，是因为多个子区块（近乎）同时被发现。 因为区块链有巨大的前后相关性，只要稍微修改一个中段区块，它的nonce以及后代的nonce都要重算，所以从中段修改一个区块要引起一个巨大的计算量问题（瀑布xiaoyin），几乎不可能做到。 你可以把区块链想象成地质构造中的地质层或者是冰川岩芯样品。表层可能会随着季节而变化，甚至在沉积之前就被风吹走了。但是越往深处，地质层就变得越稳定。到了几百英尺深的地方，你看到的将是保存了数百万年但依然保持历史原状的岩层。在区块链里，最近的几个区块可能会由于区块链分叉所引发的重新计算而被修改。最新的六个区块就像几英寸深的表土层。但是，超过这六块后，区块在区块链中的位置越深，被改变的可能性就越小。在100个区块以后，区块链已经足够稳定，这时Coinbase交易（包含新挖出的比特币的交易）可以被支付。几千个区块（一个月）后的区块链将变成确定的历史，永远不会改变。 区块的数据结构包括：区块大小（4字节）、区块头（80字节）、交易计数器（1-9字节）、交易（不定字节）。 而区块头则包括：版本（4字节）、前区块散列（32字节）、默克尔树根（32字节）、时间戳（4字节）、难度目标（4字节）、随机数nonce（4字节）。 有意思的是，区块的散列值并不是区块数据结构的一部分，传输时不携带它，存储在区块链里也没塔，而是被节点临时计算出来的（on-the-fly）。可以被存储在外部独立数据库里面，从而被更快地查找和检索。 也可以用高度来唯一确认一个区块，但有时候一个高度对应的是并不只是一个区块。区块高度也不是区块数据结构的一部分，也可以用单独的数据库来存储。在以太坊中，一个客户端只能获取最近256个区块的细节。 创世区块被编码进链的节点里，而不是通过传输同步过去的。 一个区块被解码出来往往是： 现实中的区块链的结构往往是： 区块中的交易总是以默克尔树的形式被表示出来的。在计算机科学中，树往往是带有分支的数据结构。默克尔树的叶子节点也并不存有transaction本身，而是transaction的双重SHA-256散列值。像这样： 因为Merkle树是二叉树，所以它需要偶数个叶子节点。如果仅有奇数个交易需要归纳，那最后的交易就会被复制一份以构成偶数个叶子节点，这种偶数个叶子节点的树也被称为平衡树。 当区块大小由16笔交易（4KB）急剧增加至65,535笔交易（16MB）时，为证明交易存在的Merkle路径长度增长极其缓慢，仅仅从128字节到512字节。有了Merkle树，一个节点能够仅下载区块头（80字节/区块），然后通过从一个满节点回溯一条小的Merkle路径就能认证一笔交易的存在，而不需要存储或者传输大量区块链中大多数内容，这些内容可能有几个G的大小。这种不需要维护一条完整的区块链的节点，又被称作简单支付验证（SPV）节点，它不需要下载整个区块而通过Merkle路径去验证交易的存在。即使只是几条默克尔树的路径，也是难以通过伪造的方式来提供的，所以SPV是可信的。 例如，一个SPV节点想知道它钱包中某个比特币地址即将到达的支付。该节点会在节点间的通信链接上建立起bloom过滤器，限制只接受含有目标比特币地址的交易。当对等体探测到某交易符合bloom过滤器，它将以Merkleblock消息的形式发送该区块。Merkleblock消息包含区块头和一条连接目标交易与Merkle根的Merkle路径。SPV节点能够使用该路径找到与该交易相关的区块，进而验证对应区块中该交易的有无。SPV节点同时也使用区块头去关联区块和区块链中的其余区块。这两种关联，交易与区块、区块和区块链，就可以证明交易存在于区块链。简而言之，SPV节点会收到少于1KB的有关区块头和Merkle路径的数据，其数据量比一个完整的区块（目前大约有1MB）少了一千多倍。 当前的测试网络（testnet）本身已经是第三次重启了。这个网络本身设计出来只是作为一个低价值的网络，但经常被人提高难度，所以需要从创世区块开始重新构造和挖掘。 第十章 挖矿和共识比特币本质上是M0的cash，而不是M2的money。 挖矿虽然创造了新货币，但挖矿最主要的目的是实现了去中心化的。 比特币一共20,999,999,980个，将在2140年发行完毕。随着时间的发展，挖矿的奖励将越来越少，而矿工将逐渐转变为依赖交易费。 总创造的比特币的曲线： 通货膨胀导致货币缓慢但不可避免的贬值，这是一种隐性税收的形式，惩罚在银行存钱的人从而实现解救债务人（包括政府这个最大的债务人）。 政府控制下的货币容易遭受债务发行的道德风险，之后可能会以牺牲储蓄者为代价，通过贬值来抹去债务。 每一个新区块的到达，既是旧的竞赛的结束，也是新的竞赛的开始的发令枪。每一个矿工总是先从自己的交易池里制造出候选区块，然再开始寻找nonce作为自己的工作量证明的证据的。 一个合法区块的第一个交易（且只有第一个）是coinbase交易。 ​任何时候，主链都是累计了最多难度的区块链。主链也会有一些分支，这些分支中的区块与主链上的区块互为“兄弟”区块。这些区 块是有效的，但不是主链的一部分。保留这些分支的目的是如果在未来的某个时刻它们中的一个延长了并在难度值上超 过了主链，那么后续的区块就会引用它们。 。比特币将区块间隔设计为10分钟，是在更快速的交易确认和更低的分叉概率间作出的妥协。更短的区块产生间隔会让交易清算更快地完成，也会导致更加频繁地区块链分叉。与之相对地，更长的间隔会减少分叉数量，却会导致更长的清算时间。 原本设计的nonce值不够大，只有4字节。有时候穷举了这4字节的空间，还是不能找到合适的nonce，这时候，只能往两个方向扩展：coinbase的脚本以及修改timestamp。8个字节的额外随机数，加上4个字节的“标准”随机数，允许矿工每秒尝试2^96（8后面跟28个零）种可能性而无需修改时间戳。如果未来矿工穿过了以上所有的可能性，他们还可以通过修改时间戳来解决。同样，coinbase脚本中也有更多额外的空间可以为将来随机数的扩展做准备。 比特币的共识机制依赖于这样一个前提，那就是绝大多数的矿工，出于自己利益最大化的考虑，都会通过诚实地挖矿来维持整个比特币系统。然而，当一个或者一群拥有了整个系统中大量算力的矿工出现之后，他们就可以通过攻击比特币的共识机制来达到破坏比特币网络的安全性和可靠性的目的。 想象这么一个场景，一群矿工控制了整个比特币网络51％的算力，他们联合起来打算攻击整个比特币系统。由于这群矿工可以生成绝大多数的块，他们就可以通过故意制造块链分叉来实现“双重支付”或者通过拒绝服务的方式来阻止特定的交易或者攻击特定的钱包地址。 咖啡店老板 Bob 愿意在 Alice 给自己的转账交易确认数为零的时候就向其提供咖啡，这是因为这种小额交易遭遇“51%攻击”的风险和顾客购物的即时性（Alice能立即拿到咖啡）比起来，显得微不足道。这就和大部分的咖啡店对低于25美元 的信用卡消费不会费时费力地向顾客索要签名是一样的，因为和顾客有可能撤销这笔信用卡支付的风险比起来，向用户索要信用卡签名的成本更高。 比特币的分叉，体现在各个层面上，既包括软件的分叉，也包括共识算法客户端的分叉。分叉就是从同一份历史数据中分出不同的发展。分叉的结果如果是能收敛的还好，不能收敛的话，实际上区块链组织就分裂成了几个小组织，算力就分散了。 第十一章 比特币安全比特币的去中心化安全模型很大程度上将权力移交到用户手上，随之而来的是用户们保管好密钥的责任。 传统的安全体系基于一个称为信任根（ROOT OF TRUST）的概念，它指的总体系统或应用程序中一个可信赖的安全核心。安全体系像一圈同心圆一样围绕着信任根源来进行开发，像层层包裹的洋葱一样，信任从内至外依次延伸。每一层都构建于更可信的内层之上，通过访问控制，数字签名，加密和其他安全方式确保可信。随着软件系统变得越来越复杂，它们更可能出现问题，安全更容易受到威胁。其结果是，软件系统变得越复杂，就越难维护安全性。信任根的概念确保绝大多数的信任被置于一个不是过于复杂系统的一部分，因此该系统的这部分也相对坚固，而更复杂的软件则在它之上构建。这样的安全体系随着规模扩大而不断重复出现，首先信任根建立于单个系统的硬件内，然后将该信任根通过操作系统扩展到更高级别的系统服务，最后逐次扩散到圈内多台服务器上。 第十二章 比特币应用支付通道是在比特币区块链之外双方之间交换的比特币交易的无信任机制。这些交易，如果在比特币区块链上结算，则是有效的，然而他们却是在链外被持有的，以期票的形式等待最终批量结算。由于交易尚未结算，因此他们可以在没有通常的结算延迟的情况下进行交换，从而可以满足极高的交易吞吐量，低（亚毫秒）延迟和精细（satoshi级）粒度。 实际上，通道 一词是一个比喻。状态通道是区块链外，由双方之间的交换状态代表的虚拟结构。实际上没有“渠道”，底层数据传输机制并不是渠道。我们使用通道这个术语来表示链外双方之间的关系和共享状态。 为了进一步解释这个概念，想一想TCP流。从高层协议的角度来看，它是一个横跨互联网连接两个应用程序的“socket”。但是，如果您查看网络流量，TCP流只是IP数据包之上的虚拟通道。 TCP流的每个端点通过排序并组装IP数据包以产生字节流的错觉。实际上在背后，所有的数据包都是断开分散的。同理，支付通道只是一系列交易。如果妥善排序和连接，即使您不信任通道的另一方，（经过排序连接后的交易）也可以创建可以信任的可兑换的债务。 闪电网络是第二层路由技术。它可以应用于支持一些基本功能的任何区块链，如多重签名交易，时间锁定和基本的智能合约。 如果闪电网络搭建在在比特币网络之上，则比特币网络可以大大提高容量，隐私性，粒度和速度，而不会牺牲无中介机构的无信任操作原则："},{"title":"重放攻击问题","date":"2018-03-08T11:00:01.000Z","url":"/2018/03/08/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB%E9%97%AE%E9%A2%98/","tags":["区块链","Ethereum","比特币"],"content":"比特币靠不同的地址前缀可以规避重放攻击问题。以太坊可以靠 EIP155 钱包来规避重放攻击问题。 何为重放攻击问题？ 一个区块链有若干个测试网络。如果一套公私钥可以在不同的网络上通用，则可以恶意地把在测试网络中出现的 transaction 播放到主网上。如果在测试网络上有人从账户 A 转了一笔钱到账户 B，而账户 B 是一个傻瓜测试账户，私钥是由类似123456之类的种子生成的话。那么只要账户 A 在主网中的余额大于这笔钱，心怀恶意者就能把主网中 A 的钱财转走，从主网中的账户 B 里把钱取出来。即使心怀恶意者没有 B 的取款方法，也能让账户 A 蒙受资金损失。 所以不要跨网使用相同的公私钥对。"},{"title":"UTXO 与 account balance 模型","date":"2018-03-08T10:23:13.000Z","url":"/2018/03/08/UTXO-%E4%B8%8E-account-balance-%E6%A8%A1%E5%9E%8B/","tags":["区块链","比特币"],"content":"UTXO 简介&emsp;&emsp;UTXO 的全称的 unspent transaction output，就是没有被人用过的可用资金。 &emsp;&emsp;这个模型是比特币首创的，被其他货币所模仿。以太坊天然的模型不是 UTXO 而是 account balance。 &emsp;&emsp;UTXO 必须配平，UTXO 的输入者必须上一个 UTXO 的输出者： &emsp;&emsp;这就把一个一个账户型数据库，转成了链式的交易数据库，交易要靠 merge 整个数据库的相关节点。 &emsp;&emsp;UTXO 的好处是： 更加好的隐私模型 更加强的并发范型（因为不会触发间隙锁了吗？） ZCash 的 UTXO&emsp;&emsp;ZCash 也一样有 UTXO，但它的 UTXO 是加密过的，而且每个矿工那里还有一个专门的 UTXO 作废数据库。具体情况见《不是程序员也能看懂的ZCash零知识证明》。 ##以太坊中的 account 模型## &emsp;&emsp;以太坊没有使用 UTXO 模型，而使用 account balance 模型，他们把 account balance 模型称为 world state。account balance 模型比 UTXO 模型更加容易实现智能合约，且具有以下优点： 节省更多存储空间。 更高的可替代性 - UTXO 模型不适合拿来实现黑名单。 简单：账户模型更好编码也更好理解。 账户模型的缺点是，为了防止重放攻击，必须追踪交易的 nounce。 Hyperledger Fabric 的 world state Fabric 的 world state 本身是由 transaction 叠加得来的，即它既存储了 transaction 记录，也存储了当前的世界状态。但他们并不明确地把他们的 world state 归纳为 UTXO 或者 accound balance 模型。 How do I create assets?A. Users can use chaincode (for business rules) and membership service (for digital tokens) to design assets, as well as the logic that manages them. There are two popular approaches to defining assets in most blockchain solutions: the stateless UTXO model, where account balances are encoded into past transaction records; and the account model, where account balances are kept in state storage space on the ledger. Each approach carries its own benefits and drawbacks. This blockchain technology does not advocate either one over the other. Instead, one of our first requirements was to ensure that both approaches can be easily implemented. Corda 使用 UTXO 模型对 Corda 而言，新的事务，就是把旧的 state 变为历史 state，而借此生成新的 state 的过程。 参考资料： What are the pros and cons of Ethereum balances vs. UTXOs? "},{"title":"重新学习 Solidity","date":"2018-03-08T08:25:00.000Z","url":"/2018/03/08/%E9%87%8D%E6%96%B0%E5%AD%A6%E4%B9%A0-Solidity/","tags":["区块链","Ethereum"],"content":"以下内容还是从 Solidity 文档里摘出来的。 智能合约入门/介绍第一个基本的例子 一个 contract 可以被认为是一个类型。默认的 unint 就是256位的。storedData 可以被认为是 state variable，状态变量。在 Solidity 的概念里面，这个东西可以被认为是数据库里面的一个槽，可以被函数查询和修改。注意看它不是 public 的，所以没有合成方法。 访问状态变量不需要用 this前缀（在什么 scope 下都不需要吗？）。 这个例子没有限制任何其他人调用修改状态变量的方法。 子货币的例子 address 是160位的类型（问：为什么不是2的整数次幂？如何）。可以用来存储合约地址或者属于外部人的钥匙对（所谓的 msg.sender？）。public 关键字会让编译器自动帮忙生成一个访问器函数： 而mapping (address =&gt; uint) public balances创造了一个公共状态变量，用 hash 表的形式来把地址映射到整数，其实就是把户头映射到金钱余额。这一个公共变量被虚拟地初始化了，所以所有合法的key都存在，而它们映射value都是零值（对整数而言，当然应该是0）。因为这个无限大的 map 的存在，所以不可能遍历所有的 key，也不能遍历所有的 value，只能依赖于外部数组来记住有意义的 key。而编译器帮忙生成的函数，则看起来是这个样子的： 也就是说，调用的时候，用类 balances(0x1234567)的方式来获取账户余额？ Event 的定义和我们习惯的就很相似了。但原文中举了一个观察的例子，不知道是在 Web3 api 里面使用，还是在智能合约里面使用： 当然这个例子也提供了对 balances 函数的调用示例。 Coin 函数就是在创建合约的时候只执行一次不能再被执行的。这个构造器其实显式地把创建合约的 msg（而不只是 sender）以及 tx 和 block 这样的默认变量都保存下来了。对于所有函数而言，msg.sender 永远指向当前这个函数的调用地址。 mint 因为设置了卫语句，所以在不是创建者的调用面前会提前返回。而 send 则可以被任何人调用。 这些转账事件当然不可能被链自带的货币系统反映出来。但因为这个合约自己带了事件，所以可以开发针对它的区块链浏览器。 区块链基础事务区块链是全局共享的事务型数据库，以太坊甚至可以被认为是一个序列化隔离级别的数据库。所有加入网络的人都可以从这个数据库里读取条目。如果你想改变数据库里的什么👻东西，你创造的交易必须被所有人接受。事务，也就意味着操作是原子化的，事务里的所有操作要么都被完成，要么都没执行。此外，没有人能够篡改已经被应用数据库里的事务。 只有签过名的事务，才能做相应的修改–用密码学和权限隔离来保证安全性。 区块一个需要克服的主要障碍是，按照比特币的说法，是所谓的“双花攻击”。也就是如果网络中存在相互矛盾的两笔事务怎么办？ 抽象的回答是，你不用担心这个。一个事务的排序总会为你挑选出来，（被选中的）事务会被打包进一个所谓的“区块”里，然后他们会被执行和分发到所有参与节点里面。如果两个合约相互矛盾，那么被排在第二位的合约会被拒绝而不成为区块的一部分。 这些区块行程一个线性序列，区块链这个词就源于此。 作为“顺序挑选机制”（即所谓的“挖矿”）的一部分，区块可能会被回滚，但这种情况只会发生在链的末梢。越多的区块被加到顶部，原来的区块就越不容易被回滚。 以太坊虚拟机概览以太坊虚拟机（EVM）是智能合约的运行时。它不只是一个沙盒，而且被完全隔离了，也就是说EVM 不能访问网络、文件系统和其他进程（Fabric 的智能合约理论上没有这个限制）。智能合约甚至受限访问其他智能合约。 账户以太坊中有两类账户共享同样的地址空间：由公私钥对（即人类）控制的外部账户以及与合约一同存储的代码控制的合约账户。 外部账户的地址是又公钥控制的，而合约的地址则是在合约创建时决定的（由创建者的地址和从哪个地址里发出的事务数（即 nonce）衍生。）。 不考虑账户是不是存储有代码，两种类型被 EVM 平等对待。 每一个账户有持久化的的键值存储叫 storage，映射256位的字到256位的字。 除此之外，每个账户都有一个以太币（以 wei 为单位）余额，可以通过发送含有以太币的事务进行修改。 事务事务是从一个账户发送往另一个账户（另一个账户可以是同一个账户或者特殊的零账户）的消息。它可以包含二进制数据（它的载荷）和以太币。 如果目标账户包含代码，那么代码可以被执行，而载荷则可以被当做输入数据（按，等同于 message call）。 如果目标账户是一个零账户（账户地址是0），事务会产生一个新合约（这也是编程式产生新合约的方法）。创造合约的时候，我们在事务里发送的载荷实际上并不是合约本身，而是能够产生合约的代码。 注意，这个零账户指的是一个 transaction 里面的 to 的零值： 具体思辨内容见此。 Gas一创建完成，每个事务总要收取一定量的 gas，用意是为了限制执行事务所需的工作量，并为执行事务付费。当 EVM 执行事务的时候，gas 根据特定规则被逐渐消耗。 gas 加个是由事务创建者设立的，发出（事务的）账户必须付出gas_price * gas的预付款。如果执行之后还有 gas 剩余，它会被原路退回。 如果 gas 在任何时刻被用尽，一个 out-of-gas 异常会被触发，因此会反转当前调用帧对状态的所有修改。 Storage， Memory 和 Stack每个账户都有一个持久化的内存区域，被称作storage。Storage 是一个键值存储，它把256位的字映射到256位的字。不可能在一个合约内部枚举 storage，而读storage也是相对昂贵的， 修改 storage 更是昂贵。一个合约不能读和写它自己的 storage 中自己拥有的部分之外的东西。 第二个内存区域叫做memory，它让合约为每一个消息调用获得了一个全新清理过的实例。memory 是线性的，可以在字节级别被寻址，但读被限制到256位宽，写得可以写8位到256位宽。memory 被字（256位）展开，当访问（不管是读或者写）一个之前没有接触过的内存字（即，一个字内的任何偏移）。在展开的时候，gas 的花费也必须要之丰富。memory 增长的越大，越昂贵（因为它是平方级扩容的）。 EVM 不是个寄存器机器而是个栈机器，所以所有的计算都在一个叫 stack 的区域上执行。栈有一个1024个元素的最大尺寸，并且包含256位的字。只允许通过这种方式从栈顶访问元素：可以拷贝最顶上的16个元素中的一个或者把最顶上的十六个元素中的一个与其下的元素翻转。按：这也就是 stack 里的局部变量表只允许有16个变量的原因。看起来所有的 EVM 语言，包括但不限于 Solidity，都受这个限制影响。其他操作则只能从栈上取最顶上的两个（或一或更多，取决于具体操作）元素并将结果推上栈。当然可能把栈上的元素移动到 storage 和 memory，但不可能在不移除栈顶元素的前提下，访问栈上更深的任意元素。 指令集EVM 的指令集被保持极小规模，以防错误的实现引发共识问题。所有的指令都操作在基本数据类型，256位的字上。常见的算数、位、逻辑和比较操作符是现成的。条件和非条件跳转是可行的。除此之外，合约能够访问当前区块的相关属性比如数字和时间戳。 消息调用合约可以调用其他合约，或者通过消息调用的方式发送以太币到非合约账户。消息调用类似事务，所以它有源、目标、数据载荷、以太币、gas 和返回值。事实上，所有的事务都包含一个顶级消息调用（按：可以理解为元消息调用），它可以创造更多的消息调用。 一个合约决定有多少它的剩余 gas 需要被伴随内部消息调用发送，有多少它想要保留。如果一个 out-of-gas 异常在内部调用发生了（或者任何其他异常），这件事会以一个被放在栈上的错误值作为信号。在这种情况下，只有伴随着这个调用的 gas 被用尽了（按：其它的 gas 没有被用尽）。在 Solidity 中，在这种情况下，调用方合约引发一个手动异常（按：下面传上来的是错误码，在这里才 raise 异常），所以异常状况就在调用栈上被冒泡上去了。 正如已经提到的，被调用的合约（它可以是调用者本身）会收到一个全新的被清理过的内存实例，并且可以访问调用载荷-它会在一个单独的被称作alldata 的区域里被提供。当它执行完成以后，它可以返回数据，数据会被存贮在调用者的预分配内存里的某一个部分。按：类似传统调用栈的返回值寄存器。调用被限制在一个1024的深度上，这意味着对更复杂的操作，循环应该优于递归。 Delegatecall（委托调用）/Callcode（调用代码） 和 Libraries(库)存在消息调用的一个特殊变种，名为 delegatecall，它和一个消息调用完全一样，除了目标地址的代码是在调用方合约的上下文里执行（按：意即，不是在被调用合约上下文里执行），并且 msg.sender 和 msg.value 没有改变它们的值（按：和调用方合约里的值一样）。 这意味着一个合约可以在运行时动态地从其他地址提取代码。存储、当前地址和余额，依旧指向调用方合约，只有代码是从被调用方合约里拿来的。这意味着在 Solidity 中实现库这一特征是可能的：可复用的库代码可以应用到一个合约的存储里，意即，可以（通过复用库）实现复杂的数据结构。 日志可以在专门索引过的数据结构里存储数据，这把所有的方法都映射到了区块级别（按：即在区块级别来思考怎么解决相关问题）。被称作log（日志）的特征被 Solidity 用来实现 events（事件）。合约不能在日志被创建后访问它们（即 log 被创建后就不能在内部从任何一个地方被读取了）。但它们可以从链外被读取。由于有一部分 log 数据被存储在布隆过滤器里，所以可以通过有效率和加密安全的方法来搜索其中数据，所以网络对等节点（轻客户端）不需要下载完整的区块就可以发行这些日志。 创建合约甚至可以使用特殊的opcode（操作码）创建其他合约（它们并不只是简单地调用零合约地址，这已经是第二种已知的创建合约的方法了）。创建调用和普通消息调用的唯一差别是载荷数据被执行了，而结果被当做代码存储。调用者/创建者在栈上接收到新合约的地址。 自毁代码被从区块链上移出的唯一可能性是当一个合约执行selfdestruct操作的时候。地址中存储的剩余以太币会被发送给一个设定好的目标（账户），接着状态（数据库的存储）中的存储和状态将被移除。 即使一个合约的代码中不包含一个到selfdestruct的调用，它仍然可以通过delegatecall和callcode来执行那个操作。 对于老以太坊节点而言，这个珊瑚并不一定是物理删除，也可以是软删除 当前外部账户（即个人的 account）是不能从 state 中移除掉的。按：即合约账户可以被移除 Solidity举例选举接下来的合约就非常复杂了，它显示了 Solidity 的一大堆优点。它实现了一个投票合约。当然，电子投票的主要问题是如何分配投票权给正确的人群和如何阻止操纵选举。我们不会在这里解决所有的问题，但最起码我们会显式被代理的选举如何完成，并且计票是自动和同时完全透明的。 奥妙就是每一个ballot（投票）一个合约，为每个选项提供一个短名字。然后合约的创建者作为主席会把投票权单独授予每个地址。 地址后面的人可以选择要么自己投票，要么把他们的投票权delegate（委托）一个他们信任的人。 在选举结束的时候，winningProposal()会返回最大投票数的建议。 这个合约可以提升的地方，就是怎样提升事务的效率？ 盲拍卖简单拍卖接下来出现的简单明拍卖合约的大意是每个人都可以在投标期内把投标投出去。投标已经包含了发送金钱/以太币，以把投标者和投标绑定起来。如果最高投标上升了，前一个最高投标者会拿回她的钱。在投标周期的最后，合约要让受益人手动调用来获得它的钱，合约不能激活它自己。 盲拍卖盲拍卖的优点是没有向着拍卖终点的时间压力。 简化一个盲拍卖模型。用户先用头标志的 hash 投标。投标结束后大家揭示出自己的投标值，同时校验 hash 是否相同以及数值是否最高。 为了防止有些人拍完不给钱，这个合约还进一步要求大家把价值和投标一起发送，前者自然是明文的，而后者是加密的。为了不暴露隐私，合约接受一切附带的价值高于当前最高投标价的新投标转账。这也就意味着，在价值揭示环节，有些投标是无效的不成立的。投标者甚至可以用一些错误的高投标或者低投标来迷惑整个竞争。 到目前为止，每个合约只有一个 payable 方法。 安全的远程购买 这足以证明一个合约有好几个 payable 方法，允许多角色博弈了。这个合约没有任何的 internal 函数。 深入SoliditySolidity 源文件的轮廓源文件可以包含任意多的合约定义。 版本 pragma 引入其他源文件语法和语义Solidity 用类似 JavaScript 的引入语法，但不支持“default export”。在全局层次，你可以用以下形式的引入语句： 这个语句把该文件名下所有的全局符号引入到当前的全局作用域中。 这个语句制造了一个新的全局符号，类似名字空间，所有该文件名下的符号，都是这个新的全局符号的成员。它和import &quot;filename&quot; as symbolName;等价。 部分引用和别名机制。 路径.和..的机制同 Unix 系统。 要引用同一个文件夹下的文件，用这样的语法mport &quot;./x&quot; as x;。如果你使用了import &quot;x&quot; as x;，一个全局的“include directory”里的同名文件夹会被引用。 重映射问题太无聊，直接看文档吧。 注释问题注意看下面的文档，展示了如何写注释，也展示了如何写多返回值。 合约的结构合约和面向对象程序设计语言里面的 class 很相似。每个合约可以包含状态变量、函数、函数修饰符、事件、结构类型和枚举类型的声明。 状态变量状态变量会被持久化在合约存储（状态）里： 函数函数是代码的可执行单元。 函数调用可以在内部发生，也可以在外部发生，而且面对不同的其他合约可以拥有不同的可见性。 函数修饰符函数修饰符可以以声明的方式修饰函数的语义（见Function Modifiers部分）。 事件事件就是拿来和 EVM 日志设施打交道的方便接口。 Struct 类型类似 C 语言，是基本类型的封装组合。 枚举类型依然类似 Java。 类型Solidity 是静态类型语言，这意味着不管是状态变量还是局部变量，每个变量的类型必须在运行时被指定好（至少是已知的，见Type Deduction）。Solidity 提供几个至关重要的类型，可以被组合成复合类型。 值类型以下的类型总是被称作值类型，因为这些类型的变量总是会被传值。他们作为函数参数或者赋值使用的时候，总是会被拷贝。 布尔类型bool：可能值为常量 true 或者 false。 逻辑操作符和常见的编程语言操作符类似，也支持短路操作。 整型int/uint：各种尺寸的有符号和无符号整型数。关键字uint8和 unint256以8位为步长，以及int8和int256。相对地，unint和int是uint256和int256的别名（按：即默认数据宽度就是最宽）。 除法总是会造成截断，除非两个操作符都是字面量（？）或者字面量表达式。 x &lt;&lt; y等于x * 2**y，而x &gt;&gt; y等于x / 2**y。用负数作 y 可能会出运行时异常-这是因为不同编程语言的移位有向0和向负无穷移位的区别。 定点数定点数在 Solidity 里还没被完全支持。它们可以被声明，但不能被拿来赋值或者取值。 fixed/ufixed表达的是不同尺寸的有符号和无符号定点数。关键字ufixedMxN和fixedMxN里，M 代表这个类型可以使用的位数，而N代表的是有多少个小数位可被使用。M必须可被8整除，从8增长到256。N必须在0到80之间。相应地，ufixed和fixed是ufixed128x19 和 fixed128x19的别名。 浮点数（IEEE 754）的小数点位置是可变的，而定点数是不可变的。 地址类型地址拥有20字节的数据，它也有成员，而且在0.5.0以前是所有合约的基类。在0.5.0之后，合约类型不再从地址类型里衍生出来，但可以被显式地转化为地址。 地址的成员： balance和transfer 特别地，向合约地址调用 transfer 的时候，每个合约地址的 fallback 函数会被调用。 send 是 transfer 低级对应物。如果执行失败，transfer 抛出异常而 send 返回 false。 call, callcode and delegatecall call 可以使用任意数量任意类型的参数和接口交互。 修改提供的 gas 数量的函数： 类似地，也可以在调用函数的时候转钱： 无关顺序的修饰符使用： delegatecall可以被用来调用某个特定合约上的地址，这个方法的用意就是用来调用其他合约上的库函数。它的早期版本（家园以前）callcode 同理，而且callcode 不能访问msg.sender和msg.value。callcode 将在未来的版本被移除。 尽量应该使用 transfer 而不要使用低级 API，因为它们破坏了 Solidity 的类型安全。 .gas()选项对于三个方法都可用，但.value()选项不被delegatecall所支持。 因为所有的合约都集成了地址的成员，所以在合约里可以这样查余额this.balance。 定长字节数组bytes1，bytes2，bytes3，…，bytes32。 byte 是 bytes1的别名。 这个类型也支持常见的比较、位操作符，它还支持更重要的索引操作符：如果 x 是个bytesI类型，x[k](0 &lt;= k &lt; I)返回第 k个字节。 动态长度字节数组bytes：动态长度字节数组，见Arrays。不是一个值类型（为什么要放这里？）。 string：动态utf-8编码字符串，见Arrays。不是一个值类型（为什么要放这里？）。 如果有任意长度数据的需求，应该优先使用bytes和string，否则尽量使用定长的数据数据类型，bytes1和bytes32比较便宜。 地址字面量能够通过地址测试的十六进制字面量（加上0x长度为42的字符串）如0xdCad3a6d3569DF655070DEd06cb7A1b2Ccd1D3AF是 地址类型。 有理数和整数字面量常见整数字面量：69。十进位小数字面量：1.3。科学计数法：2e10，-2e10，2e-10，2.5e1.。 早期版本的有理数除法会导致截断，当前版本不会，5/2现在等于2.5了。 字符串字面量单引号和双引号都可以包裹字符串字面量，如&quot;foo&quot;和&#39;bar&#39;。他们没有 C 中的尾随0。&quot;foo&quot;代表三个字节而不是四个。他们可以被隐式地转换为各种字节数组（见上文），定长不定长的都可能，当然也可以转化为string。 字符串字面量支持转义符，如\\n，\\xNN和\\uNNNN。\\xNN取一个十六进制的值，并插入一个正确的字节。\\uNNNN取一个 Unicode 码点，并且插入一个UTF-8序数。 十六进制字面量用hex开头，用单双引号括起来：hex&quot;001122FF&quot;。 枚举这里的枚举也是可以显式地与整型数互相转换的。 函数类型同函数式编程里面的一等类型函数差不多。 函数类型被分为两种：内部和外部函数。 内部函数只能在当前合约内被调用（更具体地说，在当前的代码单元内，也就包含了内部函数库和继承下来的函数），因为他们不能在当前合约的上下文之外被执行。调用一个内部函数的实现方式就是让控制流跳到一个条目标签上。 外部函数包括一个地址和一个函数签名，他们可以被传递进/传递出外部函数调用。 函数类型的标记法是： 不允许出现空的 return 语句。 默认函数都是 internal 的，所以 internal 实际上可以被省略（类似 C 语言呢）。 delete一个函数后，再调用它会出现运行时异常。 如果一个外部函数变量被 Solidity 之外的上下文调用（跨语言互操作 interoperability问题），他们将被当做function类型，它在一个bytes24类型里放了一个编码的地址，后面还跟着函数识别符。 public（或外部）函数同样包含一个叫selector的成员，它返回一个 ABI function selector 内部函数的例子： 一个把外部函数类型传递进 struct 的实例，这其实也是个预言机使用的好例子了： 现在还不支持 Lambda 函数和内联函数。 引用类型复合类型，也就是类型不衬进256位的类型，总要被比我们已经看到的值类型更仔细地对待。因为拷贝它们是非常昂贵的，所以我们要仔细考虑它们应该被存储在memory里（不会被持久化）还是被存储在storage（状态变量就放在这里）里。 数据位置每个复合类型，数组和结构体，都有一个额外的注解，即“数据位置”，关于它是被存储在memory里还是在storage里。依据上下文的不同，总有一个缺省值，但它可以被往类型上添加storage和memory覆盖掉。默认的函数参数是memory的，默认的局部变量是storage的（即这两者是可变的），状态变量的位置被强制设为storage。 还有第三种数据位置，calldata，它是不可修改的，不持久化的，函数实参存储在里面。外部函数的函数参数（而不是返回参数）被强制为calldata，行为表现与memory很相似。 数据位置是重要的，因为他们改变了赋值行为:memory和storage之间的赋值、状态变量之间的赋值总是会产生独立拷贝。向局部storage 变量赋值，尽管只是赋予一个引用，这个引用总是指向一个状态变量，即使后者会改变。memory和memory之间的赋值不会产生拷贝。 在实验之中，构造函数生成的总是memory类型的变量，拷贝到 storage 变量就可以让它被持久化了。 总结一下： 强制数据位置：外部函数的参数必须是calldata状态变量必须是storage缺省数据位置：函数参数默认是memory所有局部变量默认是storage 数组数组可以有编译时的固定长度，也可以是动态的。storage数组的元素类型可以是任意的（即可以是数组的数组、mapping 的数组和结构体的数组）。memory数组则不能有mapping元素，如果它是个公共可见函数（外部函数？），它的元素必须是个 ABI 类型。 定长数组写作，T[k]，变长数组写作T[]（也就是说大部分的智能合约的函数参数都是memory动态数组）。 5个unint动态数组的写法与其他语言正好反过来，uint[][15]。访问第三个动态数组的第二个元素，又反而和其它语言一样，x[2][16]。 创建内存数组可以用 new 来创建内存数组。memory数组不可以通过.length 来修改数组尺寸，但storage数组可以。 数组字面量/内联数组 成员length：只有 storage 的动态数组才能动态修改自己的尺寸。push：在数组尾部添加元素，返回新的长度。 数组的一个综合例子： 结构体类型结构体提供了定义新类型的能力。众筹合约的例子： struct 本身可以存储数组和映射，也可以被这两者存储。它不能存储它自身类型的变量，struct 的尺寸必须是有限的。 映射mapping(_KeyType =&gt; _ValueType)里的key类型不能是映射，动态长度数组、合约、枚举和结构体。value 可以是任何类型。 映射可以被认为是个被虚拟初始化的 hash 表，所有可能的键都存在而且值被初始化为0值。实际上 key 数据并不存在映射里面，只有它的keccak256散列值被存在里面，用来查值。 mapping 本身是不可迭代的，但可以看iterable mapping，看看怎么在它之上建立一个可迭代的结构。 牵涉到左值的操作符deletedelete一个变量，差不多可以说是把一个零值赋给它。除了不能 delete 一个映射以外，所有类型的变量都可以被 delete。delete 动态数组会得到一个长度为0的新动态数组，delete 一个静态数组会得到一个长度等于原长度，所有元素都等于该元素类型零值的数组，delete 一个结构体变量，所有的成员除了映射都会变成0值。 基本数据类型之间的转换所有的数据类型都可以转变为uint160，也就可以转变为地址。 显式转换的例子： 类型推导 var 不能用在函数形参和返回值上。var 只在第一次赋值时被推导出来，所以以下循环无法终止： 因为第一次赋值，使得 i 被推导为uint8类型了。 单位和全局可用变量以太币的单位四级单位wei，finney，szabo 或者 ether。2 ether == 2000 finney。 时间单位seconds，minutes，hours，day，weeks和years。小心闰秒（ leap seconds）问题。 巧妙使用单位来对比当前时间的例子： 特殊的变量和函数在全局空间里早已存在一些特殊的变量和函数，用以提供区块链的信息： 区块和事务属性 block.blockhash(uint blockNumber) returns (bytes32)：一个给定区块的散列值 - 只对当前最近的256个区块奏效。 block.coinbase (address)：当前区块挖掘者的地址。 block.difficulty (uint)：当前区块的难度。 block.gaslimit (uint)：当前区块的 gaslimit。 block.number (uint)：当前区块号 block.timestamp (uint)：当前区块的时间戳，从 unix epoch 开始的秒数形式。 msg.data (bytes)：完整的调用数据。 msg.gas (uint)：剩余 gas。 msg.sender (address)：当前调用的消息发送者。 msg.sig (bytes4)：calldata 的最初四个字节（函数标识符）。 msg.value (uint)：消息附带的价值数。 now (uint)：时间戳的别名。 tx.gasprice (uint)：事务的 gasprice。 tx.origin (address)：事务的发送者 (完整调用链)。 msg 的所有成员，可能在每个外部调用中都发生变化。 错误处理assert(bool condition)：如果条件不为真抛出异常。require(bool condition)：抛出异常如果条件不为真，用来做输入检查（通常配合 modifier 使用）。revert()：退出执行，并且反转状态变化。 数学和密码学函数 addmod(uint x, uint y, uint k) returns (uint):compute (x + y) % k where the addition is performed with arbitrary precision and does not wrap around at 2**256. Assert that k != 0 starting from version 0.5.0. mulmod(uint x, uint y, uint k) returns (uint):compute (x * y) % k where the multiplication is performed with arbitrary precision and does not wrap around at 2**256. Assert that k != 0 starting from version 0.5.0. keccak256(…) returns (bytes32):compute the Ethereum-SHA-3 (Keccak-256) hash of the (tightly packed) arguments sha256(…) returns (bytes32):compute the SHA-256 hash of the (tightly packed) arguments sha3(…) returns (bytes32):alias to keccak256 ripemd160(…) returns (bytes20):compute RIPEMD-160 hash of the (tightly packed) arguments ecrecover(bytes32 hash, uint8 v, bytes32 r, bytes32 s) returns (address):recover the address associated with the public key from elliptic curve signature or return zero on error (example usage) 因为“紧密打包”，以下内容是相等的： 表达式和控制结构输入参数和输出参数输入参数声明输入参数和声明变量一样。 输出参数输出参数的定义，很像 Golang： 控制结构除了 switch 和 goto，JavaScript 中所有的控制结构 Solidity 都支持。 多返回值我们已经看到声明的地方有多返回值了，可以像 Golang 一样写多返回值-return (v0, v1, ..., vn)。 Function Calls内部调用 内部调用会被 EVM 翻译成字节码，直接 jump 过去。因为这时候还是在内存内调用，内存内状态没有被清理掉，所以是很高效。 外部函数调用像c.g(2);这类调用，本身是在一个 contract 实例上的调用，本身必然要求 message call 的，就不能 jump 了。 调用其他合约的 payable 方法的例子。 只有被 payable 修饰的方法，才可以被 value option 方法调用。InfoFeed(addr)并不是调用一个构造方法（看来构造方法只有在合约初始化的时候才会被调用），而是向这个地址声称能一个代理对象？ 与任何其他合约交互都有潜在危险，特别是在该合约的源码事先未知的情况下。当前的合约把控制权拱手交给被调用合约，它就可以做任何事。为了让自己的成not vulnerable to exploit，应该让自己的外部函数调用有防御性，尽量让外部函数调用发生在状态改变之后。 命名调用和匿名函数参数一个简单的字面量调用的例子： 省略函数参数名 用new创建新合约可以用new来创建合约。要被创建的合约的完整代码，要事先被知道，所以，也就不可能有递归的创建依赖了： 表达式求值的顺序除了布尔表达式以外，所有表达式的求值顺序都可能是未定的。在表达式树中，只有一个节点的子节点的孩子节点一定会在它之前执行（后缀遍历），其他的全部都没有保证。 赋值解构赋值和多返回值Solidity 内部支持元组类型，即一个元素可能是不同类型，但长度在编译时就已经确定为常数的数组列表。元组才是多返回值的本质（其实在其他语言里还允许对象结构的解构返回）。 数组和结构体的复杂点数组和结构体等非值类型赋值语义稍显复杂。 赋值给一个状态变量总是会产生一个独立拷贝。 从状态变量赋数组和结构体给局部变量是传引用，再赋值还是传引用。 作用域和声明一个变量（包括在函数内）被声明的时候就会拥有字节零值。 函数内的变量里还是没有块级作用域的。 从 0.5.0 开始就有作用域了块作用域有块生命周期。for 相关变量只有 for 块的生命周期。 错误处理：断言、需求、反转和异常所有异常都会反转当前的调用及其子调用的状态变化。 在未来throw会被淘汰掉，应该使用revert。 有些调用方法是靠返回值来确认异常的，注意检查返回值。 目前不支持 catch 语句。 合约Solidity 里的合约，类似面向对象语言里面的类。他们包含持久化状态和修改状态的函数。 跨合约调用不能引用老上下文的状态变量，但依然要小心外部函数调用问题。 创建合约可以用外部事务或者在合约内部创建合约。 可以用web3.js的 API 创建合约，具体参见web3.eth.Contract。 只允许一个构造函数，不允许构造函数重载。也可以没有构造函数。 可见性和 Getter内部调用只产生 JUMP，而外部调用产生 EVM call。 有四种可见性：external，public，internal或者 private。这四个可见性，恰好是两组反义词。 状态变量默认可见性是internal而不可能是external。 函数默认可见性是 public！ external：外部函数是合约接口的一部分。意味着他们应该被从外部调用，必然产生 EVM call。一个external的f是不能f()的，只能this.f()。 public：公共函数也是合约接口的一部分。可以外部调用也可以内部调用。最简单而完美的接口设计。公共变量会自动产生一个 getter 函数。 internal：内部函数和变量只能合约内部访问，不用 this。类似 private。 private：内部函数和变量不能被继承，只能内部访问。 注意，合约的所有内容在区块链上都是公开可见的，这些修饰符只能阻止不当修改。 Gettergetter 是自动生成的，一个调用的例子。 内外访问与内部访问： 一个更复杂的例子： 生成的函数的形式很费解： 函数修饰符函数修饰符是用来改变函数行为的，比如检验条件。函数修饰符可以被集成也可以被覆盖。 状态常量状态变量可以被声明为constant。它们必须被编译时已知常量值的表达式赋值，表达式不能接触 storage (e.g. now，this.balance 或者 block.number)，不能由执行数据决定（msg.value或者gasleft()），或者外部合约调用。允许使用内部计算函数keccak256 ，sha256，ripemd160，ecrecover，addmod和mulmod。 函数view不修改状态的函数可以被声明为view。 以下情况不能用view： 写状态变量 发射事件 创建其他合约 使用自毁 用调用发送以太币（也就是说 call 也不安全） 调用其他非view或者pure方法。 使用低级调用方法。 使用某些特定内联汇编操作码。 getter 都是view。 view 是尽量做到最大限度的编程安全，有时候又不能保证。所以是个未完成品。 pure 函数不读和写 state 的函数叫 pure 函数。view 是不写，pure 更彻底。pure 可能产生副作用，不是函数式编程里的纯函数。 pure 函数首先必须满足 view 函数的要求，然后不能有以下行为： 读状态变量 访问任何 balance。 访问 block，tx 和 msg 的任何成员。 调用非pure的其他函数。 使用某些特定内联汇编操作码。 pure 也是未完成品，编译器不能保证函数的不读不写。 降级函数一个合约只能由一个无名函数。这个函数不能有参数列表，也不能有返回值。合约在被调用，但没有合适的函数匹配得上，或者没有任何调用数据的时候，这个函数就被派上用场了。 这个函数在合约接收到纯以太币（没有数据）的时候，这个函数也会被执行。为了接收以太币，这个函数必须被声明为 payable。没有这个函数，普通转账事务无法往这个合约里转账。 这个函数最少需要 2300个 gas（恰好是普通转账的十分之一）。 即使这个函数没有任何参数，它也可以用msg.data来获取调用载荷。换言之，调用这种函数，应该发送一些没有其他函数可以匹配得上的实参。 早版本的 Solidity 里面降级函数都调用失败的话，是不退币的，现在的版本退币了。 即使没有降级函数，自毁和挖矿的目标依然可以设置为这个合约账户。 函数重载大部分情况下同其他重载一样。 这个函数之所以编译错误，是因为编译后的 ABI 类型都是 address，等于没有重载。 事件事件允许方便地使用 EVM 的日志基础设施。 日志可以被在合约内部被继承。日志与事务、合约关联，与区块同在。 日志的 SPV 证明是可以做到的。 最多三个参数可以被标记为indexed来索引。其实索引的查找，可能是通过散列存储和查找的方式来实现的。本质上就是把这个参数存成 topic 类型的数据，可以被类似流处理的机制监听起来。 事件的正统 watch 用法： 低级日志设施 logn 一共取 n+1个参数。第一个参数放在 data 区，其他参数放在 topic 区。 其他理解事件的资源 Javascript documentation Example usage of events How to access them in js 继承Solidity 支持某种程度上的多继承，它需要拷贝包括多态在内的代码。当一个合约多继承的时候，在链上只创建一份合约，其他 所有的函数调用都是虚调用。 继承系统非常像 Python 的元类继承。 一个菱形继承的讨厌问题： 继承顺序大概是Final，Base2，Base1，mortal，owned。 调用顺序很复杂，需要用的时候还是看教程原文吧。 构造器构造器可以是public也可以是internal。 基类构造器参数 多重继承与线性化Solidity 学习 Python 的C3线性化来解决菱形问题。 抽象合约两种情况下会产生抽象合约： 有函数没有函数体 构造函数是internal的。 对比 接口接口就是完全没有任何函数体的合约。和 cpp 里抽象类到接口的顺序是一致的。 而且还有以下很熟悉的限制： 不能继承其他合约和接口 不能定义构造器 不能定义变量 不能定义结构体 不能定义枚举 接口就是 ABI 的等价形式，两者之间应该可以无损互转。 接口有自己的关键字。 使用接口和继承其他合约一样，也就是都是 is 关键字，没有其他用法。 库库类似于合约。他们的目的是只在特定的地址上部署一次，然后通过DELEGATECALL调用。这意味着，库函数会在当前合约的上下文里被调用，反而不像外部调用(直接调用其他合约地址的实例方法一样)，产生 EVM call。函数里的 this 都会绑定到当前合约，类似 bind。 当然，代理调用是底层实现的，在使用上是看不出来的。库的internal函数，对于调用它的合约也是可见的，这些代码就好像是一个被 mixin 进合约里的基类合约一样。调用内部函数用的是JUMP而不是DELEGATECALL。 在这里，库是一个 util 式的用法。换言之，库里必须都是是view或者pure函数。 库也有限制： 不能有状态变量 不能继承其他也不能被继承 不能接收以太币 Using Forusing A for B; 表明，把一个库的函数添加到一个指定类型上。这导致了这些库函数多了一个（隐式的）消息接受者对象作为第一个参数，这类似 Python 里的 self。 using A for *;表明 A 的库函数被附着给任意类型。这可能也是为什么库不能有自己的 state 的原因吧。 没有用到 self 的一个例子： self 可以不是必须的，也可以有，另一个例子： 对基础类型的猴子补丁： Solidity 汇编Solidity 支持手写汇编模式。 杂项有用的小技巧 使用delete删除所有的数组元素。 调用内部 send 的方法是address(contractVariable).send(amount)。 用字面量的方法初始化结构体（而不是合约）：x = MyStruct(&#123;a: 1, b: 2&#125;);。 安全问题可重入所有的 send 本质上都可以包含代码执行（因为降级函数的存在），所有以下两个合约都是有漏洞的： 被调用方如果在自己的降级函数里面再调用这个合约的提取函数，那么它可以无限提取钱，直到 out-of-gas 异常发生为止。 只有这个先扣款的钱包才能防别人反向递归调用自己。 转以太币相关问题一个地址和账户没有办法抗拒别人向它转账，除非转账失败。不用消息调用也可以移动以太币的方法有两个：挖矿和自毁。 addr.call.value(x)()等价于addr.transfer(x)，但它把剩余的 gas 全都提供给接受者，让它执行更贵的操作了。 一定要记得检查send的返回值。 tx.origin一个类似 CSRF 的相关问题： 一个检查 tx.origin 的钱包 一个攻击者的钱包 只要被攻击者往攻击者钱包转账，攻击者钱包就会发一个新的事务，并借用 tx.origin 来盗取被攻击者的全部余额。每个地址的全部余额都是公开可查的。 通用模式从合约中取钱比谁更有钱的合约： 用 modifier 来设定可访问性的问题 状态机这个例子有两个有意思的地方： modifier 可以叠加 可以由时间自动驱动状态机执行 "},{"title":"语义版本化问题","date":"2018-03-07T11:43:10.000Z","url":"/2018/03/07/%E8%AF%AD%E4%B9%89%E7%89%88%E6%9C%AC%E5%8C%96%E9%97%AE%E9%A2%98/","tags":["软件工程"],"content":"语义化版本 2.0.0《语义化版本 2.0.0》，三段版本号语义： 版本格式：主版本号.次版本号.修订号，版本号递增规则如下： 主版本号：当你做了不兼容的 API 修改， 次版本号：当你做了向下兼容的功能性新增， 修订号：当你做了向下兼容的问题修正。 先行版本号及版本编译信息可以加到“主版本号.次版本号.修订号”的后面，作为延伸。"},{"title":"以太坊为什么会有 gas 系统？","date":"2018-03-01T09:46:47.000Z","url":"/2018/03/01/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%9C%89-gas-%E7%B3%BB%E7%BB%9F%EF%BC%9F/","tags":["Ethereum"],"content":"根据官方文档： GasOne important aspect of the way the EVM works is that every single operation that is executed inside the EVM is actually simultaneously executed by every full node. This is a necessary component of the Ethereum 1.0 consensus model, and has the benefit that any contract on the EVM can call any other contract at almost zero cost, but also has the drawback that computational steps on the EVM are very expensive. Roughly, a good heuristic to use is that you will not be able to do anything on the EVM that you cannot do on a smartphone from 1999. Acceptable uses of the EVM include running business logic (“if this then that”) and verifying signatures and other cryptographic objects; at the upper limit of this are applications that verify parts of other blockchains (eg. a decentralized ether-to-bitcoin exchange); unacceptable uses include using the EVM as a file storage, email or text messaging system, anything to do with graphical interfaces, and applications best suited for cloud computing like genetic algorithms, graph analysis or machine learning. In order to prevent deliberate attacks and abuse, the Ethereum protocol charges a fee per computational step. The fee is market-based, though mandatory in practice; a floating limit on the number of operations that can be contained in a block forces even miners who can afford to include transactions at close to no cost to charge a fee commensurate with the cost of the transaction to the entire network; see the whitepaper section on fees for more details on the economic underpinnings of our fee and block operation limit system."},{"title":"《以太坊到底是如何工作》读书笔记","date":"2018-03-01T09:35:22.000Z","url":"/2018/03/01/%E3%80%8A%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%88%B0%E5%BA%95%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","tags":["Ethereum"],"content":"《以太坊到底是如何工作》 以太坊的简单定义transactional singleton machine with shared-state 事务性状态共享的单例机器 实际上就是逻辑上唯一，但物理上由多个节点维护的共识中的 world computer。这台机器的状态是由事务变迁驱动的： 幽灵协议“GHOST” = “Greedy Heaviest Observed Subtree” 简而言之，就是只在拥有最大计算量的路径上进行计算（这个协议是从比特币那里来的吗？）。 账户与事务外部账户由私钥控制，内部账户由代码控制。 外部账户可以主动发起事务，内部账户只有收到事务以后才能发起内部事务。 账户的状态构成一个账户的状态总是由四个组件构成： nonce:如果这是个外部账户，则这个数字代表了这个账户地址发出的事务数。如果这是个合约账户，则这个数字代表了这个账户创造的合约数量。这两种情况下，nonce 都不是随机数。 balance：这个地址拥有的 Wei 数量。一个以太币有个 1e+18 Wei。 storageRoot：默认为空。Merkle Patricia 树的根。 codeHash：对于内部账户，就是 EVM 代码的散列值（意味着代码存在别出）。对于外部账户，这是空字符串的散列值。 以太坊里的默克尔树以太坊的默克尔帕特里夏树的叶子节点是把地址映射到账户（状态）。 可以看出来状态树的叶子节点就是状态，特别地，状态里还有另一颗默克尔树的根。 同样的多叉 trie 树还用来存储事务和收据（receipts），一共有三种 trie：状态 trie、事务 trie 和收据 trie。 区块头的实际结构可以看到区块头里还是有自己的 nonce： 完整节点与轻节点完整节点要下载整条链（从创世区块到当前头区块），执行里面包含的所有事务，否则无以挖矿。 轻节点如果不用执行每条事务或者查询历史信息，只要下载头链即可。 轻节点使用“Merkle Proof”的证明方式来验证一片数据： 步骤如下： 1 要验证的数据 chunk 和它的散列值。2 默克尔树的根3 branch（从数据 chunk 到根的所有伙伴散列值，所以这幅图里所有深绿色的节点，都要加入验证） 问题是，这样需要单独下载 branch 到底提升了多少性能呢？这种部分知识证明到底解决了什么查找问题？ gas 与支付在每个事务里，发送者设置 gas limit 和 gas price，实际花掉的以太币是这两个值的乘积。这两个值和区块/矿工眼里的 gas limt 和 gas price还不太一样。 假设一个矿工设置了如下的两个参数值： 最终扣减账户内以太币的过程则是： 以太币不够，那么状态会回滚，而且在系统中多了一条事务执行失败记录，被用掉的以太币不会被返还： 事务执行花掉的钱最终要付给“beneficiary”地址，实际上就是矿工地址。 操作要付费，存储也要按照每三十二字节对齐一一付费。 为什么要付费呢？因为这个网络操作很贵，要支付矿工的基本维护费用（同中本聪分析的理性逐利一致），而且付费机制可以防止恶意程序拖垮全网。 事务的内容以太坊是事务性状态机，逻辑上只有一个。 事务是由外部账户生成的密码学签名的指令片，经序列化后提交给区块链。 有两种事务：消息调用和合约创建。 所有事务都包含以下内容： nonce：这个发送方地址名下创建的事务数。gasPrice：sender 愿意付的 gas 价格。gasLimit：发送方愿意支付的 gas 数量上限。to：接收方地址。value：要发给接收方的价值。对于合约事务，传送的价值将被存储为合约的初始余额。v,r,s：用来生成标识这个发送者的签名。init：生成合约的程序。只被运行一次，它的返回值就是合约本身。猜测应该就是 ABI 和二进制代码。data：只为了消息调用而存在的参数值。也就是调用的输入数据。 内部事务和外部事物可以说是如出一辙，是不由外部账户生成，也不会被序列化，只存在于以太坊执行环境里的虚拟对象。内部事务也不含 gasLimit，这就要求最初的外部事务的 gasLimit 必须能够覆盖掉所有的衍生 sub-execution。sub-executions 出现不够 gas 的情况，会 revert 掉它的子 sub-execution，而不会 revert 掉 parent-execution（为什么？）。 Ommers 叔叔区块以太坊的出块时间大约 15 s。 叔叔区块的奖励是为了奖励那些产生叔叔区块的矿工。 区块头信息区块头包含以下信息： parentHash:父区块的头的散列-所以区块散列实际上是区块头的散列。ommersHash：当前区块的ommers 列表的散列。beneficiary：生成这个区块的受益人的收款地址。stateRoot：state trie 的根。transactionRoot：transaction trie 的根。receiptsRoot：receipt trie 的根。logsBloom：用布隆过滤器来有效存 log 的地方（数据大头）。difficulty：当前区块的难度级别number：当前区块的序号。创世区块是0，每个区块加一。gasLimit：当前区块的 gasLimit。gasUsed：这个区块使用掉的 gas 总数。timestamp：这个区块开始奠基（inception）的时间戳。extraData：区块附言。mixHash：与 nonce结合说明计算量的散列值。nonce：与mixHash结合说明计算量的散列值（为什么不是随机值？）。 事务收据区块头里存储的日志信息包含事务收据。每个 transaction 都有一个收据。收据包括： 块号（区块 id1？）块散列值（区块 id2？）事务散列值（事务 id？）当前事务消耗掉的 gas执行完这个事务后，这个区块累计使用的 gas 值。执行事务生成的 log其他（是什么？） 区块难度 Hd 就是难度。所以在这里 n 并不是数学游戏的输入，而是 nonce 的目标？ 事务执行计算初始 gas 的过程见原文。 执行过程的每一步，都会生成 log，也会生成一个逐渐减少的 refund balance。 事务执行后，以太坊得到了唯一的确定性状态。 合约创建先创建一个 nonce 为空，codeHash 为空的 account，然后执行 init，把生成的合约代码和账户关联起来。 消息调用消息调用类似合约创建。 执行模型很复杂，还是看原文 PoW 的原理 还是ETHASH 算法，还是很复杂。但重点是 m 和 n 分别是 mixhash 和 nonce，这俩联合起来才能 match 这个算法。"},{"title":"IOTA","date":"2018-03-01T05:51:14.000Z","url":"/2018/03/01/IOTA/","tags":["区块链","IOTA"],"content":"IOTA 简介IOTA 是下一代（第三代）加密货币，只做货币，不做其他用途的链（？）。专注于解决机器与机器（M2M）之间的交易问题。通过实现机器与机器间无交易费的支付来构建未来机器经济（machine economy）的蓝图，即物联网 + 数字货币的经济生态。物联网天然就有分布式特性，很适合搞区块链。 德国团队创立，由德国政府资助的一个中心化的研究去中心化下一代加密货币的项目。团队成员的上一个作品是第一代 POS 货币未来币（NXT）。 IOTA 的发行量极大，IOTA总供应量为（3 ^ 33-1）/ 2 或2,779,530,283,277,761个。所有IOTA都是在初始块创建的，总数不变，也不用开采。IOTA初上市的时候只募集到五十万美金，所以早期投资者的投资回报极高。有意思的是，因为 IOTA 基金会是非盈利组织，他们甚至没有锁定货币，所以他们持有的百分之五的 IOTA 代币，还是其他投资者捐献给基金会用以维持基金会运行的。 IOTA 的优势是，免手续费且使用平行验证而提高了性能，胜过了手续费高而清算速度缓慢的比特币。但因为它的安全模型弱于比特币，所以没有在普通交易场景下与比特币竞争，只在物联网小额支付领域（nanopayment 买咖啡、交停车费）领域发力。 IOTA 使用 Tangle（缠节）支付。Blockchain 可以被看做一个环环相扣的链表的话，TANGLE则可以看做一个有向无环图（DAG Directed Acyclic Graph）。每发起一笔交易，都要替前面两笔交易做验证，这保证了网络中的所有交易是所有使用交易的人而不是底层矿工相互验证的，这种互助行为消除了手续费。用户在发起交易之前要做工作量证明（PoW），这就避免了大量的垃圾交易阻塞网络。 IOTA 能够抗量子计算机破解。IOTA 使用的签名算法是 Winternitz one-time signature (W-OTS) ，这是一种后量子签名算法，可以抵御量子攻击，在很早就被提出。就如同其名，W-OTS 算法是 one-time，即签过一次名后就不能重复使用，否则会有丢钱的风险。你可以一个地址多次打钱打钱，但取一次钱（取钱需要签名）后就不能用了，得换新地址。W-OTS 的一个缺点是签名长度特别大，这也是抗量子签名普遍的缺点。IOTA 的单个交易编码后有 2673 trytes（大约为 281.96 bytes），但签名占了 81%（2187 trytes）。对于 IoT 设备，这可能是一个很大的挑战。 安全风波密码学界有一句话：“永远不要自己写加密函数（never roll your own crypto）” 。但 IOTA 的研发团队实现了一个很蹩脚的散列函数，被 MIT 的密码学教授 Neha Narula 发现可以被碰撞，进而实现伪造用户签名，瓦解 IOTA 的安全性。IOTA 团队迅速修复了这一漏洞。 IOTA 的数据编码是三进制编码，可能是为了他们的 JINN CPU 准备的。 Tangle 细节 如图所示，每一笔新的交易，都要试图替前面的交易做验证（validation），然后才能被添加到图里。如果区块链是从低往高不断添砖加瓦地发展的单链表话，图则是不断添砖加瓦的多链表。 绿色代表已经被确认的交易。红色代表还没有被完全确认的交易。灰色代表没有被确认的交易。(Tips) 1.Signing 节点 (Computer/Mobile) 创建交易并用自己的私钥 (Private Key) 对交易进行签名。 2.Tip Selection 节点在创建新的交易时通过使用 RWMC (Random Walk Monte Carlo) 算法选出2个未被确认的Tips。 3.POW (Proof of Work) 节点首先检查被选中的两个Tips是否存在冲突。然后对选中的两个Tips进行工作量证明 (POW)，这里类似于比特币的Hashcash，不停地把Tips的哈希值加上nonce进行再哈希，直到得出的新哈希值的前N位都是0。 Tip 有权重（weight），等于本交易被提交进网络时的 POW 中消耗的计算量。 Tip 有累计权重（cumulative weight），等于自己的权重加上所有可以通过 path 直接或者间接指向它的 Tips 的权重的和。也就是以此 Tip 为终点的子图的加权和。 Tip 有分数（score），等于自己的权重加上这个 tip 直接或者间接验证了的 Tips 的权重的和。也就是以此 Tip 为起点的子图的加权和。 计算这些权重就要考虑到图的遍历问题了。 cumulative weight是一个可变值，从发出交易之后这个值会一直增加，score是一个不可变的值，交易发出之后，它的score就定了。这个cumulative weight和score能用来干什么呢？且看下面继续分析。 假如我要发起一个交易，我要怎么选2个交易去验证呢？理论上你可以随便选。你可以随机选择网络中的2个交易，或者你也可以永远只选几个很老的交易（在Tangle中处于很左边的位置的交易）。但是一个健康的Tangle应该是不断有人发起新的交易形成新的tips，这些tips也应该尽快被之后来的交易所验证。所以选择2个交易时，我们更应该倾向选择tips（Tips 是未确认交易的意思）。 那一笔交易要怎么才能算成功确认呢？这里要介绍一个非常重要的概念，叫做Finality（最终确认性）。如果我们说某一个交易或者转账在某一个分布式的账本上被“最终确认”，那么这个交易无论发生什么，也无法被回滚和撤销。 大家可能觉得，不对啊，区块链的一个基本特性不就是“历史不可更改”么？ 如果我们假设比特币不会出现51%攻击，那么随着区块链的增长，你的交易被逆转的可能性是越来越低。你对这个交易被确认的“信心”也越来越高。IOTA里呢，这个“信心”是可能变高也可能变低的。IOTA里交易的确认是这样一个“信心值”，这个信心值＝当前所有tips中，有多少tips存在一条能连通到你的交易的路径，或者换句话说，当前有多少tips间接确认了你的交易。假设当前一共有100个tips，其中有90个tips间接确认了你的交易，那你的这条交易就是90%确认。如果我能造出100个新的tips使得这100个tips都不间接确认你的交易，那么现在你的交易就变成只有45%确认了。相信你看到这儿不难看出，一个交易要想得到一个足够高的确认信心，那需要等待的时间也不短。如果每个交易都想要超过50%的确认信心的话，那网络中交易的吞吐量并没有实质性比比特币这些传统的区块链提高到哪里去。IOTA更灵活的地方是体现在交易的延迟上，因为如果你选择只要10%的确认信心的话，一笔交易被对方接受的速度会快很多。 从这段看下来，一个 Tip 的信心，可能是他自己的 cumulative weight/全网的加权和。 那坏人故意让非法交易通过验证怎么办？网络里会充满着大量非法交易吗？IOTA 的思想是这样的，节点会计算每个交易的权重值，选择权重高的交易来进行验证，这会有助于增加自己的交易被后来交易验证的可能性。如果你绑定非法交易，那后来的交易则不会选择你的交易来验证。时间一长，这个交易就被网络抛弃了，不再是网络的一部分。 这样岂不是会行程交易验证的马太效应？实际上 Random Walk 应该是个随机游走算法，一个合理的行为应该是，对于 valid 的 Tip 不看权重，而对于 invalid tip 则抛弃。久而久之，invalid tip 的权重始终不升高，也就被抛弃了。 IOTA共识机制创新传统的区块链，交易和交易验证是分离开的。使用钱包的用户不必干矿工应该干的事情，所以普通用户要向矿工支付转账手续费，这其实就导致了网络中的验证工作注定由少数人来完成，而且会提高货币的使用门槛。但 IOTA 的共识要求每位参与者都进行交易并参与共识。更具体地说，每个交易者必须直接定位两笔交易，并且间接在 Tangle 中定位其它交易。通过这种方式免除了手续费，也完全去中心化了。IOTA 中不再有区块的概念，共识的最小单位是交易。不像比特币只有一条链，这是一个网状结构，会不断往外扩散。共识是一环套一环的话，DAG 的共识的颗粒度比区块链的共识颗粒度要小。 然而这种共识也有被攻击的可能。因为它的 PoW 难度太小，所以简单的专有硬件可以发出大量的 sub-tangle 制造账户分叉，至少也能降低被确认交易的“信心”。这就导致了 IOTA 里出现了一个折衷的设计 - cordinator。这个 coordinator 表现为一个绝不会作假的仲裁者，这是一个闭源的 component，大致的行为表现就是一个公正的 RWMC 算法使用者。它通过发出交易的方式来替别人确认交易，这个特殊的交易被称作 milestone-交易所目前通过扫描这个 milestone 交易的方式来对全网账本做一个快照，进而确认目前全网的 balance 分布状况。这个 coordinator 的出现，实质上导致了暂时的中心化，使得 IOTA 主网的 TPS 很低，可以说这个网络目前还处在婴儿期，需要很强的防护和去中心化，只能牺牲性能（Vitalik 三角定理）。 确认信息由协调器发出，如果协调器一关整个网络立即陷入瘫痪状态，目前IOTA协调器执行效率很低，网络的确认速率大约为0.2TPS，其中金额大于0的有效交易占比大约10%，也就是真实网络的确认率仅为0.02TPS（每秒钟交易数）！这就是为什么最近IOTA网络极为拥堵的原因，这完全配不上IOTA原本宣称的无限扩展能力的说法，这也是最近大量用户抱怨为什么我的IOTA充值、提现1个星期还没到账的原因。 IOTA的白皮书里提到，只要attacker不掌握1/3以上的算力，那么attack成功的概率会很低。我们来计算一下，现在IOTA整个网络的交易吞吐量还很低，大约每小时1500个交易。attacker如果能发每小时500个交易就足以可以改变Tangle的形状，attacker如果能每小时发750个交易（每5秒一个交易），那么基本上整个网络他一个人就能说的算了。5秒一个交易并不是很难达到的一个目标，所以现在IOTA放了coordinator这么一个网络秩序的维护者在里面。 本文参考了知乎上的若干文章，以及：《IOTA的技术简介》，《实力解密—IOTA物联网第一币的神话》。"},{"title":"闪电网络、侧链、隔离见证与大区块扩容问题","date":"2018-02-20T09:17:33.000Z","url":"/2018/02/20/%E9%97%AA%E7%94%B5%E7%BD%91%E7%BB%9C%E3%80%81%E4%BE%A7%E9%93%BE%E3%80%81%E9%9A%94%E7%A6%BB%E8%A7%81%E8%AF%81%E4%B8%8E%E5%A4%A7%E5%8C%BA%E5%9D%97%E6%89%A9%E5%AE%B9%E9%97%AE%E9%A2%98/","tags":["区块链","比特币"],"content":"闪电网络闪电网络的原理闪电网络就是在链外专门设置一个通道（channel），所有的交易都在链上进行，只有最终结算在链上进行。这就好像我们的计算机体系结构里面加入的一个工作内存和主内存的 hiarachy。 过程描述如下： 假设我和你，咱俩人经常交易，于是就在闪电网络上开个通道，容量是2BTC； 通道里面AB在总量不超过2BTC的情况下随便相互收发，所有操作送到一个具有AB多重签名的地址，每次操作签名就好； 通道里面的操作没有手续费，因为真实的BTC在链上其实没动过，通道里面的操作本质上是只是对俩人那两个BTC份额所有权的交易； 等啥时候AB不想交易了，把隧道关闭，去真实的比特币主链上兑换一下自己在那两个BTC里的份额就好； 高手续费只发生在打开，或是关闭一个通道的时候。 为什么闪电网络会不安全这种侧链的出现，必然会导致庞大的中间人出现： 网络上会演化出一些大的中间人节点，这些节点有足够多的BTC，足够的流动性，和足够多的通道数量，所以你再也不用担心高额的手续费，自己去找中间人等等一系列麻烦。然而这些节点，和矿工不一样，他们并不和你直接交易BTC，他们更像是一种“第三方清算组织” 也就是说，去中心化（随机的中心化）被局部的中心化所控制了。 这带来的麻烦是： 要让这些组织在整个网络可信，他们一定会受制与金融监管，比如说KYC（Know you Customer，了解你的用户)和AML （anti-money laundering，反洗钱）。 因为不在链上交易，所以盗窃是可能的，如果一个节点把旧的状态在链上发布出去，你的BTC可能和你的交易数目不符，被活生生偷走。 想要防止盗窃，你要么自己跑一个全节点随时监控，要么雇第三方来干这事儿。 所以这些大的中间人节点，一定会满足以下这些条件： 接受金融监管 高流动性 设立反欺诈部门，防止盗窃等行为 对每笔交易收取小额手续费，作为设立节点的经济激励 这就又导致了传统银行行业的出现了。 这部分内容主要参考《闪电网络会毁了比特币，骚年你信不？》。 有意思的是，比特币的核心团队（Core）是支持闪电网络的方案的。他们给出的理由比较原教旨主义，如果使用扩容的方式来提升比特币的性能，那么日后比特币的全账本节点就不能放在普通电脑之上了，只能被大公司所维护，也就违背了去中心化的初衷。当然，也有人认为 core 团队是有意维持低 TPS 使得转账手续费变得奇货可居，这样比特币网络能够获得更高的佣金来支付矿工高昂的电费，也可以创造为企业开发侧链（sidechain）的机会。他们专门成立了一家 BlockStream 公司，来寻找核心团队变现的机会。 不过侧链的出现，也有可能让主链上的挖矿事业深受打击。所以矿霸们都不愿意闪电网络出现？ CORE，或者比特大陆，其实就是两个山头。在比特大陆的描述里，CORE就是一群冥顽不灵的程序员。死守着原有内核，不予变通。沉浸在程序员的小世界里，根本不知道比特币发展需要什么。而比特大陆则是白衣骑士，将拯救比特币于水火。比特大陆才能带比特币飞到新的高度。你们这些“老家伙”，不要固执了。而在CORE的描述里，比特大陆就是把持着话语权，利用信息不对称，故意歪曲事实，绑架了矿工和国内比特币圈的舆论。还假惺惺的总是扮演中立客观方的角色，其实比特大陆才是真正的幕后大黑手，有着某种不可告人的秘密。 侧链闪电网络其实是侧链的一种。从某些角度上说，交易所也是一种侧链。 侧链（sidechains）实质上不是特指某个区块链，而是指遵守侧链协议的所有区块链，该名词是相对与比特币主链来说的。侧链协议是指：可以让比特币安全地从比特币主链转移到其他区块链，又可以从其他区块链安全地返回比特币主链的一种协议。 侧链协议的目的是实现双向锚定（Two-way Peg），使得比特币可以在主链和侧链中互转（图）。 在一个侧链的生态系统里，新的代币（new tokens）只能在相应的比特币被冻结时才能创建。换句话说，如果你想在一个侧链上发行新币，你必须禁用（deactivate）你的一部分比特币。 侧链的工作过程是： 把比特币转移到特意形成的地址上面。转移之后的比特币就被固定在这个地址上，你已经丧失了对其的控制权，实际上现在没有人对其拥有控制权。 一旦固定比特币的交易被确认，你就给侧链发送一条消息，消息要包含是你做了比特币转移的交易自己该比特币已经被固定住了。一旦第二条区块链同意比特币的侧链，那按照预先的协议，会给你一定数量的该区块链上的代币，现在你对这些代币拥有控制权。 具体的效果来看确实像是比特币流转到了别的区块链上，实际上你拥有的比特币只是被固定住了，没有被销毁成为新的代币。 你想转回自己的比特币，那么操作是对称的。 所以侧链是场外交易的抵押-兑换模式。 隔离见证（SegWit）问题每一个比特币交易的数据，可以被分为两个部分。一是交易内容本身，二是见证的数据内容本身。 扩容只是隔离见证的一个副作用，隔离见证通过软升级的方式还避免了比特币的漏洞。 有些人认为隔离见证是闪电网络的必要条件（core 团队），然而另外的人则认为隔离见证只是让闪电网络的实现变得更简单了而已。 传统的比特币区块里面，有个 script 部分，大概长这样： scriptPubKey部分（由上一笔转账的转出者提供）: OP_DUP OP_HASH160 OP_EQUALVERIFY OP_CHECKSIG scriptSig部分（由这一笔转账的转出者提供）: 实际上转账者拥有比特币，是拥有比特币的转移权。scriptPubKey 是由上一个转账的转账者输入的，算是 UTXO 的一部分。现在的转账者要使用这笔钱，就是要提供一个 sig 可以推出 pubKey，而 pubKey 又能推出上面的 pubKeyHash。矿工会在区块生成的时候做一个试算过程，来验证这个交易是不是合法的。 ScriptSig 如果能够被移出传统的 transaction 数据结构，也就可以让1兆大小的区块容纳更多的交易（Core 团队认为这可以让区块的实际容量达到原先容量的1.7x 倍）。支持隔离见证的钱包，将不再使用1开头的钱包地址，而是3开头的钱包地址。交易的发起者依然需要使用自己的签名来发起交易，验证交易的时候依然要走 script 的这个路子。但最终存入区块里的数据就不再包含这种签名（即见证）信息了。 没看过具体的数据结构，但被隔离出来的见证信息，最终还是应该存在链上的某些地方才对。 隔离见证能够解决三个问题： 可以修复一个由交易延展性（transaction malleability）引起的问题。 可以实现闪电网络。 一定程度上增加一个区块里可容纳的交易数，缓解交易拥堵。 但其中最重要的，可能还是解决交易延展性问题。 先说一下交易延展性。比特币区块链上每笔交易记录里都包含有见证信息，交易的唯一标识（交易的哈希值）也是包括了见证信息计算出来的。由于见证算法的数学特性，任何人在拿到一个交易记录后，拿到其中的见证信息，然后可以在不需要知道私钥的情况下，很容易的拼凑出另外一个有效的见证信息。这样，他可以用拼凑出来的另外那个见证信息，拼凑上交易记录中的其他交易信息，制造出一个另外一个交易记录（哈希值不同）。如果可以让拼凑出来的交易记录先被写入区块链，那么，之前那个原始交易记录会被认为是无效的交易而失败。这不会造成双花，也不会对区块链造成破坏，但是对原始交易记录的发起者会造成困扰，因为如果拿着原始交易记录的哈希值找不到交易的成功记录。尤其是对于一些交易所，如果没有完整的内部日志，可能无法追溯交易记录，导致攻击者利用拼凑的交易记录先成功提币，再申诉说没有提到币，要求再次提币。 简而言之，就是 A 转了一笔钱给 B，流水单号为1。利用签名，可以制造出另一个流水单号为2，但仍然由 A 转给 B 的转账。虽然 B 确实拿到了这笔钱，流水单号位1的转账却作废了。这就使得交易有了可争议的地方。 大区块扩容比特币现金（曾经的 BCC，现在的 BCH）是比特大陆江卓尔等人带头搞出来的，分 Core 的权的大容量区块产物。 此处有待补充。"},{"title":"EOS 相关问题","date":"2018-02-20T04:51:36.000Z","url":"/2018/02/20/EOS-%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","tags":["区块链","EOS"],"content":"石墨烯（graphene，读作gurafin，没有尾音 i）技术本身是由 cryptonomex 开发的一个库，目前已经有国内的开发者开始使用它来开发公有链相关的基础设施。BM-丹尼尔•拉里默（Dan Larimer）是 cryptonomex 的创始人。 EOS 声称自己具有以下几个优点： 不易分叉 高 TPS 可以平滑升级 EOS 的365天众筹模式可以让 EOS 团队负成本的操盘。EOS 总量是无限的，（据说）增发的部分只是给矿工创造价值。"},{"title":"推荐算法笔记","date":"2018-02-20T04:17:29.000Z","url":"/2018/02/20/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/","tags":["推荐算法","数据挖掘","AI"],"content":"分类的话： 用户画像算法 用户画像算法、聚类算法 分类算法： gbtd、随机森林 识别完了看哪个变量更重要。要有可解释性。 价格相关数据：体现在什么方面？一定要跟收入密切相关的。要对数据和业务的理解很重要。 分类项目：部分已知，有一部分训练集，用未知的和已知的做一个比较。打标签。寻找标签里最重要的因素。 gbtd（底层是很多决策树）。svm。dnn。可能解释性那么强。决策树。xgbox。 输出是：分类的概率。 聚类项目：完全未知，从数据本身来发现特征。k-means。层次聚类。 输出是：不同类别的特征。 要理解商业逻辑。"},{"title":"跨域与同源策略问题","date":"2018-02-05T07:23:08.000Z","url":"/2018/02/05/%E8%B7%A8%E5%9F%9F%E4%B8%8E%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E9%97%AE%E9%A2%98/","tags":["JavaScript"],"content":"什么是同源策略同源策略(same origin policy)指的是，两个网页的协议、域名和端口都相同。 但 Windows RT IE 是例外的，对它而言，端口号并不是同源策略的组成部分之一。 同源策略的变化同源策略最初的要求是，同源的网页才能打开同源网页下的 cookie。但现代的同源策略起了轻微的变化： localStorage 和 IndexedDB 也受同源策略限制。 “Cookies使用不同的源定义方式。一个页面可以为本域和任何父域设置cookie，只要是父域不是公共后缀（public suffix）即可。设置cookie时，你可以使用 Domain，Path，Secure，和 Http-Only 标记来限定其访问性。” 对XMLHttpRequest和&lt;img&gt;标签则会受到同源策略的约束： 通常允许进行跨域写操作（Cross-origin writes）。例如链接，重定向以及表单提交。特定少数的 HTTP 请求需要添加 preflight。 允许跨域资源嵌入(Cross-origin embedding)。也就是说图片插入本质上还是不受同源策略的限制。这恐怕也是现阶段的很多 CSRF 攻击的根源。跨域资源的一些示例包括： 通常不允许跨域资源操作(Cross-origin writes)。但可以通过内嵌资源来巧妙地进行读取访问。也就是说，原始的跨域 post 请求本身是很容易被 banned 掉的（现实中浏览器的例子是，能发 request 不能收 response）。 DOM 无法跨域访问。 如何阻止跨域访问 阻止跨域访问，只要检测请求中的 CSRF token 即可。换言之，CSRF 攻击的根源还是跨域 post 成功，其原理是： 阻止资源的跨站读取和读取，需要保证该资源是不可嵌入的。阻止嵌入行为是必须的，因为嵌入资源通常向其暴露信息。（其实早期的 CSRF 攻击有把一个 http 地址隐藏在一个 img 元素里的用法）。 如何破解同源策略修改源这个方法可以使 cookie 跨域共享。 页面可以修改自己的源，但只能用它的脚本将document.domain的值设置成其当前域或当前域的超级域。如果将其设置为当前域的超级域，则较短的域将用于后续原始检查。 MDN 里举了一个例子，假设文档中的一个脚本在  执行以下语句：： 页面将会成功地通过对  的同源检测。而同理，company.com 不能设置 document.domain 为 othercompany.com。 但改域还是要注意端口号问题： 浏览器单独保存端口号。任何的赋值操作，包括document.domain = document.domain都会以null值覆盖掉原来的端口号。因此company.com:8080页面的脚本不能仅通过设置document.domain = “company.com”就能与company.com通信。赋值时必须带上端口号，以确保端口号不会为null。 还有一个需要对父页面重新赋值的注意事项： 使用document.domain允许子域安全访问其父域时，您需要设置document.domain在父域和子域中具有相同的值。这是必要的，即使这样做只是将父域设置回其原始值。否则可能会导致权限错误。 iframe 如果两个网页不同源，就无法拿到对方的DOM。典型的例子是iframe窗口和window.open方法打开的窗口，它们与父窗口无法通信。 HTML5为了解决这个问题，引入了一个全新的API：跨文档通信 API（Cross-document messaging）。 这个API为window对象新增了一个window.postMessage方法，允许跨窗口通信，不论这两个窗口是否同源。 举例来说，父窗口向子窗口发消息，调用postMessage方法就可以了。 AJAX 的方法简单 header 和非简单 header默认情况下，只有七种 simple response headers （简单响应首部）可以暴露给外部： Cache-Control Content-Language Content-Length Content-Type Expires Last-Modified Pragma non-simple-headers 可以用如下方式返回： Access-Control-Expose-Headers: Content-Length, X-Kuma-Revision JSONP&lt;script&gt;标签的存在，生动地说明了同源策略不限制普通的 http get 请求获取嵌入式资源。本质上就是让代码的上文写好，生成一个script标签请求，让服务器把下文写好。大致的例子是： 先在客户端生成一个标签： 然后再在服务器端生成一段 JavaScript 代码： WebSocketWebSocket是一种通信协议，使用ws://（非加密）和wss://（加密）作为协议前缀。该协议不实行同源政策(其实只有 AJAX 受到同源策略的限制)，只要服务器支持，就可以通过它进行跨源通信。 CORS(Cross-Origin Resource Sharing)#先把请求分成简单请求(simple request)和非简单请求(not-so-simple request)。 简单请求简单请求要求同时满足两大条件：其他请求都是非简单请求。 对于简单请求，就是在 request 里面表明当前的request 来自哪个 origin。换言之，A 要跨域到 B，A 至少要表明自己。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 其中各个字段的含义： Access-Control-Allow-Origin：该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求（习惯大方的程序员当然会选择后者了）。 Access-Control-Allow-Credentials：该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 Access-Control-Expose-Headers：该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(‘FooBar’)可以返回FooBar字段的值。 非简单请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 简而言之，在 JQuery 时代，由浏览器而不是由 JQuery 自动发出的 OPTIONS 请求，就是 preflight 请求。 一个例子如下。 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 服务器收到了这个请求，返回一个这样的响应： 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 到此我们可以看到，跨域相关的许可信息，都是放在 header 里而不是放在 body 里的。 一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。这两个字段，是浏览器和服务器自动添加上去，保证通话过程始终在对跨域的警惕和授权中度过。 附一个小问题：CSRF 攻防问题 img src 攻击可以攻击所有 get 请求。 隐藏表单不受同源策略影响，post 也需要做专门防御。 最完善的做法，应该是做一些有时效性的 token 放在网页里。像 Rails 的方案，就是一个隐藏表单里的 token，还要配合 referer 使用（这个字段能不能被 javascript 修改是个复杂问题）。 本文的主要参考文献： 《浏览器同源政策及其规避方法》 《跨域资源共享 CORS 详解》 《浏览器的同源策略》 《Cross-Origin Resource Sharing (CORS)》 "},{"title":"Echart 词汇表","date":"2018-02-03T06:51:05.000Z","url":"/2018/02/03/Echart-%E8%AF%8D%E6%B1%87%E8%A1%A8/","tags":["JavaScript","Echart","词汇"],"content":"emphasis n 强调roam 漫游scatterplot 散点图effectscatter 特效散点"},{"title":"以太坊为什么不适合拿来做联盟链？","date":"2018-02-03T05:35:10.000Z","url":"/2018/02/03/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%80%82%E5%90%88%E6%8B%BF%E6%9D%A5%E5%81%9A%E8%81%94%E7%9B%9F%E9%93%BE%EF%BC%9F/","tags":["区块链","Ethereum"],"content":"联盟链必然要求多个账户系统存在，联盟中的每个节点都必须独立保存自己的私钥，则在当前的 gas 系统限制下，每个账户必须有自己的ether存款。 是不是允许多头出块？如果允许多头出块，则各个账户可以预先prefund或者在网络启动的时候充钱，不必考虑货币流通性问题。但多头出块的缺点是，不可抵挡分叉。而且，实际上极有可能还是存在货币流通性问题。 不允许多头出块，则必须由我们自己的中心账户来出块，我们自己来出块的话，其他账户发起合约请求需要的货币需要定期从我们的中心账户提取出来。 如果可以用强一致性的协议来预先持久化所有的写消息，也许可以靠监控把错误恢复过来，当然这也对业务产生了强依赖，业务的写操作必须是可以通过类似反幂等的方式恢复过来的。这就是把Raft分布式强一致性协议当做一个分布式的WAL来用了。ES 不适合拿来当这个 WAL，因为它不是强实时写的。"},{"title":"以太坊与随机数问题","date":"2018-02-03T05:34:04.000Z","url":"/2018/02/03/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%95%B0%E9%97%AE%E9%A2%98/","tags":["区块链","Ethereum"],"content":"值得注意的几篇文章： 这个 reddit 上的帖子里提到了 RANDAO 其实是不够安全的，但下面 RANDAO 的作者又出来说这个东西被它改进过了。 这个话题下面还有人引了 Vitalik 的一篇博客。 randao的实现。基本上就是用一个dao 的方式（Decentralized autonomous organization）来运行一个匿名先知组织。这个设计思路和 Vitalik 谈到的用先知而不是全上链的版本来运行智能合约的对比基本一致。 vdice 自己的博客里也提到了用未来的块hash来生成随机数是不安全的，他们直接使用了oraclize。改天要分析下它们所谓的“200行的安全的codebase”。"},{"title":"健康闲谈-健康管理和疾病预防","date":"2018-02-03T05:32:37.000Z","url":"/2018/02/03/%E5%81%A5%E5%BA%B7%E9%97%B2%E8%B0%88-%E5%81%A5%E5%BA%B7%E7%AE%A1%E7%90%86%E5%92%8C%E7%96%BE%E7%97%85%E9%A2%84%E9%98%B2/","tags":["医学"],"content":" 健康是一种身体上、精神上和社会上的完美状态。&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;– 世界卫生组织健康定义 养生三大原则： 和谐原则 辩证调摄 “度”和“量”的适当掌握-充分进行综合调养 和谐原则-“天人相应”理论和自然界相适应。情志养生。 辩证调摄-因人、因时、因地制宜每个人都不同。不要乱吃补品。疲劳的时候吃清淡的。运动可以发泄身体的郁闷。 “度”和“量”的适当掌握-充分进行综合调养碳水化合物是很重要的。吃蛋白质尿酸高。太操劳？知道寒暑冷热。不要运动过度。 四季养生 运动养生起居养生精神养生环境养生饮食养生睡眠养生 不要喝高汤里的嘌呤不要一哄而上吃流行的 合理的饮食适量运动戒烟戒酒心理平衡充足睡眠 未病先防欲病早治已病防变"},{"title":"学习区块链的基础资料","date":"2018-01-31T03:00:23.000Z","url":"/2018/01/31/%E5%AD%A6%E4%B9%A0%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%9F%BA%E7%A1%80%E8%B5%84%E6%96%99/","tags":["区块链","Ethereum"],"content":"《猥琐发育成区块链开发者》普林斯顿的《Bitcoin and Cryptocurrency Technologies》课程《精通比特币（第二版）》"},{"title":"几种共识算法","date":"2018-01-30T05:59:56.000Z","url":"/2018/01/30/%E5%87%A0%E7%A7%8D%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/","tags":["系统架构","区块链","consensus"],"content":"达成共识的英文原文是 come to consensus。达成共识以后，也未必代表数据是完全一致的（Raft 算法中 leader 发出 append log 的 commit 命令即算达成共识？但如果中途数据丢失，则还是会有子节点数据不一致）。 在分布式环境下，多个系统协同工作的效率，受制于系统交叉点的性能。在需要达成分布式共识的场景下，分布式共识算法在保证系统安全性的同时，限制了全系统横向扩展的性能提升。 根据环境的不同，可以应用不同的共识算法。 在完全互信的环境下-私有链、私有的分布式数据库，节点之间可以使用 Paxos 或者 Raft 这种 leader 相对固定的算法。 在有限互信的环境下-联盟链，可以使用 PBFT。PBFT 算法是依据确定性的投票（可能是漫长的投票，也可能进入死循环）达到确定性一致的算法。 在没有互信的情况下-公有链，可以使用 POW/POS/DPOS/POA。这类算法是基于概率得到正确的最终一致性，性能比 PBFT 要稍微好点。 最好的共识算法应该模块化，例如 Corda 中的 notary，Hyperledger fabric 中的 solo/kafka。 FLP Impossibility（FLP 不可能定理）FLP 是三个作者的名字。 FLP Impossibility（FLP不可能性）是分布式领域中一个非常著名的结果，该结果在专业领域被称为“定理”，其地位之高可见一斑。该定理的论文是由Fischer, Lynch and Patterson三位作者于1985年发表,之后该论文毫无疑问得获得了Dijkstra奖。 顺便要提一句的是，Lynch是一位非常著名的分布式领域的女性科学家，研究遍布分布式的方方面面，对分布式领域有着极其卓越的贡献，其著有”Distributed Algorithms”一书，书中有非常严谨而简洁的逻辑讨论了许许多多的分布式算法。 FLP给出了一个令人吃惊的结论：在异步通信场景，即使只有一个进程失败，也没有任何算法能保证非失败进程达到一致性！ 因为同步通信中的一致性被证明是可以达到的，因此在之前一直有人尝试各种算法解决以异步环境的一致性问题，有个FLP的结果，这样的尝试终于有了答案。 FLP证明最难理解的是没有一个直观的sample，所有提到FLP的资料中也基本都回避了sample的要求。究其原因，sample难以设计，除非你先设计几种一致性算法，并用FLP说明这些算法都是错误的。 只要记住这样一个结论即可：在异步通信场景，即使只有一个进程失败，也没有任何算法能保证非失败进程达到一致性！ 换言之，Paxos 为代表的协议，都只能保证极大概率不出错达到一致性，不能保证真正的一致性。 可信环境下的共识算法可信环境下，节点只会故障（fault），不存在恶意节点（corrupt），可能存在丢失消息或者不响应，不会出现恶意的错误信息。 Paxos 算法Paxos 算法假定有一个全局能够自动生成递增消息编号的服务。 Paxos 算法把角色分为 proposer、acceptor 和 learner。这三种角色都可以有多个节点以避免单点故障，Paxos 算法的目的就是如果多个 proposer 在异步网络环境下有多个提案，怎样让 proposer/acceptor 最终选出一个，然后让 learner 知晓。 Acceptor 可以应对两种请求： prepare 请求，承诺一个 proposer 不再accept编号低于某个值的提案，并返回目前批准最大编号提案的值。 accept 请求，如果没有 prepare 过编号大于 N 的提案，而 N 又是可以被批准的（也就是恰好足以成为最大的编号的），则可以 accept 这条提案，这个proposer 应该就可以结束 prepare 和 accept 了，由其他 proposer 继续这个两阶段的旅程，直到这个过程终止。 proposer 就是不断地先向 majority 发出 prepare 请求，然后如果得到了一个 chosen 值，就不断地持续地向 majority广播 chosen 值，直到它被majority accept。acceptor 就在 proposer 逐渐变得一致的过程中，达到一个有 majority 的批准值。 如果两个 proposer1 完成了消息1 prepare，acceptor 又 prepare 了一个更高的 proposer2 的消息2，而会直接拒绝掉 proposer 1 的 accept 消息1，于是proposer 1 提出消息3（这个 retry 机制很有意思，因为 proposer 被拒绝以后并不是直接去询问当前高序号的值，而是用一个更高序号的值去 prepare 来询问 ），让 proposer 的消息2 accept 又失败，于是就产生了活锁。Paxos 无法终止，因为恰好每个 prepare 和 accept 的间隙都被对方给否定掉了。虽然 lamport 证明了在数学上算法应该可以收敛，但受环境所限，并不一定在现实中就必然会收敛。 Raft 算法Raft 简化 Paxos 的地方在于，它不再是一个多轮多 proposer 达到一致的算法，而是先用 leader election 来制造单一的 trust source，然后由统一的 trust source 发号施令，确定分布式场景下数据的顺序和对错的算法。这个 leader 也避免了活锁的存在。Raft 只是更好理解，属于Paxos 的一个特例场景变种，但并不更容易实现。 Raft 是先做 election，再做 log replication 的。 Raft 有三种角色，follower、candidate、leader。如果 follower 没有收听到 leader 的心跳，那么它就可以假设 leader 不在了（即使它只是因为处在一个 network partition 里，接收不到 leader 的 heartbeat），转变为 candidate，自行发动选举，能不能选举完成，要看自己所在的分区是不是多数分区。系统总是从一群 term 为0 的 follower 开始的，所以系统初始化的时候就会直接开始一场选举。 选举有两个超时。 一个叫election timeout，就是 follower 忍受 leader 不发心跳给自己，变成 candidate 的时长。不同的 follower 的忍受时长不一样，在150ms 到300ms 之间徘徊， 这就导致了有的 follower 变成 candidate 的时间早，有的变成 candidate 的时间短。follower 变成 candidate 第一件事就是选自己，然后把 vote request 发给其他节点，其他节点即使现在还是 follower/candidate 状态，收到 vote request，如果没有投过票，也会立即进入下一个 term 的投票，直接把票投给第一个给自己发 vote request 的节点，自己依然保持 follower/candidate 状态。任意一个 candidate 收到定制拓扑结构里面的多数投票就会自封为 leader。因为其他节点已经投给了别人，所以他们只能乖乖做 follower，接收他们选的 leader 发送过来的信息。 另一个 timeout 叫heartbeat timeout。leader 发送的信息叫做 Append Entries（类似 Kafka 的 appending log），这些信息本身要跟随心跳信息被发送，follower 本身也要发送 response 给 leader。 如果节点出现了一个 term 的选举平局，则这一轮已无法再投票。需要等到下一轮超时，再投一次，产生自封的 leader。感觉上这里就会产生两个问题，首先，自封的 leader 完全可以自称，这就不能解决 bft 问题，其次，这个选举的平局几乎可以无限地进行下去。 一旦一个客户端往 leader 发信息，则 leader 会先在自己的 log 上预 append，然后把 log 通过消息发送给 follower，follower 也都预 append 以后发送 acknowledgement 给 leader。leader 收到多数 acknowledgement 以后就在本地完成提交，然后先把 response 发给客户端，然后告知 follower 把预提交的信息完全提交上去（真 commit）。这也是一个两阶段提交的步骤，但和传统的两阶段提交的算法不一样的是，它的 coordinator 不是固定的，它收集 acknowledgement 并不是收集全部的，而是收集 majority，这就不能保证强一致性。它的最后发送真 commit 本身，也是像传统的两阶段提交算法一样，是不看最后的 acknowledgement 的。难道这些 log 本身是编好序号的？ 如果真的出现了网络分区，则小分区的 leader 即使不知道新的 leader 已经产生了，还能以蒙在鼓里的形式继续跟小分区里的 follower 继续通信，也无法真的更新自己的 log 和 follower 的 log，因为它收集不到足够多的 acknowledgement。 假设系统已经有了 leader，则 leader 有自己的任期（term），高任期的 leader 会自动打败低任期的 leader。leader 一定要定时地发送自己的心跳数据给 follower，以告知它们自己这一任 leader 还活着，不然系统中会产生新的 leader。 在有限互信的环境下的共识算法Bazantine General Problem 问题，是1982年 Leslie Lamport 提出的一个解释一致性问题的虚构模型。 对于拜占庭问题来说，假如节点总数为 N，叛变将军数为 F，则当 N &gt;= 3F + 1时，问题才有解，即 Byzantine Fault Tolerant (BFT) 算法。 据说有一种最直观的理解是，假设 N 为3，而 F 为1。A、B、C三个人里面有C会说谎，A、B 都向其他人广播1，而 C 广播 0，则 A 会受到一个1 和 0，B 也会收到一个 1 和 0，A 和 B 都无法判定谁是叛徒。可是 A 在收到1和发出1的时候，难道不能认定自己的1是多数派么？ PBFT 全称是 Practical Byzantine Fault Tolerant，由 Castro 和 Liskov 在1998年提出，是第一个得到广泛应用的 BFT 算法，只要系统中有2/3的节点是正常工作的，则可以保证一致性。 超级账本相关项目大量采用 BFT 相关算法。 Fabric 采用的是可插拔共识算法架构，目前包括三种具体算法： No-op (consensus ignored)（无操作共识机制？） SBFT（Zyzzyva 的实现，还未到来） SIEVE (an enhanced version of classic PBFT)（还未到来）。 传统的 BFT 算法的时间复杂度是 O（N*N），平方复杂度的算法导致它极难横向扩展。因为 n 个节点，每个节点都要广播给所有其他节点知晓自己的信息，必然导致 n*n 次通信。 在没有互信的情况下的共识算法这些不同的算法，可以说都是在公有链上的挖矿算法。挖矿有几层含义： 替别人产生了价值（公允的记账）。 为自己挣得了奖励。 能够在挖矿过程中梳理交易，防止双花攻击。 这些算法本质上都是博弈算法。总是要让参与出块决策的参与者们拿出一些高于某个门槛的抵押物，在算法中靠抵押物和少数服从多数的认同达到共识和服从。 PoW（Proof of Work）PoW 的抵押物是电。每个矿工拿出算力出来寻找随机数，找到随机数的矿工用自说明的区块向其他矿工展示自己消耗的算力，其他矿工通过重复演算确认区块的合法性。 PoW 是中本聪最初设计出来，让每一个比特币钱包的拥有者能够参与整个系统的决策机制-也就是说，他没有料想到职业矿工、加强型矿机甚至矿池的出现。即使是发生了节点故障，或者有人作恶，只要有超过百分之五十一的节点能够健康工作，这个网络就是健康的。 PoW 到现在为止暴露出的弊端是： 中本聪设计 PoW 的构想里面，节点和算力是均匀分布的，网络最终会发展成最大限度的去中心化民主制度。但现实之中，大型矿池的出现，使得几个利益集团可以操控整个网络的发展。 太耗电了。 事实上导致了全网真正确认的速度变得非常慢。因为算力竞赛的胜者，要等待全网中大部分非信任节点把被挖出来的区块加入他们的主 链条（canonical chain）中，还要防止分叉出现。即使横向扩展网络中机器的规模，也无法解决这个问题。 PoS（Proof of Stake）PoS 是个权益证明算法。 它是要求公有链上的 validator 把他们的经济权益抵押在链上的共识算法。 在 PoS 的算法下，一系列的 validator 提议区块，并给区块投票。投票的权重由他们抵押在这次投票里的权益决定。 任何持有以太坊基本货币的人都可以成为 validator。他们只要发起一个特殊的事务把他们的以太币锁起来，然后就可以开始共识算法了。 从算法的角度来看，主要有两类 PoS 算法： 基于链的 BFT 风格的 基于链的PoS 里，算法在每个时间槽伪随机地选择一个 validator。由这个 validator 来指定下一个区块是怎么样的（通常基于已知的最长链的最后一个区块）。那么投票在哪里呢？所以这种算法是不够安全的。 BFT 风格的 PoS 里，validator 被真正随机地被选出来提议区块，但哪个区块被加到主链上，是由多轮投票决定的。这个算法才是现在以太坊的 PoS 基础。 PoS 相对于 Pow 的优点是什么？ 省电。 不需要增发新的货币-实际上现在很多 ICO 里都留有货币增发的口子，就是为了不断激励矿工。 可以从博弈论机制设计的角度来防止中心化的卡泰尔出现。 PoS 是如何融入传统的拜占庭容错研究（成果）的？其实 PoW 是依赖于同步网络模型的。网络延迟越高，容错性越低。如果网络延迟等于出块时间，整个系统的容错性降为0。 Proof of work has been rigorously analyzed by Andrew Miller and others and fits into the picture as an algorithm reliant on a synchronous network model. We can model the network as being made up of a near-infinite number of nodes, with each node representing a very small unit of computing power and having a very small probability of being able to create a block in a given period. In this model, the protocol has 50% fault tolerance assuming zero network latency, ~46% (Ethereum) and ~49.5% (Bitcoin) fault tolerance under actually observed conditions, but goes down to 33% if network latency is equal to the block time, and reduces to zero as network latency approaches infinity. PoS 算法更加贴近拜占庭共识模型。 PoW 算法是 AP 的算法。BFT 风格的共识算法更加贴近一致性（依然保证可用性）。 什么是利益无关问题，以及如何解决它在 PoW 模型下，一个利益相关者不可能给每个区块都下注，因为分散下注需要分散电力，这在经济上并不划算。但如果 PoS 模型不做一些准备措施，那么在分布式环境下下注也可以以以类似双花攻击（甚至是多花攻击）的方式存在，这样的行为如果不受到惩罚，实际上是给产生共识制造障碍。 第一种解法，Slasher。不允许一个 validator 试图同时创建两条链。但这要求 validator 在分叉发生前就选好，而且两条分叉链上的 validator 都必须一样。 第二种方法就很简明了。猜对链条的人得到 +R 的奖励，猜错的人受到 -F（可以等于 R） 的惩罚。 所以这和拜占庭容错理论有什么关系？传统的拜占庭理论可以证明，“如果一个系统有安全鼓掌，那么最少三分之一的节点是有过失的”。而 BFT 风格的 PoS 算法则试图证明，“如果一个系统有安全鼓掌，那么最少三分之一的节点是有过失的，而且你知道哪些节点有过失，即使你在故障发生时不在线”。（译者按：这简直就是记名投票）。 PoS 技术说明的英文和中文版本。 看了那么多 PoS 到底是怎么工作的呢？ PoS 里的 validator 不再被称作 miner，而被称作 forger。 在所有货币都预售了的系统里面，PoS 是没有区块奖励的（挖矿有点名不副实了），只赚手续费。 所有人如果想成为 validator，可以加入一个 validator 池，然后总会被选上： “You automatically get inducted after some time,” explained Vitalik Buterin himself on a post shared on Reddit. Casper 是带有惩罚机制的 PoS 算法。系统会挑出它认为做了坏事的 validator，扣除它的准备金赌注，并取消掉它成为 validator 的资格（这有什么意义？）。具体步骤： The validators stake a portion of their Ethers as stake.After that, they will start validating the blocks. Meaning, when they discover a block which they think can be added to the chain, they will validate it by placing a bet on it.If the block gets appended, then the validators will get a reward proportionate to their bets.However, if a validator acts in a malicious manner and tries to do a “nothing at stake”, they will immediately be reprimanded, and all of their stake is going to get slashed. 恶意攻击被称作Malicious manner 或者 Byzantine manner。 在出现惩罚措施以前，nothing at stake 问题使得攻击 PoS 网络变得很简单，惩罚措施试图使得全网的共识更加像 PoW。在 PoS 中，51%攻击的必要条件是，一个人必须有全网51%的货币。 Casper 的两种版本 Casper FFG 和 Casper CBC，详情见本文。 Casper 和 Pow 一样，都会造成富者愈富-Pow 本身已经让很多矿池成为 cartel了。 PoA（Proof of Authority）PoA 算法指的是网络里有些预先批准节点（sealers），新的签名者 加入网络必须经过老的 sealer 批准。这样其实就制造了一个严格控制的网络环境。为了防止坏节点破坏网络，一个签名者只能签署一定数量的连续区块（(floor(SIGNER_COUNT / 2) + 1)）中的最多一个区块。换言之，心怀恶意的攻击无法防御，只能被这种设计有限控制。 以太坊的 PoA 算法被称作 Clique 协议，协议的描述在这里，它还产生了一个Rinkeby test network。这个测试网络每15秒出一个块，和主网的ethash想要达到的目标一致。 是不是 PoS 永远不能升级到 PoA 了？PoA 是不是就是为了联盟链设计的？ 另外一篇描述了 Clique 用法的文。 接下来我们来好好描述 Clique 的具体细节： 授权（即签署）区块要为网络签署一个区块，一个签名者要给一个包含一切数据（偏偏不包含签名本身）的哈希值签名。这这意味着这个哈希值包含了块头部的一切字段（包括nonce和mixDigest），以及除了65字节后缀以外的 extraData。这些字段按照黄皮书里定义的顺序被散列（译者按：类似比特币的试算算法）。 这个哈希值用标准的secp256k1曲线（椭圆曲线）算法签名，得到的65字节签名就作为65字节的拖尾后缀被嵌入extraData。 为了保证心怀恶意的签名者（丢失了私钥）不能对网络造成伤害。每个签名者被允许签署SIGNER_LIMIT个连续区块中的最多一个。区块顺序不是固定的，但循序签名区块比不循序签名区块权重更大。 授权策略只要签名者遵守上述规范，他们可以授权和散播他们认为合适的区块。下面的建议策略会减少网络通信和小分叉，所以它是建议特征： 如果一个签名者被允许签署一个区块（他在授权名单上而且最近没有签过名）。 计算下一个区块的最佳签署时间（父区块 + BLOCK_PERIOD）。 如果签名者是循序的，等到那个确定时间，直接签署和广播区块。 如果签名者是不循序的，按照rand(SIGNER_COUNT * 500ms)延迟签名。 这个小策略可以保证循序签名者（它的区块权重更高）相比起不循序签名者有轻微的签署和传播优势。也因此这个设计也允许通过提升签名者的数量得到轻微的（性能）扩展。 从以上策略可以看出，实际上 PoA 里依然有可能产生分叉，除非使用严格的单账户 PoA。 为什么要标准化 PoAPoW 在无价值网络上是不安全的，PoS 还远未实现。PoA 作为一个过分简单的解，就被实现出来挽救测试网络了。 PoA 可以被认为是 PoW 的简化版-而不是 PoS 的进化版（以前我想错了），它直接授权了一群主，让他们尽量按顺序出块，当然这种设计（scheme）下依然有分叉的可能。 Clique 算法的相关文献在这里。 DPoS（Delegated Proof of Stake）旧的共识算法无法解决交易性能问题。 DPoS 使用见证人（witness）的机制来解决中心化和性能问题的矛盾。 传统的区块链共识算法有一个很大的弊病，就是需要在大规模范围内被验证非出块节点验证过。DPoS 争取把收集事务、生成区块、验证区块这一系列事件局部化到小范围的少量可被信任节点里，特别是不需要再等待若干个区块累加确认时间。 DPoS 是受控中心化的，每个客户端最终可以通过公平选举，决定哪些节点成为代表绝大多数用户的代理人。 DPoS 背后的理性逻辑（Rationale）是： 使权益所有者能够通过投票决定记账人 最大化权益所有者的红利 最小化保证网络安全的消耗 最大化网络的性能（可能诚实节点之间通过架设专有网络进行通信） 最小化运行网络的成本（可能诚实节点之间通过架设专有网络进行通信） 每个权益所有者通过投票决定区块的签名验证者，任何一个拥有超过1%投票的人都可以参与到董事会。所有的代表构成一个“董事会”，轮流签署区块。如果一个董事错过了签署区块的机会，客户会自动把投票给予其他人。最终，这些错过签署机会的董事会被取消资格，其他人就可以加入董事会。董事会成员会收到少量代币作为奖励，用来激励在线时间和参与竞选。每一个董事必须要将单个区块平均奖励的100倍作为保证金，从而确保其至少99%的在线时间。 EOS 的候选代表出自各大研究所、大学、交易所等地方，是 well-known 节点。 不从普通用户中选择见证者的原因： 普通用户大部分时间不在线 攻击者可以使用其权益控制网络，而不经过其他人的认可 由于没有挖矿，在去中心化网络中生成随机数变得不可能。 现实工作中，普通用户是通过钱包中的投票选项来选择见证者的。在全网出现不诚实区块的时候，正常的钱包可能在交易以前强制举行一轮新投票。但具体的投票过程，没有具体文献披露出来。 假设手续费等于验证成本，则全网只能有一个验证节点，蜕变为中心化节点。假设手续费100倍于验证成本，则全网可以拥有100个去中心化节点。这个平均成本核算说明了现在比特币挖矿并不 rational，需要依靠矿金激励的支持。 见证人干了什么： 生成区块和广播区块的权威（类似 authority）。 负责用自己的私钥对收集来的 P2P 网络中的合法交易进行验证、打包和签名。 在比特股实现中，见证人的排列顺序是随机的，因为网络拓扑结构不固定，而且网络连通性没有保障。而 EOS 的实现则是定制拓扑的 round robin 结构，因为它是确定 well-known 节点的，每个出块者都可以跟下一个出块者直连以防块扩散速度不足。而且这种定制的 round robin 顺序可能还会被洗牌算法所改变。 经典的出块过程： 在比特股/Steemit的时代，3秒出一个块，EOS 的时代，可能1秒就出一个块。 出块时间深受假定的网络延迟模型影响。 EOS 的出块过程里面，如果一个见证者的出块失败了，该 slot 的指定区块会被 skipped 掉，而不是由其他出块者补上。 理论上每个 transaction 都包含对一个最近区块的交易 hash 值（这也就意味着 transaction 必须有时效性了，其他区块链的区块里是没有这个限制的）。这也就意味着，每个签署人签署一个新区块，都会增强对历史交易的认定。这被称为 TaPoS（Transaction as Proof of Stake）。它可以： 防止跨分叉的事务重放。 通知网络某个用户和它们的权益在某个特定分叉上。 按照 BM 在视频里的说法，在 DPoS + TaPoS 双重防御下，也需要三分之二的区块生产者都在老的区块上产生新的区块，最终确定性(finality)才能被保证，这至少需要45（3*15）秒。这个数字为什么和 BFT 要求的比例一模一样？按照 BM 在视频里的说法，只需要三分之一的节点是非拜占庭恶意节点，网络就不会被拜占庭恶意攻击攻破。 DPoS 对于攻击的抑制 不管是因为掉线，还是因为有意拒绝，如果见证人没有签署它应该签署的区块，它将被解职，并是去未来的稳定预期收入。因此不诚实的委托代表只有在明确有其他利益诉求时才会选择放弃区块生成。 见证人无法签署无效的交易，因为交易需要所有见证人都确认。 在现实世界里，通常需要11个或者21个当选见证者，候选见证者可能需要100个。 以上内容参考《区块链核心技术：委任权益证明算法DPoS》和《缺失的白皮书：DPOS共识算法工作原理及鲁棒性根源分析》。我们都知道区块链应该能够防止双重支付攻击，但这篇文章《》也提到要防止拒绝服务攻击。"},{"title":"Vue 值得注意的小知识点","date":"2018-01-30T03:25:22.000Z","url":"/2018/01/30/Vue-%E5%80%BC%E5%BE%97%E6%B3%A8%E6%84%8F%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/","tags":["JavaScript","Vue","前端"],"content":" this.$el.querySelector(‘#map’) 只能查找第一个 dom 以内的 dom 节点，不包括当前的 dom。 在 webpack:// 这个域下可以看到可调式的 vue 文件。 "},{"title":"Spark Standalone 模式启动的全过程","date":"2018-01-29T08:20:15.000Z","url":"/2018/01/29/Spark-Standalone-%E6%A8%A1%E5%BC%8F%E5%90%AF%E5%8A%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/","tags":["Spark"],"content":"把这个事情做成一个小 routine，免得以后每次都要看英文文档来搭 dev 环境 准备工作下载安装包，解压并进入根目录。 ./sbin/start-master.sh。看 jps 果然已经有了一个 Master 进，文档里面说会打印出 spark 的 master url，但没打印出来。就去默认的上看即可： 这个6066在本地 telnet 不通，也是很神奇。 把这个 URL 拼接成 worker 的启动命令./start-slave.sh spark://magicliang:7077，然后可以看到以下这张图： 文档里的给出的定义 worker 节点的方法：在 Spark 根目录下定义一个 conf/slaves 的文件，每一行写一个主机名。如果这个文件不存在（就是我们现在这个状况），则 worker 就会全部启动在 localhost 上。而 master 是通过 ssh 跟 worker 通信的。默认情况下，ssh 是并行执行，而且要求免密码登录。如果不能提供免密码，要配置一个环境变量 SPARK_SSH_FOREGROUND 并显式地为每个 worker 提供密码。 sbin 里自带了一大套脚本： sbin/start-master.sh - Starts a master instance on the machine the script is executed on.sbin/start-slaves.sh - Starts a slave instance on each machine specified in the conf/slaves file.sbin/start-slave.sh - Starts a slave instance on the machine the script is executed on.sbin/start-all.sh - Starts both a master and a number of slaves as described above.sbin/stop-master.sh - Stops the master that was started via the sbin/start-master.sh script.sbin/stop-slaves.sh - Stops all slave instances on the machines specified in the conf/slaves file.sbin/stop-all.sh - Stops both the master and the slaves as described above. master 和 worker 相关脚本都支持以下参数： -h HOST, –host HOST Hostname to listen on-i HOST, –ip HOST Hostname to listen on (deprecated, use -h or –host)-p PORT, –port PORT Port for service to listen on (default: 7077 for master, random for worker)–webui-port PORT Port for web UI (default: 8080 for master, 8081 for worker)-c CORES, –cores CORES Total CPU cores to allow Spark applications to use on the machine (default: all available); only on worker-m MEM, –memory MEM Total amount of memory to allow Spark applications to use on the machine, in a format like 1000M or 2G (default: your machine’s total RAM minus 1 GB); only on worker-d DIR, –work-dir DIR Directory to use for scratch space and job output logs (default: SPARK_HOME/work); only on worker–properties-file FILE Path to a custom Spark properties file to load (default: conf/spark-defaults.conf) 我们还可以通过在conf/spark-env里设置环境变量进一步配置集群。可以通过conf/spark-env.sh.template来设置初始的 worker 配置，然后把改过的配置拷贝到 worker 机器上去（TODO: 换言之 Spark 也像 Hadoop 一样要求 Master 和 Worker 的目录结构同构？改天试试。）。 把应用程序连接到集群上两个选择： 把spark://magicliang:7077传递给 SparkContext constructor。 直接开 Spark Shell 来连集群：./bin/spark-shell --master spark://magicliang:7077。这时候就会启动一个被修改过的 scala repl 环境 在 shell 环境里输入： 最后一个缓存是特别有意思的地方。即使这些数据是分布在整个集群的各个地方的，Spark 也有办法把它缓存起来。 开始写一个小小的程序建一个新项目sbt new sbt/scala-seed.g8，输入项目名 first-app。 或者用 idea 建立一个项目。然后把相关代码写进去。 重点关注几个文件。 Dependencies.scala(这个文件就是下面文件里面 import 的对象) build.sbt 具体的项目代码： 完整的目标工程见此。 sbt 部分的参考链接。本文主要参考 Spark 的quickstart。"},{"title":"DAG 执行框架优于 MapReduce 的地方在哪里？","date":"2018-01-28T10:07:31.000Z","url":"/2018/01/28/DAG-%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6%E4%BC%98%E4%BA%8E-MapReduce-%E7%9A%84%E5%9C%B0%E6%96%B9%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F/","tags":["大数据","Spark","Storm","MapReduce"],"content":"有个同学问我什么是 DAG 框架。我感觉隐隐约约听过，但又讲不清楚它的概念。 上网搜了一下，我们常见的新大数据执行框架如 Spark、Storm，还有一个我没听过的 Tez，都算 DAG 任务执行框架。他们的主要优点是，可以用 DAG 事先通晓整个任务的全部步骤，然后进行转换优化。如 Tez 就可以把多个任务转换为一个大任务，而 Spark 则可以把相关联的 Map 直接串联起来， 免得多次写回 hdfs（看来 hdfs 也很慢）。传统的 MapReduce 框架为什么不能理解这种优化空间的存在，在任务运行的时候好像一个盲人一样，是个很有意思的话题。 Quora 上的一个相关的问答。"},{"title":"风险问题","date":"2018-01-28T08:41:52.000Z","url":"/2018/01/28/%E9%A3%8E%E9%99%A9%E9%97%AE%E9%A2%98/","tags":["FinTech"],"content":"风险可能有收入也可能有损失。风控先是管理，然后是控制。 精细化管理，平衡点。 信用风险（Credit Risk）欺诈风险（Fraud Risk）操作风险（Operationl Risk）伦敦乌龙指？现金流风险（Liquidity Risk）市场风险（Market Risk）监管风险（Regulator Risk）声望风险（Reputational Risk） Exposion 担保套利 美国三大征信局 Experian、TransUnion、Equifax。美国百分之八十五的人的信息在民间征信局。 美国的征信分数 FICO 由五个部分组成。 中国人会抹掉五年期的征信历史。 Payday Loan 是没有年化上限的。"},{"title":"比特币小细节","date":"2018-01-27T08:45:27.000Z","url":"/2018/01/27/%E6%AF%94%E7%89%B9%E5%B8%81%E5%B0%8F%E7%BB%86%E8%8A%82/","tags":["区块链","比特币"],"content":" 收款地址是公钥的hash。 区块结构： 数据项 描述 长度 Magic No 魔数 总是 0xD9B4BEF9 4 字节（定长） BlockSize 区块大小 到区块结束的字节长度 4字节（定长） BlockHeader 区块头 包含六个数据项 80字节（定长） Transaction Counter 交易计数器 正整数 VI=VarInt 1-9字节（变长） BlockHeader 区块头 包含六个数据项 80字节（定长） Transactions 交易 交易列表（非空） 由Transaction Counter 描述的长度（变长） 由此表可见，只有交易计数器和交易明细列表是变长的。 比特币使用 SHA256 算法，它的结果哈希值大小为 256 位。也就是说，只要输入超过2的256次方个数，就一定会发生碰撞，即使只有2的255次方个数，也有百分之九十九的几率发生碰撞（为什么？）。 当前（这一百年内），每个区块都至少包含一个 Transaction，它被称为生产交易，或者coinbase交易，用于给生成这个区块的矿工以奖励，它经常是区块中第一个交易。 奖励每21万个区块减半一次。 区块客户端的目标总是每小时产生6个区块。每2016个区块（大约2周）后，所有客户端（即矿工节点）收集当前区块的实际数目，和目标数目做对比，借此调整目标 Hash值，来调节产生区块的难度。 区块链的客户端总是接受最长链。在这里，长度指的是“难度”，而不是具有最大区块数量的链，可以防止某些人构造大量低难度的链制造分叉。 如果能够制造分叉，则可以在比特币网络里为所欲为，双花攻击只是其中之一。 创世区块讽刺了银行动用准备金而导致金融系统稳定性下降。创世区块中的50个比特币无法被花掉。简而言之，是每个客户端的创世区块不尽相同： 创世块的收益不可能被花掉，因为创世块是用代码表示的(这个巧合可能是故意的)，尽管如此，其50BTC收益还是被发送到地址：1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa。(译者按：创世块的收益花不掉，原因如下：比特币客户端把区块和交易分开存贮在两个数据库中，当客户端发现区块数据库为空时，用代码直接生成一个创世块，但是没有生成这个交易，所以客户端中的交易数据库中是没有发送到上述地址这个交易的，因而一旦收到要花掉该收益的交易时，都会拒绝，所以无法得到任何确认，就花不掉这50个币。出现这种情况很可能是中本聪故意的。) 区块和区块链把交易的world history break down 成了若干个小的时间片内的记录，而记录之间又因为数学相关性互相串联，形成了可追溯又抗篡改的强大特性。 区块的奖励有一个100个区块的成熟时间： 译者按：区块成熟时间(Maturation Time)，是指矿工产生一个新区块得到25BTC收益后，要等过了100个块后，才能使用这些币；这个100区块时间，即收到100个确认的时间，就是区块成熟时间。为什么要设这个时间？如果这个区块在分叉时变成了孤立区块，25个BTC的收益将消失，如果矿工挖到比特币后可以马上花掉，就会造成后续的一系列接收者损失比特币，因而设定了100个确认的限制，在这之后产生分叉的可能性非常小，即使产生分叉，也只会影响矿工收益，不会影响到其他人。 区块头的格式： 数据项 目的 更新时间 大小 Version 版本 区域版本号 更新软件后，它指定了一个新版本号（也就是说，客户端是有自己的版本号区别的） 4字节 hashPrevBlock 前一个区块Hash 前一区块的256位HASH值 新的区块进来时 32字节 恰好等于 SHA256散列的结果字符串长度 hashMerkleRoot Merkele根节点HASH值 基于一个区块中所有交易产生的默克尔树的 256位SHA值（也就是32个字节，32个 Ascii码） 接受一个交易时（也就是说在区块更新时会一直更新？） 32字节 恰好等于 SHA256散列的结果字符串长度 Time 时间戳 从1970-01-01 00:00 UTC开始到现在，以秒为单位的当前时间戳（类似 Unix epoch） 这个时间戳在全球范围内可能出现不准的情况，怎么办？ 每几秒就更新一次（终止于区块生成时？） 4字节（对毫秒而言不够，对秒而言就够了） Bits 压缩格式当前的目标值 当挖矿难度调整时 4字节（4 * 8 = 32位） 使用特殊的方法用4字节表达32字节的 SHA256 散列字符串 Nonce 随机数 从0开始的32位随机数 产生Hash时（每次产生Hash随机数都要增长，为什么？） 4字节 区块内包含许多交易，它们通过Merkle根节点间接被HASH，因为所有交易不可能直接被HASH，HASH包含一个交易的区块所花的时间，和HASH包含1万个交易的区块一样。 也就是说区块的Hash里包含了非常多的内容。 目标HASH值的压缩格式是一个特殊的浮点编码类型，首字节是指数(仅使用了5个最低位)，后3个字节是尾数，它能表示256位的数值。一个区块头的SHA256值必定要小于或等于目标HASH值，该区块才能被网络所接受，目标HASH越低，产生一个新区块的难度越大。 用特殊的格式用一个4字节的Bit来描述32字节的难度字符串。 上述大部分数据项对所有用户是一致的，可能在时间戳上有些区别。(译者按：该段的以下内容来自：)如果当前区块的时间戳大于前11个区块的的平均时间戳，并且小于“网络调整时间(Network-Adjusted Time)”+2小时，则认为该时间戳是有效的。其中的“网络调整时间”是指与你相连接的所有节点的平均时间。当节点A连接到节点B时，A从B处得到一个UTC标准的时间戳，A先转换成本地UTC标准时间保存起来，网络调整时间等于所有节点的本地UTC时间+所有相连节点的偏移量平均值，然而，该网络时间永远不会调整到超过本地系统时间70分钟以上。 时间戳确实是有用的，不能乱写时间。 Nonce随机数通常不同，但是它以严格的线性方式增长，从0开始，每次HASH时都会增长，当Nonce溢出时(此事经常发生)，生产交易的extraNonce项会增长，将改变Merkle树的根节点。 extraNonce有人认为会占用默克尔树的根，也有人认为会占用coinbase： A solo miner increments Nonce until it overflows. Then it increments extraNonce and resets Nonce. extraNonce is located in the coinbase transaction, so changing it alters the Merkle root. extraNonce is reset based on the time. nonce的增长过程请看接下来的解谜过程详解。 解谜过程详解： 可以在这个字符串后面添加一个整数值（在比特币中为nonce的标记），对变更后的字符串进行SHA256哈希运算，如果得到的哈希结果（以16进制的形式表示）是以”0000”开头的，则验证通过。为了达到这个工作量证明的目标。我们需要不停的递增值，对得到的新字符串进行SHA256哈希运算。按照这个规则，我们预计需要经过4251次计算才能找到恰好前4位为0的哈希散列。 “Hello, world!0” =&gt; 1312af178c253f84028d480a6adc1e25e81caa44c749ec81976192e2ec934c64“Hello, world!1” =&gt; e9afc424b79e4f6ab42d99c81156d3a17228d6e1eef4139be78e948a9332a7d8“Hello, world!2” =&gt; ae37343a357a8297591625e7134cbea22f5928be8ca2a32aa475cf05fd4266b7…“Hello, world!4248” =&gt; 6e110d98b388e77e9c6f042ac6b497cec46660deef75a55ebc7cfdf65cc0b965“Hello, world!4249” =&gt; c004190b822f1669cac8dc37e761cb73652e7832fb814565702245cf26ebb9e6“Hello, world!4250” =&gt; 0000c3af42fc31103f1fdc0151fa747ff87349a4714df7cc52ea464e12dcd4e9 比特币使用双重散列区块头：SHA256(SHA256(区块头))计算HASH，但你要注意字节序。这也就是其他客户端节点验算区块的过程。 例如：以下python代码用于计算某一区块的HASH值，使用2011年6月的区块号125552的最小HASH值。该区块头建立上述6个数据项之上，并且以十六进制的小端结尾方式连接在一起。 比特币是一个附带脚本的货币，也就意味着，汇款可以有附录。这个附录启发了智能合约区块链的诞生： 正如我们所见，每个比特币交易里都有一段比特币脚本语言。这个脚本在这篇文章里被简化成了类似于这样的话 “我Alice要给Bob 10个比特币”。 但是这个脚本语言可以同时被用来表述更复杂的交易。换句话说，比特币是一个可编程的货币。 挖矿硬件的演变：最开始的CPU挖矿，过度到GPU挖矿，最终演化到当前的ASIC（专业矿机）。目前为止，诞生了两种矿池协议： 参考文献：     "},{"title":"什么情况下 Scala 应该省略 Return 关键字","date":"2018-01-26T02:49:37.000Z","url":"/2018/01/26/%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B-Scala-%E5%BA%94%E8%AF%A5%E7%9C%81%E7%95%A5-Return-%E5%85%B3%E9%94%AE%E5%AD%97/","tags":["Scala"],"content":"&emsp;&emsp;一个很有意思的回答。 &emsp;&emsp;总体而言，如果我们能够分得清什么 last expression，我们就能推导出和编译器一样的返回类型结果。否则，我们应该显式地加上 return，这样既指定了实际返回类型，也指定了控制流上的返回点。"},{"title":"以太坊的硬分叉","date":"2018-01-24T06:55:57.000Z","url":"/2018/01/24/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9A%84%E7%A1%AC%E5%88%86%E5%8F%89/","tags":["区块链","Ethereum"],"content":"&emsp;&emsp;有四次计划内的软件升级，每次都是硬分叉：Frontier，Homestead，Metropolis，Serenity。 &emsp;&emsp;有一次意料之外的分叉（DAO 事件），制造出 ETH 和以太经典两种货币。 &emsp;&emsp;每次分叉都会造成矿工的迁移。旧链会因为流失算力而丧失安全性。 &emsp;&emsp;大都会分叉本来打算引爆难度炸弹，迫使矿工们从 PoW 共识算法移动到 PoA 共识算法，让以太坊进入冰河时代。但这个难度炸弹的引爆被延后了。 &emsp;&emsp;大都会同样引入了一个 PoS 的早期实施，Casper共存 算法允许每一百个区块里会有一个 PoS 区块。关于 PoS 算法，Vitalik 的解释是： 想象现在有 100 个人围着圆桌，其中有一个人拿着很多张纸，每张纸记录着很多笔历史交易信息。第一个人拿起笔签完后递给第二个人，第二个人也做出了相同的选择，如果大多数人做出了相同的选择，即都签署了同一张纸那么每一个参与者会获得1美元，当你做出和绝大多数人不同的选择时，那么你的房子就会着火！ &emsp;&emsp;如果真的不能阻止矿工停留在 PoW 上继续挖矿，那将会创建三种以太坊币：ETC、ETH-PoW、ETH-PoS，这对以太坊绝对是个噩梦！因为那不仅会降低以太坊的可信度和经济价值，还会稀释整个系统的哈希值比例，使得它更容易被黑客攻击！ 但如果能够把矿工移动到 PoS 网络上去，ETH 可以保持一致（通过新的账户映射做到？），不会有新的以太币。 &emsp;&emsp;挖出每个区块的奖励从5个 ETH 减少到3个。"},{"title":"Scala 泛型中的协变（covariant）与逆变(contravariant)符号","date":"2018-01-19T09:10:31.000Z","url":"/2018/01/19/Scala-%E6%B3%9B%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%8D%8F%E5%8F%98%EF%BC%88covariant%EF%BC%89%E4%B8%8E%E9%80%86%E5%8F%98-contravariant-%E7%AC%A6%E5%8F%B7/","tags":["Scala","泛型"],"content":"&emsp;&emsp;看到这个问题《+- Signs in Generic Declaration in Scala》下面有一个很有意思的答案： “+” and “-“ mean covariant and contravariant types respectively. In short, it means that: PartialFunction[-A1, +B1] &lt;: PartialFunction[-A2, +B2] only if A1 :&gt; A2 and B1 &lt;: B2, where &lt;: is subtyping relationship. &emsp;&emsp;简而言之，-意味着逆变成立，+意味着协变成立。"},{"title":"布隆（Bloom）过滤器","date":"2018-01-17T13:14:53.000Z","url":"/2018/01/17/%E5%B8%83%E9%9A%86%EF%BC%88Bloom%EF%BC%89%E8%BF%87%E6%BB%A4%E5%99%A8/","tags":["散列"],"content":"&emsp;&emsp;本文还是对《区块链：原理、设计与应用》的一个基础技术的总结和摘录。 &emsp;&emsp;散列的本质，是把任意内容，映射成固定长度的内容域里的某一个内容。 &emsp;&emsp;布隆过滤器的本质，是在常数时间内回答，“一个元素是否在一个集合内”的问题。 直观的方法及其缺陷&emsp;&emsp;假设我们总可以把任意内容映射到某一个数组的 item 上，那么只要看看那个数组的 item 是否为空，就可以确认某一个内容是否存在。然而现实之中，一个数组总是会产生冲突，操作性能会因为局部冲突而产生退化。 多重散列的布隆过滤器&emsp;&emsp;布隆过滤器的原理很简单，就是插入元素时，在一个容量为 m 的bit数组上， 用 k 个散列函数对一个输入标记 k 个 bit，而查找元素时，再用 k 个散列函数来寻找 k 个 bit，若这 k 个 bit 都被标记过了，则这个内容存在。 &emsp;&emsp;普通的布隆过滤器是不应该支持删除的，因为删除一个 bit 可能顺便删除掉其他内容的 bit。但如果把 bit 换成一个计数器，那么就可以考虑删除了。这也就会产生 counter bloom filter。 &emsp;&emsp;当hash函数个数k=(ln2)*(m/n)时错误率最小。 &emsp;&emsp;实际上，不管是散列算法，还是布隆过滤器，基本思想是一致的，都是基于内容的编址。Hash 函数存在冲突，布隆过滤器同样存在冲突。这就造成了两种方法都存在着假阳性误报问题（false positive），但绝不会存在假阴性漏报的问题（false negative）。布隆过滤器的误报率比单纯的散列算法低得多。 一个布隆过滤器相关的面试题 问题实例：给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？ 根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。"},{"title":"Merkle Tree","date":"2018-01-17T12:42:18.000Z","url":"/2018/01/17/Merkle-Tree/","tags":["区块链","散列"],"content":"本文还是对《区块链：原理、设计与应用》的一个基础技术的总结和摘录。 默克尔树的特点&emsp;&emsp;默克尔树是多层散列表（Hash List），目的是做多层摘要，把对多个 item 的校验，转化为对一个 item 的校验。 &emsp;&emsp;默克尔树可以是二叉树，也可以是多叉树。 &emsp;&emsp;叶子节点是 item 的 value 和 value 的散列值。中间每一层的值，都是它们子女散列值的和的散列值-多叉树的结果就是多个散列值加法的结果的再散列，孤儿的计算结果就是在孤儿散列值上进行再散列。 默克尔树的用途快速比较大量数据&emsp;&emsp;两组数据的排序后构建默克尔树，只要比较两个树的root 就可以确定两组数据是否一样。 快速 diff&emsp;&emsp;如果默克尔树是二叉树，则只要从 root 开始做二分的 diff，就能快速定位到不一致的叶子节点。这在 p2p 传输文件数据的场景里非常有用。实际上 rsync 的 diff 算法就是一个一层的 Hash List ， 零（部分知识）知识证明&emsp;&emsp;所谓的零知识证明，就是不告诉 verifier 验证一个论断真伪的全部信息。只提供部分信息，就可以让 verifier 相信某个事情是真的。 &emsp;&emsp;在默克尔树中，我们可以剪去部分枝节，只向 verifier 提供某一个叶子节点通往 root 所需要的 node，然后 verifier 就能断定一个特定的叶子 node 是否在此默克尔树中。也就是说，verifier 要求公允的验算可以让它自己来，我们只提供部分信息。在我看来，这不能算是零知识证明，只能算是部分知识证明。 默克尔树在比特币中的用途&emsp;&emsp;在比特币中，每个区块里都存有所有交易的完整信息。这些完整信息又可以组成默克尔树的叶子节点，进而组成默克尔树。而每个区块中80bytes的区块头中，都含有五个数据： 上一个区块的散列值 时间戳 挖矿难度值 工作量证明随机数(nounce) 包含该区块交易的默克尔树的 root &emsp;&emsp;轻节点可以只下载这个头，就能做到 SPV（Simplified Payment Verification）。具体过程如下： 验证某个交易是否真实存在时，理论上，用户可以通过以下方式进行验证：0. 从网络上获取并保存最长链的所有block header至本地； 计算该交易的hash值tx_hash； 定位到包含该tx_hash所在的区块，验证block header是否包含在已知的最长链中； 从区块中获取构建merkle tree所需的hash值； 根据这些hash值计算merkle_root_hash； 若计算结果与block header中的merkle_root_hash相等，则交易真实存在。 根据该block header所处的位置，确定该交易已经得到多少个确认。 优点：极大地节省存储空间。减轻终端用户的负担。无论未来的交易量有多大，block header的大小始终不变，只有80字节。按照每小时6个的出块速度，每年产出52560个区块。当只保存block header时，每年新增的存储需求约为4兆字节，100年后累计的存储需求仅为400兆，即使用户使用的是最低端的设备，正常情况下也完全能够负载。 默克尔树在以太坊中的应用&emsp;&emsp;以太坊中实际上有三种默克尔树： transaction tree reciept tree state tree 这三种 tree 可以构建一个很强大的客户，允许轻客户端轻松地进行并核实以下类型的查询答案： 这笔交易被包含在特定的区块中了么？ 告诉我这个地址在过去30天中，发出X类型事件的所有实例（例如，一个众筹合约完成了它的目标） 目前我的账户余额是多少？ 这个账户是否存在？ 假如在这个合约中运行这笔交易，它的输出会是什么？ &emsp;&emsp;第一种是由交易树（transaction tree）来处理的；第三和第四种则是由状态树（state tree）负责处理，第二种则由收据树（receipt tree）处理。计算前四个查询任务是相当简单的。服务器简单地找到对象，获取Merkle分支，并通过分支来回复轻客户端。 &emsp;&emsp;第五种查询任务同样也是由状态树处理，但它的计算方式会比较复杂。这里，我们需要构建一个Merkle状态转变证明（Merkle state transition proof）。从本质上来讲，这样的证明也就是在说“如果你在根S的状态树上运行交易T，其结果状态树将是根为S’，log为L，输出为O” （“输出”作为存在于以太坊的一种概念，因为每一笔交易都是一个函数调用；它在理论上并不是必要的）。"},{"title":"不常见的 Java 集合类的用法","date":"2018-01-04T14:20:35.000Z","url":"/2018/01/04/%E4%B8%8D%E5%B8%B8%E8%A7%81%E7%9A%84-Java-%E9%9B%86%E5%90%88%E7%B1%BB%E7%9A%84%E7%94%A8%E6%B3%95/","tags":["Java"],"content":"Sorted 集合##Sorted集合 Navigable 集合Navigable Priority集合Priority Identity 集合##Identity SkipList 集合跳表系列。 DelayQueue延迟队列"},{"title":"CoffeeScript2 简明教程","date":"2017-12-29T11:50:37.000Z","url":"/2017/12/29/CoffeeScript2-%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/","tags":["CoffeeScript"],"content":"写在前面的话&emsp;&emsp;之前在工作群里看到一个排行榜: &emsp;&emsp;在羡慕美国同行的薪水超高的同时，也奇怪为何 CoffeeScript 的生命力超过了自己之前的想象。 &emsp;&emsp;JavaScript 本是 Brendan Eich 在10天内做完的急就章之作，在设计之初，即带有大量的大意设计和缺陷。可以说，即使到了 1.5 时代，JavaScript 作为一门现代语言，依然要提防 Douglas Crockford 在《JavaScript:The Good Parts》中提出的种种陷阱。历年来，各路框架作者和超集语言作者，都不断在 JavaScript 上做出各种各样炫目的模式用法和衍生方言，足见其可提高空间之大。包括 CoffeeScript/TypeScript/Dart/Elm 等解决方案的出现，其实就是在倡导使用 Pre-JavaScript 的语言编写抽象逻辑，然后编译成原生 JavaScript 运行。 &emsp;&emsp;CoffeeScript 即是 JavaScript 1.5 时代的 Pre-JavaScript 语言中的佼佼者。其设计的语法和句法利用了 Ruby 和 Python 的优点，然而又能去除 JavaScript 中容易产生二义性的部分，可以认为是一种变换写法的 JavaScript 语言子集，也就是美化过的“The Good Parts”。CoffeeScript 的定位，本来是一门 little language，它的目的不是取代 JavaScript，而是用更好的风格来编写 JavaScript，因此其最终目标也是编译成 JavaScript。因此，很多人都把它当做下一代 JavaScript 标准出现以前的过渡用法。 &emsp;&emsp;2015年以来，ES6.0以及后来的 ES2015等标准的制定以及现代浏览器对原生语法支持的逐步实现，使得大部分众望所归的语言特性都可以在原生 JavaScript 中找到。旧的 CoffeeScript(CoffeeScript 1) 编译的结果已然不兼容新的ES2015的发展方向，CoffeeScript 作为一个过渡时期的产物，似乎已然完成了它的历史使命。 &emsp;&emsp;但 CoffeeScript 的发展并没有停止。CofffeeScript 紧随现代 JavaScript 推出了 CoffeeScript 2。这一版本的 CoffeeScript 不仅保留了大部分上一版本 Ruby/Python 风格的优美语法，也大量兼容了 ES2015 的新特性（除了 import/export 这个在前后端实行起来经常需要转义和 polyfill 的特性以外），成为了一门更加现代的 little langugage。 &emsp;&emsp;可能有读者会问，既然已经有了 ES2015，为什么还要再来一门编程语言呢？笔者认为，不同的编程语言，其实是不同的思考和设计工具。虽说图灵完备的语言总是等价的，但通过另一个角度来对问题和解建模，可以更有效地提高自己对原本掌握的语言的理解。因此，了解 CoffeeScript 的设计和使用理念，一定能对使用原生 JavaScript 编程有所脾益。 &emsp;&emsp;本文基本上是 coffeescript.org 在2.0版本后文档的摘译和简化。每一个小的知识点会配上若干的代码块，两个相连的代码块总是代表一段 CoffeeScript 代码和它编译生成的 JavaScript 代码。阅读本文需要一定的 JavaScript 基础。 简明教程CoffeeScript 是什么？CoffeeScript 是一门编译成 Javascript 的小语言。在 Java 风格的笨拙锈色之下，JavaScript 有着一颗华丽的心。CoffeeScript 试图用简明的方式，把 JavaScript 中的精粹部分表现出来。 CoffeeScript 的黄金法则是：“它只是 JavaScript”。代码会被一对一地编译成对等的 JS，不会有运行时解释。可以在 CoffeeScript 中无缝地使用任何现存的 JavaScript 库（反之亦然）。编译输出是可读，美化打印过的，而且趋向于和等价的手写 JavaScript 跑得一样快。 安装和试用 coffee最新版本：2.1.0 假设我们有一个 test.coffee 的文件如下： 运行coffee -c test.coffee就会得到一个test.js 文件如下： 缺省的 coffee 编译结果为了最大限度地保证不污染顶层的变量，总是会把文件编译成一个立即执行的函数，使得所有变量的声明和使用局限在一个小作用域里面。当然，它也有个 bare 模式可以去掉这种立即执行函数，如果使用import和export 的功能，也可以自动进入 bare 模式。这个模式的细节很繁琐，请读者自行查阅文档。 普通函数 使用-&gt;生成 function 函数。带默认值的参数，同样是 ES2015 的内容。 字符串 CoffeeScript 的字符串同 JavaScript 一样，可以用&quot;和&#39;分界。用”引用的字符串，可以用#&#123;&#125; 来进行内插（甚至可以在对象的key 里执行内插）。用’引用的字符串是字面量。 双引号的多行字符串可以自动被编译器连接起来，当然，所有的缩进都失效了： 使用三引号&quot;&quot;&quot;和三个单引号&#39;&#39;&#39;，还可以生成保留格式（特别是缩进）的块字符串： 用双引号制造出来的块字符串，也一样支持字符串内插功能。 对象和数组CoffeeScript 支持 JavaScript 格式的对象和数组字面量，也支持更简明的无逗号的、依靠换行的字面量： CoffeeScript 也支持 ES2015的字面量语法： 注释聪明的读者可能已经发现了注释应该怎么写，但这里还是要总结下。CoffeeScript 里的注释其实是脚本语言的注释的应用： 值得注意的是，###支持了类型注解。 词法作用域和变量安全聪明的读者可能也发现了，在 CoffeeScript 中，是不需要手写var这样的关键字的。实际上，ES2015为了解决过去的 JavaScript 中不存在块级作用域这样的问题，专门提出的const和let解决方案，CoffeeScript 也不支持。在有多层变量的时候，CoffeeScript 会自动地推导变量的作用域，保证内层的变量绝不会污染任何外层变量。每个变量的实际作用域，会被限制在它首次被声明的地方。JavaScript 无意之中忘加var关键字而污染全局变量的情况便不复存在了。 outer 因为在外部作用域里已经声明过了，所以不需要重复声明。而inner只是在内部作用域里被使用，所以还额外声明了一个函数内的 inner来专门隔离它的作用域。外部专门声明的var inner其实就是一个编译器为了谨慎做的声明顶部上推，在这个编译的例子里不影响任何语义。 因为无法使用var关键字，所以实际上我们是无法遮蔽（shadow）住外部变量的，只能在内部作用域引用外部变量。 If,Else,Unless, 与条件赋值if/else 里可以不用写小括号和大括号，使用 python 式的缩进定界，用户也可以使用单行 if 和 unless。 不定参数语法Java 程序员里面可能都习惯了类似 … 语法的不定参数语法来了。在 CoffeeScript 中它被称为 Splats 参数。ES2015吸收了这一语法，做出了 rest 参数。 循环和表处理CoffeeScript 的 for 循环可以处理数组、对象和 range，有点类似 Python。而且，它的 for 循环是有返回值的。 特别地，CoffeScript 提供一个低级的 while 循环，它同样是带有返回值的。 JavaScript 老手可能会很习惯匿名函数立即执行的用法，CoffeeScript 用 do 关键字支持把循环和匿名函数立即执行结合起来： 数组分片和 range 分片CoffeeScript 同样以索引操作符的形式（类 Python 和 C++）支持对数组的 slicing。 一切皆表达式表达式特别于普通语句的地方，就是它们总是可以求值的。诸位读者可能已经注意到，CoffeeScript 中几乎没有 return。在函数中，最后一行表达式，就是整个块的表达式返回值，这点也是 CoffeeScript 从 Ruby 那里吸收来的特性。 比较有意思的是，try/catch 也是可以有返回值的： 当然，有些语句在 JavaScript 中也是不能当做表达式的，比如break、continue和return，如果你在代码块中使用了它们，CoffeeScript不会试图进行转换。 操作符与别名==操作符经常引起出乎意料的、与其他语言中表现不一致的行为。所以 CoffeeScript 里没有==，而会试着进行再编译。把==编译成===，!=编译成!==。另外，它还提供了可读性更好的两个操作符，is会被编译为===，isnt 会被编译为isnt。 除此之外，还可以用not作取反操作符!的别名。 对于逻辑操作符，and会被编译为&amp;&amp;，or会被便以为||。 在 JavaScript 中，有时候条件语句需要另起一行或者在单行内用分号断句，但CoffeeScript 中的 then 就可以帮我们把条件语句（特别是 while、if、switch 的结构中）和被执行语句连起来。 同YAML中一样，on和yes是布尔值true的同义词，off和no是布尔值false的同义词。 同其他脚本语言一样，unless是if的反写。 同 Ruby 一样，@property可以当做this.property来用（少写一个字符）。 可以用in来做数组元素的存在检查，用of来做 JavaScript 键值对的存在性检查。 在for循环中，from关键字会被编译成 ES2015 的of。 为了简化数学表达式，**代表幂运算，而//执行地板除法（同 Python 一样，去掉小数向下取整） 存在操作符在 JavaScript 中确认一个变量是否存在是很困难的。因为if (variable) 不仅会在变量不存在时生效，在变量为0值（0,空字符串，false）时也会生效。CoffeeScript 的?操作符只在变量为null和 undefined的时候返回false，这很像 Ruby 中的 nil？(实际上高版本的 ES 也会有一个叫 Null Propagation Operator的类似特性)。 这样我们就可以做更加安全的条件赋值了（比a = a || value安全）。 注意看，一个?被翻译成了对undefined和null的严格求不等!==。但是，?与unless搭配的时候，就会被翻译成==。 可以用存在操作符来达到其他语言中经常出现的流利调用，流利调用失败用户会得到undefined而不会出现烦人的空指针（在 JavaScript 中实际上是不能在undefined上调用特定成员的TypeError）异常： 无括号的链式调用用.和断行缩进可以像其他脚本语言一样进行无括号链式调用： 解构赋值用过 ES2015 以后版本的读者应该能够理解什么是解构赋值了： 解构赋值搭配上多返回值的函数调用也很有用： 解构赋值对任意深度嵌套的数组和对象也是一个有用的特性： 解构赋值也可以搭配 splats 不定参数使用： 取数组末尾元素的例子： 与构造函数结合的例子： 绑定（胖）函数用-&gt;定义的函数会直接转化为普通的function。 JavaScript 中this指向的值可以被动态绑定（这真是由来已久的弊病）。有经验的读者肯定能理解，我们在传递回调的时候， 原始this经常会丢失，变成新作用域里的this。 而使用胖箭头=&gt;定义的函数，可以把当前上下文的this绑定到函数里（好像调用了一个隐式的bind一样）。当我们在 Prototype 和 JQuery 之类的毁掉库里使用函数时，这回变得非常有用。 如果我们在这里使用-&gt;，函数里的@customer实际上就会指向undefined。因为$(‘.shopping_cart’) 这个东西指向的是 dom 变量，很可能没有customer这个属性。 胖函数是 CoffeeScript 里最受欢迎的特性，也被 ES2015 吸收了，使用 CoffeeScript 中的=&gt;就会被编译成JavaScript 中的=&gt;。 生成器函数CoffeeScript 通过yield关键字支持 ES2015中的generator functions。CoffeeScript 中没有function*()&#123;&#125;这样的无意义结构，只要有yield就够了。 yield当然也可以配合for...from使用： 异步函数ES2017 的异步函数是通过await支持的。同生成器函数一样，CoffeeScript 中的不需要async关键字，只要有await就行了。 类CoffeeScript 1 就提供了class和extends关键字，作为原型相关函数的语法糖。ES2015吸收了这两个关键字，CoffeeScript 2 直接把这两个关键字编译成 ES2015的类。 可以用@开头的函数来定义静态方法： 原型式继承ES2015提供了一个短路操作符给原型链相关的操作： Switch/When/ElseCoffeeScript 中的switch不用担心忘记写break出现错误的跳转： 在之前读者已经看到了 CoffeeScript 中大量的语句都可以带有返回值，switch也不例外。以下的例子里面，switch 后面连表达式都没有： Try/Catch/FinallyCoffeeScript 中的try/catch/finally块可以完全不带大括号： 链式比较CoffeeScript 从 Python 中借来了链式比较，这样范围比较的语句就变得更加简单了。 块状的正则表达式我们已经看到了块状（多行）字符串和注释，CoffeeScript 同样支持块状正则表达式。模仿自 Perl 的/x修饰符，CoffeeScript 使用///来对多行表达式定界，这样多行的正则比单行的正则就更加可读了： 标签化的模板字面量CoffeeScript 支持 ES2015中的标签化模板字面量，提供了自定义的字符串内插的能力。 模块CoffeeScript 中的模块和 ES2015中的模块很相似，都是import和export语法： 嵌入式 JavaScript在 CoffeeScript 中可以用倒引号（`）直接引用 JavaScript 代码： 用三个倒引号可以很轻松地引用一大块 JavaScript 代码： JSXCoffeeScript 不需要专门的插件或者设置，就可以理解 JSX。 同普通的 JSX 一样，&lt;和&gt;指明了XML 元素，由 &#123;和&#125;包围的代码会被内插替换。为了避免和大于、小于的比较混淆，类似i &lt; len的代码必须带空格，不能写作i&lt;len。编译器有时候能够在你忘记加空格的时候，猜到你的意图，但不要心怀侥幸，还是要尽量自己加空格。 类型注解Flow 风格的注释式类型注解可以在 CoffeeScript 中提供静态类型检查的能力（TypeScript 的粉丝可能要头痛了）： 如果用户已经成功安装了 Flow 和最新的 CoffeeScript，可以用如下命令进行类型检查： --bare --no-header非常重要，因为 Flow 要求文件中的第一行是// @flow注释。"},{"title":"client 与 server","date":"2017-12-24T06:29:59.000Z","url":"/2017/12/24/client-%E4%B8%8E-server/","tags":["JVM"],"content":"client 模式默认的jit编译器，c1。默认的gc：serial-serial old。需要更短的启动时间和初始堆大小，能做更保守的优化。默认-Xms是1M，-Xmx是64M。适合 GUI 程序。 server 模式默认的jit编译器，c2。默认的gc：ps-serial old即 PS MarkSweep（可以启用parallel old）。需要更长的启动时间和更大的堆大小，能够做更有深度的优化。默认-Xms是128M，-Xmx是1024M。适合长时间运转的程序。 64 位JVM#在64位 JVM 上有个 -d64 的模式，实际上就是禁止client模式单独启动，只允许server模式或者混合编译模式启动的模式。"},{"title":"分布式事务","date":"2017-12-22T06:16:19.000Z","url":"/2017/12/22/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","tags":["系统架构"],"content":"问题定义对经典的电商场景而言：下单是个插入操作，扣减金额和库存是个更新操作，操作的模型不同，如果进行分布式的服务拆分，则可能无法在一个本地事务里操作几个模型，涉及跨库事务。 CAP 定义根据 Eric Brewer 提出的 CAP 理论： Consistency：All Nodes see the same data at the same time Availability：Reads and writes always succeed Partition tolerance：System continues to operate despite arbitrary message loss or failure of part of the system 由此诞生三种共识/分布式一致性算法： CA = 2PC，即 2PC 无法分区容错 AP = Gossip，即 Gossip 无法保证一致性 CP = Paxos，即 Paxos 无法保证吞吐 在分布式场景下，网络分区不可避免。网络分区带来一个不可解决的基本问题：执行本地事务的一个节点，无法确知其他节点的事务执行状况。 BASE 定义强一致性 = 共识算法 + 复制状态机，2PC更更新操作成功并返回客户端完成后，所有节点在同⼀一时间的数据完全⼀一致，不不能存在中间状态。例例如⽤用户下单操作，库存减少、⽤用户资⾦金金账户扣减、积分增加等操作必须在⽤用户下单操作完成后必须是⼀一致的。不不能出现库存已经减少，⽽而⽤用户资⾦金金账户尚未扣减，积分也未增加的情况。 弱一致性系统在数据写⼊入成功之后，不不承诺⽴立即可以读到最新写⼊入的值，也不不会承诺多久之后可以读到。但会尽可能保证在某个时间级别（⽐比如秒级别）之后，可以让数据达到⼀一致性状态。 最终一致性 柔性事务是弱⼀一致性的⼀一个特例例，系统会保证在⼀一定的时间内，能够达到⼀一个数据⼀一致的状态。业界在⼤大型分布式系统的数据⼀致性上⽐比较推崇的模型。 事务模型2PC当代的 2PC 有两种实现方案：经典的 XA 事务，谷歌的 Percolator。 XA 事务简述对于经典的 XA 事务，⼆阶段提交协议，即将事务的提交过程分为两个阶段来进⾏处理：准备阶段和提交阶段。事务的发起者称协调者（coordinator），事务的执⾏者称参与者（participant）。当⼀个事务跨多个节点时，为了了保持事务的原⼦子性与⼀致性，需要引⼊入⼀个协调者（Coordinator）来统⼀掌控所有参与者的操作结果，并指示它们是否要把操作结果进⾏真正的提交或者回滚。 2PC 的 FailoverSafety：不会出现一个 participant 提交一个 participant 回滚的情况，即无相反态。Liveness：最终一个分布式事务处于全局提交或者回滚的状态，即无悬垂态（2PC 中的阻塞操作可能引发异常等待）。 一个典型的 2PC 的例子一个 TC 的主要操作有： 对 participant prepare、对 participant confirm、对 participant abort/cancel。 一个 participant 的主要操作有：返回 ok，返回 not ok，返回 commit 成功，返回 commit 失败，返回 abort/cancel 成功，返回 abort/cancel 失败。 节点超时和宕机会严重降低系统的整体吞吐量。节点中要不断引入重试才能度过各种各样的宕机的困难。 如果没有重试和超时，则任一 participant 节点失灵，都可能导致已经做了 pre-commit 的其他 participant 永久 hang 住，因为 coordinator 会收集不到足够的签名（vote/ballot）而 hang 住。 而如果 coordinator hang 住，结果会更糟，因为再起一个 coordinator 也无法让 hang 住的节点真正提交或者回滚。 这两种情况都是死锁，只有超时检测 + cancel 操作能解决这个问题（见下方的 TCC）。 中心化和去中心化的 2PC如果存在一个没有业务逻辑的 coordinator，则这种 2PC 是中心化的；如果某个 participant 自己带有 coordinator 的职能，则这种 2PC 可以认为是近于去中心化的。 3PC 这幅图的出处在这里。 三个阶段：CanCommit -&gt; preCommit -&gt; doCommit 第一阶段锁定资源。第二阶段进入自动提交的轨道。第三阶段协调者指示手动提交。 3PC是各个阶段都有超时设置的算法，而且在特定的超时阶段–第二、第三阶段，如果协调者察觉到超时，都会尽量发出 abort 指令令事务放弃提交。 但比较特别的是，如果 cohorts（也就是participants）在precommit ack 以后，没有收到 docommit 的命令，它居然就径自根据超时的策略提交了。如果这个时候有abort命令在网络通信中丢失了，岂不是造成了数据不一致？这个问题的一个勉强的答案是，因为在第一阶段协调者 CanCommit 的询问得到了一个全局的yes才能进入这一阶段，所以cohorts只能在超时的时候，姑且走下去。 3PC 的做法，使用一个 canCommit 的阶段来询问，这样一些 cohorts 不在线的问题可以被解决，减少了预扣资源的浪费。 而引入超时，则可以避免死锁。 TCC 所谓的 TCC，指的是： Try：完成所有业务检查（一致性），预扣业务资源(准隔离性)。 Confirm：确认执行业务操作，不做任何业务检查，只使⽤用Try阶段预留留的业务资源 Cancel：取消Try阶段预扣的业务资源。 Try，Confirm，Cancel。增加的是 cancel 而不是 cancommit 预问阶段，所以实际上还是实现了2PC，而且两个 C 本质上是第二阶段的正反操作。 TCC 对 2PC 的改进是在业务层做资源锁定，这种资源锁定不是直接面向数据库的，通过抽象允许了各种资源通过各种方式来混合在一个分布式事务里协同。 本地模式其中 tcc 接口不一定要实现在被调用方，可以实现在调用方（类 RMI 模式，bingo！） try 和 catch 的使用方法要注意 try 的独立 try-catch 块，且 cancel 时要先检查 try 的状态。 空回滚和事务悬挂要注意空回滚的忽略问题和事务悬挂的超时检查且释放的功能： 适用 TCC 的业务场景 对事务隔离性有要求的服务，Try 阶段的存在可以很好地保证 TCC 事务之间的隔离性 - 这里的隔离指的是 Try 一定要带有预扣资源的功能（而不是像 MVCC 那样的 SNAPSHOT ISOLATION）。 对性能有要求的服务，TCC 仅第一阶段加锁，因此性能较好。 新服务，没有陈旧的历史包袱，可以方便地抽象出 TCC 的三个阶段。 改造成本小，没有历史包袱的服务。 Saga 模型 假设一个分布式场景涉及三个服务，我们要有随时能够从某个失败链条上反向补偿回去，保证全局追平的能力。 这里面要考虑正反操作的请求要线性编排，严格有序。如果有必要，还是要加入类似 update where 的语义。 saga 的中心化实现SAGA 通常有两种模型，一种是事务协调器器集中协调，由它来收集分支状态并发号施令；另⼀种是基于事件订阅的⽅式让分支之间根据“信号”进⾏交互（我们经常使用的一个服务用一个 MQ 来驱动下一个的服务来追平状态，是一种去中心化的 saga 模型。）。 ![saga 的中心化实现.jpg](saga 的中心化实现.jpg) saga 的两种恢复策略 从这里至少可以抽象出三种接口 compensation、reverseCompensation、needRetry。 saga 的适用场景 业务流程多、业务流程⻓，期间调⽤用若⼲干个分⽀支事务。 ⽆法抽象出 TCC 的 Try 阶段（即无法预扣资源，实现隔离），但是可以很方便地实现补偿⽅法。 要求框架支持业务流程既能向前重试⼜可以逆序回滚的（正逆向幂等）。 对不不同事务间的隔离性要求不不高，可以在业务层⾯面通过代码解决的。 长事务不能容忍长期锁定，又不需要长期锁定，可以考虑 saga（现实中的分布式事务往往暗合 saga 模型）；反之则可以使用 tcc。 阿里的 Seata 模型衍生的数据库中间件跨库事务首先要把物理 sql 的改写逻辑抽象化，然后在这里实现一个具体的 然后要在事务的前后加上 WAL： 然后就可以实现跨库事务了： 但跨库事务需要保证本地事务有写隔离，类似全局意向锁： 局部的意向锁实现： 带事务消息中间件（Kafka 的方案）-消息事务 从 producer 到 broker：要有 ack 机制。消息要么做好顺序编号生成机制，要么干脆根据消息的内容生成 id。broker 用 ack 给 producer 确认，producer 自己做超时重试（借鉴 TCP 协议的思路）。broker 可以通过一个数据库的主键依赖，或者内存里的 set 对消息 id 进行去重(实际上 Kafka 是通过 leader replica 写入磁盘的方式自己维护了这样一个数据库)。可以认为 producer 到 broker 天然是幂等的，得到了间接的 exactly-once。 broker 到 consumer：同样要有 consumer 到 broker 的 commit 机制。重点的问题是，consumer 自己做好本地的事务和 commit 操作的原子性。这种原子性如果无法保证（在本地事务完成后未 commit 程序即崩溃），则要考虑在本地做 message id 的去重。即在本地单独维护一张 message 表，在本地事务的原子性操作里囊括对 message 表的同步更新，更新完成后再 commit 到 broker，如果 commit 到 broker 失败，则下次再收到这条消息时，新的事务也会失败。可以认为 broker 到 consumer 并不天然是幂等的，如果消息不天然是幂等的，则需要做本地事务结构的修改。 换言之，好的，完整的带事务的消息中间件，只有带上事务性的 RDBMS 这一种基本解。exactly-onece 几乎必然引起性能的下降。但因为 producer-broker、broker-consumer 之间都是局部事务，所以性能比起两段提交，三段提交高了很多。 在流处理里面，exactly-once 例来是个难题，只有 Kafka-Stream 真正做到了，如果不是走 Stream，则起码客户端需要做单独处理。 基于本地事件表系统的 scan and send 机制 本质上还是把本地事务和事件在同一个事务里面写入本地数据库，然后写一个单独的服务来 scan 这个 event 表。对业务侵入性很大。 基于外部事件表系统的 prepared and send 机制 大致上就是： 把消息 enqueue 给broker，让消息进入 prepared 发射状态。 在本地事务执行完成或者失败了以后，发送 confirm 或者 cancel消息给 broker。 broker 自己也定时扫描 enqueued 的 message，如果超时，按照既定配置来使用消息（通常是准备一个 fallback 接口，在接口里决定硬是发射消息或者取消发射）。 这其实是 broker 不提供 ack 机制的时候的一种折中。先 prepare 再 confirm，其实是一种变相的小分布式事务，主事务是本地的数据库事务，辅事务是 broker 事务，辅事务预先分配锁定资源，由主事务激发释放。 RocketMQ 的分布式事务也是采取这种外部事件表的形式。早期是基于文件系统来实现的，后期是基于数据库来实现的。 我在 bridgemq 问题下的评论以下评论是错的~~感觉上这个问题在消息发送方的地方被做得复杂化了。根据我个人浅薄的理解，这里 bridgemq 的存在，是把这种（事务加 MQ）的解决思路，做成了一个单独的服务，即很多人所说的外部事件表或者外部消息表。在这个架构里面，本地事务 + bridgemq，其实就是 jta 里面的所谓的预扣资源 + 确认的模式：1 bridgemq 预扣资源。2 本地事务预扣资源。3 本地事务提交或失败。4 bridgemq 提交或失败。只不过这里的设计是一个只有两个服务的小 JTA，所以事务的颗粒度更小，而 bridgemq 作为辅助事务，其生命周期完全是由本地事务这个主事务决定的，所以主事务的：1 性能更更好，2 被 bridgemq 耦合造成的改造更小。而且这个 bridgemq 的设计，本身只解决了发送方 exactly-once 的问题，正如下面评论所说的，consumer 的 exactly-once 还是要靠业务方自己解决–实际上还是做消息的幂等要求设计或者准备本地事务去重。实际上，Kafka 当前版本（1.0以后的版本），有了一个全局 exactly-once 的解决方案。据他们估计，可以在 Kafka Stream 里面做到 exactly-once（）。即使是在非 Stream 的场景里面，他们的 Producer API 也是支持 exactly once 的。具体地说,新版本的 Producer实际上给每个消息准备了一个序号（sequence no），producer 大部分情况下通过 ack 机制来保证 at-least-once，重复消息，就像 tcp 协议一样通过序号在 broker 这端去重（TCP 是在内存里去重的，Kafka 还支持 leader replica 在分布式场景下用文件系统去重）。这样就达到了 producer 端的 exactly-once 语义，保证了只要通信是可达的，producer 总能正确地发送消息到 broker。那么套用到这篇文章的场景里面，这个问题就非常简单了，不需要 bridgeMQ 的帮助，只要： 本地事务先执行成功。否则中断流程。 在 producer 端使用 exactly-once 语义发送消息。发送端的事务性就达到了。~~ 在事务里调 rpc 的铁律 无论如何，不依靠补偿和反查，不可能保证事务和网络 io 原子性成功或者失败。而且这两者不可偏废，要引入一个终态管理机制，调度补偿和反查。 尽量让所有的 rpc 分成两段，前半段在事务之前，后半段在事务之后执行，在后半段上加上补偿，是最简单的方法。 如果无法做到第二条，则把求锁类 rpc 放在事务之前，解锁类 rpc 放在事务之内，把初始化任务类事务放在 rpc 之前，把更新结果类事务放在 rpc 之后。 在事务里实现 rpc，只有实现 at-least-once 的语义时有用。很多时候不加任务进行局部重试，或者上游全局重试的话事务太大-或者事务要幂等问题，勉强可以使用这种 at-least-once 语义。 分布式 xajava7 xa 本文重点参考了： 《分布式事务：不过是在一致性、吞吐量和复杂度之间，做一个选择》 《Exactly-once Semantics are Possible: Here’s How Kafka Does it》 《从银行转账失败到分布式事务：总结与思考。 除了Paxos，没有真正的分布式一致算法。 《JTA 深度历险》。 《分布式系统的事务处理》 "},{"title":"函数缓存 memoize","date":"2017-12-17T06:21:07.000Z","url":"/2017/12/17/%E5%87%BD%E6%95%B0%E7%BC%93%E5%AD%98-memoize/","tags":["函数式编程"],"content":""},{"title":"读书--拓展你的认知边界","date":"2017-12-15T10:14:50.000Z","url":"/2017/12/15/%E8%AF%BB%E4%B9%A6-%E6%8B%93%E5%B1%95%E4%BD%A0%E7%9A%84%E8%AE%A4%E7%9F%A5%E8%BE%B9%E7%95%8C/","tags":["自我提升"],"content":"新的书在不断打破认知边界，以前都是机械的方法论世界观的书，现在出了打通一切关于进化的书。 如何读书？#《如何阅读一本书》，《快速阅读》。 如何选书？跟主题，跟作者，跟大牛。不要看编著的书。李善友的书单。 怎么有时间去看书？亚马逊的推荐比京东准。找固定板的时间看书。 Kindle 电子书和纸板书怎么选？精华书都买 实在没时间，怎么办？#樊登读书会得到 听书 从哪里开始从扉页来判断，从序言来判断一下。 读书最好抛弃论据和论证，而要寻找宏旨。 听书完，还是要自己看。"},{"title":"JSX","date":"2017-12-12T10:16:10.000Z","url":"/2017/12/12/JSX/","tags":["JavaScript"],"content":"简介&emsp;&emsp;JSX 是点缀着 XML 元素的 JavaScript。它是由 React 这个库最初构思出来的，但又不是专门为了某个库或者框架设计的。它是一种 DSL。 &emsp;&emsp;JSX 是 html in JavaScript 的一种很好体现。这里的 XML，实际上还是 html 元素。粗略看下来，和当初 backbone 写 rendertemplate 的函数差不多。要引入 JSX 的语法，在很多场景下都要引入 Babel 这个 transpiler，也就是要搞到工具链满天飞。照抄官网的例子的话，可以看到： &emsp;&emsp;可以看到，&lt;h1&gt;Hello, world!&lt;/h1&gt;本来是不应该出现在 javascript 语句中的，它又不是合法的 identifier，又不是合法的 keyword。但后来 compiler 和 transpiler 就可以把它转化成这种实际的形式： &emsp;&emsp;注意，这个过程应该是类型安全的，即在运行以前就能检查出组件内的错误。 &emsp;&emsp;如果使用纯粹的 React 形式的 JSX 的话，还需要满足两个条件： &lt;script&gt; 标签的 type 属性为 text/babel，这是React 独有的 JSX 语法，跟 JavaScript 不兼容。凡是在页面中直接使用 JSX 的地方，都要加上 type=”text/babel”。 一共用了三个库： react.js 、react-dom.js 和 browser.min.js ，它们必须首先加载。其中，react.js 是 React 的核心库，react-dom.js 是提供与 DOM 相关的功能， browser.min.js的作用是将 JSX 语法转为 JavaScript 语法。 &emsp;&emsp;JSX 的特点是，结合了 Javascript 的强表达能力，和 XML 的结构能力。把两种抽象糅合在一起。每一个组件必须附带一个 render 函数（Vue 和 Ember 也都支持）。 &emsp;&emsp; React 组件的命名规范里，自定义的组件首字母大写，html 标签首字母小写。这点也很像 Ember。 &emsp;&emsp; 一个一看就懂的动态组件的写法： &emsp;&emsp; JSX 表达的是是虚拟 dom，而不是 html。虚拟 dom 特别像虚拟内存。在虚拟内存中，malloc() 的时候并不会真的对物理内存产生影响。但发生 paging，page error 的时候，虚拟内存就会真的试图往物理内存里调度内存页。virtual Dom 也只是在插入文档后，才变成真正的 DOM，才可以通过 this.refs.[refName]引用真正 DOM 节点。如： &emsp;&emsp;{}抱起来的 expression 可以在 JSX 语法中内插（interpolate）使用。但这个大括号包裹的必须是 expression，而不能是无返回值的 statement。我们可以把这种{}看做一种特殊的语法糖，因此也不能直接使用 if 和 for 语句。work-around 的解决方案： &emsp;&emsp;本文的例子大部分来自于React基础——JSX语法。 &emsp;&emsp;另一个基于菜鸟教程的例子： 调试问题&emsp;&emsp;debug 怎么办，是 debug transpile 以前的还是以后的？有很好的 sourceMap 么？"},{"title":"Docker 小笔记","date":"2017-12-10T05:10:18.000Z","url":"/2017/12/10/Docker-%E5%B0%8F%E7%AC%94%E8%AE%B0/","tags":["Docker"],"content":"记录一些特别容易遗忘的 Docker 知识细节： 镜像实际上是文件夹，每个镜像命令会产生出单独的一层。 容器像是集装箱。这通常是启动内部代理的一个方法。 Docker 同hypervisor的区别是，hypervisor总是起了多个内核。实际上阿里开源的容器技术 pouch，也是基于多 hypervisor 的。 docker inspect 既可以查看容器，也可以查看镜像。用以下的命令单独查看一个属性： 后台运行 docker 问题&emsp;&emsp;不知道为什么，直接docker run -d abc 容器总是会得到直接退出的结果。&emsp;&emsp;根据docker-container-will-automatically-stop-after-docker-run-d的结果，没有准备 -t 的 unattached 状态的容器，在运行一起来的时候，bash 就会退出。所以正确的用法恐怕是docker run -td abc。示例： -t的用处是启动一个tty，让这个os处在一种可以被attach的状态，这就可以不让它自动退出了。"},{"title":"虚拟机","date":"2017-12-10T04:25:49.000Z","url":"/2017/12/10/%E8%99%9A%E6%8B%9F%E6%9C%BA/","tags":["体系结构"],"content":"&emsp;&emsp;虚拟机意味着单独的指令集体系结构（ISA Instruction Set Architecture）。"},{"title":"为什么要自建实时计算平台","date":"2017-12-07T09:16:01.000Z","url":"/2017/12/07/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%87%AA%E5%BB%BA%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0/","tags":["大数据"],"content":"#为什么要自建一个离线平台# 可以优化资源利用率。 业务平台应该把精力放在业务上。 #什么是实时计算# 强调响应时间短（相对于离线计算）：毫秒级、亚秒级、秒级。T+1 的报表都是离线计算。 数据的价值随着时间的流逝而迅速降低。 常见技术方案： 流计算 + 实时存储 or 消息队列 流计算 + 实现 OLAP #什么是流式计算# 实时且无界。 数据驱动计算，事件触发。 有状态及持续集成。 流计算引擎：Spark Streaming、Flink Streaming、Storm/JStorm、Samza 等。 #Spark Streaming 模型# Micro-Batch 模式。看起来是流式处理的，实际上还是一小批一小批处理的。从批处理走到流处理。 最小延时：batch 的处理时间 最大延时：batch interval（通常2s-10s） + batch 处理时间。 使用场景：数据清洗（实时数据通道）、数据 ETL 等。 对于熟悉 Spark 批处理的 RD 非常容易上手。 #Flink Streaming# Native Streaming。 低延时，通常在毫秒级。 使用场景：事件驱动、实时风控、在线业务等。 比 Spark 更新。 #Druid.io# 实时数据存储及多维度聚合计算引擎。 服务于时间序列数据。 低延时数据写入（只写消费 kafka）,实时数据可见。 快速交互式查询（99% 查询1秒内返回）。 支持 SQL 及 DSL 两种查询语言。 适用场景：实时报表、实时监控。 #Presto 模型及服务# 基于全内存计算的分布式 SQL 查询引擎。 针对响应时间 20S 以内的 OLAP 场景。 通过 Connector 支持多种数据源。 #重流还是轻流# &emsp;&emsp;计算到底是在存储里 OLAP 里算出来，还是从存储里导出来，用流来计算的？ 用调整算子并发的方式，可以提升性能瓶颈。"},{"title":"Golang 并发的一些我自己才看得懂的总结","date":"2017-12-05T08:40:11.000Z","url":"/2017/12/05/Golang-%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%80%E4%BA%9B%E6%88%91%E8%87%AA%E5%B7%B1%E6%89%8D%E7%9C%8B%E5%BE%97%E6%87%82%E7%9A%84%E6%80%BB%E7%BB%93/","tags":["Go"],"content":" Goroutine 是绿色线程，下面自带调度器。可以在 syscall 进入阻塞状态的时候自动出让 CPU（类似 Java 在进入锁以前自动引入自旋，这实际上是一种抢占式调度–preemptive scheduling），也可以通过runtime.Gosched()主动出让 CPU，调度器还可能无缘由地主动抢占 Goroutine 的时间片（比如已经运行了10ms）。因为是绿色线程，所以可以很便宜地创造百万Goroutine。在 Go 1.5 以后，可以通过 GOMAXPROCS 来使用更多的逻辑 CPU（而不也是系统进程）来利用多核。主线程不是主线程，主线程也是一个 main goroutine。 Go 关键字基本就等同于 Java 中提交一个 Runnable 到 CompletableFuture 的 CommonPool。在没有 Channel 的帮助时，goroutine 几乎可以等同于一个绿色的守护线程。 Go 也是有 mutex 的，但是不提倡使用，用 channel 最好。 share memory by communicating。 channel 是通过描述若干操作的模式匹配来实现 select 的。它的无 buffer 版本和有 buffer版本类似于 SynchronousQueue 和 BlockingQueue。这个东西是化异步为同步的利器。default 和 timeout 可以让阻塞操作变为非阻塞的操作。channel 的阻塞也是会引起 Goroutine 的调度的。 channel 是 CSP（Communicating Sequential Proceesses）模型的实现。 单向 channel 有点像泛型里的单边操作的 wildchar，可以封印掉读/写能力，而且需要通过声明强转。 channel 可以被关闭。但关闭有什么用呢？不关闭它也会被垃圾回收，关闭只是 sender 给 reciever 发送的一个状态变化。 和其他方案的对比 异步回调会把程序拆得七零八落。人脑还是线性思维的。化异步为同步是最重要的。 Goroutine 就是化异步为同步的。 GreenThread/Coroutine/Fiber方案 遇到阻塞的时候，可以自己 yield 出 CPU，但还是需要外部的线程把 context resume 回来。Go 则由 scheduler 自动识别代劳了。需要外部线程来不断切换 context，其实是一种单线程的并发，尽量减少阻塞时间而能够多利用 CPU 罢了。 调度器的细节：调度器就好像是一个分层调度的线程池。M 代表 物理处理器（其实是 machine 的意思），P 代表逻辑处理器，G 代表 Goroutine。Go 实现了 M:N 的调度（而不是1：M 的调度），G 通过 P（只看到P），可以在不同的 M 之间自由切换,这是其他 Green Thread 做不到的（因为其他 Green Thread 本质上还是但进程/系统线程）。G 可以阻塞，M永远不阻塞。这方面的出处见这里。注意看图，这里面还是用的工作窃取算法。调度器的细节可以查看《也谈goroutine调度器》。 更多的例子见Go by Example，《并发之痛 Thread，Goroutine，Actor》和《Go 调度器: M, P 和 G》。 "},{"title":"Vim cheatsheet","date":"2017-12-05T02:52:03.000Z","url":"/2017/12/05/Vim-cheatsheet/","tags":["vim"],"content":"&emsp;&emsp;比较好用的两个 vim 寄存器代码： "},{"title":"保险电销与互联网保险","date":"2017-12-03T07:30:35.000Z","url":"/2017/12/03/%E4%BF%9D%E9%99%A9%E7%94%B5%E9%94%80%E4%B8%8E%E4%BA%92%E8%81%94%E7%BD%91%E4%BF%9D%E9%99%A9/","tags":["tag"],"content":"保险电销的发迹史 电销在早期国内的常见渠道方式零售-求职-电视购物-保险-房地产-理财-催收-教育 人才从一个行业去到另一个行业。保险电销卖的保险业都在慢慢变化。 保险电销的发展历程 电销鼻祖–中美大都会人寿04年。先收集用户信息，然后再卖保险。 真正符合国际发展主流的电销–招商信诺。佣金模式很重要。 国内的保险电销为何逐步衰落。保险电销两三年后，坐席两三万很容易。职业瓶颈也出现了。 保险电销核心竞争力。 保险电销的流程 开场（黄金三十秒） 产品介绍 激发需求 核保 促成 成交确认 保险销售的套路 为客户创造需求。 如何激发你的保险需求。 如何未曾谋面判断你的财务状况。 如何让你冲动消费。 保险电销目前的机遇 结合互联网提升效率（互联网+电销） 健康险需求已经被激发，互联网模式有待考究，需要电销介入。 车险电销需要改变（系统智能化）。 由人海战术转变精英战术。 保险的逻辑 风险转移-保险可以解决风险的不确定性。愿意用确定的金额来为不确定性的风险买单。 保险的机制是独特的经济补偿机制。 有杠杆。 法律保护保险金。 保险资金投融资作用。 保险促进产业链整合。 商业问题解决。 "},{"title":"系统调用为什么昂贵","date":"2017-12-02T16:09:33.000Z","url":"/2017/12/03/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%82%E8%B4%B5/","tags":["操作系统"],"content":"#系统调用的过程# &emsp;&emsp;系统有些高特权的操作，比如访问 IO 设备，修改内核状态，修改其他程序，在rings模型下，只有rings 0才能做得到。用户程序(通常是ring3)在自己的地址空间里面，是没有办法看到这些资源，也就无法修改它们。这时候用户程序就需要request service，发出软（件）中断，让程序trapped 进内核态(通过int 0x80 指令，实际上这不仅仅是进程的状态转换，也是进程的状态转换)。实际上此时的控制权已经交给内核了，内核可以在自己的内核地址空间里面，使用高特权操作，特权操作做完了以后，控制权才交回给用户程序。这个过程就成为syscall。x86 虽然有四层 ring，但通常只使用了0和3层ring。 &emsp;&emsp;系统通常提供API或者lib来提供syscall的能力。比如在 Unix-Like系统里，就是glibc。lib提供的函数，通常被称为Wrapper Function。 #系统调用的代价在哪里# &emsp;&emsp;每次产生系统调用，程序的上下文通常会产生切换，CPU必然是要把进程状态寄存器里面往内存里塞，再把其他进程的上下文从内存里往寄存器里面塞。即使只是单进程做系统调用也如此，因为系统调用自己也有特殊的上下文，需要从内存里往寄存器塞。然后系统调用执行完了以后，原本进程的上下文，又要从内存里塞回寄存器。再加上程序的进程切换会让硬件体系结构缓存失效，上下文切换回来以后，有些缓存又要重新加载。这种种的因果，必然会增加内存查找（memory look up）次数。 &emsp;&emsp;而且有些系统调用，会涉及IO操作，这容易让 CPU 进入一种阻塞状态，浪费 CPU 时间。这种阻塞状态是不会（主动）出让 CPU 的。 相关参考资料：     "},{"title":"单核上的多线程-Python中的 GIL","date":"2017-12-01T15:41:19.000Z","url":"/2017/12/01/%E5%8D%95%E6%A0%B8%E4%B8%8A%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B-Python%E4%B8%AD%E7%9A%84%20GIL/","tags":["Python"],"content":"&emsp;&emsp;GIL （Global Interpreter Lock）的存在虽然无法利用多核，但是可以勉强让系统在在单核上，任何一个线程使用过多时间片/主动放弃 CPU 的时候，让其他线程上下文切入进来。算是尽量跑满CPU吧。Python中的对象很多都是默认线程安全的，GIL的这种不可见的特性，让很多旧的程序依赖起 GIL，以至于无法从Python中移除掉它。GIL 的存在，让 Python 特别适合跑 Nodejs 爬虫一样的 IO 密集型（IO-bound）任务，反而不适合跑CPU 密集型任务（CPU-bound）。但实际上这种混蛋多线程的形式，恐怕还不如 EventLoop 的 Nodejs，因为多了很多 Context Switch 的代价。"},{"title":"面向对象范式的历史","date":"2017-12-01T15:18:46.000Z","url":"/2017/12/01/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%8C%83%E5%BC%8F%E7%9A%84%E5%8E%86%E5%8F%B2/","tags":["面向对象"],"content":""},{"title":"Java中的幽灵类型","date":"2017-11-30T06:45:28.000Z","url":"/2017/11/30/Java%E4%B8%AD%E7%9A%84%E5%B9%BD%E7%81%B5%E7%B1%BB%E5%9E%8B/","tags":["Java"],"content":"&emsp;&emsp;先上结论：幽灵类型（Phantom Type）是一种可以把有些运行时才能检测到的错误，在编译时检测出来的技巧。按照有些老外的观点，就是“Making Wrong Code Look Wrong”。在面向对象的编程语言之中，幽灵类型的实现，往往与状态模式较为接近，但比状态模式提供了更强的纠错功能。在Java 5 以后的版本里，程序员可以使用泛型。通过泛型的类型参数，Java 中也拥有了幽灵类型的能力。 &emsp;&emsp;上面的阐述是不是很难看懂？我也觉得拗口，让我们直接进入具体的例子。假设我们要写一个飞机控制程序，操作飞机起飞或者落地。这个程序有一个非常强的业务约束，就是必须保证飞机一开始必须出现在的地上，只有在地上的飞机可以起飞，只有起飞的飞机可以落地，那么我们应该怎样设计我们的程序（主要是类型关系），来保证这个约束必然成立呢？ &emsp;&emsp;让我们先来定义一组状态接口: &emsp;&emsp;从字面上即可看出，这是三个接口表示状态的接口类型。Flying 与 Landed 分别是 FlightStatus 的子类型，它们全都不包含任何可以使用的内容，完全通过类型名称来进行识别和区分。在 Java 这种指称类型（Nominal Typing） 的语言中，这通常被称为 Tagging Interface 或者叫 Mark Interface。 &emsp;&emsp;接下来我们来定义一个飞机类型： &emsp;&emsp;这个 Plane 类型有什么特别的地方呢？ 它只能使用有限的构造器来构造飞机,除此之外，都会因为方法签名带来编译错误。 实际上，一开始只有用工厂方法才能构造出落地的飞机，无法一开始就制造出在天上飞的飞机，否则，也会因为方法签名带来编译错误。 只有有状态的飞机，才能产生新的有状态的飞机。而这个有状态的飞机的转换构造函数（类似 CPP 的拷贝构造函数），只有 AirTrafficController 可以访问。 AirTrafficController 提供了两个状态转换方法: land 与 takeOff 。这两个方法会根据一个输入飞机的状态，来切换出另一个状态的飞机。而它们因为方法签名的关系，只能接受有限的飞机状态，否则会产生编译错误。 &emsp;&emsp;到此我们的类库已经写完了。试试写一个应用程序来测试它： &emsp;&emsp;想一想，如果我们把我们的程序当做类库发布出去给其他的程序员用。类库使用者因为加班上线已经写代码到了凌晨一点，错误地试图把一架正在起飞的飞机再次起飞，立刻就会得到编译器的错误提醒。这种预先设计的防呆类型系统，成功地降低了系统在变得复杂的以后，出现低级错误的可能。 &emsp;&emsp;为什么这种技巧叫幽灵类型呢？因为我们只在方法的签名的类型参数（type parameter）里指定了一个具体类型，并没有实际在方法体内部真的使用到这种类型的任何具体内容。诚如我们在代码中所见，FlightStatus 这种接口只是一种编译时类型识别的 type witness（类型见证人），帮助编译器推导当前的代码的合法性，其本身及其子类型，都不包含任何可以使用的内容。 &emsp;&emsp;可能有读者会问，这种方法很像状态模式，它和状态模式的区别在哪里呢？ 一个最显著的区别就是，状态模式里面，表示 state 的是实例里的一个 state 变量，而不是写在实例类型参数里的 state 类型见证人。使用状态模式，很容易让程序员写出 if(state == flying) throw new Exception() 之类的代码，这种代码即使写错了，编译器也检测不出来，因为这是运行时检测（是不是很讽刺，检测出错的代码，自己也会出错）。 更重要的是，类型参数的出现，使得一段代码里 plane 的状态表面化了。想一想，一个使用状态模式的 plane，我们在客户端代码里未必就能在当前上下文里知道它内部的 state 现在变成什么样了。但如果我们使用幽灵类型，那么我们只要看看当前上下文的方法签名的类型参数，就能明确理解当前飞机的 state。 &emsp;&emsp;我们应该什么时候使用幽灵类型呢？这是一个很难把控的问题。读者已经看到了，实际上这个飞机的例子也是非常精巧，需要仔细思考才能明白其中奥妙的，所以幽灵类型在 Java 的世界里长久不为人知。笔者的愚见是，在像飞机这类例子里面，有需要严格区分状态（或者子类型）和方法的匹配的需求，可以考虑使用幽灵类型。 &emsp;&emsp; 这篇文章缘于知乎上的一个有意思的问答《你见过哪些让你瞠目结舌的 Java 代码技巧？》。当时看到这种用法，我就觉得这是一种很有意思的利用编译器进行防御性编程的例子。此外，本文的飞机例子基本源自于此，但加上了一些w=我自己的注释和修改，便于读者理解（在原文的例子中，原作者似乎意识不到 Plane(Plane&lt;? extends FlightStatus &gt; p)不应该是个公有方法，而 AirTrafficController 应该是个内部类。请读者自行思考为什么。 ）。实际上还有更多的例子，可以在这里看到。在函数式编程语言的世界，如 Haskell、Scala、OCaml 里，幽灵类型是天然被支持的，但在 Java 的世界里，必须要到提供泛型能力的 Java 5 版本以后，才能这种技巧。"},{"title":"一段改写的超级账本的链码","date":"2017-11-29T06:00:16.000Z","url":"/2017/11/29/%E4%B8%80%E6%AE%B5%E6%94%B9%E5%86%99%E7%9A%84%E8%B6%85%E7%BA%A7%E8%B4%A6%E6%9C%AC%E7%9A%84%E9%93%BE%E7%A0%81/","tags":["Hyperledger","Go"],"content":""},{"title":"hibernate的缓存","date":"2017-11-25T15:21:11.000Z","url":"/2017/11/25/hibernate%E7%9A%84%E7%BC%93%E5%AD%98/"},{"title":"OOM Killer","date":"2017-11-20T08:48:04.000Z","url":"/2017/11/20/OOM-Killer/","tags":["Linux"],"content":"&emsp;&emsp;Linux 内核有个 OOM Killer 的机制，可以在系统内存不足的时候，通过主动杀死一些进程来释放更多的内存空间。 &emsp;&emsp;很多时候，我们可以 ping 通一台服务器，但无法 ssh 上去，因为 sshd 被 OOM Killer 杀掉了。ping 能 ping 通，是因为处在内核态协议栈还能工作，发出回送报文。sshd 则因为是用户态进程，直接被干掉了。 &emsp;&emsp;关闭再打开 OOM Killer 的方法： &emsp;&emsp;OOM Killer 决定是否要杀死一个进程，主要看两个指标： /proc/PID/oom_score 的分数 /proc/PID/oom_adj &emsp;&emsp;可以通过以下方法强制内核不得杀死某个进程： 参考文档： 关于OOM-killer 这里有一篇《OOM Killer》讨论它的工作细节。 Linux 下 OOM Killer 机制的详解 Linux内核OOM机制的详细分析 "},{"title":"支付业务","date":"2017-11-20T03:24:46.000Z","url":"/2017/11/20/%E6%94%AF%E4%BB%98%E4%B8%9A%E5%8A%A1/","tags":["互联网金融","FinTech"],"content":"&emsp;&emsp;支付牌照是金融体系里唯一还在卖的交易拍照。 &emsp;&emsp;金融业务分为三大类：银行、保险、证券。 &emsp;&emsp;银行业分为表内和表外的业务。支付是银行业的一部分。 &emsp;&emsp;是不是计入资产负债表–表内、表外业务。 &emsp;&emsp;表外业务是银行的服务业务，毛利高。 &emsp;&emsp;支付是表外业务。 &emsp;&emsp;互联网三大赚钱业务（变现场景对应支付的三个工具）： 游戏（支付工具）。 广告（大数据量级几张）。 互联网金融（电子账户和实名认证）。把银行账户体系电子化了。 &emsp;&emsp;货币最终是由国家发行的，铸币权是国家权力的体现。后来出现电子化货币，简化了票据类银行业务。 支付基础概念&emsp;&emsp;电子支付是在付款银行和收款银行之间的货币债权转移。 &emsp;&emsp;支付体系的构成–基于银行卡体系的四方模式： 发卡方（服务商户，提供银行卡/二维码） 商户 收单方（服务商户。老式的 pos 机是要拓片留印记的。pos 机/摄像头） 清算方（卡组的清算机构，国内是银联，国外就是 VISA 和 MASTARCARD。银行之间形成交易指令集–形成记账。央行的清算系统来调拨真正的钱的流动。头寸只要足够，不需要准备足够多的现金。）。 &emsp;&emsp;四方模式既涉及支付体系，也涉及金融体系。 &emsp;&emsp;国内的支付体系是持牌的（清算是没有牌的）。有清算能力的机构定义了卡组的交易规则（包括 Pos 机）。二维码是一种支付工具吗？网联会网上做，银联会往下沉。 &emsp;&emsp;支付宝囊括了四方模式（除了银联，绝无仅有），靠一百多个高级商务，连上了全国所有的银行。微信连了两百家。 &emsp;&emsp;网联出现后，不用拉专线了，接口也统一了。 &emsp;&emsp;中国互联网新四大发明，电子支付。把卡体系的四方模式，转变为公司内支付账户内的清算，银行变成了一个资金池–账户支付体系。 &emsp;&emsp;去年央行允许银行生成二类银行账户，等同账户支付体系的三级支付账户，三级支付账户做了一个限额。出海的问题，国外还是银行卡体系。 &emsp;&emsp;微信在14年靠着滴滴和红包这两件事，完成了账户支付体系的绑卡动作，建立了支付账户。以前的绑卡动作一个账户花费不到10块钱，现在互金上差不多200块才可以买卖账户。国内至少丢失了亿级别的磁条卡的信息。 &emsp;&emsp;支付本质上还是付钱和收钱。收钱和场景相关。所以收钱一端也可以有支付机构。 &emsp;&emsp;电商业务，给司机发工资，公司内部的清算是合规的。 &emsp;&emsp;金融业务。 &emsp;&emsp;国际业务。 &emsp;&emsp;场景业务。 &emsp;&emsp;发卡银行是有资金成本的。账户在交易中还是有成本的。自己做账户有千三的收益。"},{"title":"破解本博客不能部署的问题","date":"2017-11-19T06:00:20.000Z","url":"/2017/11/19/%E7%A0%B4%E8%A7%A3%E4%B8%8D%E8%83%BD%E9%83%A8%E7%BD%B2%E7%9A%84%E9%97%AE%E9%A2%98/","tags":["github","hexo"],"content":" 试着生成公钥，然后一定要记得把 pubkey 粘贴到 github 的 setting 里然后用ssh ping github ssh -T git@github.com，即使返回错误也不要紧。 改用这个github 的部署地址： repo: git@github.com:magicliang/magicliang.github.io。 "},{"title":"CMD 与 ENTRYPOINT","date":"2017-11-17T07:21:44.000Z","url":"/2017/11/17/CMD-%E4%B8%8E-ENTRYPOINT/","tags":["Docker"],"content":"&emsp;&emsp;CMD 与 ENTRYPOINT 都是为了让容器工作得像可执行文件一样，接受参数，产生特定的输出存在的–容器命令化工具。如果没有这些工具，那么docker run -it abc:v0.0.1 /bin/bash 的最后一个参数就会变成启动命令。如果有CMD，它的命令也会被 docker run 结尾的参数命令锁覆盖，原本的命令不会作为 startup command 执行;如果有 ENTRYPOINT，docker run 结尾的参数命令会作为 ENTRYPOINT 的命令执行; CMD 还可以为 ENTRYPOINT 提供参数。 &emsp;&emsp;比较奇怪的地方是,如果使用了非 /bin/bash 的 startup command，docker run 的时候就不能 /bin/bash 进去了。 &emsp;&emsp;一个容器最好只有一个 CMD，一个 ENTRYPOINT。子容器的 CMD 会覆盖父容器的 CMD。 &emsp;&emsp;CMD 可以为 ENTRYPOINT 提供参数。 &emsp;&emsp;他们都有 exec 和 SHELL 两种工作模式。 &emsp;&emsp;例如以下的例子，可以用 docker run -it d8c80106de01 tty 接管上去： &emsp;&emsp;因为最后一个命令使用了 /bin/bash 所以容器最终成为了一个 bash 命令。 &emsp;&emsp;如果使用 sshd 的话，还可以 ssh 进去。在启动容器的时候直接打开端口映射docker run -it -p 52022:22 d8c80106de01,然后在内部打开 sshd /usr/sbin/sshd（不知道为什么是直接写ENTRYPOINT /usr/sbin/sshd 不能正常工作），在本地直接用端口去 ssh 即可ssh -p 52022 root@localhost。如果容器内部没有打开 sshd，则需要 exec（低版本使用attach ）进去了。"},{"title":"Linux hypervisor","date":"2017-11-16T06:46:24.000Z","url":"/2017/11/16/Linux-hypervisor/","tags":["Linux","虚拟化","hypervisor"],"content":"&emsp;&emsp;hypervisor 可以被认为等于 virtual hardware。他们的出现，可以有效减少硬件服务器数量。 &emsp;&emsp;常见的 hypervisor 分成两类： 直接运行在硬件上的，基于内核的虚拟机。 OS as hypervisor。典型例子是 KVM。KVM 是被集成到 Linux 内核之中的完整虚拟化解决方案。 运行于另一个操作系统之上。典型的例子是 QEMU 和 WINE。 &emsp;&emsp;hypervisor的实现，总是要映射一些磁盘设备和网络设备的。"},{"title":"MariaDB 调优相关","date":"2017-11-15T12:36:43.000Z","url":"/2017/11/15/MariaDB-%E8%B0%83%E4%BC%98%E7%9B%B8%E5%85%B3/","tags":["数据库","MySQL","MariaDB"],"content":"&emsp;&emsp;本文主要摘译自这里。 &emsp;&emsp;MySQL 曾经有独立的公司。但那间公司后来被 Sun 微系统公司获取了。 Sun 微系统公司又被 Oracle 获取了。原 MySQL 开发者担心 MySQL 成为闭源软件，因此成立了一家SkySQL 公司维护开源的 MySQL 分支–MariaDB。 &emsp;&emsp;MariaDB 支持的存储引擎包括： InnoDB/XtraDB 后者是前者的加强版，属于事务性存储引擎，也叫 ACID-compliant（ACID 遵从的）。XtraDB 是 Percona 开发的存储引擎，整体向下兼容。使用普通的 mysqldump 会耗尽 cpu（因为要把数据库转化成正经的 SQL 语句）。而 xtrabackup 在大库上的备份、还原、冗余都表现得更好（因为像 Oracle 一样是二进制备份吗？）。 TokuDB。另一个事务性存储引擎。以高压缩率著称（最高25倍压缩）。适合小空间存储大数据。 MyISAM。MySQL 上最古老的存储引擎。非事务性存储引擎，只支持表级锁，不支持 MVCC。 SphinxSE。非事务性存储引擎。这名字和古希腊猜谜语的怪兽，斯芬克斯一样。本以上是用来做搜索引擎的，所以需要外部服务。 MEMORY。非事务性存储引擎。如其名字一样，只支持在内存中读写数据，可以当缓存用。 其他引擎，Federated 与 Cassandra。 &emsp;&emsp; 性能调优的话题 寻找好的硬件。最好用 SSD + RAID 10。 要有良好的 schema 设计，也要有良好的 query 设计。 使用查询缓存。但是写事务较多的场景就不适合查询缓存了。最多使用512MB 的查询缓存就足够了。 使用 EXPLAIN。可以看到查询计划，甚至可以通过 SET optimizer_trace=”enabled=on”看到优化器追踪结果。 调高相应的内存参数，如tmp-table-size = 1G max-heap-table-size = 1G。可以用 Mysqltuner 来查看内存参数是否足够。 注意，上面的内存参数只是存临时表的内存空间，实际上还有 join buffer 和 sort buffer。他们有助于提升 join 和 sort 的效率。 还有 buffer pool 相关参数，也很重要。 关掉文件系统中的 noatime 选项。 使用裸盘作为存储。 "},{"title":" KOA 初探","date":"2017-11-14T09:51:05.000Z","url":"/2017/11/14/KOA-%E5%88%9D%E6%8E%A2/","tags":["JavaScript","KOA"],"content":"&emsp;&emsp;KOA 是 express 的进化版。都是被作者玩腻了扔掉的东西。 &emsp;&emsp;它简化了各个中间件层面的工作，提供了高级的“糖”，把各个中间件转化为了函数。 &emsp;&emsp;裸的 koa 是一个超轻量级的中间件，只是一个更好用的 http 模块，所以没有多少开箱即用的功能。如果需要路由的话，有必要引入 koa-router 模块。 &emsp;&emsp;引述自阮一峰的博客，中间件的一个模糊定义是： 像上面代码中的logger函数就叫做”中间件”（middleware），因为它处在 HTTP Request 和 HTTP Response 中间，用来实现某种中间功能。app.use()用来加载中间件。基本上，Koa 所有的功能都是通过中间件实现的，前面例子里面的main也是中间件。每个中间件默认接受两个参数，第一个参数是 Context 对象，第二个参数是next函数。只要调用next函数，就可以把执行权转交给下一个中间件。 "},{"title":"线程安全与锁优化","date":"2017-11-10T11:51:43.000Z","url":"/2017/11/10/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E9%94%81%E4%BC%98%E5%8C%96/","tags":["JVM","多线程"],"content":"线程安全什么是线程安全“当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方法进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那么这个对象就是线程安全的。” 相对的线程安全，可以分成五个等级： 线程安全的分类不可变不可变的数据，都是线程安全的。不可变的对象引用，加上所有field都是不可变的。如果有得选，尽量连方法都是final的。 绝对线程安全Vector不是线程安全的。它也会出现并发修改时 Out of Range 的异常（注意，不是 ConcurrentModification 的异常）。 相对线程安全需要保证对这个对象的单独操作是线程安全的，在调用的时候不需要加上额外的保障措施。对于特定顺序的连续操作，就需要额外的同步来保证调用的正确性了。 线程兼容可以通过特殊手段做到线程安全的普通类，绝大部分类都属于相对线程安全的。 线程对立线程对立，是不管调用端是否采取了同步措施，都无法在多线程环境中使用的代码。常见的线程对立的操作还有 suspend()，resume()， System.setIn()，System.setOut()和System.runFinalizerOnExit()。 线程安全的实现互斥同步（Mutual Exclusion &amp; Synchronization)这是最常见（也是我们在考虑并发问题的时候，首先应该考虑的万能解决方案，也是《Java并发编程实践》和《Thinking in Java 》中最推荐的做法。）的保障并发正确性的手段。同步是指在多个线程并发访问共享数据的时候，保证共享数据在同一个时刻只被一条（使用信号量的话，多条）线程访问。而互斥是实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量都是实现互斥的常见方式。互斥是因，同步是果，互斥是方法，同步是目的。这些同步的手段，同样也会出现在 OS 层面上。同步的终极目标，应该是化并发的乱序，转化为类型无并发时的有序。 在 Java 里面，最基本的互斥手段就是 synchronized 关键字。它经过编译后，会转化为 moniterenter 和 moniterexit 这两个字节码指令（bytecode instructions）。这两个字节码都需要一个 reference 类型的参数来指明加锁和解锁的对象。我们当然都知道，这个reference，不是一个平凡对象实例，就是一个 Class 对象了。 根据虚拟机规范，在执行 monitorenter 指令时，首先尝试获取对象的锁（实际上就是去用线程信息写 markword）。如果这个对象没有被锁定，或者当前线程已经拥有了那个对象的锁，那么把锁的计数器加1。相应地，在执行 monitorexit 时，会对计数器减1，当计数器为0时，锁就被释放了。从某种意义上来讲，这种设计可以在分布式场景下用 Redis 实现。如果获取锁失败了，那么就会进入阻塞状态，直到对象锁被释放为止。虚拟机规范对 monitorenter 和 monitorexit 两条指令的行为描述中，有两点是需要特别注意的。首先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死（阻塞）的情况。其次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入对于映射到操作系统原生进程的实现，不管是阻塞还是唤醒线程，都需要操作系统的调用帮忙，也就会牵涉到用户态转变入核心态的问题（系统控制权从用户空间转入内核空间）。这种切换需要消耗很多 CPU 时间。这也是为什么它是昂贵的原因，时间是最昂贵的。对于很多简单的getter()、setter（）操作，花在状态切换上的时间，甚至会多过用户代码执行的时间。甚至可以认为，这样的状态切换需要使用很多的汇编指令代码，以至于要使用很多的 cpu 时钟周期。因此synchronized本身是一种重量级（Heavyweight）操作。JVM（注意，不是Java语言） 本身可能会对重量锁进行优化，使用自旋来避免频繁地切入核心态之中（自旋难道就不浪费CPU 时间了吗？）。 J.U.C包里专门提供了Reentrantlock来实现同步。它同样具有 syncrhonized具有的可重入、阻塞其他求锁者的特性。但它还具有三个额外的特点： 等待可中断。Lock接口有实现类可以实现试锁，超时试锁等功能。这样synchronized中，其他求索线程傻等的情况可以避免。 公平锁。公平锁指的是按照求锁顺序来分配锁（求锁也是有顺序的）。默认的锁（synchronized 和 ReentrantLock 的默认构造函数）是非公平的，随机给予锁，这样性能更好。 绑定多个条件。在 synchronized 的时代，多个 condition 就意味着多层 synchronized。 synchronized 的性能屡屡被 JVM 的实现者改进，因此还是优先要使用synchronized（《TIJ》、《Java 并发实践》和《深入理解 Java 虚拟机》到此达到了同一结论）。 非阻塞同步（Non-Blocking Synchronization)也就是我们常说的乐观策略。不需要加锁，也就不需要负担线程状态切换的代价。但代价是，如果真的发生了冲突，乐观操作需要付出的代价就是补偿（compensation）。最常见的补偿，应该就是不断重试（又要引入自旋了）。乐观锁的核心基石，实际上是 CAS（CompareAndSet或者 CompareAndSwap），这两个操作必须是原子化操作，这就要求现代的处理器提供这样的指令原语（instruction primitive）。JVM 虚拟机里，专门通过 Unsafe 包来向上层提供这种原语的语义。 CAS操作有一个很讨厌的 ABA 问题。虽然 ABA 问题本身在大部分情况下不会引起问题，但J.U.C还是提供了一个 AtomicStampedReference操作来避免这个问题（所以说，带版本的原子值才是最安全的）。在大多数情况下，进入互斥同步，还比用这些鸡肋功能要高效（为什么？）。 无同步方案可重入代码（Reentrant Code）也叫纯代码（Pure Code）。在它执行的任意时刻中断它，转而去执行另一端代码，再切换上下文回来以后，不会发生任何错误。所有可重入的代码都是线程安全的，但并非所有线程安全的代码都是可重入的。可重入性是基本的特性。 其实这就是函数式编程里的纯函数，所有的状态都由输入参数决定，结果可预测，不依赖其他global状态。这也是为什么函数式编程在高并发下是安全的，他们天然满足栈封闭的标准。 线程本地存储Thread中含有 ThreadLocalMap，而 ThreadLocal 的变量反而是 ThreadLocalMap 的 key，ThreadLocal 对应的 value ，被ThreadLocalMap强引用。所以单单让 ThreadLocal 被回收，反而会因为无法再摸到 value 而造成内存泄露。 Thread -&gt; ThreadLocalMap -&gt; 弱引用 key（也就是我们的 ThreadLocal） -&gt; 强引用 value（也就是 ThreadLocal 自己的 value，经常被 init 操作的那个） key 经常被声明为静态变量，这个静态变量如果泄露，就是方法区泄露。但 ThreadLocalMap 对 ThreadLocal 的弱引用与它无关，所以它自身的泄露和对静态变量生命周期的管理有关。 value 可能被跨线程混用，所以每个线程处理完以后都要及时 remove。它被 ThreadLocalMap 强引用，但只要频繁使用 ThreadLocalMap，它内部的自带方法都会隐式地 expunge 掉这些过期的 key-也就是说，只要 key 设为 null 了，entry 会被自动消灭。所以 value 的泄露实际上是由 key 的泄露导致的。value 本身并不被 key referenced，它是被 map referenced。 因此，我们需要至少做几件事：1.尽可能手动地 remove ThreadLocal 的value。2. 尽可能关掉线程（在使用线程池的方案里，这恐怕很难做到）。3. 尽量触发一些 get/set/remove 操作，让 ThreadLocal 的内部操作把的 stale 的 给去除引用。 锁优化自旋锁（Spinning Lock）一个已经拥有 CPU 执行时间的线程，在求锁的时候，如果直接被阻塞，其实是会降低操作系统的并发性能。所以这种时候可以让线程执行一个忙循环（busy waiting，怎么做到的？ PC jump 到一个一段被插入的代码上吗？）。循环的次数通常是不是很多，也就是10次而已。这个次数可以通过 -XX:PreBlockSpin 调整。当前版本的 JVM 还引入了自适应自旋锁（Adaptive Spinning）。自旋锁不适合长时间等待，那种情况下浪费的 CPU 时间实在太多了。CAS 这种非常小的 Set 值操作适合使用自旋锁。 锁消除（Lock Elimination）如果 JVM 通过逃逸分析，可以去除掉不必要的同步。可以消除掉 Reentrantlock吗？根据这篇文，是可以的。 锁粗化（Lock Coarsening）多个连续的频繁加锁，可能被虚拟机优化为一把大锁。 轻量级锁（Lightweight Lock）轻量级锁本身是 JDK 1.6 以后才加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的（Mutex等于重量锁。可以认为OS的系统调用提供了并发机制-线程，就会必然提供互斥量机制。）。它不是用来代替重量级锁的，用意是在多线程竞争不激烈的情况下，减少重量级锁的使用，来减少性能消耗。 我们已经知道，对象头（Object Header）分成两个部分（不算Padding的话），“Mark Word” 与 Klass Point。Mark Word 的大小取决于虚拟机的版本，分别是32bits 和 64bits（总之总是字长对齐）。数组对象的 Klass Point 还有一个额外的部分存储数组长度。轻量级锁和偏向锁的关键是“Mark Word”。 “Mark Word”被设计成一个非固定的数据结构，以便在极小的空间内存储尽量多的信息。因此，它的内存布局是可变的。 在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储所对象目前的 Mark Word的拷贝（实际上被命名为 Displaced Markd Word）。也就是说，试图求锁的线程局部栈帧可能是不一样的。 然后虚拟机试图使用 CAS 操作尝试将对象的Mark Word 更新为指向 Lock Record 的指针（注意是整个Mark Word）。如果更新成功了，那么线程就拥有了该对象的锁，并且 Mark Word 的锁标志位（Markword的最后两位）转变为“00”。如果这个更新失败了，虚拟机首先会检查对象的 Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word也就变成指向重量级锁的指针（也就是说，不再指向 Lock Record）。 轻量级锁的解锁过程，也必须借助 CAS 操作，把 Displaced Mark Word 的值写到 Mark Word 上。如果替换完成，同步结束。如果替换失败，证明有其他线程常识获取过该锁，那就要在释放锁的同时（可以看出此时锁已经膨胀过了，也就意味着要去释放 mutex，岂不是不对称的操作？），唤醒被挂起的线程。 轻量级锁在发生竞争时，依然会出现锁膨胀，而且还加上了CAS的开销，反而比直接使用重量级锁更慢。使用偏向锁只能根据一种经验假定，“绝大部分锁，在同步周期内是不存在竞争的”。 从这个过程我们可以看出来，mark word里并不是存了线程号，而是直接把mark word指向了目标线程的栈帧，轻量级锁和重量级锁的差别就在于底层是不是会触发 Mutex。 偏向锁（Biased Lock）偏向锁也是 JDK 1.6 中引入的一项锁优化。它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁在无竞争的情况下使用 CAS操作去消除同步使用的互斥量，偏向锁就是在无竞争的情况下，把整个同步过程都消除掉，连 CAS 都不做了。 偏向锁的偏，是偏心的。这个锁会偏向于第一个获得它的线程，如果接下来的执行过程中，该锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。从这点来看，偏向锁导致同步消除了，等同于锁消除了。但锁消除并不等同于偏向锁，可能有JIT自己去掉同步代码的优化。 当对象在第一次被线程锁定的时候，虚拟机会把标志位设置为“01”（至此标志位已经被用尽了）。同时使用 CAS 模式（因为此时还不能保证没有竞争）试图把线程 ID 写入 Mark Word中（此处就真的写入线程号了）。如果CAS成功，那么以后再进入同步块，都不需要执行任何同步操作。 如果这个时候发生锁竞争，则会发生撤销偏向（Revoke Bias），对象回到未锁定状态，然后进入轻量级锁的竞争阶段（难道不是直接进入重量级锁的竞争阶段吗？）。偏向锁是默认打开的，很多推荐的JVM配置都关掉它，因为多线程竞争很激烈的情况下，偏向锁的假定往往会失效（轻量级锁实际上也会失效）。所以可以用 -XX:-UseBiasedLocking 来关闭偏向锁。 所以锁的变化过程就是无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁。 "},{"title":"Java 与线程","date":"2017-11-09T15:25:10.000Z","url":"/2017/11/09/Java-%E4%B8%8E%E7%BA%BF%E7%A8%8B/","tags":["JVM","多线程"],"content":"&emsp;&emsp;线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件 I/O），又可以独立调度（线程是 CPU 调度的最基本单位）。主流的操作系统都提供了线程的实现，但 Java 的线程实现却在关键方法上大量使用 Native（这也就意味着，不能使用平台无关的实现），其中主要包括三种方法： 内核线程实现。 用户线程实现（Green Thread）。 用户线程加轻量级线程实现。 内核线程实现&emsp;&emsp;内核线程（Kernel Thread，KLT）就是直接由操作系统内核（Kernel）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以被看做是内核的一个分身，这样操作系统就有能力处理多件事情。支持多线程的内核就叫多线程内核。 程序一半不会直接去使用内核线程，而是去使用内核线程的一种高级接口–轻量级进程（Light Weight Process，LWP）,轻量级进程就是我们通常意义上所讲的线程。由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程1:1的关系称为一对一的线程模型。 由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元。即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作。但轻量级进程具有它的局限性：首先，各种线程的创建、析构和同步，都需要进行系统调用，也就是用户态（User Mode）trapped 到内核态（Kernel Mode），来回切换。其次，每个 LWP 都需要一个内核线程的支持，因此轻量级进程还要消耗一定的内核资源（如内核线程的栈空间），因此，一个系统能够支持的轻量级进程的数量是有限的。 用户线程实现&emsp;&emsp;从广义上来讲，一个线程只要不是内核线程，就可以被认为是用户线程。因此从这个定义上来说讲，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用。&emsp;&emsp;而下一的用户线程值得是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，线程不需要切换到内核态，因此程序可以是非常快速而且是低消耗的，也因此可以支持规模更大的线程数量，部分高性能的数据库中的多线程就是由用户线程实现的（node？数据库中间件？redis？）。这种进程与用户线程之间 1:N 的关系称为一对多的线程模型。&emsp;&emsp;使用用户线程的优势是不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、qiehu切换和调度都是需要考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来会异常困难，甚至是不可能完成的。所以现在越来越少使用用户线程来实现线程了。据我所知，只有早期的 Java （1.2以前）， Ruby（1.9以前）使用绿色线程。 很多程序员将它称为基于分时（time-sharing）的调度方式，不无道理，它要自己写自己的scheduler，是一个非常麻烦的事情，等于把批发回来的资源再分配了一遍。 混合实现&emsp;&emsp; 将内核线程和用户线程一起使用的方式。用户线程依然完全建立在用户空间内，而LWP则是用户线程和内核沟通的桥梁，可以让用户线程通过它背后的内核线程 leverage kernel scheduler， processor mapping和 system call。这种设计大大降低了一个线程阻塞另一个线程以至于进程全被阻塞的风险，但还是存在这样的风险。所以还是一对一的线程模型好，虽然操作可能有昂贵的地方，但是也很省心实用99。 Java的线程实现&emsp;&emsp;Java在当前的规范里面取消了绿色线程，也就是线程使用的透明性需要结合操作系统来看待。目前对于 Hot-Spot 虚拟机而言，Windows版和 Linux 版是使用一对一的模型实现的。在其他平台上，JVM 还有些可选参数来专门选择线程模型。 &emsp;&emsp;以Linux为例。Linux历史上，最开始使用的线程是LinuxThreads，但LinuxThreads有些方面受限于内核的特性，从而违背了SUSV3 Pthreads标准。即它要根据内核的特性来实现线程，有些地方没有遵循统一的标准。后来IBM开发了NGPT(Next Generation POSIX Threads)，性能明显优于LinuxThreads，人们曾把它当作LinuxThreads的继任者。但最后，又有一个项目NPTL(Native POSIX Threads Library)出来后，性能更优于NGPT。2002年NGPT项目停止开发，我们现在用的Linux线程就是NPTL。 &emsp;&emsp;线程的实现曾有3种模型： 1.多对一(M:1)的用户级线程模型 2.一对一(1:1)的内核级线程模型 3.多对多(M:N)的两级线程模型 &emsp;&emsp;上面的x对y(x:y)即x个用户线程对应y个内核调度实体(Kernel Scheduling Entity，这个是内核分配CPU的对象单位)。 &emsp;&emsp;LinuxThreads和NPTL都是采用一对一的线程模型，NGPT采用的是多对多的线程模型！！！ Java的线程调度&emsp;&emsp;不要试图依赖线程优先级。因为线程优先级并不是操作系统本地的优先级（windows 系统优先级 &lt; JVM 优先级 &lt; Solaris 系统优先级），而且优先级还会发生变动（Windows上的 Priority Boosting）。 &emsp;&emsp;在 OS 级别可能实现由抢占式调度和协作式调度，抢占式调度更强大而协作式调度更简单，Java 只有协作式调度（Thread.yield()方法）。 Java的线程状态转换&emsp;&emsp;六种被写进线程里的枚举状态，可以在 jstack 等 JMX 工具里得到解答： New 新建后尚未开始启动的状态 Runnable 等于系统线程中 Running 和 Ready（操作系统也有不同的状态）。线程可能正在运行，也可能准备可以运行（在阻塞或者等待状态被唤醒，等待 CPU 分配时间片）。 Waiting 无限期等待。除非被显式唤醒（notify，notifyAll，signal，signalAll，interrupt），不然无限期地等待下去。可以导致 Waiting 的方法有： 没有设置 Timeout 参数的 Object.wait()。 没有设置 Timeout 参数的 Thread.join()。 LockSupport.park()方法（所以这个方法就是无限黑洞）。 Timed Waiting 处于这种状态的线程没有 CPU 时间，可以被自动唤醒（也可以被 interrrupt()）。由以下方法可以看出，Sleep 和 Wait 除了附着的对象不同，都要让出 CPU 时间片： Thread.sleep() 设置了 Timeout 参数的 Object.wait() 方法。 设置了TimeOut参数的 Thread.join() 方法。 LockSupport.parkNanos() 方法。 LockSupport.parkUntil() 方法。 Blocked: 等待排他锁（synchronized， reentrantlock，获取阻塞队列的操作权）的时候。wait 在后置的 wait_set 里面，synchronized 在 entry_set 里面。 Terminated: 结束执行的线程的状态，比如走完了栈帧里程的 main 函数。 "},{"title":"JVM 的内存模型与线程","date":"2017-11-03T15:11:14.000Z","url":"/2017/11/03/JVM-%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/","tags":["JVM","多线程","内存"],"content":"1.性能何处寻&emsp;&emsp;计算机的CPU比起其他所有的设备，都快得多，所以怎样尽量复用 CPU 的时间片，是压榨计算机性能的目标。多核和并发，使得阿姆达尔定律大显神威，超越摩尔定律成为提升系统性能的金科玉律 - 现在单核计算能力已经无法垂直提升，要水平提升核数来提升整体性能。 2.缓存一致性问题（Cache Coherence）&emsp;&emsp;软件缓存，不过是硬件缓存的模仿，真正的缓存，早已存在于计算机的多级存储体系结构中。JVM 里，我们可以认为每个处理器都会在主内存（Main Memory）之外有高速缓存作为工作内存（Working memory）。除此之外，处理器和 JVM 都可能出现指令重排（Instruction Reorder）的的情况。工作内存是线程 Save 和 Load 的主要场所，主内存则是他们沟通的场所。 3.JVM 的对象信息&emsp;&emsp;Java Object 除了基本的内存轮廓以外，还有： Mark Word（对象的 Hash Code 的缓存值、GC标志、GC年龄、同步锁等信息）。 Klass Point（指向对象元数据信息的指针，指向 .class 的指针吗？不是，是指向方法区的类型元数据的指针。.Class文件实际上是那个区域的另一个入口了。）。 padding。如果对象是8位对齐的（也就是最长标量类型对齐的），则不存在padding。 4.内存间（主内存与工作内存）相互操作&emsp;&emsp;Java内存模型（Java Memory Model）定义了八种内存操作（而不是字节码）。虚拟机在是现实必须保证每一种操作都是原子的、不可再分的（对于 double 和 long 类型的变量来说，load、store、read 和 write 操作在某些平台上可以例外）： lock 把主内存变量为一个线程锁定起来。 unlock 把主内存的变量解锁，这样其他线程才能锁定。 read 把一个变量的值，从主内存读到工作内存里。是 load 指令的前置动作。 load 把read出来的变量，放到工作内存的副本里。 use 把工作内存的值传给工作执行引擎。 assign 把执行引擎里得到的值传给工作内存的变量副本。它是一种工作内存的局部写。 store 把工作内存中的变量的值传递给主内存。 &emsp;&emsp;实际上的执行顺序恐怕是 read-&gt;load-&gt;use-&gt;assign-&gt;store-&gt; write。 &emsp;&emsp;如果要把一个变量从主内存复制到工作内存，那就要按顺序地执行 read 和load 操作，如果要把变量从工作内存同不会主内存，就要执行 store 和 write 操作。 JMM 只要求上述两类操作必须按顺序执行，没有保证必须是连续执行，也就是说在 read 和 load之间、store 和 write 之间是可插入其他指令的。如对主内存的变量 a、b 进行访问的时候，可能出现 read a、read b、load b、load a 的操作顺序。 &emsp;&emsp;除此之外， JVM 还规定了额外的指令执行的偏序规则(正好也有八条)： 不允许 read 和 load、store 和 write 操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起了写回但工作内存不接受的情况。 不允许一个线程丢弃它的最近的 assign 操作，即变量在工作内存中发生了改变必须（最终）把该变化同步回主内存里去。 不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从线程的工作内存同步回主内存中。 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load 或者 assign）的变量，换句话说就是对一个变量实施 use 和 store操作之前，必须经过 assign 和 load 的操作。 一个变量在同一个时刻只允许一条线程对它进行 lock 操作，且 lock 操作可以被同一个线程执行多次（多种可重入锁的底层机制就在这里了）。而且只有执行相同数量的 unlock 操作，才能彻底解锁该变量。 如果对一个变量进行 lock 操作，会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 和 assign 操作。也就是说，这是一个 flush 加上 reload的过程。 如果一个变量没有被 lock 锁住，则 unlock 非法，只有本线程才能unlock。 对一个变量进行unlock操作之前，必须先把变量同步回主内存中（执行 store 和 write 操作）。也就是说，变量被线程锁住以后，不是在主内存上工作，而是在自己的工作内存里被使用的，这也印证了上面的八种指令中的 use 必须在 load 之后工作，执行引擎必须使用 use 的印象。 5.volatile关键字&emsp;&emsp;volatile 关键字具有可见性，会使得每次写操作，都会导致全flush 的出现（assign必然导致 store 和 write 回主内存），读操作必须read + load至工作内存， use 到执行引擎（而不能只是use上次留在工作内存里的值），必然总是得到最新的值，不管中间是否有不一致的暂时情况发生，读的语义必然是一致正确的。而如果没有这条语义，use得到的值，可能是之前 use 和 assign 得到的值。 &emsp;&emsp;注意，如果使用字节码分析多线程操作，即使只出现一条指令，也不能认为实际执行的机器指令是原子化的，但如果出现多条字节码指令，那么必然操作没有原子性。这也是 volatile 修饰的变量只是轻量级同步，不能做到真正互斥原子化的原因。它只保证了可见性。 &emsp;&emsp;因此，只有两种情况，不必然要使用标准同步机制： 远算结果不依赖指定非栈上变量的当前值，或者能够确保单线程修改指定变量的当前值。 变量不需要与其他变量参与同一个不变性约束。 &emsp;&emsp;此外，volatile关键字还可以通过插入内存屏障（memory barier）阻止内存指令重排（instruction reorder），阻止特定的赋值顺序被打乱。这点在 Java 5以前是做不到的，也就会经常性导致 Double Check Lock 在 Java 5以前失败。具体地说，相关联的操作是不可重排序的。相关联的read-&gt;load-&gt;use/assign-&gt;store-&gt;write可以看做是不可被重排插入中间指令的，一个指令 read 先于另一个指令 read，那么所有相关联的指令都是前者先于后者。这被称为“线程内表现为穿行语义”（Within-Thread As-If-Serial Semantics）。 6.Java内存模型的（Java）的特性6.1 原子性（Atomicity）##&emsp;&emsp;8个操作，read、load、use、assign、store、write这六个操作是必须原子的（64字节的 long、double 非原子性是可以由lock 和 unlock 的更强原子语义包裹起来规避掉的）。lock 和 unlock 操作虽然不是字节码，但几乎同意的 monitoerenter和monitorexit却是字节码指令。 6.2 可见性（Visibility）##&emsp;&emsp;一个线程的修改，立刻可以被另一个线程看到，方法主要有三个： 同步块 final （final 并不是不可更改的，所以依然有工作内存修改后flush的问题） volatile 6.3 有序性（Ordering）##&emsp;&emsp;volatile和同步块可以保证这点。方法内的指令不会被重排，是一个特别重要的不会产生特别副作用的保证。 6.4 volatile 和同步块比较##&emsp;&emsp;volatile不具有原子性，其他场景volatile和同步块都可以使用。 6.5 先行发生原则（happens-before）##&emsp;&emsp;JVM 为程序中所有的操作定义了一个偏序关系（偏序关系 π 是集合上的一种关系，据有反对称、自反和传递属性。但对于任意两个元素x，y来说，并不需要一定满足 x π y， y π x的关系。我们每天都在使用偏序关系表达喜好。），称之为 Happens-Before。只有操作 A 和操作 B 之间满足 Happens-Before 关系，才能保证保证操作 B 一定能够看到操作 A 的结果。 &emsp;&emsp;Happens-Before 的八条原则包括： 程序顺序原则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作线性发生于书写在后面的操作。这一条并不绝对，首先要考虑控制流循环跳转的问题，其次是，如果后操作无法感知前操作（即不存在依赖关系），则指令重排仍然可能发生。 监视器锁定原则（Monitor Lock Rule）：一个 unlock 操作时间顺序上先行发生于后面对同一个锁的 lock 操作。（单纯的lock 操作语义只提供了可见性，这条原则还保证了有序性。） volatile 变量原则（volatile variable rule）：对 volatile 变量的写入操作，必须要在读取操作时间顺序之前进行。 线程启动规则（Thread Start Rule）：Thread对象的 start()方法先行发生于此线程的每一个动作。 线程终止规则（Thread Termination Rule）：线程中所有操作，都先行发生于线程的终止检测。常见终止检测是 Thread.join() 的返回，Thread.isAlive()的返回。 线程中断原则（Thread Interruption）：对线程 interrupt() 方法的调用先行发生于被中断线程检测中断事件的发生。常见检测事件的方法是 Thread.interrupted()。 对象终结原则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize()方法的开始。 传递性（Transitivity） 操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，操作 A 先行发生于操作 C。 "},{"title":"如何把 composer 锚定到 e2e 的复杂网络","date":"2017-11-02T09:21:27.000Z","url":"/2017/11/02/%E5%A6%82%E4%BD%95%E6%8A%8A-composer-%E9%94%9A%E5%AE%9A%E5%88%B0-e2e-%E7%9A%84%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/","tags":["Hyperledger","Composer","Explorer"],"content":" 下载并进入/blockchain-explorer 项目。 cd fabric-docker-compose-svt。 download_images.sh（不要让 start.sh 代劳，要用特定的版本）。 ./start.sh 建立这个隐藏文件夹 /Users/magicliang/.composer-credentials，如果里面有内容要先清空。 把公私钥导入这个文件夹，注意最后一个 keystore 的私钥可能会变化： 7.在已经制作好的网络的 dist 文件夹下执行： 8.开启 compose-rest-server： $ composer-rest-server? Enter your Connection Profile Name: explorer? Enter your Business Network name : charity-network? Enter your enrollment ID : admin? Enter your enrollment secret : adminpw? Specify if you want namespaces in the generated REST API: never use namespaces? Specify if you want to enable authentication for the REST API using Passport: No? Specify if you want to enable event publication over WebSockets: Yes? Specify if you want to enable TLS security for the REST API: No "},{"title":"Cello 在 mac 上需要特别注意的几个问题","date":"2017-11-02T09:09:46.000Z","url":"/2017/11/02/Cello-%E5%9C%A8-mac-%E4%B8%8A%E9%9C%80%E8%A6%81%E7%89%B9%E5%88%AB%E6%B3%A8%E6%84%8F%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98/","tags":["区块链","Hyperledger","Cello"],"content":" /opt/cello 和 /opt/cello2 以及下面的 mongo 和 fabric-1.0 都尽量把 owner 和 group 改成当前用户名和当前用户名组名。然后把这两个子文件夹用 docker file sharing 打开。 docker 会对 cello 下的 file sharing 有很麻烦的冲突影响。解决方法是建立一个 cello2 文件夹，然后在 cello 项目下用以下脚本把 fabric-1.0 的文件夹迁移过去： 然后修改 vi .//src/agent/docker/docker_swarm.py，把 COMPOSE_PROJECT_PATH 改为： ‘COMPOSE_PROJECT_PATH’: ‘/opt/cello2/fabric-1.0/local’。以保证 ./src/agent/docker/_compose_files/fabric-1.0/local/docker-compose-base.yaml 和 vi ./src/agent/docker/_compose_files/fabric-1.0/local/fabric-solo-4.yaml 可以正确地重新 mount 上该目录。 修改防火墙打开 ip 转发： 通常，Cello 网络的 channel id 是businesschannel或者testchainid。 "},{"title":"Docker 的 Volume","date":"2017-11-01T04:31:35.000Z","url":"/2017/11/01/Docker-%E7%9A%84-Volume/","tags":["Docker"],"content":"为什么要有数据卷 Docker镜像是由多个文件系统（只读层）叠加而成。当我们启动一个容器的时候，Docker会加载只读镜像层并在其上（译者注：镜像栈顶部）添加一个读写层。如果运行中的容器修改了现有的一个已经存在的文件，那该文件将会从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在，只是已经被读写层中该文件的副本所隐藏。当删除Docker容器，并通过该镜像重新启动时，之前的更改将会丢失。在Docker中，只读层及在顶部的读写层的组合被称为Union File System（联合文件系统）。 &emsp;&emsp;换言之，删除容器的时候要记得顺便删除数据卷，例如： &emsp;&emsp;Volume 必须在容器初始化时就创建，也就意味着，只能在 docker run 或者 Dockerfile 里面指定数据卷。 $ docker run -it –name container-test -h CONTAINER -v /data debian /bin/bashroot@CONTAINER:/# ls /dataroot@CONTAINER:/# &emsp;&emsp;单参数的情况下，把一个 /data 目录挂载到了容器中（可以认为之前这个容器中并不存在这个目录）。如果使用 docker inspect 的方式来查看容器的内容，则可以看到： &emsp;&emsp;输出: map[/data:/var/lib/docker/vfs/dir/cde167197ccc3e138a14f1a4f…b32cec92e79059437a9] &emsp;&emsp;注意看，是container path 在前， host path 在后。&emsp;&emsp;如果我们在 host 主机上修改本地目录: &emsp;&emsp;则可以在容器中看到: $ root@CONTAINER:/# ls /datatest-file 对应的 Dockerfile 版本是，注意，这里依然是单参数的： FROM debian:wheezyVOLUME /data 但是 但还有另一件只有-v参数能够做到而Dockerfile是做不到的事情就是在容器上挂载指定的主机目录。例如：$ docker run -v /home/adrian/data:/data debian ls /data 该命令将挂载主机的/home/adrian/data目录到容器内的/data目录上。任何在/home/adrian/data目录的文件都将会出现在容器内。这对于在主机和容器之间共享文件是非常有帮助的，例如挂载需要编译的源代码。为了保证可移植性（并不是所有的系统的主机目录都是可以用的），挂载主机目录不需要从Dockerfile指定。当使用-v参数时，镜像目录下的任何文件都不会被复制到Volume中。（译者注：Volume会复制到镜像目录，镜像不会复制到卷） &emsp;&emsp;此处虽然奇怪，却是真的，可以指定 volume mapping 的地方不是 Dockerfile，而是 docker-compose file。 &emsp;&emsp;容器的 Volume 不是为了持久化自己的状态。docker 自己的可读写层的状态另有存储的地方。Volume 是为了把容器及容器产生的数据分离出来。实际上有文档显式 Volume 可以在容器被删除后被其他容器所复用。 &emsp;&emsp;Volume可以使用以下两种方式创建： 在Dockerfile中指定VOLUME /some/dir 执行docker run -v /some/dir命令来指定 &emsp;&emsp;无论哪种方式都是做了同样的事情。它们告诉Docker在主机上创建一个目录（默认情况下是在**/var/lib/docker**下），然后将其挂载到指定的路径（例子中是：/some/dir）。当删除使用该Volume的容器时，Volume本身不会受到影响，它可以一直存在下去。 &emsp;&emsp;双参数的 docker run 的语法，和 docker inspect 的语法顺序是相反的： docker run -v /host/path:/some/path … &emsp;&emsp;也就是说 docker run -v -p 的选项后接的参数都是从外到内的，而 docker inspect 的显示结果，则是从内到外的。 单独使用 Volume&emsp;&emsp;没有容器可以创建 Volume，几个例子如下： Create a volume: $ docker volume create my-vol List volumes: $ docker volume lslocal my-vol Inspect a volume: $ docker volume inspect my-vol[ { “Driver”: “local”, “Labels”: {}, “Mountpoint”: “/var/lib/docker/volumes/my-vol/_data”, “Name”: “my-vol”, “Options”: {}, “Scope”: “local” }] Remove a volume: $ docker volume rm my-vol 新用户应该优先使用 mount 选项 $ docker run -d -it –name devtest –mount source=myvol2,target=/app nginx:latest &emsp;&emsp;本文参考了《深入理解Docker Volume（一）》, 《深入理解Docker Volume（二）》, 《Docker 的官方文档》。"},{"title":"Cmd Markdown 简明语法手册","date":"2017-10-31T08:23:28.000Z","url":"/2017/10/31/Cmd-Markdown-%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/","tags":["Cmd-Markdown"],"content":"1. 斜体和粗体使用 * 和 ** 表示斜体和粗体。 示例： 这是 斜体，这是 粗体。 2. 分级标题使用 === 表示一级标题，使用 — 表示二级标题。 示例： 你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。 3. 外链接使用 [描述](链接地址) 为文字增加外链接。 示例： 这是去往 本人博客 的链接。 4. 无序列表使用 *，+，- 表示无序列表。 示例： 无序列表项 一 无序列表项 二 无序列表项 三 5. 有序列表使用数字和点表示有序列表。 示例： 有序列表项 一 有序列表项 二 有序列表项 三 6. 文字引用使用 &gt; 表示文字引用。 示例： 野火烧不尽，春风吹又生。 7. 行内代码块使用 `代码` 表示行内代码块。 示例： 让我们聊聊 html。 8. 代码块使用 四个缩进空格 表示代码块。 示例： 9. 插入图像使用 ![描述](图片链接地址) 插入图像。 示例： Cmd Markdown 高阶语法手册1. 内容目录在段落中填写 [TOC] 以显示全文内容的目录结构。 [TOC] 2. 标签分类在编辑区任意行的列首位置输入以下代码给文稿标签： 标签： 数学 英语 Markdown 或者 Tags： 数学 英语 Markdown 3. 删除线使用 ~~ 表示删除线。 这是一段错误的文本。 4. 注脚使用 [^keyword] 表示注脚。 这是一个注脚[^footnote]的样例。 这是第二个注脚[^footnote2]的样例。 5. LaTeX 公式$ 表示行内公式： 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 $$ 表示整行公式： $$\\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$ $$\\sum^{j-1}{k=0}{\\widehat{\\gamma}{kj} z_k}$$ 访问 MathJax 参考更多使用方法。 6. 加强的代码块支持四十一种编程语言的语法高亮的显示，行号显示。 非代码示例： Python 示例： JavaScript 示例： 7. 流程图示例 更多语法参考：流程图语法参考8. 序列图示例 1 示例 2 更多语法参考：序列图语法参考9. 甘特图甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。 更多语法参考：甘特图语法参考10. Mermaid 流程图 更多语法参考：Mermaid 流程图语法参考11. Mermaid 序列图 更多语法参考：Mermaid 序列图语法参考12. 表格支持 项目 价格 数量 计算机 $1600 5 手机 $12 12 管线 $1 234 13. 定义型列表名词 1定义 1（左侧有一个可见的冒号和四个不可见的空格）代码块 2这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 14. Html 标签本站支持在 Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格： 值班人员 星期一 星期二 星期三 李强 张明 王平 15. 内嵌图标本站的图标系统对外开放，在文档中输入 即显示微博的图标： 替换 上述 i 标签 内的 icon-weibo 以显示不同的图标，例如： 即显示人人的图标： 更多的图标和玩法可以参看 font-awesome 官方网站。 16. 待办事宜 Todo 列表使用带有 [ ] 或 [x] （未完成或已完成）项的列表语法撰写一个待办事宜列表，并且支持子列表嵌套以及混用Markdown语法，例如： 对应显示如下待办事宜 Todo 列表： Cmd Markdown 开发 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 支持以 PDF 格式导出文稿 新增Todo列表功能 语法参考 改进 LaTex 功能 修复 LaTex 公式渲染问题 新增 LaTex 公式编号功能 语法参考 七月旅行准备 准备邮轮上需要携带的物品 浏览日本免税店的物品 购买蓝宝石公主号七月一日的船票 [^footnote]: 这是一个 注脚 的 文本。 [^footnote2]: 这是另一个 注脚 的 文本。"},{"title":"以太坊相关研究资料","date":"2017-10-31T07:46:08.000Z","url":"/2017/10/31/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%E8%B5%84%E6%96%99/","tags":["区块链","Ethereum"],"content":" 《以太坊的 gas 费率一览表》 《以太坊学习笔记：私有链搭建操作指南》 《以太坊中的账户、交易、Gas和区块Gas Limit》 StackOverflow 上的问答：以太坊主链到底需要多大空间？ StackOverflow 上的问答：怎样提供无限次数的智能合约操作？ 《区块链技术-智能合约-以太坊 （译文）》 《以太坊官方文档》 《以太坊私有链搭建指南》 《以太坊关于搭建私有网络的 wiki》 《预充值以太坊资金的方法》。注意看 carchrae 的回复，这里面也提供了拷贝私钥复用私钥的方法，可以考虑在多节点的情况下使用。 《一本与参数有关的介绍怎样搭建私链的 gitbook》。 StackOverflow 上的问答：以太坊的网络难度是否可以静态锁死？注意看它还有个相关的子问题。如果网络算力的稳定的话，应该不会出现难度增长才对。 值得大读特读的 geth 的文档。特别是挖矿、账户管理的部分。 geth 的命令行选项。注意，有些选项在当前版本中已经消失了，如（gpomin、gpomax）。 StackOverflow 上的问答：如何降低测试网络中的难度。感觉没多大用。 搜索以太坊上运行的 dapps 的网站。 solidity 官方文档里关于生成合约的部分代码其中提到了“web3.eth.Contract to facilitate contract creation.” 是最佳实践。 计算 gas 的一个例子。总算好懂一点了。 查看以太坊的智能合约列表的网站。 一个以太坊探测器的安装教程,安装区块链私链的例子，Truffle console 的例子（重要 ）。 以太坊的拥抱者例子。 以太坊的自定义货币的例子，注意看里面设定货币总量的部分，和智能合约收费的部分。 以太坊闹钟的例子。 一个 web3js 编写调用合约的例子。 如何学习 solidity。 StackOverflow 上的问答：用 call 和 send 来预写入、准写入区块链。类似超级账本的多重事件订阅。 以太坊的名词解释。 以太坊中 gas 和 log 的关系。 StackOverflow 上的问答：以太坊如何从外部世界获取数据，介绍 Oraclize 服务。 blockcypher Solidity 拷贝 memory 内容到 storage 的问答。 remix 的部署和测试环境的用法。 使用 PoA 算法的私有链配置方法。 用折衷的方法来升级以太坊合约。 开源的以太坊钱包项目地址。 "},{"title":"把 Unix 的 Domain Socket 转成可本地访问的 TCP 端口","date":"2017-10-31T07:27:33.000Z","url":"/2017/10/31/%E6%8A%8A-Unix-%E7%9A%84-Domain-Socket-%E8%BD%AC%E6%88%90%E5%8F%AF%E6%9C%AC%E5%9C%B0%E8%AE%BF%E9%97%AE%E7%9A%84-TCP-%E7%AB%AF%E5%8F%A3/","tags":["Docker","Socket"],"content":"使用管道命令的做法： 简洁的做法（使用守护进程而不是使用管道命令） 从容器内往外看的主机，对应外部主机就是 127.0.0.1的端口ping docker.for.mac.localhost 通常结果是192.168.65.1。 值得参考的文：  "},{"title":"Docker in Docker","date":"2017-10-31T07:11:53.000Z","url":"/2017/10/31/Docker-in-Docker/","tags":["Docker","ubuntu"],"content":"官方博客里提供的DinD 的解决方案&emsp;&emsp;在遥远的年代，需要很多其他的东西来辅助生成一个 docker in docker 的例子，但如今一个 –privileged 的 flag 就搞定一切了。 &emsp;&emsp;当前版本正确的 DinD 方案，是这样启动一个 DinD 容器: &emsp;&emsp;exec 进入这个容器： &emsp;&emsp;然后在容器里再跑一个容器： ##Docker in Docker 为什么难？## 这有一篇博客《~jpetazzo/Using Docker-in-Docker for your CI or testing environment? Think twice.》，专门解释这个问题。总体看下来，有方便的地方，但也会让 Linux 安全机制和文件系统产生混乱。 &emsp;&emsp;因为某个特殊的 Unix domain 套接字在容器内是不可复用的。 ##以下步骤未完全成功## &emsp;&emsp;映射多端口启动 ubuntu 容器： &emsp;&emsp;容器内再安装容器并启动： "},{"title":"银翼杀手","date":"2017-10-30T13:03:45.000Z","url":"/2017/10/30/%E9%93%B6%E7%BF%BC%E6%9D%80%E6%89%8B/","tags":["影评","科幻"],"content":""},{"title":"JVM 与编译优化","date":"2017-10-30T03:12:30.000Z","url":"/2017/10/30/JVM-%E4%B8%8E%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/","tags":["JVM","javac","JIT","字节码","性能优化"],"content":"&emsp;&emsp;Java 的编译分期，至少可以分为两个阶段（有些情况下还有额外的第三种编译过程）： 编译前端（前端编译）：把 *.java 变成 *.class 文件的过程。也就是把源语言文件变成中间语言文件的过程。典型的例子有：javac、Eclipse 的 ECJ的工作过程。 编译后端（后端编译）：由 JIT（Just In Time Compiler。我认为应该还要把 Interpreter包括在内）把中间语言（字节码）转换成二进制目标体系结构机器码的过程。典型的例子有，HotSpot 的 C1，C2编译器的工作过程。 AOT（Ahead Of Time） 编译器直接把源代码编译成转换成二进制目标体系结构机器码的过程。 早期（编译）优化&emsp;&emsp;javac 自从1.3版本已经不再支持什么 -O 的优化了。所有的优化策略集中到后端编译里。这样没有经过 javac 编译的 JRuby、Jython程序，也可以享受到 JVM 的优化福利。 &emsp;&emsp;javac的编译过程，大致上是： 解析和填充符号表（Parse and Enter）。 注解处理（Annotation Processing，Java 5以后加入的过程）。 分析与字节码生成（Analyze and Generate） &emsp;&emsp;它们的流程图大致上是： &emsp;&emsp; 解析与词法分析的过程包括两个阶段： 词法、语法分析。通过 Parser 把字符流，转变为 Token 集合，把 Token 集合又转成 AST 的过程。抽象语法树的每一个节点是一个 construct。可以使用 Eclipse AST View 来查看抽象语法树的内容。 填充符号表，把 AST 里的 Construct 变成地址和符号信息构成的表格。 &emsp;&emsp; 在 Java 6 以后的 JST-269 实现里，有一组插入式注解处理器（Plugable Annotations Processing API）可供编译器处理。这些处理器在运行时，可以读取、修改和添加 AST 的元素。每次修改完成，都会回到“解析与填充”的阶段冲走一个循环，这每一个循环实际上是一个 Round。 &emsp;&emsp;语义分析有标注检查和数据及控制流分析两个步骤： 标注检查的内容有变量使用前是否已经被生命、变量与复制之间的数据类型是否能够匹配等等。我们常说的常量折叠，是标注检查的一部分。 数据及控制流分析则检查诸如局部变量是否有赋值、方法的每条路径是否都有返回值、是否所有的受检异常都被正确处理了等问题。注意，我们都知道 JVM 里面没有checked exception，实际上 JVM 里面也是没有 final local variable的，这些都是由编译期保证的。 &emsp;&emsp;接下来字节码生成的部分，分为解糖（desugar）和字节码生成。 &emsp;&emsp;解糖就是把语法糖转换成非语法糖的代码，比如把泛型转换为非泛型，把拆装箱换成普通方法。其实我认为 checked exception 和局部变量 final 都是语法糖。因为无类型优化，所以 Java 的泛型比 C#、C++ 的泛型要慢一些。关于泛型还是要专门说一点，运行时擦除到边界的类型，总是会在 .Class 的地方 equals 成功的，这是因为 .Code 属性里面没有类型信息，但其他元数据区（如LocalVariableTypeTable的表里）还能拿到类型信息，所以我们的反射才能正常运行下去。 &emsp;&emsp;字节码生成阶段会生成我们的 和 。 &emsp;&emsp;还有一种特殊的语法糖，条件编译。即方法内的 if 加上布尔常量可以消除无法到达的死代码（ 不同于后面提到的 Dead Code Elmination）。 晚期（运行）优化 &emsp;&emsp;mixed mode 指的是解释器和 JIT 一起运行。在没有打开分层编译的情况下，C1（客户端虚拟机默认编译器） 和 C2（服务器端虚拟机默认编译器） 只有一个会与解释器一起工作，特别地： -Xint 关掉 JIT，强制用解释器执行。 -Xcomp 关掉解释器，强制编译执行（实际上解释器仍然会在不能编译的极端情况下介入，作为兜底方案）。 &emsp;&emsp;JIT会根据概率统计才去一些激进的优化措施，但遇到一些优化失败的场景时（比如 Uncommon Trap），则可能发生 Deoptimization。 &emsp;&emsp;分层编译将代码的执行看做三层内容： 第0层：解释执行，不开启 Profiling，触发第1层编译。 第1层：C1 编译，简单可靠。可能加入监控逻辑。更高的编译速度。 第2层：C2 编译，激进，深度编译，可能编译耗时较长。更好的编译质量。 &emsp;&emsp;不管是 C1 还是 C2，都有一个编译器队列。也有异步编译模式可以减少编译线程对代码执行的影响。 编译对象和触发条件&emsp;&emsp;热点代码有两类： 被多次调用的方法。 被多次执行的循环体。 &emsp;&emsp;这两种编译目标，最终都是以方法为单位执行编译。而这种编译方法因为发生在方法执行时，因此称为栈上替换（On Stack Replacement， OSR）。JVM 会试图用 JIT 的本地代码栈帧代替解释器栈帧。 &emsp;&emsp;热点代码的侦测方式叫做热点侦测（Hot Spot Detection），有两种具体形式： 基于采样的（Sample Based Hot Spot Detection）：定期查看栈顶的方法，统计最常出现的方法名。 基于计数器的热点方法。每个方法使用一个计数器，超出阈值就成为热点方法。 &emsp;&emsp;Hotspot 就是采用两种计数器，调用计数器（Invocation Counter） 和回边计数器（Back Edge Counter）。 &emsp;&emsp;-XX:CompileThreshold 可以设定JIT 的编译阈值。不过这个阈值是相对阈值，会根据半衰期（Counter Half Life Time）直接减掉一半的计数器。所以可以使用 -XX:-UseCounterDecay 关掉热度衰减。 ，可以使用 -XX：CounterHalfLifeTime来设置半衰期，单位是秒。 &emsp;&emsp;JIT 的工作流程如图： &emsp;&emsp;在图中我们可以看到 &emsp;&emsp;所谓回边，就是字节码中，控制流向后跳转的指令。顾名思义，回边计数器就是对方法中循环体代码的执行次数进行统计的。有一个 -XX:BackEdgeThreshold 这样的参数可以可以设置这个回边阈值，但现实中的 JVM 并没有直接采用这一参数。而是使用了 OnStackReplacePercentage这一参数来配置。 &emsp;&emsp;与方法计数器不同，回边计数器没有热度半衰期，因此它统计的时候方法执行的绝对次数。而且如果回边计数器溢出，方法计数器也就溢出了，方法执行标准编译过程。 &emsp;&emsp;回边计数器的执行过程如图: &emsp;&emsp;在缺省的情况下，后台的编译线程和解释器线程是并发执行的，但也可以用 -XX:-BackgroundCompilation 来禁止后台编译。 &emsp;&emsp;我们常见的编译动作（如同 gcc 的 -O2的编译器那样做的）：死代码消除（Dead Code Elimination）、循环展开（Loop Unrolling）、循环表达式外提（Loop Epression Hoisting）、公共子表达式消除（Common Subexpression Elimination）、常量传播（Constant Propagation）、基本块重排序（Basic Block Reordering）。还有一些 Java语言特有的优化，如范围检查消除（Range Check Elimination）、空间插消除（Null Check Elimination）。还有一些激进的优化，如守护内联（Guarded Inlining）、分支频率预测（Branch Frequency Prediction）。 &emsp;&emsp;可以通过 -XX:+PrintCompilation 查看到底有哪几个方法被编译了。还可以用-XX:PrintInlining要求虚拟机输出内联信息。 &emsp;&emsp;可以使用各种hsdis反汇编适配器（如hsdis-i386）与虚拟机结合在一起看待 JIT 出的汇编指令。或者使用 -XX:printOptoAssembly(C2)或者-XX:+printLIR(C1)。 常见的编译优化技术公共子表达式消除（Common Subexpression Elimination）&emsp;&emsp;如果 a + b 已经计算过了，则接下来的 a + b 不再需要通过字节码计算。这项技术是语言无关的。 数组边界检查消除(Array Bounds Checking Elimination)&emsp;&emsp;这项技术是与 Java 的数组实现相关的。Java 会对每次的数组下标访问做一个是否越界的检查，这也是越界异常抛出的根源。但如果能够在数据流检查的阶段，提前确认常量访问数组下标的情况，这种检查可以被去掉，开销也就消失了。 方法内联（Method Inlining）&emsp;&emsp;这是对性能提升最大的技术。 逃逸分析（Escape Analysis）&emsp;&emsp;逃逸分析就是考察一个对象是不是会被传递到方法或者线程之外。如果没有逃逸成功，则有特别的优化措施： 栈上分配对象，而不再在堆上（Hotspot上没有这项优化，哪里有呢？）。 同步消除，不再同步这个变量（如何做到？）。 标量替换。对象是聚合量（Aggregate），基本的数据类型是标量（Scalar）。可以直接不生成对象而生成对象的成员变量，再配合栈上分配，可以极大提高性能。 &emsp;&emsp;逃逸分析对于不正确的同步代码，可能会引入意想不到的bug。"},{"title":"如何用 Github 客户端取出自己 Github 里的某一个 repo","date":"2017-10-27T13:29:31.000Z","url":"/2017/10/27/%E5%A6%82%E4%BD%95%E7%94%A8-Github-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%96%E5%87%BA%E8%87%AA%E5%B7%B1-Github-%E9%87%8C%E7%9A%84%E6%9F%90%E4%B8%80%E4%B8%AA-repo/","tags":["git","github"],"content":"如果显式clone失败，再试一次。"},{"title":"基于栈的虚拟机","date":"2017-10-27T13:15:40.000Z","url":"/2017/10/27/%E5%9F%BA%E4%BA%8E%E6%A0%88%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA/","tags":["JVM"],"content":"基于栈的虚拟机，可移植性更好。"},{"title":"Hyperledger Fabric 网络的启动步骤","date":"2017-10-27T11:54:07.000Z","url":"/2017/10/27/Hyperledger-Fabric-%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%AF%E5%8A%A8%E6%AD%A5%E9%AA%A4/","tags":["区块链","Hyperledger","Fabric"],"content":"&emsp;&emsp;本文是截至日前（2017.10.27）时对官方教程和自我实验的重新梳理。 &emsp;&emsp;Hyperledger Fabric 可以说是 Hyperledger 的拳头项目。虽然同为 Apache 的顶级项目，但大部分其他项目都以 Fabric 为基础。它是顶级项目中的顶级项目，可以认为是0级项目。 docker 要有高于 17.06.2-ce 的版本。docker-compose 要有 1.14.0 及以上的版本。当然当前的高版本的 docker 已经自带了高版本的 docker-compose，这通常不用担心。 安装1.9+ 的 Golang。应该预期这样的结果： echo $GOPATH /Users/xxx/go 如果这个结果出不来，考虑当前 Shell 的环境变量没有正确设置： export GOPATH=$HOME/go export PATH=$PATH:$GOPATH/bin 要用一个很特别的 nodejs 版本。6.9以上，却不能用8.x。npm 也有特别的版本要求： npm install &#x6e;&#112;&#x6d;&#64;&#x33;&#x2e;&#49;&#48;&#46;&#x31;&#x30; -g 要用一个很反直觉的 python 版本，python 2.7（也就是不能用 ubuntu 自带的）。 开始下载范例网络： git clone  fabric-samples 在 fabric-samples 目录下，用这个命令下载必须的镜像和二进制库： curl -sSL  | bash &emsp;&emsp;实际上，这会在目录中替我们下载： cryptogen（配置密码学相关材料的二进制工具）configtxgen（配置频道交易事务相关材料的二进制工具）configtxlator（配置的转译器）peer （peer 的操纵工具） 我们还可以把这些工具的路径加入 PATH 中： export PATH=/bin:$PATH 在 first-network 的文件夹内，依次执行： 生成密码学文件：../bin/cryptogen generate –config=./crypto-config.yaml 重映射当前路径为 fabric 相关环境变量：export FABRIC_CFG_PATH=$PWD 根据双组织排序器的配置，生成创世区块：../bin/configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block 指定当前频道名称(自定义频道不在各种 yml 文件里面，而在这里面)：export CHANNEL_NAME=mychannel 根据频道名称，生成频道的事务文件：../bin/configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME 生成组织一与组织二的 MSP，注意锚平等节点必须配置好了：../bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP../bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP 注释掉 docker-compose-cli.yaml 里的这一行： #command: /bin/bash -c ‘./scripts/script.sh ${CHANNEL_NAME} ${DELAY}; sleep $TIMEOUT’ 启动容器： CHANNEL_NAME=$CHANNEL_NAME TIMEOUT=10000 docker-compose -f docker-compose-cli.yaml up -d 进入 cli 容器，只有在 cli 容器里，才能进行 channel 相关的操作： docker exec -it cli bash 在容器内： 又要重新命名频道名为环境变量：export CHANNEL_NAME=mychannel 生成频道区块：peer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx –tls $CORE_PEER_TLS_ENABLED –cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 把当前的 org1 的 peer0 加入这个频道(注意此时已经有四个核心的环境变量被注入到容器内部了)：peer channel join -b mychannel.block 把智能合约装到当前的四个peer 里的一个(哪一个？是仅仅 peer0吗？有待再实验 )：peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 初始化一个合约，初始化合约会为 peer node 生成一个专门拿来跑智能合约的安全容器(即 dev-xxx 的容器)： peer chaincode instantiate -o orderer.example.com:7050 –tls $CORE_PEER_TLS_ENABLED –cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c ‘{“Args”:[“init”,”a”, “100”, “b”,”200”]}’ -P “OR (‘Org1MSP.member’,’Org2MSP.member’)” 测试初始合约的状态：peer chaincode query -C $CHANNEL_NAME -n mycc -c ‘{“Args”:[“query”,”a”]}’ 第一次 invoke 这个 chaincode：peer chaincode invoke -o orderer.example.com:7050 –tls $CORE_PEER_TLS_ENABLED –cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -c ‘{“Args”:[“invoke”,”a”,”b”,”10”]}’ 再次查询:peer chaincode query -C $CHANNEL_NAME -n mycc -c ‘{“Args”:[“query”,”a”]}’ 容器之外 优雅关闭网络：docker-compose -f docker-compose-cli.yaml down 去除无用的 docker 容器:docker rm -f $(docker ps -aq) 在容器外查看特定容器的日志：sudo docker logs -f peer0# control + c will exit the processsudo docker logs -f orderer0 专门删除与 chaincode 有关的镜像docker rmi -f (docker images | grep peer[0-9]-peer[0-9] | awk ‘{print3}’) "},{"title":"思考区块链","date":"2017-10-27T10:34:05.000Z","url":"/2017/10/27/%E6%80%9D%E8%80%83%E5%8C%BA%E5%9D%97%E9%93%BE/","tags":["区块链","Hyperledger","Corda","私有链","联盟链","共识算法"],"content":" 区块链是比特币的基础设施。由区块组成链，是为区块链。各个区块链的持有者之间，总是在玩不确定选主的游戏，所以这和所有传统的分布式数据库不同，是一个去中心的数据存储模式。 比特币的区块链是1.0的玩法，以太坊是2.0的玩法。有些人认为 Hyperledger 是3.0的玩法，还有待怀疑。 区块链上的资产，可以是自带的（比特币网络里的比特币，以太坊网络里的以太币），也可以是智能合约定义和约束的。 智能合约是个看起来很美好，实际上只能执行在沙盒里面的东西。曾经在某个IBM程序员的分享里看到过，Hyperledger 的智能合约本质上也是 GO 程序，所以理论上可以做一切事情。但目前没有看到除了调用各种 Shim API 以外的任何用处。比如，如果我们想要用智能合约发出另外一个调用请求，让真实的系统发生转账，如何做到？ 很多人都有热思考，人类再也回不到没有比特币的时代了。也有冷思考，区块链的时代还未到来。就目前而言，现在的计算性能真的不足以支撑真实的行业流量，只能养养鸡，运运肉。 也有观点认为，公有链是真命题，而私有链是伪命题。就目前的观察看来，不管是 Hyperledger 还是 Corda，中心化节点是不可避免的。Corda 是为了 Uniqueness Validty 的职责分离，设计了 Notary 节点。 Hyperledger 则是为了收集所有背书后的事务，准备再提交给 peer 写入账本中。毫无疑问，这两种设计都出现了中心化的系统交汇点。R3 区块链联盟的开发者明确告诉我，notary 会是影响性能的因素。但性能还在其次，更重要的是，在联盟链或者私链里面，谁来掌管这个 orderer。区块链的共识公正性，在公有链上由陌生人矿工相互制衡实现，在私有链上，却是可有可无的，真的沦为了一个共享数据库了。那么，联盟链存在的价值是什么，强迫大家共享账本里的所有信息吗？ "},{"title":"给 Jetbrains 的产品应用明日主题","date":"2017-10-27T07:09:58.000Z","url":"/2017/10/27/%E7%BB%99-Jetbrains-%E7%9A%84%E4%BA%A7%E5%93%81%E5%BA%94%E7%94%A8%E6%98%8E%E6%97%A5%E4%B8%BB%E9%A2%98/","tags":["开发工具","JetBrains","Intellij"],"content":" git clone  用 file -&gt; import settings 来导入相应的 Jetbrains 文件夹的 jar。 "},{"title":"昂贵的异常","date":"2017-10-23T11:29:39.000Z","url":"/2017/10/23/%E6%98%82%E8%B4%B5%E7%9A%84%E5%BC%82%E5%B8%B8/","tags":["JVM","Java","异常处理"],"content":"抛出问题&emsp;&emsp;Joshua Bloch 在《Effective Java》的 Item 57 里明确地提到过，不要试图用 Exception 的跳转来代替正常的程序控制流。他列举了很多原因，但特别提到了抛出异常会使得整个程序运行变慢。抛出异常远比普通的 return , break 等操作对控制流、数据流的性能影响要大，它就只适合拿来作异常分支的控制语句，而不能拿来编写正常的逻辑。 Throwing exception is expensive. &emsp;&emsp;这句话在 Java 的程序员世界里面已经成为老生常谈。却很少有人谈及，但到底抛出异常比正常的程序跳转返回慢在哪里，有多慢。“不要滥用异常”好像一个猴子定律，人们忘记了为什么不能这么做，却不明白为什么不能这么做。 &emsp;&emsp;这几天读了一位同事写的好文[《Java虚拟机是如何处理异常的》][2]，深入地分析了 JVM 对异常跳转的处理过程: JVM 会通过异常表的机制，优化异常抛出和正常返回之间的性能差异。仅从程序计数器的移动上来讲，抛出一个异常对栈帧的弹栈并不比直接返回更昂贵。写在前头的结论是：“try-catch语句块几乎不会影响程序运行性能！在开启JIT的情况下，throw也不会增加多少系统开销。”实际上这篇文章也做了一些对比，在不同的场景下，try-catch 会不会让系统变慢。 文中还提到一个有趣的实验： 代码 A 代码 B 实验结果是： 异常抛出 关闭JIT 开启JIT(默认开启) 无异常抛出 两者耗时几乎相同 两者耗时几乎相同 A每次都抛异常 A耗时约是B的30倍 两者耗时几乎相同 &emsp;&emsp;这几乎推翻了我们既有的刻板印象，从此抛出异常不再是一个需要考虑性能的设计决定了。在仔细研究了这个问题以后，我却有了一个不同的结论：try-catch 语句在 jit 的帮助下 ，也许可以达到和正常 return 一样的性能 ，然而 throw 却会产生远比文中描述的更严重的性能影响 ，因为 throw 不是孤立的语句，它必须伴随着异常对象的创建，而异常对象的创建的昂贵代价，是不可能被 jit 优化掉的。也就是说，我认为[《Java虚拟机是如何处理异常的》][3]中结论的前半部分是正确的，后半部分是不准确的。 异常的机制&emsp;&emsp;JVM 的异常处理机制，大致可以分为三个部分 ： new Exception throw Exception catch and deal with Exception &emsp;&emsp;通过[《Java虚拟机是如何处理异常的》][4]我们已经可以明确理解，JVM 对于 try-throw-catch 的程序控制流处理，与普通的 return 如出一辙，都是基于程序计数器的改变，直接使得控制流发生跳转，并无特别之处。而 catch 异常如果为空（即如果我们生吞异常），则开销上看起来和平凡 return 一样。然而，new Exception 实际上是一个非常昂贵的操作。因为异常对象在生成的时候，其父类构造函数 Throwable 中的一部分会调用 fillInStackTrace() 操作。这个 fillInStackTrace() 函数，会试图把当前抛出异常的栈帧全都囊括在内，在实际的运行之中，有可能导致复杂的 CPU 寄存器读写操作。这种读写操作的复杂度与是否使用 jit 无关，也就不可能为 jit 锁优化，是一种很昂贵的固定成本。&emsp;&emsp;[《Java虚拟机是如何处理异常的》][6]中提到的实验并不代表 Java in real world 的工作状况，因为现实中几乎没有栈深只为1的方法调用，一个框架或者容器，本身就会带来几十层的调用栈深度。 一个实验&emsp;&emsp;StackOverflow 上已经有很多人做了相关的实验，我也决定试试用以下代码来印证自己的结论： &emsp;&emsp;这是一个基于 JMH 的测试方案，先预热一万轮，再跑一万轮 benchmark 方法，使 jit 完全发挥作用。实验环境是 CentOS 7，使用 Java 8 的 JVM，默认打开了分层编译。栈深度分别为1、100，200，1000，2000。 &emsp;&emsp;实验结果如下： 测试方法 栈深度 操作平均耗时（微秒） benchMarkReturn 1 0.002 benchMarkThrow 1 1.462 benchMarkReturn 100 0.178 benchMarkThrow 100 15.200 benchMarkReturn 200 0.369 benchMarkThrow 200 28.595 benchMarkReturn 1000 1.864 benchMarkThrow 1000 152.968 benchMarkReturn 2000 7.563 benchMarkThrow 2000 238.049 &emsp;&emsp;我们可以清晰地看到： 在相同的栈深度下，抛出异常的时间有可能有是返回普通的对象的时间的30倍到700倍。 在我们的实验里，可能因为存在边际效应，栈深为1的时候反而是性能差距最大的。 &emsp;&emsp;这也基本符合在网上看到的其他人的测试的结论（例子1，例子2）。 &emsp;&emsp;如果我们再试图在 catch 块里 printStackTrace()，性能差距只会更大。 结论 在开启JIT的情况下，throw也不会增加多少系统开销。 &emsp;&emsp;固然是实话。 &emsp;&emsp;然而现实之中，throw 却不能离开任何 Throwable 的子类，我们在使用异常机制的时候，必须背负上生成栈帧这样一个沉重的负担，空谈 throw 的性能优化是无意义的。所以 所以当你遇到有人说try-catch一定要少用会影响性能时，或许你就不会再去盲从这种“建议”了。 却是一种过于乐观的结论。我们当然不能无节制地使用 try-catch，因它不仅使程序变得支离破碎，而且除非不会发生异常抛出，否则 JVM 对它进行的优化，只是杯水车薪。 &emsp;&emsp;我们应当永远记住，抛出异常是昂贵的，不是因为 try-catch 是昂贵的，因为无论怎么使用异常，异常都是昂贵的。 附原文： 异常机制 异常机制可以让你顺利的处理程序运行过程中所遇到的许多意想不到的情况。为了说明Java虚拟机处理异常的方式，我们来看一个名为NitPickyMath的类，它提供了针对整型的求模运算。和直接进行运算操作不同的是，该方法除零情况下将抛出受检查的异常（checked exceptions）。在Java虚拟机中除零时同样也会抛出ArithmeticException异常。NitPickyMath类抛出的异常定义如下： class DivideByZeroException extends Exception {} NitPickyMath类的remainder方法简单地捕获并抛出了异常： static int remainder(int dividend, int divisor) throws DivideByZeroException { try { return dividend % divisor; } catch (ArithmeticException e) { throw new DivideByZeroException(); }} remainder方法仅仅只是将两个int入参进行了求模运算（也使用了除法）。当除数为0时，求模运算将抛出ArithmeticException异常，该方法将捕获这个异常并抛出一个自定义DivideByZeroException异常。 DivideByZeroException 和ArithmeticException 的不同之处在于前者是受检查异常，而后者是非受检查异常。因此后者抛出时不需要在方法头添加throws语句。Error或RuntimeException类的所有子类都是非受检查异常（例如ArithmeticException就是RuntimeException的子类）。 使用javac对remainder方法进行编译，将得到如下字节码： remainder方法主体的字节码序列: 0 iload_0 // 压入局部变量0 (传入的除数) 1 iload_1 // 压入局部变量0 (传入的被除数) 2 irem // 弹出除数, 弹出被除数, 压入余数 3 ireturn // 返回栈顶的int值 (余数) catch语句的的字节码序列 (ArithmeticException): 4 pop // 弹出ArithmeticException引用（因为没被用到） 5 new #5 // 创建并压入新对象DivideByZeroException的引用 DivideByZeroException 8 dup // 复制栈顶的DivideByZeroException引用，因为它既要被初始化又要被抛出，初始化将消耗掉栈顶的一个引用 9 invokenonvirtual #9 &lt;Method DivideByZeroException.()V&gt; // 调用DivideByZeroException的构造器来初始化，栈顶引用出栈 12 athrow // 弹出Throwable对象的引用并抛出异常 可以看到remainder的字节码序列主要分成了两部分，第一部分是方法正常执行的路径，这部分对应的pc程序计数器偏移为0到3。第二部分是catch语句，pc偏移为4到12。 运行时，字节码序列中的irem指令将抛出ArithmeticException异常，虚拟机将会根据异常查表来找到可以跳转到的catch语句位置。每个含有catch语句的方法的字节码中都附带了一个异常表，它包含每个异常try语句块的条目（entry）。每个条目都有四项信息：起点、终点、跳转的pc偏移位置以及该异常类所在常量池中的索引。remainder方法的异常表如下所示： Exception table：from to target type0 4 4 上面的异常表显示了try语句块的起始位置为0，结束位置为4（不包含4），如果ArithmeticException异常在0-3的语句块中抛出，那么pc计数器将直接跳转到偏移为4的位置。 如果在运行时抛出了一个异常，那么java虚拟机会按顺序搜索整个异常表找到匹配的条目，并且仅会匹配到在其指定范围内的异常。当找到第一个匹配的条目后，虚拟机便将程序计数器设置为新的偏移位置，然后继续执行指令。如果没有条目被匹配到，java虚拟机会弹出当前的栈帧（停止执行当前方法），并继续向上（调用remainder方法的方法）抛出同样的异常。当然上级方法也不会继续正常执行的，它同样需要查表来处理该异常，如此反复。 开发者可以使用throw申明来抛出一个异常，就像remainder方法的catch块中那样。相应的字节码描述如下：操作码 操作数 描述athrow 无 弹出Throwable对象引用，并抛出该异常 athrow指令弹出操作数栈栈顶的引用，该引用应当为Throwable的子类 (或者就是 Throwable自身)。思考 回到开头讨论的话题，你觉得下面两段代码性能差异有多大A： for (int i = 0; i &lt; 1000000; i++) { try { // throw exception; } catch (Exception e) { }} B： try { for (int i = 0; i &lt; 1000000; i++) { }} catch (Exception e) {} 这篇博客给出了结果以及基准测试方法：try catch 对性能影响 。 我也使用JMH进行了测试，环境和细节就不列出了。其中使用了-Xint参数控制JIT热点编译，结果如下：异常抛出 关闭JIT 开启JIT(默认开启)A无异常抛出 两者耗时几乎相同 两者耗时几乎相同A每次都抛异常 A耗时约是B的30倍 两者耗时几乎相同 了解了译文中的异常的机制后，我们知道try-catch其实不过是在class文件中加了一个异常表用于异常查表，如果没有异常抛出，程序的执行方式和不包含try-catch块完全相同。如果有异常抛出，那么性能的确会下降，而这是有throw导致的，与try-catch无关。此时需要根据实际的业务来预估该方法抛出异常的频率有多高，就算你不去管，当方法被执行次数过多时，java虚拟机也会通过JIT来编译这段方法，编译过后两者的执行效率也是几乎相同的。注意，关闭JIT后循环方法整体性能下降了几十倍。 所以当你遇到有人说try-catch一定要少用会影响性能时，或许你就不会再去盲从这种“建议”了。当然在知晓这个信息的同时，我们反倒更应该去思考如何从业务和代码逻辑的角度来适当地使用try-catch写出更漂亮的代码。 本文参考："},{"title":"系统的弹性","date":"2017-10-21T12:07:23.000Z","url":"/2017/10/21/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/","tags":["系统架构"],"content":"背景介绍&emsp;&emsp;1999年，Dan Kegel 在互联网上发表了一篇文章，首次将 C10K 问题带入软件工程师的视野。在那个互联网勃兴的年代，计算机的运算处理能力，ISP 能够提供的带宽和网速都还十分有限，用户的数量也很少（那时候一个网站几百个人是很正常的事）。Dan Kegel 却已经敏锐地注意到极端的场景下资源紧张的问题。按照他的观察，某些大型的网络站点需要面对高达10000个客户端的并行请求。以当时的通行系统架构，单机服务器并不足以处理这个这个问题（当时绝大部分系统也没有那么大的流量，所以大部分人也没意识到这个问题）。因此，系统设计者必须为 C10K 问题做好准备。在那篇文章之中， Dan Kegel 提出了使用非阻塞异步 IO 模型，和使用各种内核系统调用黑魔法来提高系统 IO 性能的方式，来提高单机的并行处理能力。不得不说，这篇文章在当时很有先驱意义，它使得大规模网络系统的流量问题浮上了水面，也让人们意识到了系统容量建模和扩容提升性能的重要性。在它的启发下，C10K 问题出现了很多变种，从并发 C10K clients，到并发 C10K connections，到 C10K concurrency，可谓百花齐放。针对这些问题，也出现了很多的解决方案： &emsp;&emsp;cpu 密集型？上高频 CPU， 上多核，上多处理器，开多线程/进程。 &emsp;&emsp;io 密集型？换ssd。还不够？更改 IO 策略，Reactor/Proactor。调高系统参数（包括但不仅限于文件描述符等系统资源，tcp 协议栈队列大小等等）。windows 出现了 IOCP，Java 把 IO 更新换代，从 BIO 变成了 NIO/AIO。 &emsp;&emsp;内存密集型？换 OS，加内存条，使用池化内存，使用各种 kernal call（又是各种黑魔法）。 &emsp;&emsp;单机纵向扩容提升（scale up）处理能力有极限，那就来横向扩容提升（scale out）分布式处理。在系统上找一条竖线切开，化整为零，负载均衡，各种 Hash Mod，Round robin 轮番上阵。 &emsp;&emsp;时间过去十几年，系统设计师要解决的架构问题，恐怕已经是 C1000K 问题了。 &emsp;&emsp;时代的发展，并没有停步于此。 &emsp;&emsp;当今系统设计要面临的问题，出现了新的特点： &emsp;&emsp;首先，总有些有限的资源，不像带宽 cpu 一样呼之即来，最典型的例子是火车票、天猫双十一时的秒杀iPad。谚语有云，一只舰队的航行速度，由其中最慢的舰船决定。高并发的千军万马，即使浩浩荡荡地通过了我们设计的各种数据链路，最终到达要争夺各种各样资源的使用权的地方–数据库。这种争夺的互斥性，为我们带来了各种各样的锁（不管是乐观的还是悲观的）。锁是不可避免的。而这种锁的存在，使得一个大型系统的 QPS 和 QoS，严重受到后端数据存储层的制约。相信很多人对常见的 RDBMS 都有各种各样的使用经验。不同场景下不同类型的数据库的 TPS 可以达到几千到上万，甚至几万。但可以明确的看到，这种性能效率，无法和 C10K-C1000K 的系统轻松对接。传统的关系型数据库从关系代数出发的各种范型理论，给其实现戴上了沉重的历史枷锁，大部分的 RDBMS 的性能提升空间的天花板很快就能看到。从阿姆达尔定律出发，这就是系统的不可扩展瓶颈。我们当然可以使用分布式存储或者 NoSQL 来缓解这一问题，但因为 CAP 定律和网络分区现象的存在，我们并不能根本改善虚幻的锁的困境。这种困境的存在，使得一个很高 QPS 的系统的性能，会被后端 TPS 拉平，因而 QPS 并不能无限推高。因为没有 TPS 1000K 的 RDBMS，真正的 C1000K 的系统恐怕是镜花水月，无法实现的。 &emsp;&emsp;其次，流量出现了分化。大部分的系统设计的额定性能，总有界限，但在某些场景下，却会出现要求无限性能的需求。因为带宽和上网设备变得廉价，制造海量网络流量在当今变得非常轻而易举。最典型的例子是，12306每年都饱受人肉 DDoS 攻击的困扰，因为火车票是一种紧俏资源，用户如果刷不到就回不了家，所以一个无效的请求会触发更多的无效请求。一个抢不到票的用户的行为模式会变得好像肉鸡一样，刷不到票就他会无限刷，一台电脑刷不到就换两台，不行再来手机刷，再不行去买抢票插件。网络时代变发达，用户可以发送请求的能力变得无比强大，火车座位却没有变多 ，12306的系统似乎设计得无论多高，都无法承载那么多流量（如果把12306全年的流量可视化出来，恐怕会看到一个非常尖锐的 Spike）。一个很高 QPS 的系统，终究不是一个无限 QPS 的系统。 &emsp;&emsp;最后，并没有必要刻意追求 C10K 到 C1000K的高流量设计。软件设计的艺术是掌控复杂性（Complexity），不要为了设计的性能指标使设计失控，无法维护。 一个系统的平均 QPS 和峰值 QPS 完全可以不是一个数量级。如何兼顾这两种运行模式，是一个很大的设计难题。因为为峰值的 QPS 准备的系统在空闲的时候会浪费很多资源，为了设计一个高 QPS 的系统已经带来了很多复杂性（见上面列举的方法），要设计一个弹性伸缩的系统，又要带来更多的复杂性。这些复杂性当然催生了很多新技术的诞生，比如各种弹性云，秒级启动的容器，各种虚拟化技术（根据小道消息，亚马逊的云服务就是这样逼出来的）。但我们是不是真的有必要投入那么多的 effort，来追求这种尽善尽美？逆取不得，且宜顺守。有的时候， worse is better。 &emsp;&emsp;溯游从之，道阻且长。溯洄从之，宛在水中央。我们也许可以停下追求 QPS 的脚步，尝试思考下如何用恒定的一般性能（比如，几千的 QPS？），来解决大并发问题。如果我们能够用一些简单的技巧来保护我们的系统，能够过滤掉无效的流量，进而满足极端场景下性能的可靠性需求。 如何保护系统&emsp;&emsp;首先定义几个概念。在高并发的场景下，有一些请求是低质量的，没有触及到核心系统的核心资源的争夺，而有一些请求则是高质量的，必然要进入核心系统进行有限资源的争夺。保护核心系统的技术手段的中心思想，应该是尽量保证从高质量请求视角下看服务的高可用性，减少低质量请求对核心系统负载能力的干扰。 &emsp;&emsp;缓存、降级和限流，是常见的三种保护系统的利器。这三者相辅相成，最终的目的是把流量的峰值削掉，让蜂拥而至的请求在一个漏斗型的链路里逐渐变少。我们需要追求的效果，就是我们核心系统的正常设计，能够负载最终到达的高质量流量。 &emsp;&emsp;缓存提高了系统的读能力。如果我们能够把很多不需要用到锁的相对静态的资源，放到高速缓存之中，就能剥离掉大部分的低质量请求。这样一个外围系统的存在，就像一个护城河，泾渭分明地把不需要太强大一致性的低质量请求拦在核心系统之外。优秀的缓存，就像一个乘数效应的放大器，可以把一个低负载能力的系统，增幅为一个强大负载能力的系统。一个常见的例子，就是各种骨干网络上 CDN 的存在。 &emsp;&emsp;降级，则试图彻底过滤掉低质量的请求。如果核心系统存在多种类型的服务，高质量请求的服务和低质量请求的服务混布（有些低质量请求的依然具有动态性和强一致性，不适合使用缓存），甚至有些弹性系统，出现高质量请求和低质量请求的多租户部署，则系统流量紧张时，有必要关掉所有低质量请求进入系统的可能性。一个常见的例子，就是支付宝在流量紧张的时候（比如双十一大促），会关掉支付宝查询信用卡账单的功能。这种情况下低质量的请求不会混在高质量的请求之中，争夺性能资源，间接放大了核心系统的性能容量。降级的存在，使得系统可能从完全可用（fully functional）的状态，进入部分可用（partially functional）的状态。有损服务虽然不如正常服务体验好，总好过最后大家同归于尽，系统 panic 甚至 crash 要得多。降级不仅保护了核心系统作为被调用的高质量请求响应能力，实际上也保护了调用方的负载能力。因为在复杂调用链路中，如果没有做过异步化改造，链路上的任何一个 callee hangs，会导致整条链路向前所有的 caller 都逐渐 hangs。因为牵一发而动全身的效应，各种层面上的 request 会在前段 caller 里不断累积，进而导致各种 caller 也进入 panic 甚至 crash 的状态。 &emsp;&emsp;限流的应用场景，更加广泛。它不需要做各种请求的区分，就可以直接保证进入核心系统的流量不好超过系统的负载能力。限流的中心思想非常简单，即在各种层面上彻底限制住系统的并发能力，不做不着边际的性能承诺，只承诺响应达到 QPS 的负载能力，超过限制的请求，一律拒绝掉。可以说，限流的存在实现了降级的效果。笔者认为，降级和限流的关系，类似 Factory Method Pattern 与 Template Method Pattern 的关系。 开始谈谈限流&emsp;&emsp;实际上我们在工作生活中已经见识过许多限流的例子。 &emsp;&emsp;一台机器，明明各种性能指标都还没有打满，QPS 却一直上不去，最后发现是网卡的问题，换了一块新网卡（有时候是换掉交换机上的一根光纤），QPS 马上就上去了。 这是硬件因素在限流。 &emsp;&emsp;我们想要下载一个电影，但被百度云的会员限制，没有办法开到全速，充了会员，下载速度立刻就上去了，这是软件因素在限流。 &emsp;&emsp;限流可以发生在 OSI 协议栈的硬件部分，也可以发生在软件部分。流量可以被限制在协议的出口端，也可以被限制在协议的入口端。限流还可以发生协议栈之上，有时候，我们可以把底层的协议栈当做空气一样透明，只在应用内部做限流。 &emsp;&emsp;我们可以粗略地把将要讨论的问题分为几个小的子问题：常见的限流算法是什么？如何在一台机器上限流？如何在分布式环境中限流？ 常见的限流算法&emsp;&emsp;在网上搜一搜，就可以常见的限流算法并不多，大致上分为计数器算法、漏桶（Leacky Bucket）和令牌桶（Token Bucket）。这些算法各有各的长处，但他们都有一个基于配额（Quota） 的设计思路，颇有异曲同工之妙。即要产生请求，必须要得到许可（Permit），通过控制许可的总数，和通过控制许可发放的速度，来实现 QPS 的节流（Throttling）。不同的算法，就是在这些要素上做不同的变化。我们可以把这种算法称作精确限流算法，我们姑且称之为 Rate Limiter Algorithm。 &emsp;&emsp;除此之外，实际上还存在一些可以进行不精确限流的模糊限流算法，我们姑且称之为 Concurrency Limiter Algorithm。 &emsp;&emsp;并发性和速率实际上是紧密相连的。维基百科上有有趣的讨论。 计数器算法&emsp;&emsp;这种算法的设计思想，是对一个要限流的资源配上一个计数器。每次请求前对这个计数器进行加操作或者减操作，通过对当前计数器的值与 Limit 值的 对比，决定是否允许操作执行（即发放 Permit）。 &emsp;&emsp;让我们用一个应用内的多线程环境举例。 &emsp;&emsp;一个简单的总量计数器如下： &emsp;&emsp;这个总量计数器的设计，使得我们可以让我们控制同一瞬间能够处理的请求的数量。聪明的读者可能已经想到了，这是在一种控制并发请求进入临界区访问资源的节流思想，和使用 Java 自带的 Semaphore 异曲同工。唯一的差别是，Semaphore 可以阻塞请求，使得请求最终可以可以执行完成，而使用 atomic 的做法更加简单粗暴，如果没有办法处理请求，就丢弃请求，不再等待。我们当然可以让 atomic 具备阻塞的能力，但这就要引入自旋了。 &emsp;&emsp;这个总量计数器并不与某个特定的时间窗口挂钩，而且又有衰减作用，这也就意味着它能够限制一瞬间的并发总数，并且可以被复用，但我们无法预测它实际控制出的 QPS 数目。所以它是一个 Concurrency Limiter Algorithm。 &emsp;&emsp;所以我们可以试着把它和某个特定的时间窗口挂钩，让这个计数器只针对一个时间节点起作用。这就达到了 Rate Limiter Algorithm 的作用。借用缓存的实现如下： &emsp;&emsp;在这里，我们使用了一个有效期为2秒的缓存（为了防止时间不准，实际上应该是任何大于1s 的缓存有效期都可以拿来配置缓存）来存储 atomic与当前的时间。每个请求会在当前的时间窗口里尝试增加计数器，如果当前时间窗口内计数器还没有超过 QPS 极限值，就处理请求，否则就进入自旋，等待下一秒的新的缓存计数器的到来。 &emsp;&emsp;这种 QPS 算法的时间窗口，最好设置为1秒为单位。以上面的例子为单位，每秒钟诞生一个limit = 1000的计数器是正确的做法。如果为了减少缓存计数器数量，试图用1分钟长度的缓存配合 limit = 60000，有可能在极端情况下会出现，在59秒 和61一共出现120000个请求的情况。此时计数器依然允许这些流量通过，但这三秒的 QPS 已经远远高于1000。使用计数器的 RateLimiter 的简单粗暴方法，只能说是够用，为了防止临界点性能毛刺（Spike）的存在，我们要严格保证生成计数器的数量和顺序，本质上还是有很大的优化空间。 &emsp;&emsp;思考题：如果想用更大的时间窗口，其实还有一个办法，就是使用滑动窗口的方法（Sliding Window）。具体的设计思路，可以参考这篇博文。 漏桶算法 根据维基百科，漏桶算法的描述如下： 一个固定容量的漏桶，按照常量固定速率流出水滴； 如果桶是空的，则不需流出水滴； 可以以任意速率流入水滴到漏桶； 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。 &emsp;&emsp;我们可以把水滴想象成一个个许可。request 们在漏桶里排队，漏桶算法是一个完全定时发令牌的算法，因此这些请求也因此被间隔性地阻滞在桶中，只有通过固定的时间间隔，才能顺利的通过这个漏桶。 &emsp;&emsp;Java 程序员看到这里，恐怕很容易联想到一个 Bouded Queue 和一个 Timing Comsumer 的组合。实际上，我们把准备一个定长的 Queue，和一个定时线程池，每次有新的请求发生，都投入这个定长 Queue 中，然后让定时线程池里的 worker 线程定时地取出 Queue 里面的请求，就可以模拟漏桶算法。或者，我们也可以参考以下的代码，来把漏桶赋予许可的部分单独封装成一个 API： &emsp;&emsp;我们可以看到，漏桶算法使得不管是任何速度的入（inboud）流量，最后都规规矩矩地变成了固定速度的出（outbound）流量。因此，漏桶算法不仅起到了限流的作用，还可以作为计量工具（The Leaky Bucket Algorithm as a Meter），起到流量整形（Traffic Shaping）和流量控制（Traffic Policing）的作用。但限流算法，也有一个固有的缺点，就是不允许突发流量一次通过，必须严格按照 qps 的时间窗口一个一个地通过漏桶。 令牌桶算法 &emsp;&emsp;令牌桶算法是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下： 假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌； 桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝； 当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上； 如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。 &emsp;&emsp;在这里，我们可以看到令牌桶算法表现出的和漏桶算法不一样的特点： 令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求； 漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝； 令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌），并允许一定程度突发流量； 漏桶限制的是常量流出速率（即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2），从而平滑突发流入速率； 令牌桶允许一定程度的突发，而漏桶主要目的是平滑流入速率； 令牌桶算法拿不到令牌的时候，是可以在缓冲区等待的。而漏桶算法请求无法进入漏桶，则只有被丢弃的结局。 两个算法实现可以一样，但是方向是相反的，对于相同的参数得到的限流效果是一样的。 &emsp;&emsp;由此看来，令牌桶算法的包容性更强。 &emsp;&emsp;如果我们同样用 Java 来实现的话，一个简单的令牌桶算法可以用一个 token 计数器来实现。有一个后台线程定期地为计数器进行加值，而众多 request 处理线程则随时地为这个计数器减值，两者处于竞争状态（因此要考虑 Thread Safety 问题）。后台线程如果加满了计数器，会暂时放弃加值操作，request 处理线程如果将计数器减为负数，可以暂时放弃减值并放弃请求或将请求放回缓冲区。 &emsp;&emsp;或者，我们也可以参考以下的代码，来把令牌桶赋予许可的部分单独封装成一个 API： &emsp;&emsp;如果仔细思考漏桶算法和令牌桶算法，他们适用的场景都比计数器算法要广泛，使用起来对流量的调整也更平滑，而且也不会出现临界点性能毛刺（思考下，为什么），所以是更加健壮的业界通行算法。也因为它们是业界通行的算法（实际上中兴和华为都有关于这两种算法的限流专利。互联网公司遇到的流量问题，被通信公司解决了。其实这也是一种思考和学习的启示，我们在新的领域遇到的新的问题，是不是已经被其他人解决了？这种情况 Dijkstra 也遇到过好几次。），所以 Guava 类库提供了相关的实现，不需要我们自己实现。 Guava 的 RateLimiter 实现&emsp;&emsp;com.google.common.util.concurrent.RateLimiter 是 Guava 并发包中的限流器的抽象类。它有一个子类叫 SmoothRateLimiter。这个 SmoothRateLimiter 又有两个内部子类 SmoothBursty 和 SmoothWarmingUp。这两个子类用不同方式实现了近似令牌桶和漏桶的算法。 &emsp;&emsp;其中 SmoothBursty 专门针对大流量设计，允许请求使用未来令牌担保（想象一个允许负数的令牌机制），它不计算当前请求的的等待时间，而是计算下一个请求的等待时间，是一个非常有意思的实现。 &emsp;&emsp;而 SmoothWarmingUp 实现了一个类似 TCP 流量拥塞控制“加性增”的算法，基本思路是：系统在未启动和长期不启动后会存在缓存失效等性能下降的问题。在走完预热周期以前不允许达到指定的 QPS。这个实现对突发流量依然有一定的支持，因此并不是一个严格的楼桶算法。 &emsp;&emsp;SmoothWarmingUp 的预热算法示意图： &emsp;&emsp;RateLimiter 的具体用法颇为复杂，此处就不贴代码了，请读者自行搜索教程和阅读 Github 上的项目文档。 我们应该如何在一台机器上限流&emsp;&emsp;聊了这么多底层的代码和原理，应该想想怎么应用了。 &emsp;&emsp;上面已经提到，我们可以使用模糊的并发性限流算法，也可以使用精确而主动的速率限流算法。让我们思路广泛点，想想可以在什么层面上做各种限流。 &emsp;&emsp;从操作系统层面，我们可以一开始就限制一个操作系统能够使用的硬件资源，包括但不限于 CPU、内存、硬盘和网卡。现代应用可以借助虚拟机或者容器对资源进行虚拟切割，制造一个有物理极限的操作系统配额限制。 &emsp;&emsp;在应用层面，我们可以限制一个进程可以使用的内存和可用的文件描述符数量。 &emsp;&emsp;在涉及到 JVM 的应用程序时，我们还可以对内存限制进行细化调优配置。 &emsp;&emsp;在涉及到 TCP 协议时，也有很多内核参数可以调节，比如缓冲区队列的大小，irqbalance， MTU 等等。 &emsp;&emsp;在上层的应用软件，通常存在一种连接资源池化复用的机制。在 Tomcat/MySQL/Redis 里，通常都有连接数、工作线程数和请求/backlog缓冲区等不同的配置选项（和 TCP 的协议栈实现大同小异）。 &emsp;&emsp;在经过这些模糊的限流配置以后，我们可以在应用内部使用上面提到的算法自己实现精确的限流。也可以使用上面提到 RateLimiter 限流，甚至可以使用近几年新出的 Hystrix 做限流（Hystrix 自带一个池化复用的解决方案，感兴趣的读者可以研究下）。 我们应该如何在分布式环境下限流&emsp;&emsp;现代的服务化/组件化应用，在一个虚拟的应用调用背后，往往有若干个真正的服务实例在承载 QPS。这也就意味着，我们对一个服务进行限流，要考虑分布式环境下多个实例的协同问题。 &emsp;&emsp;在分布式环境下限流的思路，主要有两种： 在一台机器上把所有流量控制住，然后分发给其他所有机器。我们姑且把这种限流思路称为反向代理式限流或者接入层限流。 在每台机器上单独做整体限流，然后寻找一个全局协调工具来协调全局的整体流量。我们姑且把这种思路称为协调器限流。 &emsp;&emsp;接入层同步限流的方案已经很成熟。 &emsp;&emsp;我们常见的反向代理 nginx 里有 ngx_http_limit_req_module 和 ngx_http_limit_conn_module 模块可以提供基于连接/请求测度的限流。在更加复杂的 OpenResty/Kong 上还可以实现各种粒度/维度的限流。 &emsp;&emsp;我们应该仔细考虑接入层限流的配置粒度。往接入层的上游来看，是针对自己后置的所有服务共用同一套限流配置，还是针对每一个资源单独一套限流配置？在做这样的配置的时候，要充分考虑后台不同资源的负载能力，使用大一统的配置不适合复杂的流量入口。 &emsp;&emsp;在这种分布式场景下限流还要考虑限流维度的问题。 &emsp;&emsp;从请求的链路两端来看，是以被调用方资源为维度来限流，还是以调用方请求来源为维度来限流？ &emsp;&emsp;以被调用方资源为维度来限流，是一种相当保守的策略，相当于一个资源的总体限流被所有调用方共享了，使一个资源变成了大锅饭。所有的调用方共享一个资源，贪婪的调用方会蚕食其他调用方的 QPS 配额。如果一个调用方的调用频率很高，在资源紧张的场景下，其他调用方会发生饥饿。如果资源的紧张，进一步导致限流策略更趋保守，那真是城门失火殃及池鱼了。 &emsp;&emsp;而如果以调用方为维度来限流，则需要引入类似分级的服务区分制度，对不同级别的服务调用授予不同级别的流量许可。这就要求服务在发起调用的时候能够表达自己的身份，而服务接入层可以理解这种身份，而我们可以针对不同的身份做不同的配置。实际上上面提到的几个反向代理，都支持区分调用方的 ip 地址甚至主机名的鉴别方案。但基于 ip 的流量限制还是略显粗疏，除非我们明确地知道请求 ip 地址背后的服务到底是什么（这可以引入一张配置表，可以是一张 excel 表，也可以是一个数据库的 table），否则还是使用某些服务鉴别报头为好。例如，我们可以要求所有的服务调用方都在发起请求时携带一个 requester-header 一样的 http 请求头，对调用链路上下游进行全面改造，然后在请求通过接入层时做专门鉴别。这种设计的思想类似于操作系统的优先级调度，比被调用方维度更为灵活，也需要做更细致的配置。 &emsp;&emsp;我们都知道接入层限流依赖于反向代理式的系统架构风格，而这种风格要求我们必须使用把限流放在调用方和被调用方的中间，好像一个仲裁者，有没有其他风格的体系结构呢？这就是我们接下来要谈到的协调器限流。 &emsp;&emsp;协调者限流的思想，是通过进程间通信的方法，在多个服务实例之间寻找到一个高性能支持原子化读写（也就意味着并发/并行安全）的存储，维护一个全局的限流计数器，然后多个服务实例通过动态地更新这一个限流计数器，来实现全局的限流配额动态扩散到各个服务节点的效果。通常的情况下，我们可以使用 Redis 的 incr 操作，配合编程语言（Lua/Java）等等来实现这一效果。 Redis 的官网上专门有一个例子，讨论这一问题。在我们得到了每台机器的限流配额以后，我们可以采用之前讨论过的单机限流方法进行限流了。当然，在这个思路上还有其他的延伸，如果不嫌 Zookeeper 的写性能低，也可以考虑使用 Zookeeper。 &emsp;&emsp;此外，如果我们的服务之间使用的是异步通信，如使用了 Kafka 或者 AMQP 的队列，可以考虑使用队列限流（阿里的人喜欢说的削峰填谷）。这种限流需要考虑的问题是怎样在 Message Consumer 消息分发时做限流，做设计的时候要考虑多个 Consumer 之间是怎样共享消息队列的（是拉模式还是推模式，是 queue 风格还是 P/S 风格？本 Consumer 的吞吐率能不能影响全局的吞吐率？）。 &emsp;&emsp;如果我们的服务之间的通信走的是自定义协议，比如两个服务器之间使用的是类 Thrift 客户端相互通信，那么可以考虑对客户端进行改造。这样不仅可以在请求到达被调用方时进行限流，也可以在流量离开调用方时进行限流。 最后做个总结&emsp;&emsp;总体来讲，限流是为了保护核心系统不要超负荷运行。系统超负荷运行，不仅对被调用者是危险，也对调用者是潜在风险。毕竟被调用者垮了，调用者也不能继续运行下去。限流可以从源头防止系统雪崩。但整个复杂的调用链路的使用场景千变万化，一套死板的限流不可能应付所有情况。所以我们应该有办法正确地识别系统的负载状况，采取对症下药的限流策略。这要求限流系统设计得必须有识别、统计能力（这需要监控系统提供数据输出），也要有动态配置能力。如果流量一上来，没有办法确认源头做细致配置，就盲目地把所有的流量都限死，那么只能保护自己，会造成其他本来正常运行的系统发生没有必要的性能抖动（Thrash），是一种头痛医头，脚痛医脚的方案。 &emsp;&emsp;本文写了那么长，总算结束了。下面列一下我囫囵吞枣的参考资料：      "},{"title":"大明朝里没好人","date":"2017-09-17T12:30:32.000Z","url":"/2017/09/17/%E5%A4%A7%E6%98%8E%E6%9C%9D%E9%87%8C%E6%B2%A1%E5%A5%BD%E4%BA%BA/","tags":["影评","杨幂"],"content":"&emsp;&emsp;大明朝里无好人。这篇文主要写写杨幂。"},{"title":"过零丁洋","date":"2017-09-17T11:23:45.000Z","url":"/2017/09/17/%E8%BF%87%E9%9B%B6%E4%B8%81%E6%B4%8B/","tags":["影评","诺兰"],"content":"倒叙把完整的段落裁剪开来，突显了拼接的价值。观众心中的悬念一得解脱，戏剧高潮就放大了。诺兰以往的片子，多层次的叙事构成了宏大的立体结构，也使得故事有了深邃的思考空间。 但是，《敦刻尔克》却是灵性全无，扬短避长的片子。 影片的前中半部充满了刻意的剪切，一直都在追亡逐北的急剧压迫感中度过，不断堆积观众的焦虑感，让人失去耐性。战争永远是荒谬的。《神奇女侠》虽然烂，但导演还知道要穿插几场文戏，让人思考个人、集体与战争的矛盾关系。更不用说《拯救大兵瑞恩》夜晚的对谈，导演借战士之口向观众口述人性的矛盾。诺兰不知道是不是有意拒绝平庸套路，把战争的煎熬一再翻炒，别的什么都不拍，观众在联军的狼狈里饱尝炼狱感，大晕其浪。以至于后来长空翰海一机划破夕阳和百船破浪，变成了功能性的高潮。观众看得长舒一口气，这场逃亡终于结束了，这个冗长的结构走到了尽头。 历史上的敦刻尔克大逃亡里，出现过很多毫不逊色于电影镜头的英勇作战场面。德军装甲师与空军，法国的陆军和英国的空军进行激烈交锋，敦刻尔克的逃亡空间可谓用无数尸体铺出的血路。而诺兰为了突出逃亡的仓皇，放弃了全局的观察视角，只是局促于海滩一隅。这部电影最讨厌的部分就是已经爬上船的败兵不断地被打进水里，好像下饺子过了火。似乎只有这样做，这场逃亡才能变成不到两个小时的电影长度。诺兰真该再跟卡梅隆学学怎么拍灾难和往电影里灌水。 月长石号游艇乘风破浪穿过英吉利海峡的故事可谓全片最上乘的部分，因为战争并不只是爆炸，枪炮和飞机飞来飞去，它其实关乎每个人的进退选择。敦刻尔克之所以取得成功，既是海岸边的士兵们苦苦求生的结果，也是民间救援人士勇赴国难的结果。月长石号的船长沉稳而坚毅，既富有人性的同情，又充满了夹缝中寻找生机的智慧。他宽容了失手行凶的懦夫败兵，不惜犯难，努力拯救可能给自己带来危机的飞行员，更不畏汤火，在燃油中把落水的盟军塞满船舱。这个故事里他无豪言壮语，却有很多一往无前的行动。他注定成为历史里不起眼的注脚，正如那个意外摔死的孩子一样。但导演写他却不是闲笔，是堂堂的主角待遇。 全片还有几个令人特别讨厌的地方。 首先就是船舱里的生存游戏，相比起以往电影人性考验桥段显得滑稽而不可推敲。诺兰为了凸显人性的复杂，设计了一个破船里的囚徒困境。这种人性实验是电影里的寓言，当然并不一定要有好结果，但当然要拍出有信服力的结果才能让观众忍受下去。大家同舟共济变同室操戈才不过几分钟，就讨厌得观众恨不得船早点翻了。我看来看去不明白，他们这个时候归罪于一个法国士兵的重量，于一艘将覆漏舟有何意义。后来果然大家一起做了落汤鸡。相信有不少观众一定十分怀念黑暗骑士里面的炸弹故事。 其次就是结尾作为煞尾的历史切入。法国与德军交战六个礼拜即投降，英法部队毫无准备即被逼入绝境。敦刻尔克乃是大英帝国的白登之围，正是光荣四碎，长期黑暗到来的历史转折点（接下来就到鹰击长空的不列颠空战，抢滩登陆的海狮计划，沉船无数的潜艇战，巴巴罗萨闪击，直到斯大林格勒了）。但不知道是不是导演拍到这里已然预算用完，结尾的舰船既少得可怜，回家的过程也几乎都略过了。迫降的飞行员烧掉飞机，一副功成身退的表情。回到家的士兵们也突然惊魂得定，虽然不屑于丘吉尔的政客说辞，却有解甲归田的放松。历史的厚重被犬儒式的英雄主义代替了，电影戛然而止。诺兰一反传统战争片的拔高结尾也不是不可以，但这种其惟春秋的史官态度并无思考余地，因为结尾选取的历史人物的状态并不相互呼应，也就谈不上什么耐人寻味的留白了。 最后就是中文的字幕翻译，可能贾老师不知道，信达雅这三个字是有先后顺序的。有些地方为了雅而扭曲原意，信达都丧失了。 "}]