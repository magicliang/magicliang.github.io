<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>系统的弹性 | 守株阁</title><meta name="author" content="magicliang"><meta name="copyright" content="magicliang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="背景介绍 1999年，Dan Kegel 在互联网上发表了一篇文章，首次将 C10K 问题带入软件工程师的视野。在那个互联网勃兴的年代，计算机的运算处理能力，ISP 能够提供的带宽和网速都还十分有限，用户的数量也很少（那时候一个网站几百个人是很正常的事）。Dan Kegel 却已经敏锐地注意到极端的场景下资源紧张的问题。按照他的观察，某些大型的网络站点需要面对高达10000个客户端的并行请求。以当">
<meta property="og:type" content="article">
<meta property="og:title" content="系统的弹性">
<meta property="og:url" content="https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/index.html">
<meta property="og:site_name" content="守株阁">
<meta property="og:description" content="背景介绍 1999年，Dan Kegel 在互联网上发表了一篇文章，首次将 C10K 问题带入软件工程师的视野。在那个互联网勃兴的年代，计算机的运算处理能力，ISP 能够提供的带宽和网速都还十分有限，用户的数量也很少（那时候一个网站几百个人是很正常的事）。Dan Kegel 却已经敏锐地注意到极端的场景下资源紧张的问题。按照他的观察，某些大型的网络站点需要面对高达10000个客户端的并行请求。以当">
<meta property="og:locale">
<meta property="og:image" content="https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/leaky-bucket.png">
<meta property="article:published_time" content="2025-07-15T13:18:10.000Z">
<meta property="article:modified_time" content="2025-10-22T08:01:33.087Z">
<meta property="article:author" content="magicliang">
<meta property="article:tag" content="系统架构">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/leaky-bucket.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "系统的弹性",
  "url": "https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/",
  "image": "https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/leaky-bucket.png",
  "datePublished": "2025-07-15T13:18:10.000Z",
  "dateModified": "2025-10-22T08:01:33.087Z",
  "author": [
    {
      "@type": "Person",
      "name": "magicliang",
      "url": "https://magicliang.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: magicliang","link":"Link: ","source":"Source: 守株阁","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '系统的弹性',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="守株阁" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/leaky-bucket.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">守株阁</span></a><a class="nav-page-title" href="/"><span class="site-name">系统的弹性</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">系统的弹性</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-07-15T13:18:10.000Z" title="Created 2025-07-15 21:18:10">2025-07-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-10-22T08:01:33.087Z" title="Updated 2025-10-22 16:01:33">2025-10-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">36k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>129mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>背景介绍</h1>
<p>1999年，Dan Kegel 在互联网上发表了一篇文章，首次将 <a target="_blank" rel="noopener" href="http://www.kegel.com/c10k.html">C10K</a> 问题带入软件工程师的视野。在那个互联网勃兴的年代，计算机的运算处理能力，ISP 能够提供的带宽和网速都还十分有限，用户的数量也很少（那时候一个网站几百个人是很正常的事）。Dan Kegel 却已经敏锐地注意到极端的场景下资源紧张的问题。按照他的观察，某些大型的网络站点需要面对高达10000个客户端的并行请求。以当时的通行系统架构，单机服务器并不足以处理这个这个问题（当时绝大部分系统也没有那么大的流量，所以大部分人也没意识到这个问题）。因此，系统设计者必须为 C10K 问题做好准备。在那篇文章之中， Dan Kegel 提出了使用非阻塞异步 IO 模型，和使用各种内核系统调用黑魔法来提高系统 IO 性能的方式，来提高单机的并行处理能力。不得不说，这篇文章在当时很有先驱意义，它使得大规模网络系统的流量问题浮上了水面，也让人们意识到了系统容量建模和扩容提升性能的重要性。在它的启发下，C10K 问题出现了很多变种，从并发 C10K clients，到并发 C10K connections，到 C10K concurrency，可谓百花齐放。针对这些问题，也出现了很多的解决方案：</p>
<p>cpu 密集型？上高频 CPU， 上多核，上多处理器，开多线程/进程。</p>
<p>io 密集型？换ssd。还不够？更改 IO 策略，Reactor/Proactor。调高系统参数（包括但不仅限于文件描述符等系统资源，tcp 协议栈队列大小等等）。windows 出现了 IOCP，Java 把 IO 更新换代，从 BIO 变成了 NIO/AIO。</p>
<p>内存密集型？换 OS，加内存条，使用池化内存，使用各种 kernal call（又是各种黑魔法）。</p>
<p>单机纵向扩容提升（scale up）处理能力有极限，那就来横向扩容提升（scale out）分布式处理。在系统上找一条竖线切开，化整为零，负载均衡，各种 Hash Mod，Round robin 轮番上阵。</p>
<p>时间过去十几年，系统设计师要解决的架构问题，恐怕已经是 <a target="_blank" rel="noopener" href="http://www.ideawu.net/blog/tag/c1000k">C1000K</a> 问题了。</p>
<p>时代的发展，并没有停步于此。</p>
<p>当今系统设计要面临的问题，出现了新的特点：</p>
<p>首先，总有些有限的资源，不像带宽 cpu 一样呼之即来，最典型的例子是火车票、天猫双十一时的秒杀iPad。谚语有云，一只舰队的航行速度，由其中最慢的舰船决定。高并发的千军万马，即使浩浩荡荡地通过了我们设计的各种数据链路，最终到达要争夺各种各样资源的使用权的地方–数据库。这种争夺的互斥性，为我们带来了各种各样的锁（不管是乐观的还是悲观的）。<a target="_blank" rel="noopener" href="http://www.ideawu.net/blog/tag/c1000k">锁是不可避免的</a>。而这种锁的存在，使得一个大型系统的 QPS 和 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/qos/404053?fr=aladdin">QoS</a>，严重受到后端数据存储层的制约。相信很多人对常见的 RDBMS 都有各种各样的使用经验。不同场景下不同类型的数据库的 TPS 可以达到几千到上万，甚至几万。但可以明确的看到，这种性能效率，无法和 C10K-C1000K 的系统轻松对接。传统的关系型数据库从关系代数出发的各种范型理论，给其实现戴上了沉重的历史枷锁，大部分的 RDBMS 的性能提升空间的天花板很快就能看到。从阿姆达尔定律出发，这就是系统的不可扩展瓶颈。我们当然可以使用分布式存储或者 NoSQL 来缓解这一问题，但因为 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/CAP#3">CAP</a> 定律和网络分区现象的存在，我们并不能根本改善虚幻的锁的困境。这种困境的存在，<strong>使得一个很高 QPS 的系统的性能，会被后端  TPS 拉住</strong>，因而 QPS 并不能无限推高。因为没有 TPS 1000K 的 RDBMS，真正的 C1000K 的系统恐怕是镜花水月，无法实现的。</p>
<p>其次，流量出现了分化。大部分的系统设计的额定性能，总有界限。<strong>世界是互连的，但在某些场景下，却会出现要求无限性能的需求</strong>。因为带宽和上网设备变得廉价，制造海量网络流量在当今变得非常轻而易举。最典型的例子是，12306每年都饱受人肉 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E6%94%BB%E5%87%BB/3802159?fromtitle=DDOS&amp;fromid=444572">DDoS</a> 攻击的困扰，因为火车票是一种紧俏资源，用户如果刷不到就回不了家，所以一个无效的请求会触发更多的无效请求。一个抢不到票的用户的行为模式会变得好像<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E8%82%89%E9%B8%A1/33880">肉鸡</a>一样，刷不到票就他会无限刷，一台电脑刷不到就换两台，不行再来手机刷，再不行去买抢票插件。网络时代变发达，用户可以发送请求的能力变得无比强大，火车座位却没有变多 ，12306的系统似乎设计得无论多高，都无法承载那么多流量（如果把12306全年的流量可视化出来，恐怕会看到一个非常尖锐的 Spike）。<strong>一个很高 QPS 的系统，终究不是一个无限 QPS 的系统</strong>。</p>
<p>最后，并没有必要刻意追求 C10K 到 C1000K的高流量设计。软件设计的艺术是掌控复杂性（Complexity），不要为了设计的性能指标使设计失控，无法维护。 一个系统的平均 QPS 和峰值 QPS 完全可以不是一个数量级。如何兼顾这两种运行模式，是一个很大的设计难题。因为为峰值的 QPS 准备的系统在空闲的时候会浪费很多资源，为了设计一个高 QPS 的系统已经带来了很多复杂性（见上面列举的方法），要设计一个弹性伸缩的系统，又要带来更多的复杂性。这些复杂性当然催生了很多新技术的诞生，比如各种弹性云，秒级启动的容器，各种虚拟化技术（<a target="_blank" rel="noopener" href="https://www.quora.com/How-and-why-did-Amazon-get-into-the-cloud-computing-business-Rumor-has-it-that-they-wanted-to-lease-out-their-excess-capacity-outside-of-the-holiday-season-November%E2%80%93January-Is-that-true">根据小道消息，亚马逊的云服务就是这样逼出来的</a>）。<strong>但我们是不是真的有必要投入那么多的 effort，来追求这种尽善尽美</strong>？逆取不得，且宜顺守。有的时候， worse is better。</p>
<p>溯游从之，道阻且长。溯洄从之，宛在水中央。我们也许可以停下追求 QPS 的脚步，尝试思考下如何用恒定的一般性能（比如，几千的 QPS？），来解决大并发问题。如果我们能够用一些简单的技巧来保护我们的系统，能够过滤掉无效的流量，进而满足极端场景下性能的可靠性需求。</p>
<h1>如何保护系统</h1>
<h2 id="对-workload-进行分级">对 workload 进行分级</h2>
<p>在高并发的场景下，有一些请求是低质量的，没有触及到核心系统的核心资源的争夺，而有一些请求则是高质量的，必然要进入核心系统进行有限资源的争夺。保护核心系统的技术手段的中心思想，应该是尽量保证从高质量请求视角下看服务的高可用性，减少低质量请求对核心系统负载能力的干扰。在有些系统分析里，这是对工作负载（workload）进行分级，要按照服务级别来确保可用性标准，优先保护高级别的服务响应</p>
<h2 id="三件利器">三件利器</h2>
<p>缓存、降级和限流，是常见的三种保护系统的利器。这三者相辅相成，最终的目的是把流量的峰值削掉，让蜂拥而至的请求在一个漏斗型的链路里逐渐变少。我们需要追求的效果，就是我们核心系统的正常设计，能够负载最终到达的高质量流量。</p>
<h3 id="缓存">缓存</h3>
<p>缓存提高了系统的读能力。如果我们能够把很多不需要用到锁的相对静态的资源，放到高速缓存之中，就能剥离掉大部分的低质量请求。这样一个外围系统的存在，就像一个护城河，泾渭分明地把不需要太强大一致性的低质量请求拦在核心系统之外。优秀的缓存，就像一个乘数效应的放大器，可以把一个低负载能力的系统，增幅为一个强大负载能力的系统。一个常见的例子，就是各种骨干网络上 CDN 的存在。</p>
<h3 id="降级">降级</h3>
<p>降级，则试图彻底过滤掉低质量的请求。如果核心系统存在多种类型的服务，高质量请求的服务和低质量请求的服务混布（有些低质量请求的依然具有动态性和强一致性，不适合使用缓存），甚至有些弹性系统，出现高质量请求和低质量请求的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Multitenancy">多租户部署</a>，则系统流量紧张时，有必要关掉所有低质量请求进入系统的可能性。一个常见的例子，就是支付宝在流量紧张的时候（比如双十一大促），会关掉支付宝查询信用卡账单的功能。这种情况下低质量的请求不会混在高质量的请求之中，争夺性能资源，间接放大了核心系统的性能容量。降级的存在，使得系统可能从完全可用（fully functional）的状态，进入部分可用（partially functional）的状态。有损服务虽然不如正常服务体验好，总好过最后大家同归于尽，系统 panic 甚至 crash 要得多。降级不仅保护了核心系统作为被调用的高质量请求响应能力，实际上也保护了调用方的负载能力。因为在复杂调用链路中，如果没有做过异步化改造，链路上的任何一个 callee hangs，会导致整条链路向前所有的 caller 都逐渐 hangs。因为牵一发而动全身的效应，各种层面上的 request 会在前段 caller 里不断累积，进而导致各种 caller 也进入 panic 甚至 crash 的状态。</p>
<h3 id="限流">限流</h3>
<p>限流的应用场景，更加广泛。它不需要做各种请求的区分，就可以直接保证进入核心系统的流量不好超过系统的负载能力。限流的中心思想非常简单，即在各种层面上彻底限制住系统的并发能力，不做不着边际的性能承诺，只承诺响应达到 QPS 的负载能力，超过限制的请求，一律拒绝掉。可以说，限流的存在实现了降级的效果。笔者认为，降级和限流的关系，类似 Factory Method Pattern 与 Template Method Pattern 的关系。</p>
<h1>开始谈谈限流</h1>
<p>实际上我们在工作生活中已经见识过许多限流的例子。</p>
<p>一台机器，明明各种性能指标都还没有打满，QPS 却一直上不去，最后发现是网卡的问题，换了一块新网卡（有时候是换掉交换机上的一根光纤），QPS 马上就上去了。 这是硬件因素在限流。</p>
<p>我们想要下载一个电影，但被百度云的会员限制，没有办法开到全速，充了会员，下载速度立刻就上去了，这是软件因素在限流。</p>
<p>限流可以发生在 OSI 协议栈的硬件部分，也可以发生在软件部分。流量可以被限制在协议的出口端，也可以被限制在协议的入口端。限流还可以发生协议栈之上，有时候，我们可以把底层的协议栈当做空气一样透明，只在应用内部做限流。</p>
<p>我们可以粗略地把将要讨论的问题分为几个小的子问题：常见的限流算法是什么？如何在一台机器上限流？如何在分布式环境中限流？</p>
<h2 id="几个概念的廓清">几个概念的廓清</h2>
<h3 id="限流-rate-limiting-vs-限频-frequency-limiting">限流 (Rate Limiting) VS 限频 (Frequency Limiting)</h3>
<p>限流 (Rate Limiting)：一个更宏观的概念。它指的是对系统总体的请求速率进行限制，保护整个服务不被流量洪峰冲垮。它的保护对象是**“服务”**。例如：</p>
<p>限频 (Frequency Limiting)：一个更微观的概念。它通常针对某个实体（如用户ID、设备ID、IP地址）在某个具体功能上的使用频率。它的保护对象是**“功能”**或防止资源被滥用。例如：</p>
<p>我们常说的其实是限频，这最终涉及我们的限频 key 的设计，限频的key通常至少是某个 path 或者 id 正交组合成一个维度-当然还可以引入更多的其他维度。</p>
<h3 id="流量整形-traffic-shaping-vs-流量节流-throttling-vs-背压-back-pressure">流量整形 (Traffic Shaping) VS 流量节流 (Throttling) VS 背压 (Back Pressure)</h3>
<p>Shaping (整形) 是**“缓冲和延迟”，让流量平滑；Throttling (节流) 是“监督和丢弃”**，直接拒绝超额流量。</p>
<ul>
<li>
<p>流量整形 (Traffic Shaping)：核心是**“平滑”。它会把突发的流量缓冲**到一个队列里，然后以一个平稳的、预设的速率将请求释放给下游服务。它不会立即丢弃请求，而是尝试延迟处理。</p>
<ul>
<li>对应算法：漏桶 (Leaky Bucket) 就是典型的流量整形实现。</li>
<li>效果：下游服务收到的流量曲线非常平滑，但代价是增加了请求的延迟。</li>
</ul>
</li>
<li>
<p>流量节流 (Throttling)：核心是**“丢弃”。它会监控流量速率，一旦发现超过了阈值，就会直接拒绝或丢弃**超出的请求，不会进行缓冲。</p>
<ul>
<li>对应算法：令牌桶 (Token Bucket) 就是典型的流量节流实现。</li>
<li>效果：响应快，有令牌就立即处理，没令牌就立即拒绝。能应对突发，但超出部分会被直接丢弃。</li>
</ul>
</li>
<li>
<p>背压（back pressure）：</p>
<ul>
<li>核心目的：“反向施压”。这是一种系统间的通信机制，当下游消费者处理不过来时，它会向上游生产者发送一个“慢一点”的信号，从源头上控制流量的产生。</li>
<li>处理方式：背压是一种控制策略。它不是在流量到达后再处理，而是阻止流量的产生。
<ul>
<li>隐式背压：例如，一个阻塞队列满了，生产者线程在尝试放入新数据时会被阻塞（Block），这就自然地形成了背压。</li>
<li>显式背压：例如，在响应式编程（Reactive Streams）中，消费者会明确地向上游请求 n 个数据 (request(n))，生产者只会发送被请求的数量，从而实现了精确的流量控制。</li>
</ul>
</li>
<li>它与节流和整形的关系：
<ul>
<li>背压是实现流量节流的一种高级方式。传统的节流是被动地丢弃已经到来的流量，而背压是主动地、从源头阻止流量的发送，效果上都是“限速”，但背压更为优雅和高效，避免了不必要的网络传输和资源浪费。</li>
<li>背压与流量整形有本质区别。整形的核心是“缓冲和延迟发送”，而背压的核心是“停止或减慢发送”。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="qps限流：发生数量-vs-完成数量">QPS限流：发生数量 VS 完成数量</h3>
<p>这是一个非常关键的实现细节问题。当我们说“QPS限流100”，我们到底在限制什么？</p>
<p>答案是：我们限制的是每秒允许进入系统的请求发生数量 (Number of incoming requests)。</p>
<p>限流组件（如Nginx限流模块、API网关）通常工作在系统的最前端。它的职责是在请求进入后端业务逻辑之前就做出判断。</p>
<ul>
<li>为什么是发生数量？
<ul>
<li>保护目的：限流的根本目的是防止过多的请求压垮后端服务。如果等到请求都处理完成了再来统计，那就失去了保护的意义。</li>
<li>实现简单高效：在入口处简单地对请求计数是非常快的操作。如果要统计“完成数量”，就需要追踪每个请求的处理状态，这会大大增加限流逻辑的复杂性和开销。</li>
</ul>
</li>
</ul>
<p>所以，QPS限流可以理解为：“门卫每秒只放100个人进大楼，不管进去的人要花多久办完事出来。”</p>
<h1>常见的限流算法</h1>
<p>在网上搜一搜，就可以常见的限流算法并不多，大致上分为计数器算法、漏桶（Leacky Bucket）和令牌桶（Token Bucket）。这些算法各有各的长处，但他们都有一个基于配额（Quota） 的设计思路，颇有异曲同工之妙。即要产生请求，必须要得到许可（Permit），通过控制许可的总数，和通过控制许可发放的速度，来实现 QPS 的节流（Throttling）。不同的算法，就是在这些要素上做不同的变化。我们可以把这种算法称作精确限流算法，我们姑且称之为 Rate Limiter Algorithm。</p>
<p>除此之外，实际上还存在一些可以进行不精确限流的模糊限流算法，我们姑且称之为 Concurrency Limiter Algorithm。</p>
<p>两种算法的核心区别是：<strong>限制同一个时刻同时执行的请求数</strong> vs <strong>限制一个时间窗口同时执行的请求数</strong>。</p>
<table>
<thead>
<tr>
<th>特性维度</th>
<th>Concurrency Limiter Algorithm-通常是Semaphore（信号量）</th>
<th>Rate Limiter Algorithm-通常是令牌桶／漏桶</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>核心目标</strong></td>
<td>并发数控制（Concurrency Control）</td>
<td>速率控制（Rate Control）</td>
</tr>
<tr>
<td><strong>限制对象</strong></td>
<td>同时访问特定资源的线程数量</td>
<td>一个时间窗口内允许通过的请求数量（QPS）</td>
</tr>
<tr>
<td><strong>工作模式</strong></td>
<td>“许可”模型：有固定数量的“许可证”，线程拿到许可才能执行，用完必须归还。</td>
<td>“令牌”模型：系统按固定速率生成令牌，请求拿到令牌才能执行，令牌用完即丢弃。</td>
</tr>
<tr>
<td><strong>流量形态</strong></td>
<td>无法处理突发流量。一旦许可被占满，新来的请求只能阻塞等待。</td>
<td>可以平滑处理突发流量。SmoothBursty 允许“透支”未来的令牌；SmoothWarmingUp 通过预热逐步提升处理速率。</td>
</tr>
<tr>
<td><strong>关注点</strong></td>
<td>“当前有多少在运行？”</td>
<td>“过去一秒处理了多少？”</td>
</tr>
<tr>
<td><strong>典型场景</strong></td>
<td>1. 数据库连接池（连接数限制）<br>2. 线程池（并发任务数限制）<br>3. 资源密集型操作（文件读写、重计算）</td>
<td>1. API 接口限流（QPS 限制）<br>2. 消息消费限流（MQ Consumer）<br>3. 反爬虫（IP/用户分钟级限制）</td>
</tr>
<tr>
<td><strong>代码隐喻</strong></td>
<td>餐厅只有 3 张桌子（<code>new Semaphore(3)</code>）。无论顾客来得多快，最多只能同时服务 3 桌，其余需排队等位。</td>
<td>高速公路收费站每秒抬杆 2 次（<code>RateLimiter.create(2.0)</code>）。允许几辆车紧跟着冲过去（突发），之后车辆需等待更久。</td>
</tr>
</tbody>
</table>
<ul>
<li>Concurrency Limiter Algorithm (并发限制算法)：
<ul>
<li>核心工具：Semaphore (信号量) 是其最经典的实现。</li>
<li>关注点：存量。即“池子”里有多少可用的资源。它不关心请求来得多快，只关心当前有没有空闲的“坑位”。</li>
<li>应用场景：保护系统内部的有限资源不被耗尽。
<ul>
<li>数据库连接池：池中只有 10 个连接，用 Semaphore(10) 限制，确保最多只有 10 个线程能拿到连接。</li>
<li>本地资源：限制同时打开的文件句柄数，或者同时执行某个非常消耗 CPU/内存的计算任务的线程数。</li>
</ul>
</li>
</ul>
</li>
<li>Rate Limiter Algorithm (速率限制算法)
<ul>
<li>核心工具：令牌桶 (Token Bucket)、漏桶 (Leaky Bucket)、GCRA 等都是这类算法的具体实现。Guava 的 RateLimiter 就是典型的令牌桶实现。</li>
<li>关注点：流量。即“水管”里流速有多快。它不关心某个瞬间有多少任务在并行，只关心进入的速率是否超标。</li>
<li>应用场景：控制外部或内部的请求流量，以满足服务等级协议 (SLA) 或保护下游系统。
<ul>
<li>API 网关：限制外部用户对 /api/v1/data 接口的调用为 100 QPS。</li>
<li>服务间调用：服务 A 调用服务 B 时，服务 A 内置一个速率限制器，确保自己访问服务 B 的速率不会超过约定值，做个“有礼貌的”调用方。</li>
<li>消息队列消费：控制消费者从队列中拉取消息的速率，防止瞬间打垮数据库。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="little-s-law-利特尔定律的推论">Little’s Law 利特尔定律的推论</h2>
<h3 id="智力游戏推论">智力游戏推论</h3>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>总开销</mtext><mo>=</mo><mtext>单元开销</mtext><mo>×</mo><mtext>单元数量</mtext></mrow><annotation encoding="application/x-tex">\text{总开销} = \text{单元开销} \times \text{单元数量}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">总开销</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord text"><span class="mord cjk_fallback">单元开销</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">单元数量</span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>系统中物体的平均数量</mtext><mo>=</mo><mtext>离开系统的速度=进入系统的速度</mtext><mo>×</mo><mtext>每个物体在系统中的停留时长</mtext></mrow><annotation encoding="application/x-tex">\text{系统中物体的平均数量} = \text{离开系统的速度=进入系统的速度} \times \text{每个物体在系统中的停留时长}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">系统中物体的平均数量</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord text"><span class="mord cjk_fallback">离开系统的速度</span><span class="mord">=</span><span class="mord cjk_fallback">进入系统的速度</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">每个物体在系统中的停留时长</span></span></span></span></span></span></p>
<p>这是一个流入流出系统的通用法则：</p>
<ol>
<li>夜总会总容量60人，平均停留3小时。则人的离去速率是20人/小时。如果前面排了20人，我们还需要等10小时。</li>
<li>如果我有150箱酒，我年喝25箱再买入25箱，则每箱酒的停留时间是多少？要先求出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>总离开量（150）</mtext><mo>=</mo><mtext>酒离开系统的速度（25）</mtext><mo>×</mo><mtext>离开时间==停留时间</mtext></mrow><annotation encoding="application/x-tex">\text{总离开量（150）} = \text{酒离开系统的速度（25）} \times \text{离开时间==停留时间}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">总离开量（</span><span class="mord">150</span><span class="mord cjk_fallback">）</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord text"><span class="mord cjk_fallback">酒离开系统的速度（</span><span class="mord">25</span><span class="mord cjk_fallback">）</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">离开时间</span><span class="mord">==</span><span class="mord cjk_fallback">停留时间</span></span></span></span></span>。这里面的买入酒是迷惑信息。</li>
<li>如果一个系统的磁盘每秒钟处理25个请求。一个任务由100个请求组成，则系统的吞吐量为0.25个任务每秒。如果有20个终端，每个终端的用户的思考时间为20秒（这个设定有什么用是值得存疑的）。系统的吞吐量和响应时间是多少？</li>
</ol>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>并发性=n=20</mtext><mo>=</mo><mtext>吞吐量0.25task每秒</mtext><mo>×</mo><mtext>思考时间20s+响应时间</mtext></mrow><annotation encoding="application/x-tex">\text{并发性=n=20} = \text{吞吐量0.25task每秒} \times \text{思考时间20s+响应时间}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">并发性</span><span class="mord">=n=20</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord text"><span class="mord cjk_fallback">吞吐量</span><span class="mord">0.25task</span><span class="mord cjk_fallback">每秒</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord text"><span class="mord cjk_fallback">思考时间</span><span class="mord">20s+</span><span class="mord cjk_fallback">响应时间</span></span></span></span></span></span></p>
<p>当我们算出0.25task每秒的时候，我们就能算出响应时间为80-20=60。所以磁盘作为最窄带宽的设备的吞吐量决定了系统的响应时间-短板定律。</p>
<h3 id="并发性推论">并发性推论</h3>
<p>并发性和速率实际上是紧密相连的。<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Little%27s_law">维基百科上有有趣的讨论</a>。</p>
<ul>
<li>公式：L=λW
<ul>
<li>L：系统中长期平均的顾客数量（如排队人数+正在服务人数）。</li>
<li>λ：长期平均到达率（单位时间内进入系统的顾客数）。</li>
<li>W：顾客在系统中停留的平均时间（包括等待和服务时间）。</li>
</ul>
</li>
<li>本质：揭示了<strong>系统库存（L）</strong>、**吞吐率（λ）<strong>与</strong>流动时间（W）**的乘法关系，适用于任何稳态系统。</li>
</ul>
<p>利特尔法则 (Little’s Law) 的一个推论：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Concurrency</mtext><mo>=</mo><mtext>QPS</mtext><mo>×</mo><mtext>RT</mtext></mrow><annotation encoding="application/x-tex">\text{Concurrency} = \text{QPS} \times \text{RT}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">Concurrency</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">QPS</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord">RT</span></span></span></span></span></span></p>
<ul>
<li>QPS: 每秒查询数（系统的吞吐量）</li>
<li>Concurrency: 系统中正在被处理的并发请求数。你可以把它理解为系统有多少个“工人”在同时干活（例如，Web服务器的线程数）。</li>
<li>RT (Response Time): 处理单个请求所需的平均时间。</li>
</ul>
<p>假设一个系统有 150个“工人”（并发处理能力为150）。</p>
<ul>
<li>
<p>优化前：RT = 1.5s</p>
<ul>
<li>理论最大 QPS = 150 / 1.5s = 100</li>
</ul>
</li>
<li>
<p>优化后：RT = 1.0s</p>
<ul>
<li>理论最大 QPS = 150 / 1.0s = 150</li>
</ul>
</li>
</ul>
<p>结论： 在并发能力（工人数量）不变的情况下，将请求处理时间（RT）从1.5秒降低到1秒，系统的理论最大QPS从100提升到了150，足足提升了50%！</p>
<p>这背后的逻辑很简单：每个工人干活的速度变快了，单位时间内能完成的活就更多了。</p>
<p>这个公式在系统中的实际表现情况是：</p>
<ol>
<li>为了提升系统的容量：你必须想办法降低RT（优化代码、升级硬件、增加缓存等）。从这个角度看，RT和QPS的能力是负相关的。</li>
<li>当分析一个正在运行的系统时：随着负载（QPS）的增加，RT会从平稳到急剧上升。从这个角度看，在系统达到瓶颈时，QPS和RT的表现是正相关的。</li>
</ol>
<p>我们还可以通过 concurrency 来直接推导不同时期的 worker，进而调节线程池的 core thread 数量和 max thread 数量。</p>
<h2 id="计数器算法">计数器算法</h2>
<h3 id="并发计数器-concurrency-limiter">并发计数器 Concurrency Limiter</h3>
<p>这种算法的设计思想，是对一个要限流的资源配上一个计数器。每次请求前对这个计数器进行加操作或者减操作，通过对当前计数器的值与 Limit 值的对比，决定是否允许操作执行（即发放 Permit）。</p>
<p>让我们用一个应用内的多线程环境举例。</p>
<h4 id="方法原型">方法原型</h4>
<p>一个简单的总量计数器如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// &#x27;limit&#x27; 代表最大并发处理数</span><br><span class="hljs-comment">// &#x27;atomicCounter&#x27; 是一个全局的原子计数器</span><br><span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-comment">// 请求进入，计数器加1</span><br>    <span class="hljs-keyword">if</span>(atomicCounter.incrementAndGet() &gt; limit) &#123;<br>        <span class="hljs-comment">// 超出并发限制，立即拒绝</span><br>        <span class="hljs-comment">// rejectRequest();</span><br>        <span class="hljs-keyword">return</span>;<br>   &#125;<br><br>    <span class="hljs-comment">// 在限制范围内，处理核心业务逻辑</span><br>    <span class="hljs-comment">// processRequest();</span><br><br>&#125; <span class="hljs-keyword">finally</span> &#123;<br>    <span class="hljs-comment">// 无论业务成功或异常，处理完成后必须释放一个许可，计数器减1</span><br>    atomicCounter.decrementAndGet();<br>&#125;<br></code></pre></td></tr></table></figure>
<p>这个总量计数器的设计，使得我们可以让我们控制同一瞬间能够处理的请求的数量。聪明的读者可能已经想到了，这是在一种控制并发请求进入临界区访问资源的节流思想，和使用 Java 自带的 Semaphore 异曲同工。</p>
<h4 id="semaphore-版本">Semaphore 版本</h4>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.concurrent.ExecutorService;<br><span class="hljs-keyword">import</span> java.util.concurrent.Executors;<br><span class="hljs-keyword">import</span> java.util.concurrent.Semaphore;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SemaphoreConcurrencyLimiter</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-comment">// 1. 定义一个信号量，并设置许可总数为 3。</span><br>        <span class="hljs-comment">// 这意味着，在任何同一时刻，最多只允许 3 个线程访问受保护的资源。</span><br>        <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">MAX_CONCURRENT_REQUESTS</span> <span class="hljs-operator">=</span> <span class="hljs-number">3</span>;<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">Semaphore</span> <span class="hljs-variable">semaphore</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Semaphore</span>(MAX_CONCURRENT_REQUESTS);<br><br>        <span class="hljs-comment">// 使用线程池模拟高并发请求</span><br>        <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">executor</span> <span class="hljs-operator">=</span> Executors.newCachedThreadPool();<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">10</span>; i++) &#123;<br>            <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">requestId</span> <span class="hljs-operator">=</span> i;<br>            executor.submit(() -&gt; &#123;<br>                <span class="hljs-keyword">try</span> &#123;<br>                    <span class="hljs-comment">// 2. 核心：尝试获取一个许可。</span><br>                    <span class="hljs-comment">// 如果当前许可数量 &gt; 0，则此方法立即返回，许可数减 1。</span><br>                    <span class="hljs-comment">// 如果当前许可数量 = 0，则当前线程会进入【阻塞】状态，直到有其他线程释放许可。</span><br>                    System.out.printf(<span class="hljs-string">&quot;[请求 %d] 等待获取许可... (当前可用许可: %d)\n&quot;</span>, requestId, semaphore.availablePermits());<br>                    semaphore.acquire();<br><br>                    <span class="hljs-comment">// 3. 成功获取许可，进入临界区执行核心业务逻辑。</span><br>                    System.out.printf(<span class="hljs-string">&quot;✅ [请求 %d] 成功获取许可，开始处理业务...\n&quot;</span>, requestId);<br>                    <span class="hljs-comment">// 模拟业务处理耗时</span><br>                    TimeUnit.SECONDS.sleep(<span class="hljs-number">2</span>);<br><br>                &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                    Thread.currentThread().interrupt();<br>                &#125; <span class="hljs-keyword">finally</span> &#123;<br>                    <span class="hljs-comment">// 4. 关键：必须在 finally 块中释放许可。</span><br>                    <span class="hljs-comment">// 这确保了即使业务处理发生异常，许可也一定会被归还，防止“许可泄漏”。</span><br>                    <span class="hljs-comment">// 释放后，许可数会加 1，其他正在等待的线程之一将被唤醒并获取该许可。</span><br>                    semaphore.release();<br>                    System.out.printf(<span class="hljs-string">&quot;❌ [请求 %d] 业务处理完成，释放许可。\n&quot;</span>, requestId);<br>                &#125;<br>            &#125;);<br>        &#125;<br><br>        executor.shutdown();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>唯一的差别是，Semaphore 可以阻塞请求，使得请求最终可以可以执行完成，而使用 atomic 的做法更加简单粗暴，如果没有办法处理请求，就丢弃请求，不再等待。</p>
<h4 id="阻塞与自旋">阻塞与自旋</h4>
<p>我们当然可以让 atomic 具备阻塞的能力，但这就要引入自旋了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.concurrent.ExecutorService;<br><span class="hljs-keyword">import</span> java.util.concurrent.Executors;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicInteger;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AtomicSpinLockLimiter</span> &#123;<br><br>    <span class="hljs-comment">// 定义最大并发处理数</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">MAX_CONCURRENT_REQUESTS</span> <span class="hljs-operator">=</span> <span class="hljs-number">3</span>;<br>    <span class="hljs-comment">// 全局原子计数器</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">atomicCounter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processRequest</span><span class="hljs-params">(<span class="hljs-type">int</span> requestId)</span> &#123;<br>        <span class="hljs-comment">// 1. 进入自旋循环，尝试获取“许可”。</span><br>        <span class="hljs-comment">// 这是一种乐观锁的实现思路。</span><br>        <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>            <span class="hljs-comment">// 2. 读取当前计数器的值。</span><br>            <span class="hljs-type">int</span> <span class="hljs-variable">currentCount</span> <span class="hljs-operator">=</span> atomicCounter.get();<br><br>            <span class="hljs-comment">// 3. 检查是否已达到并发上限。</span><br>            <span class="hljs-keyword">if</span> (currentCount &gt;= MAX_CONCURRENT_REQUESTS) &#123;<br>                <span class="hljs-comment">// 如果已达上限，则【不退出循环】，继续下一次尝试。</span><br>                <span class="hljs-comment">// 这就是“自旋”，线程在此处空转，消耗 CPU 时间来等待其他线程释放许可。</span><br>                <span class="hljs-comment">// 为了防止 CPU 100% 空转，可以加上短暂的 sleep 或者 Thread.yield()。</span><br>                <span class="hljs-comment">// Thread.yield(); // 让出CPU给其他线程，但并不保证立即切换</span><br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br><br>            <span class="hljs-comment">// 4. 核心：尝试以原子方式将计数器加 1。</span><br>            <span class="hljs-comment">// 使用 CAS (Compare-And-Set) 操作，只有当“当前值”仍然是我们第2步读取到的`currentCount`时，</span><br>            <span class="hljs-comment">// 才将其更新为 `currentCount + 1`。</span><br>            <span class="hljs-comment">// 如果在读取和更新之间，有其他线程修改了`atomicCounter`，则此方法会返回 false，循环继续。</span><br>            <span class="hljs-keyword">if</span> (atomicCounter.compareAndSet(currentCount, currentCount + <span class="hljs-number">1</span>)) &#123;<br>                <span class="hljs-comment">// 5. CAS 更新成功，意味着我们成功“抢”到了一个许可，可以跳出循环。</span><br>                System.out.printf(<span class="hljs-string">&quot;✅ [请求 %d] 成功获取许可 (当前并发数: %d)\n&quot;</span>, requestId, atomicCounter.get());<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <span class="hljs-comment">// 如果 CAS 失败，说明有并发竞争，循环将继续，在下一轮重试。</span><br>        &#125;<br><br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-comment">// 6. 执行核心业务逻辑。</span><br>            System.out.printf(<span class="hljs-string">&quot;... [请求 %d] 正在处理业务...\n&quot;</span>, requestId);<br>            TimeUnit.SECONDS.sleep(<span class="hljs-number">2</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>            Thread.currentThread().interrupt();<br>        &#125; <span class="hljs-keyword">finally</span> &#123;<br>            <span class="hljs-comment">// 7. 关键：业务完成后，必须将计数器减 1，相当于“释放许可”。</span><br>            <span class="hljs-type">int</span> <span class="hljs-variable">finalCount</span> <span class="hljs-operator">=</span> atomicCounter.decrementAndGet();<br>            System.out.printf(<span class="hljs-string">&quot;❌ [请求 %d] 业务处理完成，释放许可 (当前并发数: %d)\n&quot;</span>, requestId, finalCount);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">executor</span> <span class="hljs-operator">=</span> Executors.newCachedThreadPool();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">10</span>; i++) &#123;<br>            <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">reqId</span> <span class="hljs-operator">=</span> i;<br>            executor.submit(() -&gt; processRequest(reqId));<br>        &#125;<br>        executor.shutdown();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>这种方式的优点是避免了线程上下文切换带来的开销，对于那些“等待时间非常短”的场景，性能会很高。缺点是如果等待时间很长，它会持续空耗 CPU 资源。</p>
<h4 id="总结">总结</h4>
<p>基于 Atomic 的实现是快速失败 (Fail-fast) 的，而<code>Semaphore.acquire()</code>则是阻塞等待。前者适用于那些可以被轻易丢弃或由客户端重试的请求，如果引入重试；后者则适用于希望请求最终能被处理的场景。</p>
<h3 id="rate-limiter-algorithm">Rate Limiter Algorithm</h3>
<p><strong>这个总量计数器并不与某个特定的时间窗口挂钩，而且又有衰减作用</strong>，这也就意味着它能够限制一瞬间的并发总数，并且可以被复用，<strong>但我们无法预测它实际控制出的 QPS 数目</strong>。所以它是一个 Concurrency Limiter Algorithm。</p>
<p>所以我们可以试着把它和某个特定的时间窗口挂钩，让这个计数器只针对一个时间节点起作用。这就达到了 Rate Limiter Algorithm 的作用。</p>
<h4 id="固定窗口计数器-fixed-window-counter">固定窗口计数器 (Fixed Window Counter)</h4>
<pre><code class="hljs mermaid">graph TD
    subgraph &quot;固定窗口计数器 (Fixed Window Counter)&quot;
        A&#123;请求到达&#125; --&gt; B&#123;当前窗口是否结束?&#125;
        B --&gt;|是| C[重置计数器为 1]
        B --&gt;|否| D[计数器 +1]
        C --&gt; E&#123;计数器 &gt; 阈值?&#125;
        D --&gt; E
        E --&gt;|否| F[允许请求]
        E --&gt;|是| G[拒绝请求]
    end</code></pre>
<p>借用缓存的实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 使用 Guava Cache 来为每个时间窗口（秒）创建一个独立的原子计数器</span><br><span class="hljs-comment">// expireAfterWrite 设置为2秒，确保当前秒的计数器不会在下一秒检查时立即失效</span><br>LoadingCache&lt;Long, AtomicLong&gt; counters = CacheBuilder.newBuilder()<br>        .expireAfterWrite(<span class="hljs-number">2</span>, TimeUnit.SECONDS)<br>        .build(<span class="hljs-keyword">new</span> <span class="hljs-title class_">CacheLoader</span>&lt;Long, AtomicLong&gt;() &#123;<br>            <span class="hljs-keyword">public</span> AtomicLong <span class="hljs-title function_">load</span><span class="hljs-params">(Long key)</span> &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicLong</span>(<span class="hljs-number">0</span>);<br>            &#125;<br>        &#125;);<br><br><span class="hljs-type">long</span> <span class="hljs-variable">limit</span> <span class="hljs-operator">=</span> <span class="hljs-number">1000</span>; <span class="hljs-comment">// QPS 限制为 1000</span><br><br><span class="hljs-comment">// 实际应用中，这段逻辑会在每个请求的入口处执行</span><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">handleRequest</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">long</span> <span class="hljs-variable">currentSecond</span> <span class="hljs-operator">=</span> System.currentTimeMillis() / <span class="hljs-number">1000</span>;<br>    <span class="hljs-keyword">if</span> (counters.getUnchecked(currentSecond).incrementAndGet() &gt; limit) &#123;<br>        <span class="hljs-comment">// 超出 QPS 限制，拒绝请求</span><br>        <span class="hljs-comment">// rejectRequest(&quot;Rate limit exceeded&quot;);</span><br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-comment">// processing request...</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>在这里，我们使用了一个有效期为2秒的缓存（为了防止时间不准，实际上应该是任何大于1s 的缓存有效期都可以拿来配置缓存）来存储 atomic与当前的时间。每个请求会在当前的时间窗口里尝试增加计数器，如果当前时间窗口内计数器还没有超过 QPS 极限值，就处理请求，否则就进入自旋，等待下一秒的新的缓存计数器的到来。</p>
<h5 id="这种-qps-算法的时间窗口-最好设置为1秒为单位">这种 QPS 算法的时间窗口，最好设置为1秒为单位</h5>
<p>以上面的例子为单位，每秒钟诞生一个limit = 1000的计数器是正确的做法。如果为了减少缓存计数器数量，试图用1分钟长度的缓存配合 limit = 60000，有可能在极端情况下会出现，在59秒 和61一共出现120000个请求的情况。此时计数器依然允许这些流量通过，但这三秒的 QPS 已经远远高于1000。使用计数器的 RateLimiter 的简单粗暴方法，只能说是够用，为了防止临界点性能毛刺（Spike）的存在，我们要严格保证生成计数器的数量和顺序，本质上还是有很大的优化空间。</p>
<h4 id="滑动窗口日志-sliding-window-log">滑动窗口日志 (Sliding Window Log)</h4>
<pre><code class="hljs mermaid">graph TD
    subgraph &quot;滑动窗口日志 (Sliding Window Log)&quot;
        A&#123;请求到达&#125; --&gt; B[移除日志中过期的请求时间戳];
        B --&gt; C[获取日志中剩余请求的数量];
        C --&gt; D&#123;数量 &lt; 阈值?&#125;;
        D -- 是 --&gt; E[记录当前请求时间戳, 允许请求];
        D -- 否 --&gt; F[拒绝请求];
    end</code></pre>
<p>固定窗口算法之所以会产生毛刺，根源在于它粗暴地将时间分片，忘记了每个请求实际发生的时间点。那么，最精确的修正方法，就是不忘掉它们。</p>
<p>滑动窗口日志 (Sliding Window Log) 算法的核心思想正是如此：记录下每个请求实际发生的时间戳。它在概念上维护了一个以时间为轴的“滑动窗口”，通过精确计算落在这个窗口内的请求数量来做出决策，从而彻底消除了边界问题，实现了最平滑的流量控制。</p>
<p>这种算法通常会借助一个有序的数据结构（如队列或有序集合）来存储请求的时间戳。其工作流程如下：</p>
<ol>
<li>移除过期时间戳：当一个新请求到达时，算法会首先从集合中移除所有已经“滑出”时间窗口的时间戳。例如，如果我们的时间窗口是1秒，那么所有在 (当前时间 - 1秒) 之前的时间戳都会被清理掉。</li>
<li>添加新请求时间戳：将当前请求的时间戳存入集合中。</li>
<li>计算窗口内请求数：计算集合中当前元素的数量。这个数量，就是过去一个时间窗口内最精确的请求总数。</li>
<li>判断并执行：如果该数量小于或等于限流阈值 limit，则允许请求通过；否则，拒绝该请求。</li>
</ol>
<h5 id="基于-java-util-linkedlist-单机环境">基于 java.util.LinkedList (单机环境)</h5>
<p>在单个 JVM 实例中，LinkedList 是一个实现此算法的直观选择。它作为一个队列，可以高效地在头部移除过期的时间戳，并在尾部添加新的时间戳。</p>
<p>要点：在多线程环境下，对 LinkedList 的所有访问都必须是线程安全的，因此需要使用 synchronized 关键字来保证操作的原子性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.LinkedList;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 使用 LinkedList 作为底层存储，适用于单机环境的滑动窗口日志算法。</span><br><span class="hljs-comment"> * 优点：简单直观，易于理解。</span><br><span class="hljs-comment"> * 缺点：有锁竞争，且内存占用与QPS成正比。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SlidingWindowLogByLinkedList</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> windowSizeInMillis; <span class="hljs-comment">// 窗口大小，单位：毫秒</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> limit;               <span class="hljs-comment">// 窗口内的请求上限</span><br>    <span class="hljs-comment">// 使用 LinkedList 作为存储请求时间戳的队列</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> LinkedList&lt;Long&gt; requestTimestamps = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SlidingWindowLogByLinkedList</span><span class="hljs-params">(<span class="hljs-type">long</span> windowDuration, TimeUnit unit, <span class="hljs-type">int</span> limit)</span> &#123;<br>        <span class="hljs-built_in">this</span>.windowSizeInMillis = unit.toMillis(windowDuration);<br>        <span class="hljs-built_in">this</span>.limit = limit;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取一个许可。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> true 如果成功获取，false 如果被限流。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentTime</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br>        <span class="hljs-type">long</span> <span class="hljs-variable">windowStart</span> <span class="hljs-operator">=</span> currentTime - windowSizeInMillis;<br><br>        <span class="hljs-comment">// 1. 核心步骤：移除窗口之外的旧时间戳。</span><br>        <span class="hljs-comment">// peek() 查看队头元素，poll() 移除队头元素，两者都是 O(1) 操作。</span><br>        <span class="hljs-keyword">while</span> (!requestTimestamps.isEmpty() &amp;&amp; requestTimestamps.peek() &lt;= windowStart) &#123;<br>            requestTimestamps.poll();<br>        &#125;<br><br>        <span class="hljs-comment">// 2. 检查当前窗口内的请求数量是否已达到上限。</span><br>        <span class="hljs-keyword">if</span> (requestTimestamps.size() &gt;= limit) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 已达到上限，拒绝请求</span><br>        &#125;<br><br>        <span class="hljs-comment">// 3. 将当前请求的时间戳加入队列尾部。</span><br>        requestTimestamps.add(currentTime);<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h5 id="基于-redis-zset-分布式环境">基于 Redis ZSET (分布式环境)</h5>
<p>当限流策略需要跨越多个服务实例时（例如在微服务架构中），就需要一个集中的存储。Redis 的有序集合 ZSET 是实现分布式滑动窗口日志的完美工具。</p>
<p>要点：ZSET 是一个神奇的数据结构，它为每个成员（member）关联一个分数（score）。我们可以将时间戳作为 score，将唯一的请求ID（或时间戳本身）作为 member。Redis 提供了原子性的命令来移除一个分数区间内的成员并计算成员总数，这使得实现非常高效。</p>
<p>为什么要用时间戳？</p>
<p>Redis Sorted Set 中对 Member 的唯一硬性要求是：在一个 ZSET 中，每个 Member 的值必须是唯一的。</p>
<p>如果你尝试用一个已经存在的 Member 去执行 <code>ZADD</code>，Redis 不会添加一个新元素，而只会更新这个现有 Member 的 Score（分数），并且命令会返回 0（表示新增了0个元素）。</p>
<p>使用请求ID是可行的，但有唯一性风险；单独使用时间戳更简单，但有碰撞风险。最稳妥的方案是通过 “高精度时间戳 + 随机数” 的方式来生成一个绝对唯一的 Member，这样能确保限流器既准确又可靠。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-comment"># Score 是请求发生的时间戳，用于排序</span><br>SCORE = 1678886400123 (当前的毫秒级Unix时间戳)<br><br><span class="hljs-comment"># Member 是时间戳 + 一个随机字符串，来保证绝对唯一</span><br>MEMBER = <span class="hljs-string">&quot;1678886400123:abcdef12345&quot;</span> <br><br>ZADD rate_limit:user_id SCORE MEMBER<br></code></pre></td></tr></table></figure>
<h6 id="基于-multi-exec">基于 multi/exec</h6>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> redis.clients.jedis.Jedis;<br><span class="hljs-keyword">import</span> redis.clients.jedis.Transaction;<br><br><span class="hljs-keyword">import</span> java.util.UUID;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 使用 Redis ZSET 实现分布式滑动窗口日志算法。</span><br><span class="hljs-comment"> * 优点：天然支持分布式，可实现全局限流，性能高。</span><br><span class="hljs-comment"> * 缺点：引入外部依赖（Redis），有网络开销。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SlidingWindowLogByRedisZSet</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Jedis jedis;              <span class="hljs-comment">// Redis 客户端</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String key;               <span class="hljs-comment">// ZSET 在 Redis 中的 key</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> windowSizeInMillis;  <span class="hljs-comment">// 窗口大小</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> limit;                <span class="hljs-comment">// 限制数量</span><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SlidingWindowLogByRedisZSet</span><span class="hljs-params">(Jedis jedis, String key, <span class="hljs-type">long</span> windowDuration, TimeUnit unit, <span class="hljs-type">int</span> limit)</span> &#123;<br>        <span class="hljs-built_in">this</span>.jedis = jedis;<br>        <span class="hljs-built_in">this</span>.key = key;<br>        <span class="hljs-built_in">this</span>.windowSizeInMillis = unit.toMillis(windowDuration);<br>        <span class="hljs-built_in">this</span>.limit = limit;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取一个许可。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> true 如果成功获取，false 如果被限流。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentTime</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br>        <span class="hljs-type">long</span> <span class="hljs-variable">windowStart</span> <span class="hljs-operator">=</span> currentTime - windowSizeInMillis;<br><br>        <span class="hljs-comment">// 为了保证原子性，最好使用 Lua 脚本，或者 Redis 的事务（MULTI/EXEC）。</span><br>        <span class="hljs-comment">// 这里使用事务作为示例。</span><br>        <span class="hljs-type">Transaction</span> <span class="hljs-variable">multi</span> <span class="hljs-operator">=</span> jedis.multi();<br><br>        <span class="hljs-comment">// 1. 核心步骤：移除窗口之外的旧时间戳。</span><br>        <span class="hljs-comment">// ZREMRANGEBYSCORE 命令会移除所有 score 在 [0, windowStart] 范围内的成员。</span><br>        <span class="hljs-comment">// 这是一个 O(log(N)+M) 的操作，其中 N 是集合中的元素数，M 是被移除的元素数，非常高效。</span><br>        multi.zremrangeByScore(key, <span class="hljs-number">0</span>, windowStart);<br><br>        <span class="hljs-comment">// 2. 获取当前窗口内的请求总数。</span><br>        <span class="hljs-comment">// ZCARD 命令返回集合中的成员数量，这是一个 O(1) 的操作。</span><br>        multi.zcard(key);<br><br>        <span class="hljs-comment">// 3. 尝试添加当前请求。</span><br>        <span class="hljs-comment">// 使用一个唯一的 member 来避免重复，这里用 UUID。score 就是当前时间戳。</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">member</span> <span class="hljs-operator">=</span> UUID.randomUUID().toString();<br>        multi.zadd(key, currentTime, member);<br><br>        <span class="hljs-comment">// 4. 设置一个过期时间，防止冷key无限增长。</span><br>        <span class="hljs-comment">// 过期时间比窗口稍长即可，确保数据能被自动清理。</span><br>        multi.expire(key, (<span class="hljs-type">int</span>) (windowSizeInMillis / <span class="hljs-number">1000</span>) + <span class="hljs-number">2</span>);<br><br>        <span class="hljs-comment">// 执行事务</span><br>        java.util.List&lt;Object&gt; results = multi.exec();<br><br>        <span class="hljs-comment">// 检查 ZCARD 的结果</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentCount</span> <span class="hljs-operator">=</span> (Long) results.get(<span class="hljs-number">1</span>);<br><br>        <span class="hljs-keyword">if</span> (currentCount &gt;= limit) &#123;<br>            <span class="hljs-comment">// 如果在添加之前数量就已超限，需要撤销刚才的添加操作。</span><br>            <span class="hljs-comment">// 注意：事务已经提交，需要额外操作来补偿。</span><br>            <span class="hljs-comment">// 这也是为什么 Lua 脚本是更优选择的原因，因为它可以实现 &quot;先检查再添加&quot; 的原子逻辑。</span><br>            jedis.zrem(key, member); <span class="hljs-comment">// 补偿操作</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    <span class="hljs-comment">// 注：使用 Lua 脚本可以更优雅地实现原子性，避免补偿操作。</span><br>    <span class="hljs-comment">// Lua 脚本伪代码:</span><br>    <span class="hljs-comment">// local count = redis.call(&#x27;zcard&#x27;, KEYS[1])</span><br>    <span class="hljs-comment">// if count &lt; limit then</span><br>    <span class="hljs-comment">//   redis.call(&#x27;zadd&#x27;, KEYS[1], ARGV[1], ARGV[2])</span><br>    <span class="hljs-comment">//   return 1</span><br>    <span class="hljs-comment">// else</span><br>    <span class="hljs-comment">//   return 0</span><br>    <span class="hljs-comment">// end</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>Redis 的<code>MULTI/EXEC</code>提供的原子性，更准确地说是执行原子性，它保证：</p>
<ol>
<li>命令打包：所有在<code>MULTI</code>和<code>EXEC</code>之间的命令会被打包成一个队列，然后一次性、按顺序地发送给 Redis Server。</li>
<li>执行不中断：Redis Server 在执行这个命令队列时，不会被任何其他客户端的命令所打断。<br>
但是，它有一个致命的缺陷：命令在入队时，并不知道之前命令的执行结果。</li>
</ol>
<p>在我们的限流场景中，我们需要：</p>
<ol>
<li>检查当前窗口的请求数 (<code>ZCARD</code>)。</li>
<li>判断数量是否小于 <code>limit</code>。</li>
<li>如果小于，则执行添加操作 (<code>ZADD</code>)。</li>
</ol>
<p>如果使用 MULTI/EXEC，客户端的代码逻辑是这样的：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> <span class="hljs-number">1</span>. 客户端发起事务<br>MULTI<br><span class="hljs-regexp">//</span> <span class="hljs-number">2</span>. 客户端将一堆命令加入队列，但此时它并不知道 ZCARD 的结果<br>ZREMRANGEBYSCORE my_zset <span class="hljs-number">0</span> (now - <span class="hljs-number">1000</span>)<br>ZCARD my_zset<br>ZADD my_zset now <span class="hljs-string">&quot;request_id&quot;</span><br><span class="hljs-regexp">//</span> <span class="hljs-number">3</span>. 客户端命令服务器执行<br>EXEC<br></code></pre></td></tr></table></figure>
<p>当<code>EXEC</code>执行时，Redis 会一口气做完这三件事。但问题在于，<code>ZADD</code> 命令是无条件入队的。客户端必须等到<code>EXEC</code>的结果返回后，才能拿到<code>ZCARD</code> 的计数值。如果此时发现计数值已经超了，就只能再发起一个<code>ZREM</code> 命令去“补偿”，而这个补偿操作和之前的事务并非原子，中间可能已经有其他操作插入，导致逻辑混乱。</p>
<p>简单来说，<code>MULTI/EXEC</code>无法在事务中间实现条件分支逻辑。</p>
<h6 id="基于-zset">基于 zset</h6>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> redis.clients.jedis.Jedis;<br><span class="hljs-keyword">import</span> java.util.Collections;<br><span class="hljs-keyword">import</span> java.util.UUID;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 使用 Redis + Lua 脚本实现的高性能分布式滑动窗口日志算法。</span><br><span class="hljs-comment"> * 这是业界实现分布式限流器最精准、最通用的方案。</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * 优点：</span><br><span class="hljs-comment"> * 1. 逻辑原子性：通过 Lua 脚本保证了“检查并设置”操作的原子性，无竞态条件。</span><br><span class="hljs-comment"> * 2. 高性能：所有计算都在 Redis 服务端完成，减少了网络往返。</span><br><span class="hljs-comment"> * 3. 精准控制：记录了每个请求的精确时间，实现了最平滑的流量控制。</span><br><span class="hljs-comment"> * 4. 分布式友好：天然支持跨多个服务实例的全局限流。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SlidingWindowLogByRedisLua</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Jedis jedis;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String key;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> limit;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> windowSizeInMillis;<br><br>    <span class="hljs-comment">// Lua 脚本，用于原子性地执行限流逻辑</span><br>    <span class="hljs-comment">// KEYS[1]: 限流器的 ZSET key</span><br>    <span class="hljs-comment">// ARGV[1]: 当前时间戳（毫秒）</span><br>    <span class="hljs-comment">// ARGV[2]: 窗口大小（毫秒）</span><br>    <span class="hljs-comment">// ARGV[3]: 窗口内的请求上限 (limit)</span><br>    <span class="hljs-comment">// ARGV[4]: 当前请求的唯一ID</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">LUA_SCRIPT</span> <span class="hljs-operator">=</span><br>        <span class="hljs-string">&quot;local key = KEYS[1] &quot;</span> +<br>        <span class="hljs-string">&quot;local currentTime = tonumber(ARGV[1]) &quot;</span> +<br>        <span class="hljs-string">&quot;local windowSize = tonumber(ARGV[2]) &quot;</span> +<br>        <span class="hljs-string">&quot;local limit = tonumber(ARGV[3]) &quot;</span> +<br>        <span class="hljs-string">&quot;local member = ARGV[4] &quot;</span> +<br>        <span class="hljs-comment">// 1. 计算出窗口的起始时间</span><br>        <span class="hljs-string">&quot;local windowStart = currentTime - windowSize &quot;</span> +<br>        <span class="hljs-comment">// 2. [核心] 移除窗口之外的所有旧的时间戳记录</span><br>        <span class="hljs-string">&quot;redis.call(&#x27;ZREMRANGEBYSCORE&#x27;, key, 0, windowStart) &quot;</span> +<br>        <span class="hljs-comment">// 3. [核心] 获取当前窗口内的请求数量</span><br>        <span class="hljs-string">&quot;local currentCount = redis.call(&#x27;ZCARD&#x27;, key) &quot;</span> +<br>        <span class="hljs-comment">// 4. [核心] 判断是否超过限制</span><br>        <span class="hljs-string">&quot;if currentCount &lt; limit then &quot;</span> +<br>        <span class="hljs-string">&quot;    redis.call(&#x27;ZADD&#x27;, key, currentTime, member) &quot;</span> +<br>        <span class="hljs-comment">// 设置一个过期时间，防止冷key无限增长，比窗口稍长即可</span><br>        <span class="hljs-string">&quot;    redis.call(&#x27;PEXPIRE&#x27;, key, windowSize + 1000) &quot;</span> +<br>        <span class="hljs-string">&quot;    return 1 &quot;</span> + <span class="hljs-comment">// 返回 1 代表成功</span><br>        <span class="hljs-string">&quot;else &quot;</span> +<br>        <span class="hljs-string">&quot;    return 0 &quot;</span> + <span class="hljs-comment">// 返回 0 代表被限流</span><br>        <span class="hljs-string">&quot;end&quot;</span>;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SlidingWindowLogByRedisLua</span><span class="hljs-params">(Jedis jedis, String key, <span class="hljs-type">int</span> limit, <span class="hljs-type">long</span> windowDuration, TimeUnit unit)</span> &#123;<br>        <span class="hljs-built_in">this</span>.jedis = jedis;<br>        <span class="hljs-built_in">this</span>.key = key;<br>        <span class="hljs-built_in">this</span>.limit = limit;<br>        <span class="hljs-built_in">this</span>.windowSizeInMillis = unit.toMillis(windowDuration);<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取一个许可。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> true 如果成功获取，false 如果被限流。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentTime</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br>        <span class="hljs-comment">// 使用 UUID 确保 ZSET 的 member 是唯一的</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">member</span> <span class="hljs-operator">=</span> UUID.randomUUID().toString();<br><br>        <span class="hljs-comment">// 通过 eval 执行 Lua 脚本，Redis 会保证脚本的原子性</span><br>        <span class="hljs-type">Object</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> jedis.eval(<br>            LUA_SCRIPT,<br>            Collections.singletonList(key), <span class="hljs-comment">// KEYS 参数</span><br>            java.util.Arrays.asList(       <span class="hljs-comment">// ARGV 参数</span><br>                String.valueOf(currentTime),<br>                String.valueOf(windowSizeInMillis),<br>                String.valueOf(limit),<br>                member<br>            )<br>        );<br><br>        <span class="hljs-comment">// Lua 脚本返回 1 表示成功，0 表示失败</span><br>        <span class="hljs-keyword">return</span> Long.valueOf(<span class="hljs-number">1L</span>).equals(result);<br>    &#125;<br><br>    <span class="hljs-comment">// 使用示例</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-comment">// 假设 Redis 运行在本地</span><br>        <span class="hljs-type">Jedis</span> <span class="hljs-variable">jedis</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Jedis</span>(<span class="hljs-string">&quot;localhost&quot;</span>, <span class="hljs-number">6379</span>);<br><br>        <span class="hljs-comment">// 创建一个限流器：在 10 秒内，最多允许 5 个请求</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">limiterKey</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;rate_limiter:my_app&quot;</span>;<br>        <span class="hljs-type">SlidingWindowLogByRedisLua</span> <span class="hljs-variable">rateLimiter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SlidingWindowLogByRedisLua</span>(jedis, limiterKey, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>, TimeUnit.SECONDS);<br><br>        <span class="hljs-comment">// 连续测试 7 次</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">7</span>; i++) &#123;<br>            <span class="hljs-keyword">if</span> (rateLimiter.tryAcquire()) &#123;<br>                System.out.printf(<span class="hljs-string">&quot;请求 %d: 成功 (Timestamp: %d)\n&quot;</span>, i, System.currentTimeMillis());<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                System.out.printf(<span class="hljs-string">&quot;请求 %d: 被限流 (Timestamp: %d)\n&quot;</span>, i, System.currentTimeMillis());<br>            &#125;<br>            Thread.sleep(<span class="hljs-number">500</span>); <span class="hljs-comment">// 每隔 500ms 发起一次请求</span><br>        &#125;<br><br>        jedis.close();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-comment">-- KEYS[1]: 限流器的 ZSET key</span><br><span class="hljs-comment">-- ARGV[1]: 当前时间戳（毫秒）</span><br><span class="hljs-comment">-- ARGV[2]: 窗口大小（毫秒）</span><br><span class="hljs-comment">-- ARGV[3]: 窗口内的请求上限 (limit)</span><br><span class="hljs-comment">-- ARGV[4]: 当前请求的唯一ID</span><br><br><span class="hljs-keyword">local</span> key = KEYS[<span class="hljs-number">1</span>]<br><span class="hljs-keyword">local</span> currentTime = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">1</span>])<br><span class="hljs-keyword">local</span> windowSize = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">2</span>])<br><span class="hljs-keyword">local</span> limit = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">3</span>])<br><span class="hljs-keyword">local</span> member = ARGV[<span class="hljs-number">4</span>]<br><br><span class="hljs-comment">-- 1. 计算出窗口的起始时间</span><br><span class="hljs-keyword">local</span> windowStart = currentTime - windowSize<br><br><span class="hljs-comment">-- 2. [核心] 移除窗口之外的所有旧的时间戳记录</span><br><span class="hljs-comment">-- 这是滑动窗口的关键，将所有过期的请求日志清理掉。</span><br>redis.call(<span class="hljs-string">&#x27;ZREMRANGEBYSCORE&#x27;</span>, key, <span class="hljs-number">0</span>, windowStart)<br><br><span class="hljs-comment">-- 3. [核心] 获取当前窗口内的请求数量</span><br><span class="hljs-comment">-- ZCARD 返回集合大小，时间复杂度为 O(1)，非常快。</span><br><span class="hljs-keyword">local</span> currentCount = redis.call(<span class="hljs-string">&#x27;ZCARD&#x27;</span>, key)<br><br><span class="hljs-comment">-- 4. [核心] 判断是否超过限制</span><br><span class="hljs-keyword">if</span> currentCount &lt; limit <span class="hljs-keyword">then</span><br>    <span class="hljs-comment">-- 未超限：将当前请求加入 ZSET，并返回成功</span><br>    redis.call(<span class="hljs-string">&#x27;ZADD&#x27;</span>, key, currentTime, member)<br>    <span class="hljs-comment">-- 设置一个稍长的过期时间，防止冷key占用内存</span><br>    redis.call(<span class="hljs-string">&#x27;PEXPIRE&#x27;</span>, key, windowSize + <span class="hljs-number">1000</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> <span class="hljs-comment">-- 返回 1 代表成功</span><br><span class="hljs-keyword">else</span><br>    <span class="hljs-comment">-- 已超限：什么都不做，直接返回失败</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-comment">-- 返回 0 代表被限流</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<p>Redis 提供了 ZREMRANGEBYSCORE 这样的命令，可以以极高的效率（O(log(N)+M)）移除一个时间窗口之外的所有记录。</p>
<h6 id="总结">总结</h6>
<h3 id="分布式限流器场景下：redis-事务-vs-lua-脚本对比">分布式限流器场景下：Redis 事务 VS Lua 脚本对比</h3>
<table>
<thead>
<tr>
<th>特性</th>
<th>Redis 事务 (MULTI/EXEC)</th>
<th>Lua 脚本</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>原子性保证</strong></td>
<td><strong>执行原子性</strong><br>能保证 ZREMRANGEBYSCORE、ZCARD、ZADD 这三个命令连续执行不被打断</td>
<td><strong>逻辑原子性</strong><br>整个脚本在 Redis 服务端以单线程方式原子执行</td>
</tr>
<tr>
<td><strong>条件逻辑能力</strong></td>
<td><strong>不支持</strong><br>无法在事务执行中根据 ZCARD 的结果来决定是否执行 ZADD</td>
<td><strong>完全支持</strong><br>可以在脚本内部使用 <code>if currentCount &lt; limit then...</code> 进行条件判断</td>
</tr>
<tr>
<td><strong>解决竞态条件</strong></td>
<td><strong>无法解决</strong><br>这是其致命弱点。客户端必须先无条件执行 ZADD，事后才能知道是否超限，此时已产生竞态条件</td>
<td><strong>完美解决</strong><br>将&quot;检查并设置&quot;作为一个原子操作在服务端完成，彻底杜绝竞态条件</td>
</tr>
<tr>
<td><strong>实现复杂度</strong></td>
<td><strong>极高且不可靠</strong><br>需要客户端实现复杂的&quot;补偿逻辑&quot;(即如果发现超限，再发起一个 ZREM 删除刚刚添加的成员)，这违背了原子性初衷</td>
<td><strong>中等</strong><br>需要在服务端编写一小段 Lua 脚本，但逻辑清晰，且一旦写好，客户端调用非常简单</td>
</tr>
<tr>
<td><strong>性能</strong></td>
<td><strong>较差</strong><br>即使不考虑补偿逻辑的额外开销，客户端和服务器之间也需要更多的交互来判断结果</td>
<td><strong>极高</strong><br>所有逻辑在 Redis 服务端以 C 的速度执行，网络往返只有一次，是性能最优的方案</td>
</tr>
<tr>
<td><strong>主要优点</strong></td>
<td><strong>几乎没有优点</strong><br>在这个特定问题上，几乎没有优点。它给人一种能解决问题的错觉，但实际上并不能</td>
<td><strong>原子、高效、简洁</strong><br>是解决此类&quot;读-改-写&quot;原子性问题的标准和最佳实践</td>
</tr>
<tr>
<td><strong>主要缺点</strong></td>
<td><strong>方案不可行</strong><br>从根本上无法原子性地处理条件判断，导致限流逻辑失效</td>
<td><strong>脚本必须高效</strong><br>由于 Redis 是单线程的，一个缓慢的 Lua 脚本会阻塞整个 Redis 服务。因此脚本逻辑必须简单、快速</td>
</tr>
<tr>
<td><strong>结论</strong></td>
<td><strong>不适用</strong><br>对于需要条件判断的原子操作(如限流器)，MULTI/EXEC 是一个错误的工具</td>
<td><strong>最佳选择</strong><br>是实现一个精准、高效、无竞态条件的分布式限流器的唯一正确且标准的方案</td>
</tr>
</tbody>
</table>
<h4 id="滑动窗口计数器-sliding-window-counter">滑动窗口计数器 (Sliding Window Counter)</h4>
<pre><code class="hljs mermaid">graph TD
    subgraph &quot;滑动窗口计数器 (Sliding Window Counter)&quot;
        A&#123;请求到达&#125; --&gt; B[定位到当前子窗口];
        B --&gt; C[将过期的子窗口计数清零];
        C --&gt; D[对所有子窗口的计数求和];
        D --&gt; E&#123;总和 &gt; 阈值?&#125;;
        E -- 否 --&gt; F[&quot;当前子窗口计数+1, 允许请求&quot;];
        E -- 是 --&gt; G[拒绝请求];
    end</code></pre>
<p>滑动窗口日志算法虽然能实现最精确的流量控制，但其对每一个请求都进行记录的方式，在高并发场景下会消耗巨大的内存，这在工程实践中往往是难以接受的。因此，我们需要一种兼顾了精度与资源消耗的折中方案——滑动窗口计数器 (Sliding Window Counter)。</p>
<p>其核心思想是，将一个大的时间窗口，切分成若干个更小的、精细化的**“子窗口” (Sub-window)** 或称之为**“桶” (Bucket)**，并为每个子窗口独立维护一个计数器。</p>
<p>这样一来，当时间窗口向前“滑动”时，不再是粗暴地跳跃一整个大窗口的长度，而是平滑地、一格一格地滑过这些子窗口。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicInteger;<br><span class="hljs-keyword">import</span> java.util.concurrent.locks.ReentrantLock;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 使用滑动窗口计数器算法实现的、线程安全的限流器。</span><br><span class="hljs-comment"> * 该实现兼顾了内存效率和限流平滑度，是工程中非常实用的方案。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SlidingWindowCounter</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> limit; <span class="hljs-comment">// 窗口内最大请求数</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> subWindowCount; <span class="hljs-comment">// 子窗口（桶）的数量</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> AtomicInteger[] subWindowCounters; <span class="hljs-comment">// 每个子窗口的计数器数组</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> windowSizeInMillis; <span class="hljs-comment">// 整个大窗口的时间长度（毫秒）</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> subWindowSizeInMillis; <span class="hljs-comment">// 单个子窗口的时间长度（毫秒）</span><br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> <span class="hljs-variable">lastWindowIndex</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; <span class="hljs-comment">// 上次请求所在的窗口索引</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">volatile</span> <span class="hljs-type">long</span> <span class="hljs-variable">lastWindowTimestamp</span> <span class="hljs-operator">=</span> System.currentTimeMillis(); <span class="hljs-comment">// 上次请求的时间戳</span><br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">ReentrantLock</span> <span class="hljs-variable">updateLock</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ReentrantLock</span>(); <span class="hljs-comment">// 用于窗口滑动的锁</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 构造函数</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> limit 窗口内最大请求数</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> windowSizeInMillis 窗口总时长（毫秒）</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> subWindowCount 划分的子窗口数量</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SlidingWindowCounter</span><span class="hljs-params">(<span class="hljs-type">int</span> limit, <span class="hljs-type">long</span> windowSizeInMillis, <span class="hljs-type">int</span> subWindowCount)</span> &#123;<br>        <span class="hljs-built_in">this</span>.limit = limit;<br>        <span class="hljs-built_in">this</span>.windowSizeInMillis = windowSizeInMillis;<br>        <span class="hljs-built_in">this</span>.subWindowCount = subWindowCount;<br>        <span class="hljs-built_in">this</span>.subWindowSizeInMillis = windowSizeInMillis / subWindowCount;<br>        <span class="hljs-built_in">this</span>.subWindowCounters = <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>[subWindowCount];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; subWindowCount; i++) &#123;<br>            <span class="hljs-built_in">this</span>.subWindowCounters[i] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取一个许可，如果未达到限流阈值，则返回 true。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> true 如果请求被允许, false 如果请求被拒绝。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-comment">// 1. 定位当前子窗口</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentTime</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br>        <span class="hljs-type">int</span> <span class="hljs-variable">currentIndex</span> <span class="hljs-operator">=</span> (<span class="hljs-type">int</span>) ((currentTime / subWindowSizeInMillis) % subWindowCount);<br><br>        <span class="hljs-comment">// 2. 判断窗口是否需要滑动，并重置过期的子窗口</span><br>        <span class="hljs-comment">//    通过加锁保证多线程环境下只有一个线程能执行清零操作。</span><br>        <span class="hljs-keyword">if</span> (updateLock.tryLock()) &#123;<br>            <span class="hljs-keyword">try</span> &#123;<br>                <span class="hljs-type">long</span> <span class="hljs-variable">timePassed</span> <span class="hljs-operator">=</span> currentTime - lastWindowTimestamp;<br>                <span class="hljs-keyword">if</span> (timePassed &gt; windowSizeInMillis) &#123;<br>                    <span class="hljs-comment">// 如果超过一个完整窗口，直接重置所有窗口</span><br>                    resetAllWindows();<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">// 否则，只重置滑过的窗口</span><br>                    <span class="hljs-type">int</span> <span class="hljs-variable">windowsToReset</span> <span class="hljs-operator">=</span> (<span class="hljs-type">int</span>) (timePassed / subWindowSizeInMillis);<br>                    <span class="hljs-keyword">if</span> (windowsToReset &gt; <span class="hljs-number">0</span>) &#123;<br>                        resetSlidingWindows(windowsToReset);<br>                    &#125;<br>                &#125;<br>                <span class="hljs-comment">// 更新最后的时间戳和索引</span><br>                <span class="hljs-built_in">this</span>.lastWindowTimestamp = currentTime;<br>                <span class="hljs-built_in">this</span>.lastWindowIndex = currentIndex;<br>            &#125; <span class="hljs-keyword">finally</span> &#123;<br>                updateLock.unlock();<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 3. 计算窗口总数</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentCount</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (AtomicInteger counter : subWindowCounters) &#123;<br>            currentCount += counter.get();<br>        &#125;<br><br>        <span class="hljs-comment">// 4. 判断并执行</span><br>        <span class="hljs-keyword">if</span> (currentCount &lt; limit) &#123;<br>            <span class="hljs-comment">// 如果未超限，则当前子窗口计数加 1</span><br>            subWindowCounters[currentIndex].incrementAndGet();<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">resetAllWindows</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; subWindowCount; i++) &#123;<br>            subWindowCounters[i].set(<span class="hljs-number">0</span>);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">resetSlidingWindows</span><span class="hljs-params">(<span class="hljs-type">int</span> windowsToReset)</span> &#123;<br>        <span class="hljs-comment">// windowsToReset 不能超过总窗口数</span><br>        windowsToReset = Math.min(windowsToReset, subWindowCount);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; windowsToReset; i++) &#123;<br>            <span class="hljs-comment">// 使用环形数组的逻辑，从上一个窗口的下一个开始清零</span><br>            <span class="hljs-type">int</span> <span class="hljs-variable">indexToReset</span> <span class="hljs-operator">=</span> (lastWindowIndex + <span class="hljs-number">1</span> + i) % subWindowCount;<br>            subWindowCounters[indexToReset].set(<span class="hljs-number">0</span>);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// --- 使用示例 ---</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-comment">// 限制：10秒内最多允许20个请求，内部划分为10个子窗口</span><br>        <span class="hljs-type">SlidingWindowCounter</span> <span class="hljs-variable">limiter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SlidingWindowCounter</span>(<span class="hljs-number">20</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">10</span>);<br><br>        <span class="hljs-comment">// 模拟连续快速的25次请求</span><br>        System.out.println(<span class="hljs-string">&quot;--- 快速发送第一批请求 ---&quot;</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">25</span>; i++) &#123;<br>            <span class="hljs-keyword">if</span> (limiter.tryAcquire()) &#123;<br>                System.out.println(<span class="hljs-string">&quot;请求 &quot;</span> + (i + <span class="hljs-number">1</span>) + <span class="hljs-string">&quot;: 成功&quot;</span>);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                System.out.println(<span class="hljs-string">&quot;请求 &quot;</span> + (i + <span class="hljs-number">1</span>) + <span class="hljs-string">&quot;: 被限流&quot;</span>);<br>            &#125;<br>            Thread.sleep(<span class="hljs-number">100</span>); <span class="hljs-comment">// 每100ms发一个</span><br>        &#125;<br><br>        <span class="hljs-comment">// 等待窗口滑动</span><br>        System.out.println(<span class="hljs-string">&quot;\n--- 等待3秒，让部分窗口过期 ---&quot;</span>);<br>        Thread.sleep(<span class="hljs-number">3000</span>);<br><br>        <span class="hljs-comment">// 再次发送10个请求</span><br>        System.out.println(<span class="hljs-string">&quot;\n--- 发送第二批请求 ---&quot;</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123;<br>            <span class="hljs-keyword">if</span> (limiter.tryAcquire()) &#123;<br>                System.out.println(<span class="hljs-string">&quot;请求 &quot;</span> + (i + <span class="hljs-number">26</span>) + <span class="hljs-string">&quot;: 成功&quot;</span>);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                System.out.println(<span class="hljs-string">&quot;请求 &quot;</span> + (i + <span class="hljs-number">26</span>) + <span class="hljs-string">&quot;: 被限流&quot;</span>);<br>            &#125;<br>            Thread.sleep(<span class="hljs-number">100</span>);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h5 id="代码与理论的对应关系">代码与理论的对应关系</h5>
<ul>
<li>子窗口计数器：代码中的 <code>private final AtomicInteger[] subWindowCounters</code>; 就是用来存储每个子窗口计数的数组。使用<code>AtomicInteger</code> 是为了保证高并发下计数的原子性和线程安全。</li>
<li>定位当前子窗口：<code>int currentIndex = (int) ((currentTime / subWindowSizeInMillis) % subWindowCount)</code>; 这行代码精确地实现了根据当前时间定位到其在环形数组中所属的子窗口索引。</li>
<li>窗口滑动：代码中最核心的部分是<code>tryAcquire()</code>方法中<code>updateLock</code> 锁住的代码块。它通过计算当前时间与上次记录时间的差值，来判断时间流逝了多少个子窗口的长度，然后主动将已经过期的子窗口计数器清零，从而实现了窗口“向前滑动”的效果。</li>
<li>计算窗口总数：<code>for (AtomicInteger counter : subWindowCounters)</code> 循环遍历并求和，得到了当前整个滑动窗口内的总请求数。</li>
</ul>
<h5 id="优点与缺点">优点与缺点</h5>
<ul>
<li>优点：在内存消耗和算法精度之间取得了绝佳的平衡。它仅需固定数量的计数器（与子窗口数量相同），内存占用极低，同时又可以有效地缓解固定窗口算法的极端毛刺问题。</li>
<li>缺点：实现逻辑比固定窗口要复杂一些。同时，它依然是一种近似的实现，其平滑程度取决于子窗口的划分粒度，在子窗口的边界上依然可能存在微小的流量突刺。但在绝大多数工程场景下，这种精度已经完全足够。</li>
</ul>
<h2 id="桶算法">桶算法</h2>
<h3 id="哲学差异">哲学差异</h3>
<h4 id="管控入口-ingress-vs-管控出口-egress">管控入口 (Ingress) VS 管控出口 (Egress)</h4>
<ul>
<li>
<p>令牌桶 (Token Bucket)：管控入口</p>
<ul>
<li>它像一个**“门卫”**，守在系统的大门口。</li>
<li>每个请求想进入系统时，都必须从门卫那里拿到一张**“门票” (令牌)**。</li>
<li>拿到票，立刻就能进门（被处理）。拿不到票，立刻就被拒绝。</li>
<li>核心逻辑：控制的是**“能不能进”**的问题。</li>
</ul>
</li>
<li>
<p>漏桶 (Leaky Bucket)：管控出口</p>
<ul>
<li>它像一个**“固定的安检通道”**。</li>
<li>所有请求不管来得多快，都必须先进入一个**“等待区” (桶/队列)**。</li>
<li>安检通道以一个恒定的速度，从等待区里拉人去安检（处理请求）。</li>
<li>核心逻辑：控制的是**“以多快的速度处理”**的问题。</li>
</ul>
</li>
</ul>
<h4 id="管控逻辑与状态核心">管控逻辑与状态核心</h4>
<ul>
<li>
<p><strong>令牌桶 (Token Bucket)</strong>：</p>
<ul>
<li><strong>逻辑核心</strong>：系统维护一个存放**“许可”或“令牌” (Token)** 的桶。系统以固定速率向桶内添加令牌。</li>
<li><strong>状态核心</strong>：桶内的<strong>令牌数量</strong>。</li>
<li><strong>决策方式</strong>：当请求到达时，它必须尝试从桶中获取一个或多个令牌。如果成功，请求被允许；如果失败，则根据预设策略进行处理。</li>
</ul>
</li>
<li>
<p><strong>漏桶 (Leaky Bucket)</strong>：</p>
<ul>
<li><strong>逻辑核心</strong>：系统将所有进入的请求视为水滴，放入一个“漏水的桶”中，桶以恒定的速率漏出（处理请求）。</li>
<li><strong>状态核心</strong>：桶当前的**“水量”或“占用容量”<strong>。在更高效的 GCRA 实现中，这个状态被抽象成一个</strong>理论到达时间 (TAT)**。</li>
<li><strong>决策方式</strong>：当请求到达时，检查桶里是否还有空间容纳这个请求。如果可以，请求被接纳；如果不行，则根据预设策略处理。</li>
</ul>
</li>
</ul>
<h4 id="令牌桶-vs-漏桶">令牌桶 VS 漏桶</h4>
<table>
<thead>
<tr>
<th style="text-align:left">特征</th>
<th style="text-align:left">令牌桶 (Token Bucket)</th>
<th style="text-align:left">漏桶 (Leaky Bucket / GCRA)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>管控点</strong></td>
<td style="text-align:left"><strong>入口 (Ingress)</strong> — 检查是否有“许可”进入。</td>
<td style="text-align:left"><strong>出口 (Egress)</strong> — 控制以何种恒定速率“处理”请求。</td>
</tr>
<tr>
<td style="text-align:left"><strong>桶里装的</strong></td>
<td style="text-align:left"><strong>令牌 (Tokens)</strong> — 代表未来的处理能力。</td>
<td style="text-align:left"><strong>处理能力的配额</strong> — 在经典模型中是请求本身，在 GCRA 中是代表未来处理时刻的<strong>时间戳 (TAT)</strong>。</td>
</tr>
<tr>
<td style="text-align:left"><strong>核心机制</strong></td>
<td style="text-align:left"><strong>消耗令牌</strong>来为请求获得处理许可。</td>
<td style="text-align:left">请求的到来会<strong>推进</strong>一个“未来处理完成”的时间点。</td>
</tr>
<tr>
<td style="text-align:left"><strong>请求队列</strong></td>
<td style="text-align:left"><strong>可选 (Optional)</strong><br>这是一个独立的设计选择。可以配置为：<br>• <strong>无队列</strong>：获取令牌失败则立即拒绝/报错。<br>• <strong>有队列</strong>：获取令牌失败则进入队列，等待新令牌生成。</td>
<td style="text-align:left"><strong>可选，但对于流量整形是必需的 (Optional, but required for shaping)</strong><br>• <strong>用于流量整形</strong>：必须有一个队列来暂存突发请求，以实现“削峰填谷”。<br>• <strong>仅用于速率限制</strong>：可以没有队列，当桶满时（如 GCRA 检查失败）直接拒绝请求。</td>
</tr>
<tr>
<td style="text-align:left"><strong>主要优点</strong></td>
<td style="text-align:left"><strong>低延迟，允许突发</strong><br>只要桶内有足够的令牌，突发请求可以被立即处理，响应迅速。</td>
<td style="text-align:left"><strong>流量平滑</strong><br>无论入口流量如何波动，出口流量都相对恒定，对下游系统非常友好。</td>
</tr>
<tr>
<td style="text-align:left"><strong>主要缺点</strong></td>
<td style="text-align:left">突发流量可能直接冲击下游系统。</td>
<td style="text-align:left">如果配置了队列，会增加请求的平均响应时间 (Latency)。</td>
</tr>
</tbody>
</table>
<p>打个比方：</p>
<blockquote>
<ol>
<li>令牌桶里面的capacity在特定时间里面积累了30个令牌，一瞬间来了30个流量，它们会一次通过。因为令牌被积累起来，一次消耗光了。</li>
<li>同样地，假设我们认为漏桶的“空”等于 burst 的配额，一定时间以后桶漏空了，所以一瞬间来了30个流量，漏桶也能处理这30个突发流量。但是这种处理实际上是：“允许这30个请求留在桶里不丢弃”，仍然让他们按照特定速率出队，用“装请求”而不是“一次性放行”来处理这些请求。</li>
<li>所以这种“漏桶流逝时间会消耗水量”只是累积“空”而已。允许 burst 的漏桶变种实际上是，比如我的桶的容量还是30，但是我允许单位时间的 burst 为<br>
3。一次过来30个流量，有3个流量可以毛刺通过，但是有27个流量会和这个burst消耗慢慢算账，最终平滑流量到平均速率里。</li>
<li>这种burst的计算和回复方式又是和令牌桶不一样的。所以“令牌桶可以积攒令牌的”，“漏桶里流逝时间是不会累加burst的，有些版本甚至不允许burst-原始版本”。</li>
</ol>
</blockquote>
<h3 id="漏桶算法">漏桶算法</h3>
<pre><code class="hljs mermaid">graph TD

    subgraph &quot;漏桶 (Leaky Bucket)&quot;
        A&#123;请求到达&#125; -- 到达速率不固定 --&gt; B((请求队列/桶));
        B -- 队列未满 --&gt; C[进入队列等待];
        B -- 队列已满 --&gt; D[溢出/拒绝请求];
        C -- 以固定速率流出 --&gt; E[处理请求];
    end</code></pre>
<p><img src="leaky-bucket.png" alt="leaky-bucket"></p>
<p>根据维基百科，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Leaky_bucket">漏桶算法</a>的描述如下：</p>
<ul>
<li>一个固定容量的漏桶，按照常量固定速率流出水滴；</li>
<li>如果桶是空的，则不需流出水滴；</li>
<li><strong>可以以任意速率流入水滴到漏桶</strong>；</li>
<li>如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。</li>
</ul>
<p>我们可以把水滴想象成一个个许可。request 们在漏桶里排队，漏桶算法是一个完全定时发令牌的算法，因此这些请求也因此被间隔性地阻滞在桶中，只有通过固定的时间间隔，才能顺利的通过这个漏桶。</p>
<h4 id="java-的流量整形器-traffic-shaper">java 的流量整形器 (Traffic Shaper)</h4>
<p>Java 程序员看到这里，恐怕很容易联想到一个 Bouded Queue 和一个 Timing Comsumer 的组合。实际上，我们把准备一个定长的 Queue，和一个定时线程池，每次有新的请求发生，都投入这个定长 Queue 中，然后让定时线程池里的 worker 线程定时地取出 Queue 里面的请求，就可以模拟漏桶算法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.concurrent.ArrayBlockingQueue;<br><span class="hljs-keyword">import</span> java.util.concurrent.Executors;<br><span class="hljs-keyword">import</span> java.util.concurrent.ScheduledExecutorService;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicInteger;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * &lt;h1&gt;经典漏桶算法的Java实现 (流量整形)&lt;/h1&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;本类通过一个“有界队列”和一个“定时消费者”来模拟漏桶算法。</span><br><span class="hljs-comment"> * 其核心目标是&lt;b&gt;流量整形 (Traffic Shaping)&lt;/b&gt;，即将不规则的、突发的输入流量，</span><br><span class="hljs-comment"> * 转化为平滑的、速率恒定的输出流量。&lt;/p&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> *   &lt;li&gt;&lt;b&gt;桶 (Bucket)&lt;/b&gt;: 使用 &#123;<span class="hljs-doctag">@link</span> ArrayBlockingQueue&#125; 实现，它有固定的容量。&lt;/li&gt;</span><br><span class="hljs-comment"> *   &lt;li&gt;&lt;b&gt;漏孔 (Leak)&lt;/b&gt;: 使用 &#123;<span class="hljs-doctag">@link</span> ScheduledExecutorService&#125; 实现，它以固定速率从桶中取出任务处理。&lt;/li&gt;</span><br><span class="hljs-comment"> *   &lt;li&gt;&lt;b&gt;溢出 (Overflow)&lt;/b&gt;: 当请求试图进入一个已满的桶时，它会被立即拒绝。&lt;/li&gt;</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LeakyBucketShaper</span> &#123;<br><br>    <span class="hljs-comment">// --- 漏桶的核心组件 ---</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 桶本身：一个线程安全的、有固定容量的队列。</span><br><span class="hljs-comment">     * 我们使用 ArrayBlockingQueue，因为它满足“有界”这一核心要求。</span><br><span class="hljs-comment">     * &#x27;Runnable&#x27; 代表流入桶中的“水滴”，即每一个待处理的请求。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ArrayBlockingQueue&lt;Runnable&gt; bucket;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 定时任务执行器：扮演“从桶底漏水”的角色。</span><br><span class="hljs-comment">     * 它将以恒定的速率，周期性地从&#x27;bucket&#x27;队列中取出任务来执行。</span><br><span class="hljs-comment">     * 我们使用单线程的调度器，因为漏水的出口通常只有一个。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ScheduledExecutorService scheduler;<br><br>    <span class="hljs-comment">// --- 构造与初始化 ---</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 构造一个漏桶实例。</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> capacity 桶的容量 (bucket capacity)。这是桶能缓存的最大请求数。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> rate     漏水速率 (leak rate)，即每秒处理多少个请求。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">LeakyBucketShaper</span><span class="hljs-params">(<span class="hljs-type">int</span> capacity, <span class="hljs-type">int</span> rate)</span> &#123;<br>        <span class="hljs-comment">// 1. 初始化桶，设置其最大容量。</span><br>        <span class="hljs-built_in">this</span>.bucket = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayBlockingQueue</span>&lt;&gt;(capacity);<br>        <span class="hljs-comment">// 2. 初始化定时任务执行器。</span><br>        <span class="hljs-built_in">this</span>.scheduler = Executors.newSingleThreadScheduledExecutor();<br><br>        <span class="hljs-comment">// 3. 计算两次漏水之间的时间间隔（以毫秒为单位）。</span><br>        <span class="hljs-comment">//    例如，如果 rate 是 2 (个/秒)，那么时间间隔就是 1000ms / 2 = 500ms。</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">intervalMillis</span> <span class="hljs-operator">=</span> <span class="hljs-number">1000</span> / rate;<br><br>        <span class="hljs-comment">// 4. 启动核心的定时任务，这就是“漏水”过程。</span><br>        <span class="hljs-comment">//    scheduleAtFixedRate 会确保任务以近似固定的频率被执行。</span><br>        scheduler.scheduleAtFixedRate(<br>            () -&gt; &#123; <span class="hljs-comment">// 这个 Lambda 表达式就是每次“漏水”时要执行的操作</span><br>                <span class="hljs-keyword">try</span> &#123;<br>                    <span class="hljs-comment">// 从桶中取出一个任务。</span><br>                    <span class="hljs-comment">// take() 是一个阻塞方法：</span><br>                    <span class="hljs-comment">// - 如果桶里有任务，它会立即取出一个并返回。</span><br>                    <span class="hljs-comment">// - 如果桶是空的，它会暂停（阻塞）当前线程，直到有新任务进入桶中。</span><br>                    <span class="hljs-comment">// 这完美地实现了“没水时，不漏”的行为，且不会空耗CPU。</span><br>                    <span class="hljs-type">Runnable</span> <span class="hljs-variable">task</span> <span class="hljs-operator">=</span> bucket.take();<br><br>                    <span class="hljs-comment">// 在调度器自己的线程中，执行这个取出的任务。</span><br>                    task.run();<br>                &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                    <span class="hljs-comment">// 如果在 take() 阻塞等待时线程被中断，则重置中断状态并退出。</span><br>                    Thread.currentThread().interrupt();<br>                    System.err.println(<span class="hljs-string">&quot;Scheduler was interrupted while waiting for a task.&quot;</span>);<br>                &#125;<br>            &#125;,<br>            <span class="hljs-number">0</span>,                <span class="hljs-comment">// 第一次执行的初始延迟（0表示立即开始）</span><br>            intervalMillis,   <span class="hljs-comment">// 两次执行之间的固定时间间隔</span><br>            TimeUnit.MILLISECONDS <span class="hljs-comment">// 时间单位</span><br>        );<br>    &#125;<br><br>    <span class="hljs-comment">// --- 对外暴露的接口 ---</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试将一个请求（封装为Runnable任务）提交到漏桶中。</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> task 代表一个请求的 &#123;<span class="hljs-doctag">@link</span> Runnable&#125; 对象。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> 如果桶未满，请求被成功放入，返回 true。</span><br><span class="hljs-comment">     *         如果桶已满，请求被“溢出”（拒绝），返回 false。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">submit</span><span class="hljs-params">(Runnable task)</span> &#123;<br>        <span class="hljs-comment">// 使用 offer() 方法尝试将任务添加到队列（桶）的末尾。</span><br>        <span class="hljs-comment">// offer() 是非阻塞的：</span><br>        <span class="hljs-comment">// - 如果队列未满，它会立即添加元素并返回 true。</span><br>        <span class="hljs-comment">// - 如果队列已满，它不会等待，而是立即返回 false。</span><br>        <span class="hljs-comment">// 这完美地模拟了“水满则溢”的行为。</span><br>        <span class="hljs-keyword">return</span> bucket.offer(task);<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 停止漏桶的漏水过程（关闭定时任务执行器）。</span><br><span class="hljs-comment">     * 在程序结束时调用，以优雅地释放资源。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">stop</span><span class="hljs-params">()</span> &#123;<br>        scheduler.shutdown();<br>    &#125;<br><br>    <span class="hljs-comment">// --- 演示如何使用漏桶 ---</span><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        System.out.println(<span class="hljs-string">&quot;启动漏桶，容量为10，处理速率为 2个/秒...&quot;</span>);<br>        <span class="hljs-comment">// 创建一个漏桶实例</span><br>        <span class="hljs-type">LeakyBucketShaper</span> <span class="hljs-variable">shaper</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">LeakyBucketShaper</span>(<span class="hljs-number">10</span>, <span class="hljs-number">2</span>);<br>        <span class="hljs-comment">// 用于计数，观察总共有多少个请求被成功处理</span><br>        <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">requestCounter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);<br><br>        <span class="hljs-comment">// 模拟一波突发流量：在很短的时间内（1.5秒）连续提交30个请求</span><br>        System.out.println(<span class="hljs-string">&quot;模拟突发流量：在1.5秒内连续提交30个请求...&quot;</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">30</span>; i++) &#123;<br>            <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">requestId</span> <span class="hljs-operator">=</span> i + <span class="hljs-number">1</span>;<br>            <span class="hljs-comment">// 将每个请求封装成一个Runnable任务</span><br>            <span class="hljs-type">Runnable</span> <span class="hljs-variable">task</span> <span class="hljs-operator">=</span> () -&gt; &#123;<br>                <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> requestCounter.incrementAndGet();<br>                System.out.printf(<br>                    <span class="hljs-string">&quot;✅ [处理成功] 时间: %s, 请求ID: %d (这是第 %d 个被处理的请求).%n&quot;</span>,<br>                    java.time.LocalTime.now().withNano(<span class="hljs-number">0</span>), requestId, count<br>                );<br>            &#125;;<br><br>            <span class="hljs-comment">// 尝试将任务提交到漏桶</span><br>            <span class="hljs-keyword">if</span> (shaper.submit(task)) &#123;<br>                System.out.printf(<span class="hljs-string">&quot;💧 [放入桶中] 请求 %d 被成功放入桶中，等待处理.%n&quot;</span>, requestId);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                System.out.printf(<span class="hljs-string">&quot;❌ [溢出拒绝] 请求 %d 因为桶已满而被拒绝!%n&quot;</span>, requestId);<br>            &#125;<br><br>            <span class="hljs-comment">// 稍微间隔一下，让提交过程看起来更真实</span><br>            Thread.sleep(<span class="hljs-number">50</span>); <span class="hljs-comment">// 每50毫秒提交一个</span><br>        &#125;<br><br>        <span class="hljs-comment">// 主线程等待足够长的时间，以确保桶中所有缓存的任务都被处理完毕</span><br>        System.out.println(<span class="hljs-string">&quot;\n--- 突发流量提交完毕，观察处理日志... ---\n&quot;</span>);<br>        Thread.sleep(<span class="hljs-number">10000</span>);<br><br>        <span class="hljs-comment">// 停止漏桶并结束演示</span><br>        shaper.stop();<br>        System.out.println(<span class="hljs-string">&quot;\n--- 演示结束 ---&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>这种经典漏桶算法的实现的本质是：<strong>桶每个时间间隔只出一滴水</strong>。</p>
<p>流量整形器的定义是: 它的主要目标是平滑输出。它接收不规则的请求，将它们放入内部队列，然后以恒定的速率从队列中取出并自己执行。就像一个物理漏斗，无论你倒水的速度多快，水流出的速度是恒定的。</p>
<h4 id="java-的速率限制器-rate-limiter">java 的速率限制器 (Rate Limiter)</h4>
<p>它的主要目标是控制入口。它不关心任务是什么，也不执行任务。它只是一个“门卫”，多个工作线程在执行自己的任务前，必须先向这个“门卫”申请许可。如果“门卫”允许，工作线程就继续执行；如果“门卫”拒绝，工作线程就等待或放弃。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.concurrent.ExecutorService;<br><span class="hljs-keyword">import</span> java.util.concurrent.Executors;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicInteger;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * &lt;h1&gt;漏桶算法作为速率限制器 (Rate Limiter) 的实现&lt;/h1&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;本类实现了一个可被多个工作线程共享的漏桶。它不处理任务本身，</span><br><span class="hljs-comment"> * 而是充当一个“门卫”，工作线程在执行任务前必须调用 &#123;<span class="hljs-doctag">@link</span> #tryAcquire()&#125; 来获取许可。&lt;/p&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;其核心思想是：&lt;/p&gt;</span><br><span class="hljs-comment"> * &lt;ul&gt;</span><br><span class="hljs-comment"> *   &lt;li&gt;&lt;b&gt;桶 (Bucket)&lt;/b&gt;: 不再是一个任务队列，而是一个抽象的概念，由“容量”和“水位”两个状态代表。&lt;/li&gt;</span><br><span class="hljs-comment"> *   &lt;li&gt;&lt;b&gt;漏水 (Leak)&lt;/b&gt;: 水以恒定速率流出，这通过计算流逝的时间来动态模拟。&lt;/li&gt;</span><br><span class="hljs-comment"> *   &lt;li&gt;&lt;b&gt;获取许可 (Acquire)&lt;/b&gt;: 一个线程尝试获取许可，相当于往桶里“加一滴水”。如果桶没满，就成功；如果满了，就失败。&lt;/li&gt;</span><br><span class="hljs-comment"> * &lt;/ul&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;这个实现是线程安全的，多个线程可以无锁竞争地调用 &#123;<span class="hljs-doctag">@code</span> tryAcquire&#125; 方法。&lt;/p&gt;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LeakyBucketLimiter</span> &#123;<br><br>    <span class="hljs-comment">// --- 漏桶的核心状态 ---</span><br><br>    <span class="hljs-comment">/** 桶的容量 (burst capacity)，即桶中能容纳的最大水量（令牌数）。*/</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> capacity;<br><br>    <span class="hljs-comment">/** 漏水速率，即每秒钟能从桶中流出多少水（令牌）。*/</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> ratePerSecond;<br><br>    <span class="hljs-comment">/** 桶中当前的水量（令牌数）。使用 AtomicInteger 保证原子性操作。*/</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">waterLevel</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);<br><br>    <span class="hljs-comment">/** 上一次漏水的时间戳（毫秒）。*/</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">volatile</span> <span class="hljs-type">long</span> lastLeakTimestamp;<br><br>    <span class="hljs-comment">// --- 构造与初始化 ---</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 构造一个漏桶速率限制器。</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> capacity      桶的容量，代表能承受的突发请求数。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> ratePerSecond 每秒允许通过的平均请求数。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">LeakyBucketLimiter</span><span class="hljs-params">(<span class="hljs-type">int</span> capacity, <span class="hljs-type">int</span> ratePerSecond)</span> &#123;<br>        <span class="hljs-built_in">this</span>.capacity = capacity;<br>        <span class="hljs-built_in">this</span>.ratePerSecond = ratePerSecond;<br>        <span class="hljs-built_in">this</span>.lastLeakTimestamp = System.currentTimeMillis();<br>    &#125;<br><br>    <span class="hljs-comment">// --- 核心方法 ---</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取一个许可（往桶里加一滴水）。</span><br><span class="hljs-comment">     * &lt;p&gt;这是一个非阻塞方法，会立即返回结果。&lt;/p&gt;</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> 如果获取成功，返回 &#123;<span class="hljs-doctag">@code</span> true&#125;；如果桶已满导致获取失败，返回 &#123;<span class="hljs-doctag">@code</span> false&#125;。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-comment">// 1. 先执行“漏水”操作，根据流逝的时间更新水位。</span><br>        leak();<br><br>        <span class="hljs-comment">// 2. 检查当前水位是否低于容量。</span><br>        <span class="hljs-keyword">if</span> (waterLevel.get() &lt; capacity) &#123;<br>            <span class="hljs-comment">// 如果桶里还有空间，就“加一滴水”并成功返回。</span><br>            waterLevel.incrementAndGet();<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 如果桶已经满了，则拒绝加水，返回失败。</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 模拟漏水过程。这是一个内部方法，在每次尝试获取许可前调用。</span><br><span class="hljs-comment">     * &lt;p&gt;此方法必须在同步块中调用，以保证线程安全。&lt;/p&gt;</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">leak</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">now</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br>        <span class="hljs-comment">// 计算自上次漏水以来经过了多长时间。</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">elapsedTime</span> <span class="hljs-operator">=</span> now - lastLeakTimestamp;<br><br>        <span class="hljs-keyword">if</span> (elapsedTime &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-comment">// 根据流逝的时间和速率，计算应该漏掉多少水。</span><br>            <span class="hljs-comment">// (elapsedTime * ratePerSecond) / 1000 是这段时间总共可以漏掉的水量。</span><br>            <span class="hljs-type">long</span> <span class="hljs-variable">leakedAmount</span> <span class="hljs-operator">=</span> (elapsedTime * ratePerSecond) / <span class="hljs-number">1000</span>;<br><br>            <span class="hljs-keyword">if</span> (leakedAmount &gt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-comment">// 更新水位：当前水位减去漏掉的水量，但不能低于0。</span><br>                <span class="hljs-type">int</span> <span class="hljs-variable">newLevel</span> <span class="hljs-operator">=</span> Math.max(<span class="hljs-number">0</span>, waterLevel.get() - (<span class="hljs-type">int</span>) leakedAmount);<br>                waterLevel.set(newLevel);<br>                <span class="hljs-comment">// 更新最后一次漏水的时间戳。</span><br>                <span class="hljs-built_in">this</span>.lastLeakTimestamp = now;<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// --- 演示如何使用 ---</span><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-comment">// 创建一个漏桶限制器：容量为10，速率为 5个/秒。</span><br>        <span class="hljs-comment">// 这意味着它能立即处理10个突发请求，然后以每200毫秒一个的速度稳定放行。</span><br>        <span class="hljs-keyword">final</span> <span class="hljs-type">LeakyBucketLimiter</span> <span class="hljs-variable">limiter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">LeakyBucketLimiter</span>(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>);<br><br>        <span class="hljs-comment">// 创建一个拥有5个工作线程的线程池。</span><br>        <span class="hljs-comment">// 这些线程将共享同一个漏桶限制器。</span><br>        <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">workers</span> <span class="hljs-operator">=</span> Executors.newFixedThreadPool(<span class="hljs-number">5</span>);<br><br>        <span class="hljs-comment">// 用于计数，观察有多少请求被成功执行。</span><br>        <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">successCounter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(<span class="hljs-number">0</span>);<br>        System.out.println(<span class="hljs-string">&quot;启动演示：5个工作线程共享一个漏桶 (容量10, 速率5/s)&quot;</span>);<br>        System.out.println(<span class="hljs-string">&quot;将连续提交30个任务到线程池...&quot;</span>);<br><br>        <span class="hljs-comment">// 模拟在短时间内有30个任务需要处理。</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">30</span>; i++) &#123;<br>            <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">taskId</span> <span class="hljs-operator">=</span> i + <span class="hljs-number">1</span>;<br>            workers.submit(() -&gt; &#123;<br>                <span class="hljs-comment">// 工作线程在执行实际任务前，首先向漏桶申请许可。</span><br>                <span class="hljs-keyword">if</span> (limiter.tryAcquire()) &#123;<br>                    <span class="hljs-comment">// --- 获取许可成功 ---</span><br>                    <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> successCounter.incrementAndGet();<br>                    System.out.printf(<br>                        <span class="hljs-string">&quot;✅ [执行成功] 时间: %s, 任务ID: %d (第 %d 个成功任务).%n&quot;</span>,<br>                        java.time.LocalTime.now().withNano(<span class="hljs-number">0</span>), taskId, count<br>                    );<br>                    <span class="hljs-comment">// 模拟实际工作耗时</span><br>                    <span class="hljs-keyword">try</span> &#123; Thread.sleep(<span class="hljs-number">250</span>); &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;&#125;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">// --- 获取许可失败 ---</span><br>                    System.out.printf(<br>                        <span class="hljs-string">&quot;❌ [限流拒绝] 时间: %s, 任务ID: %d 被拒绝，当前流量过大.%n&quot;</span>,<br>                        java.time.LocalTime.now().withNano(<span class="hljs-number">0</span>), taskId<br>                    );<br>                &#125;<br>            &#125;);<br>            <span class="hljs-comment">// 快速提交任务，模拟突发</span><br>            Thread.sleep(<span class="hljs-number">30</span>);<br>        &#125;<br><br>        <span class="hljs-comment">// 关闭线程池并等待任务结束</span><br>        workers.shutdown();<br>        workers.awaitTermination(<span class="hljs-number">15</span>, TimeUnit.SECONDS);<br><br>        System.out.println(<span class="hljs-string">&quot;\n--- 演示结束 ---&quot;</span>);<br>        System.out.printf(<span class="hljs-string">&quot;最终，共有 %d 个任务被成功执行。%n&quot;</span>, successCounter.get());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>这个漏桶算法原本看起来是用**“能不能漏水”<strong>来决定流量是否通过，实际上也可以把这个问题转化为</strong>“能不能加水”**问题：</p>
<ol>
<li>先按照流逝的时间放水，<strong>产生空挡</strong>。</li>
<li>然后再加水看看能不能超过容量，<strong>看看空挡是否足够</strong>。</li>
<li>这里面的空挡的大小（capacity）和下面的 GCRA 算法的 burst 配置其实是等价的。空档的大小决定了应对突发流量的缓冲能力。capacity 能接纳的水的数量，恰好就是能够一瞬间接纳突发流量的能力，等于 burst。所以说空桶和水的漏出速度是两个最基础配置。capacity 和 burst 不能保证平均 QPS 严格等于 rate，但能保证平均 QPS 不会超过 rate。</li>
</ol>
<p>另一种简化实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LeakyDemo</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">long</span> <span class="hljs-variable">timeStamp</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-variable">capacity</span> <span class="hljs-operator">=</span> <span class="hljs-number">100</span>; <span class="hljs-comment">// 桶的容量</span><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-variable">rate</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; <span class="hljs-comment">// 水漏出的速度，和 qps 相关</span><br><br>    <span class="hljs-keyword">public</span>  <span class="hljs-keyword">volatile</span> <span class="hljs-type">long</span> water; <span class="hljs-comment">// 当前水量(当前累积请求数)</span><br><br>    <span class="hljs-comment">// 注意，这个 grant 函数可能可以并发执行</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">grant</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">now</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br><br>        <span class="hljs-comment">// 假定有一个请求到达桶内，应该先确认是不是还可以进入这个桶</span><br>        water = max(<span class="hljs-number">0l</span>, (<span class="hljs-type">long</span>)(water - (now - timeStamp) * rate)); <span class="hljs-comment">// 所以应该先执行漏水，计算剩余水量。执行漏水的逻辑是：流逝的时间乘以理论的qps得到理论上应该流逝的请求，这些流逝的请求可以被设定为被预先生成出来的空挡</span><br>        timeStamp = now;<br>        <span class="hljs-comment">// 在现有的容量上如果可以加水成功，意味着这一滴水可以按照当前的 QPS 落入桶中。</span><br>        <span class="hljs-comment">// 我们可以想象它满足了这个约束，未来也必然可以以相同的速率离开这个桶。所以此处可以认为它拿到了 permit。</span><br>        <span class="hljs-comment">// 而其他并发调用这个 grant 函数的其他请求，总会超过这个 QPS 的约束。因而无法得到 permit，也就保证了 QPS。</span><br>        <span class="hljs-keyword">if</span> ((water + <span class="hljs-number">1</span>) &lt; capacity) &#123;<br>            <span class="hljs-comment">// 尝试加水,并且水还未满，如果请求可以进入这些空挡，则桶的约束得到了满足</span><br>            water += <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 水满，拒绝加水</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>    &#125;<br> <br>    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-title function_">max</span><span class="hljs-params">(<span class="hljs-type">long</span> a, <span class="hljs-type">long</span> b)</span> &#123;<br>        <span class="hljs-keyword">return</span> a &gt; b ? a : b;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>我们可以看到，漏桶算法使得不管是任何速度的入（inboud）流量，最后都规规矩矩地变成了固定速度的出（outbound）流量。因此，漏桶算法不仅起到了限流的作用，还可以作为计量工具（The Leaky Bucket Algorithm as a Meter），起到流量整形（Traffic Shaping）和流量控制（Traffic Policing）的作用。但限流算法，也有一个固有的缺点，就是不允许突发流量一次通过，必须严格按照 qps 的时间窗口一个一个地通过漏桶。</p>
<h4 id="gcra-通用信元速率算法-generic-cell-rate-algorithm">GCRA 通用信元速率算法（generic cell rate algorithm）</h4>
<h5 id="从实体漏桶到-gcra：核心思想的转变">从实体漏桶到 GCRA：核心思想的转变</h5>
<p>根本的转变在于从一个物理模型演变成了一个虚拟模型：</p>
<ul>
<li>经典漏桶: 拥有一个真实的、消耗内存的队列 (ArrayBlockingQueue) 来存放请求。它是一个有状态的数据结构。速率由一个独立的定时线程从队列中拉取任务来控制。</li>
<li>GCRA (又称“作为计量器的漏桶”): 没有队列。它只维护一个核心数据：理论到达时间 (Theoretical Arrival Time, 简称 TAT)。我们不再把请求放入队列等待，而是通过一个快速的数学计算，来判断这个请求如果遵守完美的速率，它“本应该”在什么时候到达，并以此决定是否放行。它是一个有状态的算法。</li>
</ul>
<p>GCRA 回答了这样一个问题：“如果流量是绝对平滑的，那么这个请求<strong>应该在哪个时间点到达</strong>？” 然后，它会检查<strong>实际的到达时间是否与这个理论时间“足够接近”</strong>。</p>
<h5 id="基础的-5-条设定">基础的 5 条设定</h5>
<ul>
<li>初始状态 (Initial State):
<ul>
<li>算法启动的时刻为 t_0，此时，系统的理论到达时间 (TAT) 被初始化为 TAT_0 = t_0。这为整个算法确立了时间的起点。</li>
</ul>
</li>
<li>时间间隔 (Interval, T):
<ul>
<li>它是系统处理两个连续请求之间的标准时长。其计算方式为：T = 时间周期 / 速率限制。例如，限制为 100次/秒，则 T = 1秒 / 100 = 10毫秒。这是算法的“心跳节拍”。</li>
</ul>
</li>
<li>容忍度 (Tolerance, τ):
<ul>
<li>这是系统能够容忍一个请求比其理论时间“提前”到达的最大量。它由期望的突发能力决定：τ = 突发上限 * T。这个值定义了系统应对流量毛刺的缓冲能力。<br>
是有效的，又防止了因“信用”累积而导致的、远超预期的超级流量爆发。</li>
</ul>
</li>
<li>一致性检验 (Conformance Check):
<ul>
<li>对于每一个到达的请求，系统都执行一次“一致性”检验，以决定其命运。只有满足以下条件的请求才被视为“一致的”（conforming），并被放行：<strong>t_当前 ≥ TAT_旧 - τ</strong>。这个不等式是算法的“守门神”。
<ul>
<li>这个算法的核心是<strong>不能太早</strong>。</li>
</ul>
</li>
</ul>
</li>
<li>到达时间的更新 (TAT Update):
<ul>
<li><strong>每当一个请求被允许通过后，系统的下一个理论到达时间点会立即更新</strong>。其规则为：TAT_新 = max(t_当前, TAT_旧) + T。max函数的存在，是算法能够“原谅”空闲时段的关键。
<ul>
<li>它规定：如果系统空闲了一段时间，那么不要再基于过去的某个时间点来规划未来。而是应该将时钟“重置”到当前时刻 (t_当前)，并从现在开始，安排下一个请求的通行时间。</li>
<li>简而言之，max 函数确保了系统不会在空闲时无限地累积“信用”。它将限流的基准锚定在当前时间，从而保证了设定的突发容忍度 (τ)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>在这种实践中，我们每次是先校验 latest TAT，校验完了，才计算<code>TAT_新 = max(t_当前, TAT_旧) + T</code>的。因为“更新 TAT”这个行为，本身就是对“许可被授予”这个事实的记录。<br>
我们必须先确定一个请求是否应该被批准，然后才能去记录它被批准后所产生的影响（即更新下一个请求的理论时间）。</p>
<p>下面我们还会看到另一种先计算newTat、校验、再更新的做法。</p>
<h6 id="漏桶算法-vs-gcra">漏桶算法 VS GCRA</h6>
<table>
<thead>
<tr>
<th>维度</th>
<th>漏桶算法 (Leaky Bucket – 计算空档)</th>
<th>GCRA (Generic Cell Rate Algorithm – 计算理论到达时间)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>核心思想</strong></td>
<td><strong>空间思维</strong>：把流量控制看作往一个有容量、会漏水的桶里注水与排水。</td>
<td><strong>时间思维</strong>：为每个请求在时间轴上预定一个“理论上应该被处理”的时刻，并检查实际到达时间是否过早。</td>
</tr>
<tr>
<td><strong>状态变量</strong></td>
<td>两个：<br>1. <code>waterLevel</code>（当前水位，整数）<br>2. <code>lastLeakTimestamp</code>（上次漏水时间，时间戳）</td>
<td>一个：<br>1. <code>TAT</code>（下一个理论到达时间，时间戳）</td>
</tr>
<tr>
<td><strong>优点</strong></td>
<td>- 极其直观：桶与水的比喻易于团队理解沟通。<br>- 状态有界：<code>waterLevel</code> 始终落在 <code>[0, capacity]</code>，不会因时间戳溢出等极端情况而失控。</td>
<td>- 实现优雅：只需维护一个状态变量 <code>TAT</code>，在分布式场景（如仅需一个 <code>AtomicLong</code>）下更简洁。<br>- 数学严谨：源于电信网络，有大量理论基础与论文支持。</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>- 状态稍多：需同时维护两个变量（但实践开销几乎可忽略）。</td>
<td>- 不够直观：“理论到达时间”相比“桶里还有多少水”更抽象，初学者需花额外时间建立心智模型。</td>
</tr>
</tbody>
</table>
<h6 id="到底什么是-burst？">到底什么是 Burst？</h6>
<p><code>burst</code> (突发) 或 <code>capacity</code> (容量) 这类词，在高级的限流算法（如漏桶/GCRA）中，描述的<strong>不是任意一个固定时间窗口内容许的请求量</strong>。</p>
<p>它描述的是一种能力：<strong>一连串本该按速率间隔开的请求，能够多大程度上被允许“无视间隔”、连续集中地爆发。</strong></p>
<p>这个数值定义了系统从空闲状态切换到繁忙状态时，能承受的瞬时冲击上限。</p>
<h6 id="max-函数：锚定限流计算的起点"><code>max()</code> 函数：锚定限流计算的起点</h6>
<p>要理解 burst 如何被精确控制，我们必须深入 <code>max()</code> 函数的逻辑。通用速率限制算法（GCRA）的核心是两个公式：</p>
<ol>
<li><strong>准入检查</strong>：一个请求要被允许，它的到达时间 <code>t_当前</code> 必须晚于或等于一个理论时间 <code>TAT</code> 减去一个容忍度 <code>τ</code>。
<blockquote>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mtext>当前</mtext></msub><mo>≥</mo><mi>T</mi><mi>A</mi><mi>T</mi><mo>−</mo><mi>τ</mi></mrow><annotation encoding="application/x-tex">t_{当前} ≥ TAT - τ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7859700000000001em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">当</span><span class="mord cjk_fallback mtight">前</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span></p>
</blockquote>
</li>
<li><strong>时间更新</strong>：请求通过后，下一个请求的理论时间 <code>TAT</code> 会被更新。
<blockquote>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>A</mi><msub><mi>T</mi><mtext>新</mtext></msub><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mtext>当前</mtext></msub><mo separator="true">,</mo><mi>T</mi><mi>A</mi><msub><mi>T</mi><mtext>旧</mtext></msub><mo stretchy="false">)</mo><mo>+</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">TAT_{新} = max(t_{当前}, TAT_{旧}) + T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">A</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">新</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">当</span><span class="mord cjk_fallback mtight">前</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">A</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">旧</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span></span><br>
(其中 <code>T</code> 是速率决定的间隔，<code>τ</code> 是由 <code>burst</code> 决定的容忍度)</p>
</blockquote>
</li>
</ol>
<p>这里的关键点在于，<strong>计算限流的起点必须锚定在正确的时间点上</strong>。<code>max()</code> 函数就是实现这个锚定的机制。</p>
<p>我们可以通过一个反向推导来证明为什么必须是 <code>max()</code>。</p>
<h4 id="反向推导">反向推导</h4>
<p>我们的目标是，当一连串的突发请求（<code>N</code>个）到来时，系统应该在 <code>N</code> 约等于我们设定的 <code>burst</code> 值时开始拒绝请求。</p>
<p>拒绝的条件是：<code>$t_&#123;当前&#125; &lt; TAT_&#123;新&#125; - τ$</code></p>
<p>假设这 <code>N</code> 个请求是在同一时间 <code>t_当前</code> 到达的，那么对于第 <code>N</code> 个请求，<code>TAT</code> 已经被连续更新了 <code>N-1</code> 次。我们把更新公式代入拒绝条件：</p>
<p><code>$t_&#123;当前&#125; &lt; (锚点 + (N-1) * T) - τ$</code></p>
<p>这里的“锚点”就是 <code>max(t_当前, TAT_旧)</code> 所选择的时间。</p>
<p>现在，我们考虑两种情况：</p>
<p><strong>情况一：系统长时间空闲后，迎来突发流量</strong></p>
<ul>
<li>此时，上一个请求的理论时间 <code>$TAT_&#123;旧&#125;$</code> 是一个很久远过去的时间点。</li>
<li><code>$t_&#123;当前&#125;$</code> 远远大于 <code>$TAT_&#123;旧&#125;$</code>。</li>
<li>如果我们的算法<strong>不使用 <code>max()</code></strong>，而是错误地用了 <code>$TAT_&#123;旧&#125;$</code> 作为锚点：<br>
<code>$t_&#123;当前&#125; &lt; TAT_&#123;旧&#125; + (N-1) * T - τ$</code></li>
<li>在这个不等式里，左边的 <code>$t_&#123;当前&#125;$</code> 是一个很大的值，而右边的 <code>$TAT_&#123;旧&#125;$</code> 是一个很小的值。为了让这个不等式成立（即触发拒绝），右边的 <code>$(N-1) * T$</code> 必须变得非常非常大，这意味着 <code>N</code> (通过的请求数) 会远远超出我们设计的 <code>burst</code> 值！</li>
<li><strong>这就是 <code>max()</code> 的第一个作用</strong>：当系统空闲时，它通过选择 <code>$t_&#123;当前&#125;$</code> 作为锚点，强制将计算的起点“拉回”到当前时间。这相当于丢弃了所有因空闲而“积攒”的无效“信用”，确保突发能力不会无限膨胀。</li>
</ul>
<p><strong>情况二：系统持续繁忙，请求早于理论时间到达</strong></p>
<ul>
<li>此时，请求到达的频率已经超出了设定的速率，导致 <code>$TAT_&#123;旧&#125;$</code> 是一个<strong>未来的时间点</strong>（系统在“偿还”之前过载的“债务”）。</li>
<li><code>$t_&#123;当前&#125;$</code> 小于 <code>$TAT_&#123;旧&#125;$</code>。</li>
<li><strong><code>max()</code> 的第二个作用在此体现</strong>：它会选择两者中更晚的 <code>$TAT_&#123;旧&#125;$</code> 作为锚点。<br>
<code>$t_&#123;当前&#125; &lt; TAT_&#123;旧&#125; + (N-1) * T - τ$</code></li>
<li>这非常关键，因为它保证了计算的起点是我们预期的、那个“理论上系统才空闲”的未来时间点。这使得准入检查 <code>$t_&#123;当前&#125; ≥ TAT - τ$</code> 变得更难满足，从而有效地限制了持续过载的请求，强迫系统遵守设定的速率。</li>
</ul>
<h3 id="结论">结论</h3>
<p><code>max(t_当前, TAT_旧)</code> 的设计哲学可以总结为：</p>
<blockquote>
<ul>
<li><strong>应对晚到的突发（取 <code>t_当前</code>）</strong>：当系统空闲时，限流的基准应该是“现在”，防止过去的空闲时间转化为无限制的爆发能力。</li>
<li><strong>应对早到的冲击（取 <code>TAT_旧</code>）</strong>：当系统繁忙时，限流的基准应该是“未来”，确保之前过载的请求“债务”被计入，不会因为新请求的到达而被遗忘。</li>
</ul>
</blockquote>
<p>它通过动态选择正确的“时间锚点”，保证了无论流量模式如何变化，<code>burst</code> 的上限都得到了精确的控制。</p>
<p>从另一个角度看，<strong>如果此时的最新请求在当下晚于<code>TAT_旧</code>，它天然就是应该被放行的-肯定不会被拒绝</strong>。burst 的时间局部性如果围绕当前时间展开，才能精确实现<code>N * T - burst * t</code>等于0的限流。</p>
<h5 id="明星的例子">明星的例子</h5>
<pre><code class="hljs mermaid">graph TD
    subgraph &quot;前提：算法的基础设定 (Rules 1, 2, 3)&quot;
        A[&quot;&lt;b&gt;Rule 1: 初始状态&lt;/b&gt;&lt;br&gt;TAT (理论到达时间) = 启动时的当前时间&quot;]
        B[&quot;&lt;b&gt;Rule 2: 时间间隔 T&lt;/b&gt;&lt;br&gt;T = 时间周期 / 速率限制&lt;br&gt;&lt;i&gt;(明星走红毯的固定节拍)&lt;/i&gt;&quot;]
        C[&quot;&lt;b&gt;Rule 3: 容忍度 τ&lt;/b&gt;&lt;br&gt;τ = 突发上限 * T&lt;br&gt;&lt;i&gt;(明星最多可以提前多久到达而不被拒绝)&lt;/i&gt;&quot;]
    end

    subgraph &quot;流程：处理一个到达的请求&quot;
        Start(开始: 一个请求在 t_current 到达) --&gt; Check&#123;&quot;&lt;b&gt;Rule 5: 一致性检验&lt;/b&gt;&lt;br&gt;&lt;br&gt;t_current ≥ TAT - τ ?&lt;br&gt;&lt;br&gt;&lt;i&gt;(现在时刻 ≥ 计划时刻 - 容忍度 ?)&lt;/i&gt;&lt;br&gt;&lt;i&gt;(明星是否在&#x27;最早允许时间点&#x27;之后到达?)&lt;/i&gt;&quot;&#125;
        
        Check -- &quot;是 (Yes)&quot; --&gt; Allow[&quot;&lt;b&gt;决策: 放行&lt;/b&gt;&lt;br&gt;&lt;i&gt;(让这位明星走上红毯)&lt;/i&gt;&quot;]
        Allow --&gt; Update[&quot;&lt;b&gt;Rule 4: 更新状态&lt;/b&gt;&lt;br&gt;&lt;br&gt;TAT_新 = max(t_current, TAT_旧) + T&lt;br&gt;&lt;br&gt;&lt;i&gt;(根据当前情况，预约下一位明星的理论到达时间)&lt;/i&gt;&quot;]
        Update --&gt; End(结束)

        Check -- &quot;否 (No)&quot; --&gt; Reject[&quot;&lt;b&gt;决策: 拒绝&lt;/b&gt;&lt;br&gt;&lt;i&gt;(告诉这位明星他来得太早了，需要等待)&lt;/i&gt;&quot;]
        Reject --&gt; End
    end

    style Start fill:#9f9,stroke:#333,stroke-width:2px
    style End fill:#f99,stroke:#333,stroke-width:2px
    style Allow fill:#d4ffaa
    style Reject fill:#ffd4aa</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs plantuml">@startuml<br>title GCRA 算法流程: 数学设定与明星比喻<br><br>skinparam activity &#123;<br>    StartColor Green<br>    EndColor Red<br>    BackgroundColor LightBlue<br>    BorderColor RoyalBlue<br>&#125;<br><br>skinparam note &#123;<br>    BackgroundColor LightYellow<br>&#125;<br><br>start<br><br>partition &quot;前提：算法的基础设定 (Rules 1, 2, 3)&quot; &#123;<br>    :&lt;b&gt;Rule 1: 初始状态&lt;/b&gt;<br>    TAT = 启动时的当前时间;<br>    note right<br>        为整个算法设定时间基准<br>    end note<br><br>    :&lt;b&gt;Rule 2: 时间间隔 (T)&lt;/b&gt;<br>    T = 时间周期 / 速率限制;<br>    note right<br>        明星走红毯的固定节拍<br>    end note<br><br>    :&lt;b&gt;Rule 3: 容忍度 (τ)&lt;/b&gt;<br>    τ = 突发上限 * T;<br>    note right<br>        明星最多可以提前多久到达<br>        而不被拒绝 (缓冲时间)<br>    end note<br>&#125;<br><br>partition &quot;流程：处理一个到达的请求&quot; &#123;<br>    :一个请求在 t_current 到达;<br><br>    if (&lt;b&gt;Rule 5: 一致性检验&lt;/b&gt;<br>    t_current ≥ TAT - τ ?) then (yes)<br>        note right<br>            &lt;b&gt;决策依据:&lt;/b&gt;<br>            现在时刻晚于或等于<br>            &quot;最早允许时间点&quot;。<br>            明星守时或在容忍范围内。<br>        end note<br>        :&lt;b&gt;决策: 放行&lt;/b&gt;;<br>        :&lt;b&gt;Rule 4: 更新状态&lt;/b&gt;<br>        TAT_新 = max(t_current, TAT_旧) + T;<br>        note left<br>            &lt;b&gt;状态更新:&lt;/b&gt;<br>            预约下一位明星的<br>            理论到达时间。<br>            如果队伍空闲了，就从现在开始约。<br>        end note<br>    else (no)<br>        note right<br>            &lt;b&gt;决策依据:&lt;/b&gt;<br>            现在时刻早于<br>            &quot;最早允许时间点&quot;。<br>            明星来得太早了！<br>        end note<br>        :&lt;b&gt;决策: 拒绝&lt;/b&gt;<br>        (TAT 保持不变);<br>    endif<br>&#125;<br><br>stop<br>@enduml<br></code></pre></td></tr></table></figure>
<p>想象一下一场盛大电影首-映礼的红毯环节。主办方希望明星们以平稳、持续的节奏入场，方便媒体拍照。</p>
<ul>
<li>目标: 严格控制每 10 秒钟只入场 1 位明星。</li>
<li>问题: 明星们不会掐着秒表来。一辆豪华轿车可能一次就送来了 3 位明星。</li>
<li>规则 (GCRA 登场):
<ul>
<li>速率 (T): 每位明星的预期时间间隔是 10 秒。这在算法里称为 emission interval。</li>
<li>突发/容忍度 (τ): 我们可以容忍一定的突发情况。假设我们允许明星比其“理论上”的入场时间最多提前 20 秒到达。这意味着我们能额外处理 20秒 / 10秒 = 2 位提前到来的明星（即一次性处理 1+2=3 位的突发）。</li>
<li>时刻表 (TAT): 我们只用一个变量，记录下一位明星理论上应该到达的时间点。我们称之为理论到达时间 (TAT)。</li>
</ul>
</li>
</ul>
<p>现在我们来模拟一下。首映礼从 t=0 时刻开始，初始的 TAT 就是 0。</p>
<ul>
<li>
<p>第一位明星 (准时到达):</p>
<ul>
<li>在 t=0 时刻到达。</li>
<li>t=0 是否在可接受的范围内？是的，正好等于时刻表上的 TAT=0。放行！(<strong>我们的时间窗口是从 TAT为0和当前时间为0的时刻开始的</strong>)</li>
<li>更新时刻表：下一位明星的理论到达时间是 TAT = 0 + 10秒 = 10秒。</li>
</ul>
</li>
<li>
<p>一辆轿车送来 3 位明星 (突发流量):</p>
<ul>
<li>他们都在 t=2 秒这个时刻到达。</li>
<li>明星 A:
<ul>
<li>在 t=2 到达。此刻的时刻表要求是 TAT=10秒。</li>
<li>他是否“提早得过分”了？他提早了 10秒 - 2秒 = 8秒。这在我们的 20秒 容忍度之内。放行！</li>
<li>更新时刻表：我们用掉了一个名额，所以下一个名额的理论时间是 TAT = 10秒 + 10秒 = 20秒。（注意：我们是在旧的TAT基础上增加间隔，而不是在当前时间上加）。</li>
</ul>
</li>
<li>明星 B:
<ul>
<li>也在 t=2 到达。此刻的时刻表要求是 TAT=20秒。<strong>这个算法要求精确、串行地为每个明星加TAT，一个都不漏。</strong>，此时 TAT 正在不断后移。</li>
<li>他提早了 20秒 - 2秒 = 18秒。这仍在 20秒 容忍度之内。放行！</li>
<li>更新时刻表：TAT = 20秒 + 10秒 = 30秒。</li>
</ul>
</li>
<li>明星 C:
<ul>
<li>也在 t=2 到达。此刻的时刻表要求是 TAT=30秒。<strong>连续早到可以看到TAT连续后移</strong>。</li>
<li>他提早了 30秒 - 2秒 = 28秒。这超出了我们 20秒 的容忍度。拒绝！ 这位明星被告知需要等一下。时刻表 (TAT) 不会因为这次拒绝而改变。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>一位迟到的明星:</p>
<ul>
<li>在 t=45 秒到达。我们的时刻表还停留在 TAT=30秒。</li>
<li>迟到总是被允许的。放行！</li>
<li>更新时刻表：因为他迟到了，我们不能让他“偿还”过去的时间-<strong>只要TAT小于当前时间，TAT就失效了</strong>。所以我们基于他当前的到达时间来重置时刻表。下一位的理论时间是 TAT = 45秒 + 10秒 = 55秒。这可以防止旧的“欠账”不公平地影响未来的请求。</li>
</ul>
</li>
</ul>
<p>这个算法不是简单地<code>t_当前&gt;=TAT_旧-τ</code>，计算当前时间是否落在容忍时间范围内；而是当 TAT拉大和当前时间距离后，当前时间距离是否超过了容忍时间。所以 TAT 本身还有很多视角可以等价看待。</p>
<p>这就是 GCRA 的精髓：通过一个 TAT 变量和简单的数学运算，就同时管理了速率和突发，且完全不需要队列。</p>
<h5 id="完整-java-实现">完整 java 实现</h5>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicLong;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * &lt;h1&gt;GCRA (通用信元速率算法) 限流器&lt;/h1&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;这是一个高性能、无队列的漏桶算法实现。</span><br><span class="hljs-comment"> * 它通过维护下一个请求的“理论到达时间”(TAT)来控制速率。</span><br><span class="hljs-comment"> * 这种方法内存效率高，执行速度快，非常适合高吞吐量的场景。&lt;/p&gt;</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * &lt;p&gt;&lt;b&gt;实现特点:&lt;/b&gt; 此实现采用“基于过去状态裁决”的逻辑。</span><br><span class="hljs-comment"> * 它直接使用存储的、上一次请求留下的 `TAT` 来判断当前请求。</span><br><span class="hljs-comment"> * 这种方式在处理边界上的突发时，可能会允许 `burst + 1` 个请求。&lt;/p&gt;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">GCRARateLimiter</span> &#123;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * T: 排放间隔 (emission interval)，单位是纳秒。</span><br><span class="hljs-comment">     * 它代表了两个完美间隔的请求之间的时间差。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> emissionInterval;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * τ: 突发容忍度 (burst tolerance)，单位是纳秒。</span><br><span class="hljs-comment">     * 它定义了一个请求可以“提前”于其理论时间到达而不被拒绝的最大量。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> burstTolerance;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * TAT (Theoretical Arrival Time): 理论到达时间，是本算法的核心状态。</span><br><span class="hljs-comment">     * 这个时间戳（纳秒）代表了如果流量绝对平滑，下一个请求应该到达的时间。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> AtomicLong tat;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 构造一个 GCRA 限流器.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> rate  每秒允许的请求数。</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> burst 允许的最大突发请求数。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">GCRARateLimiter</span><span class="hljs-params">(<span class="hljs-type">double</span> rate, <span class="hljs-type">double</span> burst)</span> &#123;<br>        <span class="hljs-built_in">this</span>.emissionInterval = (<span class="hljs-type">long</span>) (TimeUnit.SECONDS.toNanos(<span class="hljs-number">1</span>) / rate);<br>        <span class="hljs-comment">// 注意：这里的容忍度计算方式，结合后续的判断逻辑，是导致突发可能多一个的原因。</span><br>        <span class="hljs-built_in">this</span>.burstTolerance = (<span class="hljs-type">long</span>) (burst * <span class="hljs-built_in">this</span>.emissionInterval);<br>        <span class="hljs-built_in">this</span>.tat = <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicLong</span>(System.nanoTime());<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取一个许可，这是限流的核心逻辑。</span><br><span class="hljs-comment">     * 这个方法必须是同步的(synchronized)，以确保对TAT的“先检查后设置”操作是原子的。</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> &#123;<span class="hljs-doctag">@code</span> true&#125; 如果获取许可成功 (请求被允许),</span><br><span class="hljs-comment">     *         &#123;<span class="hljs-doctag">@code</span> false&#125; 如果失败 (请求应被限流)。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">now</span> <span class="hljs-operator">=</span> System.nanoTime();<br>        <span class="hljs-comment">// 1. 【获取旧状态】获取上一次请求成功后记录的 TAT。</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">currentTat</span> <span class="hljs-operator">=</span> tat.get();<br><br>        <span class="hljs-comment">// 2. 【基于旧状态判断】</span><br>        <span class="hljs-comment">// 核心判断逻辑：用当前时间 `now` 和 `旧TAT - 容忍度` 进行比较。</span><br>        <span class="hljs-comment">// `currentTat` 是历史数据，代表上一个请求被允许后，下一个请求的理论时间。</span><br>        <span class="hljs-comment">// 这个判断检查的是：当前请求是否比“基于历史的规则”所允许的最早时间点还要早。</span><br>        <span class="hljs-keyword">if</span> (now &lt; currentTat - burstTolerance) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 拒绝请求，不更新任何状态。</span><br>        &#125;<br><br>        <span class="hljs-comment">// 3. 【计算新状态并更新】只有在判断通过后，才执行更新。</span><br>        <span class="hljs-comment">// 计算如果本次请求被允许，那么再下一个请求的理论到达时间应该是多少。</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">newTat</span> <span class="hljs-operator">=</span> Math.max(currentTat, now) + emissionInterval;<br><br>        <span class="hljs-comment">// 更新 TAT，为下一个请求做准备。</span><br>        tat.set(newTat);<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>; <span class="hljs-comment">// 批准请求</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h5 id="另一种-go-的实现">另一种 go 的实现</h5>
<p>这是一个基于策略模式+控制反转+装饰器模式的实例。</p>
<p>这里面的所有限流器都是用 key 共享状态的。</p>
<h6 id="基础的能力封装-limiter-go">基础的能力封装 limiter.go</h6>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;github.com/go-redis/redis_rate/v10&quot;</span><br>)<br><br><span class="hljs-comment">// APILimiter 频控器</span><br><span class="hljs-keyword">type</span> APILimiter <span class="hljs-keyword">struct</span> &#123;<br>    Limit   redis_rate.Limit<br>    Limiter *redis_rate.Limiter<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *APILimiter)</span></span> Allow(ctx *Context, key <span class="hljs-type">string</span>) (*redis_rate.Result, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 检查频率限制，若出错，默认允许通过</span><br>    res, err := l.Limiter.Allow(ctx, key, l.Limit)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;limiter.Allow failed, err:%+v&quot;</span>, err)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> res, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// updateAllow 用于调整频控数据</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *APILimiter)</span></span> updateAllow(ctx *Context, key <span class="hljs-type">string</span>) (*redis_rate.Result, <span class="hljs-type">error</span>) &#123;<br>    res, err := l.Limiter.AllowN(ctx, key, l.Limit, <span class="hljs-number">-1</span>)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;limiter.updateAllow failed, err:%+v&quot;</span>, err)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> res, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure>
<h6 id="qps-limiter-go">qps_limiter.go</h6>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// QPSLimiter 秒级频控</span><br><span class="hljs-keyword">type</span> QPSLimiter <span class="hljs-keyword">struct</span> &#123;<br>    APILimiter<br>&#125;<br><br><span class="hljs-comment">// NewQPSLimiter 创建一个秒级频控限制器</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewQPSLimiter</span><span class="hljs-params">(limit <span class="hljs-type">int</span>, limiter *redis_rate.Limiter)</span></span> *QPSLimiter &#123;<br>    <span class="hljs-keyword">return</span> &amp;QPSLimiter&#123;<br>        APILimiter: APILimiter&#123;<br>            Limit:   redis_rate.PerSecond(limit),<br>            Limiter: limiter,<br>        &#125;,<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 是否能放行</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *QPSLimiter)</span></span> allow(ctx *Context, myContext *mycontext.Context, key <span class="hljs-type">string</span>, qps <span class="hljs-type">uint64</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 检查频率限制，若出错，默认允许通过，注意默认允许通过</span><br>    res, _ := l.APILimiter.Allow(ctx, key)<br>    <span class="hljs-keyword">if</span> res == <span class="hljs-literal">nil</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;QPSLimiter Allow fail&quot;</span>)<br>        <span class="hljs-keyword">return</span> qps, <span class="hljs-literal">nil</span><br>    &#125;<br>    <span class="hljs-comment">// Allow &lt;= 0时，不允许通过</span><br>    <span class="hljs-keyword">if</span> res.Allowed &lt;= <span class="hljs-number">0</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;QPSLimiter Allow fail, res: %+v&quot;</span>, res)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, mkterror.ThrowError(ctx, errors.ThrowErrorWithMsg(ctx, errors.DeliverySecondRateLimitExceeded))<br>    &#125;<br><br>    ctx.Logger.Infof(<span class="hljs-string">&quot;QPSLimiter Allow qps res: %+v&quot;</span>, res)<br>    <span class="hljs-keyword">return</span> <span class="hljs-type">uint64</span>(res.Remaining), <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure>
<h6 id="qpm-limiter-go">qpm_limiter.go</h6>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// QPMLimiter 分钟级频控</span><br><span class="hljs-keyword">type</span> QPMLimiter <span class="hljs-keyword">struct</span> &#123;<br>    APILimiter<br>&#125;<br><br><span class="hljs-comment">// NewQPMLimiter 创建一个分钟级频控限制器</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewQPMLimiter</span><span class="hljs-params">(limit <span class="hljs-type">int</span>, limiter *redis_rate.Limiter)</span></span> *QPMLimiter &#123;<br>    <span class="hljs-keyword">return</span> &amp;QPMLimiter&#123;<br>        APILimiter: APILimiter&#123;<br>            Limit:   redis_rate.PerMinute(limit),<br>            Limiter: limiter,<br>        &#125;,<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 是否能放行</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *QPMLimiter)</span></span> allow(ctx *Context, myContext *mycontext.Context, key <span class="hljs-type">string</span>, qpm <span class="hljs-type">uint64</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 检查频率限制，若出错，默认允许通过，注意默认允许通过</span><br>    res, _ := l.APILimiter.Allow(ctx, key)<br>    <span class="hljs-keyword">if</span> res == <span class="hljs-literal">nil</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;qpm Allow fail&quot;</span>)<br>        <span class="hljs-keyword">return</span> qpm, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// Allow &lt;= 0时，不允许通过</span><br>    <span class="hljs-keyword">if</span> res.Allowed &lt;= <span class="hljs-number">0</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;qps Allow failed, res: %v&quot;</span>, res)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, mkterror.ThrowError(ctx, errors.ThrowErrorWithMsg(ctx, errors.DeliveryMinuteRateLimitExceeded))<br>    &#125;<br><br>    ctx.Logger.Infof(<span class="hljs-string">&quot;NewQPMLimiter Allow qpm res: %+v, &quot;</span>, res)<br>    <span class="hljs-keyword">return</span> <span class="hljs-type">uint64</span>(res.Remaining), <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// 更新通过次数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *QPMLimiter)</span></span> updateAllow(ctx *Context, myContext *mycontext.Context, key <span class="hljs-type">string</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    res, _ := l.APILimiter.updateAllow(ctx, key)<br>    <span class="hljs-keyword">if</span> res == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 失败了也不报错</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, <span class="hljs-literal">nil</span><br>    &#125;<br>    ctx.Logger.Infof(<span class="hljs-string">&quot;NewQPMLimiter updateAllow qpm Remaining: %+v, &quot;</span>, res.Remaining)<br>    <span class="hljs-keyword">return</span> <span class="hljs-type">uint64</span>(res.Remaining), <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure>
<h6 id="qpd-limiter-go">qpd_limiter.go</h6>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs go"><br><span class="hljs-comment">// QPDLimiter 天级频控</span><br><span class="hljs-keyword">type</span> QPDLimiter <span class="hljs-keyword">struct</span> &#123;<br>    APILimiter<br>&#125;<br><br><span class="hljs-comment">// NewQPDLimiter 创建一个天级频控限制器</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewQPDLimiter</span><span class="hljs-params">(limit <span class="hljs-type">int</span>, limiter *redis_rate.Limiter)</span></span> *QPDLimiter &#123;<br>    <span class="hljs-keyword">return</span> &amp;QPDLimiter&#123;<br>        APILimiter: APILimiter&#123;<br>            Limit: redis_rate.Limit&#123;<br>                Rate:   limit,<br>                Burst:  limit,<br>                Period: <span class="hljs-number">24</span> * time.Hour,<br>            &#125;,<br>            Limiter: limiter,<br>        &#125;,<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 是否能放行</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *QPDLimiter)</span></span> allow(ctx *Context, myContext *mycontext.Context, key <span class="hljs-type">string</span>, qpd <span class="hljs-type">uint64</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 检查频率限制，若出错，默认允许通过，注意默认允许通过</span><br>    res, _ := l.APILimiter.Allow(ctx, key)<br>    <span class="hljs-keyword">if</span> res == <span class="hljs-literal">nil</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;QPDLimiter Allow fail&quot;</span>)<br>        <span class="hljs-keyword">return</span> qpd, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// Allow &lt;= 0时，不允许通过</span><br>    <span class="hljs-keyword">if</span> res.Allowed &lt;= <span class="hljs-number">0</span> &#123;<br>        ctx.Logger.Errorf(<span class="hljs-string">&quot;QPDLimiter Allow fail, res: %+v&quot;</span>, res)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, mkterror.ThrowError(ctx, errors.ThrowErrorWithMsg(ctx, errors.DeliveryDayRateLimitExceeded))<br>    &#125;<br><br>    ctx.Logger.Infof(<span class="hljs-string">&quot;QPDLimiter Allow qpd res: %+v&quot;</span>, res)<br>    <span class="hljs-keyword">return</span> <span class="hljs-type">uint64</span>(res.Remaining), <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// 更新通过次数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *QPDLimiter)</span></span> updateAllow(ctx *Context, myContext *mycontext.Context, key <span class="hljs-type">string</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    res, _ := l.APILimiter.updateAllow(ctx, key)<br>    <span class="hljs-keyword">if</span> res == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 失败了也不报错</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    ctx.Logger.Infof(<span class="hljs-string">&quot;QPDLimiter updateAllow qpd res: %+v&quot;</span>, res)<br>    <span class="hljs-keyword">return</span> <span class="hljs-type">uint64</span>(res.Remaining), <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure>
<h6 id="主限流器">主限流器</h6>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// checkQPSLimit 检查QPS限制</span><br><span class="hljs-comment">// 参数:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  ctx: 请求上下文</span><br><span class="hljs-comment">//  contextInfo: 上下文信息</span><br><span class="hljs-comment">//  key: Redis键</span><br><span class="hljs-comment">//  qps: QPS限制值</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 返回值:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  uint64: 剩余量</span><br><span class="hljs-comment">//  error: 错误信息</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Plugin)</span></span> checkQPSLimit(ctx *Context, contextInfo *mycontext.Context, key <span class="hljs-type">string</span>, qps <span class="hljs-type">uint64</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    qpsLimiter := NewQPSLimiter(<span class="hljs-type">int</span>(qps), p.limiter)<br>    <span class="hljs-keyword">return</span> qpsLimiter.allow(ctx, contextInfo, key, qps)<br>&#125;<br><br><span class="hljs-comment">// checkQPMLimit 检查QPM限制</span><br><span class="hljs-comment">// 参数:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  ctx: 请求上下文</span><br><span class="hljs-comment">//  contextInfo: 上下文信息</span><br><span class="hljs-comment">//  key: Redis键</span><br><span class="hljs-comment">//  qpm: QPM限制值</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 返回值:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  uint64: 剩余量</span><br><span class="hljs-comment">//  error: 错误信息</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Plugin)</span></span> checkQPMLimit(ctx *Context, contextInfo *mycontext.Context, key <span class="hljs-type">string</span>, qpm <span class="hljs-type">uint64</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    qpmLimiter := NewQPMLimiter(<span class="hljs-type">int</span>(qpm), p.limiter)<br>    <span class="hljs-keyword">return</span> qpmLimiter.allow(ctx, contextInfo, key, qpm)<br>&#125;<br><br><span class="hljs-comment">// checkQPDLimit 检查QPD限制</span><br><span class="hljs-comment">// 参数:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  ctx: 请求上下文</span><br><span class="hljs-comment">//  contextInfo: 上下文信息</span><br><span class="hljs-comment">//  key: Redis键</span><br><span class="hljs-comment">//  qpd: QPD限制值</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 返回值:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  uint64: 剩余量</span><br><span class="hljs-comment">//  error: 错误信息</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Plugin)</span></span> checkQPDLimit(ctx *Context, contextInfo *mycontext.Context, key <span class="hljs-type">string</span>, qpd <span class="hljs-type">uint64</span>) (<span class="hljs-type">uint64</span>, <span class="hljs-type">error</span>) &#123;<br>    qpdLimiter := NewQPDLimiter(<span class="hljs-type">int</span>(qpd), p.limiter)<br>    <span class="hljs-keyword">return</span> qpdLimiter.allow(ctx, contextInfo, key, qpd)<br>&#125;<br><br><span class="hljs-comment">// createLimitFuncs 为规则创建限流检查函数</span><br><span class="hljs-comment">// 参数:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  ctx: 请求上下文</span><br><span class="hljs-comment">//  contextInfo: 上下文信息</span><br><span class="hljs-comment">//  rule: 频控规则</span><br><span class="hljs-comment">//  key: Redis键</span><br><span class="hljs-comment">//  limits: 限流结果</span><br><span class="hljs-comment">//  mu: 互斥锁</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 返回值:</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">//  []func() error: 限流检查函数列表</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Plugin)</span></span> createLimitFuncs(ctx *Context, contextInfo *mycontext.Context,<br>    rule FlowLimitRule, key RateLimitKey, limits *RateLimitResult, mu *sync.Mutex) []<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br><br>    ctx.Logger.Debugf(<span class="hljs-string">&quot;Creating rate limiting functions, Identity: %s, QPS: %d, QPM: %d, QPD: %d&quot;</span>,<br>        rule.Identity(), rule.QPS, rule.QPM, rule.QPD)<br><br>    <span class="hljs-keyword">var</span> funcs []<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span><br><br>    <span class="hljs-keyword">if</span> rule.QPS &gt; <span class="hljs-number">0</span> &#123;<br>        funcs = <span class="hljs-built_in">append</span>(funcs, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br>            ctx.Logger.Debugf(<span class="hljs-string">&quot;Executing QPS rate limit check, Redis Key: %s, Limit: %d&quot;</span>, key.keyQps(), rule.QPS)<br>            remaining, err := p.checkQPSLimit(ctx, contextInfo, key.keyQps(), rule.QPS)<br>            mu.Lock()<br>            <span class="hljs-keyword">defer</span> mu.Unlock()<br>            <span class="hljs-keyword">if</span> remaining &lt; limits.qpsRemaining &#123;<br>                ctx.Logger.Debugf(<span class="hljs-string">&quot;Updating QPS remaining: %d -&gt; %d&quot;</span>, limits.qpsRemaining, remaining)<br>                limits.qpsRemaining = remaining<br>                limits.qpsUsed = rule.QPS - remaining<br>            &#125;<br>            <span class="hljs-keyword">return</span> err<br>        &#125;)<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> rule.QPM &gt; <span class="hljs-number">0</span> &#123;<br>        funcs = <span class="hljs-built_in">append</span>(funcs, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br>            ctx.Logger.Debugf(<span class="hljs-string">&quot;Executing QPM rate limit check, Redis Key: %s, Limit: %d&quot;</span>, key.keyQpm(), rule.QPM)<br>            remaining, err := p.checkQPMLimit(ctx, contextInfo, key.keyQpm(), rule.QPM)<br>            mu.Lock()<br>            <span class="hljs-keyword">defer</span> mu.Unlock()<br>            <span class="hljs-keyword">if</span> remaining &lt; limits.qpmRemaining &#123;<br>                ctx.Logger.Debugf(<span class="hljs-string">&quot;Updating QPM remaining: %d -&gt; %d&quot;</span>, limits.qpmRemaining, remaining)<br>                limits.qpmRemaining = remaining<br>                limits.qpmUsed = rule.QPM - remaining<br>            &#125;<br>            <span class="hljs-keyword">return</span> err<br>        &#125;)<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> rule.QPD &gt; <span class="hljs-number">0</span> &#123;<br>        funcs = <span class="hljs-built_in">append</span>(funcs, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br>            ctx.Logger.Debugf(<span class="hljs-string">&quot;Executing QPD rate limit check, Redis Key: %s, Limit: %d&quot;</span>, key.keyQpd(), rule.QPD)<br>            remaining, err := p.checkQPDLimit(ctx, contextInfo, key.keyQpd(), rule.QPD)<br>            mu.Lock()<br>            <span class="hljs-keyword">defer</span> mu.Unlock()<br>            <span class="hljs-keyword">if</span> remaining &lt; limits.qpdRemaining &#123;<br>                ctx.Logger.Debugf(<span class="hljs-string">&quot;Updating QPD remaining: %d -&gt; %d&quot;</span>, limits.qpdRemaining, remaining)<br>                limits.qpdRemaining = remaining<br>                limits.qpdUsed = rule.QPD - remaining<br>            &#125;<br>            <span class="hljs-keyword">return</span> err<br>        &#125;)<br>    &#125;<br><br>    ctx.Logger.Debugf(<span class="hljs-string">&quot;Created %d rate limiting functions for rule&quot;</span>, <span class="hljs-built_in">len</span>(funcs))<br>    <span class="hljs-keyword">return</span> funcs<br>&#125;<br></code></pre></td></tr></table></figure>
<h6 id="底层实现">底层实现</h6>
<p>####### rate.go</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> redis_rate<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;context&quot;</span><br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;strconv&quot;</span><br>    <span class="hljs-string">&quot;time&quot;</span><br><br>    <span class="hljs-string">&quot;github.com/redis/go-redis/v9&quot;</span><br>)<br><br><span class="hljs-keyword">const</span> redisPrefix = <span class="hljs-string">&quot;rate:&quot;</span><br><br><span class="hljs-keyword">type</span> rediser <span class="hljs-keyword">interface</span> &#123;<br>    Eval(ctx context.Context, script <span class="hljs-type">string</span>, keys []<span class="hljs-type">string</span>, args ...<span class="hljs-keyword">interface</span>&#123;&#125;) *redis.Cmd<br>    EvalSha(ctx context.Context, sha1 <span class="hljs-type">string</span>, keys []<span class="hljs-type">string</span>, args ...<span class="hljs-keyword">interface</span>&#123;&#125;) *redis.Cmd<br>    ScriptExists(ctx context.Context, hashes ...<span class="hljs-type">string</span>) *redis.BoolSliceCmd<br>    ScriptLoad(ctx context.Context, script <span class="hljs-type">string</span>) *redis.StringCmd<br>    Del(ctx context.Context, keys ...<span class="hljs-type">string</span>) *redis.IntCmd<br><br>    EvalRO(ctx context.Context, script <span class="hljs-type">string</span>, keys []<span class="hljs-type">string</span>, args ...<span class="hljs-keyword">interface</span>&#123;&#125;) *redis.Cmd<br>    EvalShaRO(ctx context.Context, sha1 <span class="hljs-type">string</span>, keys []<span class="hljs-type">string</span>, args ...<span class="hljs-keyword">interface</span>&#123;&#125;) *redis.Cmd<br>&#125;<br><br><span class="hljs-keyword">type</span> Limit <span class="hljs-keyword">struct</span> &#123;<br>    Rate   <span class="hljs-type">int</span><br>    Burst  <span class="hljs-type">int</span><br>    Period time.Duration<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l Limit)</span></span> String() <span class="hljs-type">string</span> &#123;<br>    <span class="hljs-keyword">return</span> fmt.Sprintf(<span class="hljs-string">&quot;%d req/%s (burst %d)&quot;</span>, l.Rate, fmtDur(l.Period), l.Burst)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l Limit)</span></span> IsZero() <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-keyword">return</span> l == Limit&#123;&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">fmtDur</span><span class="hljs-params">(d time.Duration)</span></span> <span class="hljs-type">string</span> &#123;<br>    <span class="hljs-keyword">switch</span> d &#123;<br>    <span class="hljs-keyword">case</span> time.Second:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;s&quot;</span><br>    <span class="hljs-keyword">case</span> time.Minute:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;m&quot;</span><br>    <span class="hljs-keyword">case</span> time.Hour:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;h&quot;</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> d.String()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">PerSecond</span><span class="hljs-params">(rate <span class="hljs-type">int</span>)</span></span> Limit &#123;<br>    <span class="hljs-keyword">return</span> Limit&#123;<br>        Rate:   rate,<br>        Period: time.Second,<br>        Burst:  rate,<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">PerMinute</span><span class="hljs-params">(rate <span class="hljs-type">int</span>)</span></span> Limit &#123;<br>    <span class="hljs-keyword">return</span> Limit&#123;<br>        Rate:   rate,<br>        Period: time.Minute,<br>        Burst:  rate,<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">PerHour</span><span class="hljs-params">(rate <span class="hljs-type">int</span>)</span></span> Limit &#123;<br>    <span class="hljs-keyword">return</span> Limit&#123;<br>        Rate:   rate,<br>        Period: time.Hour,<br>        Burst:  rate,<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// ------------------------------------------------------------------------------</span><br><br><span class="hljs-comment">// Limiter controls how frequently events are allowed to happen.</span><br><span class="hljs-keyword">type</span> Limiter <span class="hljs-keyword">struct</span> &#123;<br>    rdb rediser<br>&#125;<br><br><span class="hljs-comment">// NewLimiter returns a new Limiter.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewLimiter</span><span class="hljs-params">(rdb rediser)</span></span> *Limiter &#123;<br>    <span class="hljs-keyword">return</span> &amp;Limiter&#123;<br>        rdb: rdb,<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// Allow is a shortcut for AllowN(ctx, key, limit, 1).</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l Limiter)</span></span> Allow(ctx context.Context, key <span class="hljs-type">string</span>, limit Limit) (*Result, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-keyword">return</span> l.AllowN(ctx, key, limit, <span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// AllowN reports whether n events may happen at time now.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l Limiter)</span></span> AllowN(<br>    ctx context.Context,<br>    key <span class="hljs-type">string</span>,<br>    limit Limit,<br>    n <span class="hljs-type">int</span>,<br>) (*Result, <span class="hljs-type">error</span>) &#123;<br>    values := []<span class="hljs-keyword">interface</span>&#123;&#125;&#123;limit.Burst, limit.Rate, limit.Period.Seconds(), n&#125;<br>    v, err := allowN.Run(ctx, l.rdb, []<span class="hljs-type">string</span>&#123;redisPrefix + key&#125;, values...).Result()<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    values = v.([]<span class="hljs-keyword">interface</span>&#123;&#125;)<br><br>    retryAfter, err := strconv.ParseFloat(values[<span class="hljs-number">2</span>].(<span class="hljs-type">string</span>), <span class="hljs-number">64</span>)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    resetAfter, err := strconv.ParseFloat(values[<span class="hljs-number">3</span>].(<span class="hljs-type">string</span>), <span class="hljs-number">64</span>)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    res := &amp;Result&#123;<br>        Limit:      limit,<br>        Allowed:    <span class="hljs-type">int</span>(values[<span class="hljs-number">0</span>].(<span class="hljs-type">int64</span>)),<br>        Remaining:  <span class="hljs-type">int</span>(values[<span class="hljs-number">1</span>].(<span class="hljs-type">int64</span>)),<br>        RetryAfter: dur(retryAfter),<br>        ResetAfter: dur(resetAfter),<br>    &#125;<br>    <span class="hljs-keyword">return</span> res, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// AllowAtMost reports whether at most n events may happen at time now.</span><br><span class="hljs-comment">// It returns number of allowed events that is less than or equal to n.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l Limiter)</span></span> AllowAtMost(<br>    ctx context.Context,<br>    key <span class="hljs-type">string</span>,<br>    limit Limit,<br>    n <span class="hljs-type">int</span>,<br>) (*Result, <span class="hljs-type">error</span>) &#123;<br>    values := []<span class="hljs-keyword">interface</span>&#123;&#125;&#123;limit.Burst, limit.Rate, limit.Period.Seconds(), n&#125;<br>    v, err := allowAtMost.Run(ctx, l.rdb, []<span class="hljs-type">string</span>&#123;redisPrefix + key&#125;, values...).Result()<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    values = v.([]<span class="hljs-keyword">interface</span>&#123;&#125;)<br><br>    retryAfter, err := strconv.ParseFloat(values[<span class="hljs-number">2</span>].(<span class="hljs-type">string</span>), <span class="hljs-number">64</span>)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    resetAfter, err := strconv.ParseFloat(values[<span class="hljs-number">3</span>].(<span class="hljs-type">string</span>), <span class="hljs-number">64</span>)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    res := &amp;Result&#123;<br>        Limit:      limit,<br>        Allowed:    <span class="hljs-type">int</span>(values[<span class="hljs-number">0</span>].(<span class="hljs-type">int64</span>)),<br>        Remaining:  <span class="hljs-type">int</span>(values[<span class="hljs-number">1</span>].(<span class="hljs-type">int64</span>)),<br>        RetryAfter: dur(retryAfter),<br>        ResetAfter: dur(resetAfter),<br>    &#125;<br>    <span class="hljs-keyword">return</span> res, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// Reset gets a key and reset all limitations and previous usages</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *Limiter)</span></span> Reset(ctx context.Context, key <span class="hljs-type">string</span>) <span class="hljs-type">error</span> &#123;<br>    <span class="hljs-keyword">return</span> l.rdb.Del(ctx, redisPrefix+key).Err()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">dur</span><span class="hljs-params">(f <span class="hljs-type">float64</span>)</span></span> time.Duration &#123;<br>    <span class="hljs-keyword">if</span> f == <span class="hljs-number">-1</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> time.Duration(f * <span class="hljs-type">float64</span>(time.Second))<br>&#125;<br><br><span class="hljs-keyword">type</span> Result <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-comment">// Limit is the limit that was used to obtain this result.</span><br>    Limit Limit<br><br>    <span class="hljs-comment">// Allowed is the number of events that may happen at time now.</span><br>    Allowed <span class="hljs-type">int</span><br><br>    <span class="hljs-comment">// Remaining is the maximum number of requests that could be</span><br>    <span class="hljs-comment">// permitted instantaneously for this key given the current</span><br>    <span class="hljs-comment">// state. For example, if a rate limiter allows 10 requests per</span><br>    <span class="hljs-comment">// second and has already received 6 requests for this key this</span><br>    <span class="hljs-comment">// second, Remaining would be 4.</span><br>    Remaining <span class="hljs-type">int</span><br><br>    <span class="hljs-comment">// RetryAfter is the time until the next request will be permitted.</span><br>    <span class="hljs-comment">// It should be -1 unless the rate limit has been exceeded.</span><br>    RetryAfter time.Duration<br><br>    <span class="hljs-comment">// ResetAfter is the time until the RateLimiter returns to its</span><br>    <span class="hljs-comment">// initial state for a given key. For example, if a rate limiter</span><br>    <span class="hljs-comment">// manages requests per second and received one request 200ms ago,</span><br>    <span class="hljs-comment">// Reset would return 800ms. You can also think of this as the time</span><br>    <span class="hljs-comment">// until Limit and Remaining will be equal.</span><br>    ResetAfter time.Duration<br>&#125;<br><br></code></pre></td></tr></table></figure>
<p>####### lua.go</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs go">--[[<br>  GCRA 算法的 Redis Lua 实现 (固定成本)<br><br>  实现特点: 此实现采用“基于未来状态裁决”的逻辑，更为精确。<br>  它在脚本内预先计算出“如果本次请求被批准，未来的TAT将会是多少”，<br>  然后用这个预计算出的新TAT来判断当前请求是否有效。<br>  这种方法可以精确地执行 burst 的限制，避免“差一错误”。<br>  整个脚本由 Redis 保证原子性。<br>]]<br><br>-- 确保脚本的副作用（SET命令）可以被正确复制<br>redis.replicate_commands()<br><br>-- 脚本入参<br>local rate_limit_key = KEYS[<span class="hljs-number">1</span>]      -- 存储 TAT 的 Redis Key<br>local burst = tonumber(ARGV[<span class="hljs-number">1</span>])     -- 允许的突发量<br>local rate = tonumber(ARGV[<span class="hljs-number">2</span>])      -- 单位时间内的速率<br>local period = tonumber(ARGV[<span class="hljs-number">3</span>])    -- 时间周期（秒）<br>local cost = tonumber(ARGV[<span class="hljs-number">4</span>])      -- 本次请求的成本（消耗多少个令牌）<br><br>-- 算法核心参数计算<br>local emission_interval = period / rate         -- T: 排放间隔<br>local increment = emission_interval * cost      -- 本次请求需要推进的 TAT 增量<br>local burst_offset = emission_interval * burst  -- τ: 突发容忍度<br><br>-- 获取当前时间（使用相对纪元以避免浮点数精度问题）<br>local jan_1_2017 = <span class="hljs-number">1483228800</span><br>local now_arr = redis.call(<span class="hljs-string">&quot;TIME&quot;</span>)<br>local now = (now_arr[<span class="hljs-number">1</span>] - jan_1_2017) + (now_arr[<span class="hljs-number">2</span>] / <span class="hljs-number">1000000</span>)<br><br>-- <span class="hljs-number">1.</span> 【获取旧状态】获取上一次请求成功后记录的 TAT<br>local tat = redis.call(<span class="hljs-string">&quot;GET&quot;</span>, rate_limit_key)<br><span class="hljs-keyword">if</span> not tat then<br>  tat = now<br><span class="hljs-keyword">else</span><br>  tat = tonumber(tat)<br>end<br><br>-- <span class="hljs-number">2.</span> 【预计算未来状态】<br>-- 这不是最终更新，只是在脚本局部变量中进行计算。<br>-- 首先，确定计算基准时间，如果系统空闲，则从当前时间开始计算。<br>local tat_base = math.max(tat, now)<br>-- 然后，计算出如果本次请求被允许，未来的新 TAT 将会是多少。<br>local new_tat = tat_base + increment<br><br>-- <span class="hljs-number">3.</span> 【基于未来状态判断】<br>-- 核心判断逻辑：用预计算出的 <span class="hljs-string">`new_tat`</span> 来反推当前请求所允许的最早到达时间。<br>-- <span class="hljs-string">`allow_at`</span> = <span class="hljs-string">`new_tat`</span> - <span class="hljs-string">`burst_offset`</span><br>-- 判断 <span class="hljs-string">`now`</span> 是否晚于或等于 <span class="hljs-string">`allow_at`</span>。<br>local allow_at = new_tat - burst_offset<br><span class="hljs-keyword">if</span> now &lt; allow_at then<br>  -- 如果当前时间早于允许时间，则拒绝请求。<br>  local diff = allow_at - now<br>  local reset_after = tat - now<br>  <span class="hljs-keyword">return</span> &#123; <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, tostring(diff), tostring(reset_after) &#125; -- 返回拒绝信息<br>end<br><br>-- <span class="hljs-number">4.</span> 【更新状态】只有在判断通过后，才执行真正的状态更新。<br>-- 将预计算出的 <span class="hljs-string">`new_tat`</span> 持久化到 Redis 中。<br>local reset_after = new_tat - now<br><span class="hljs-keyword">if</span> reset_after &gt; <span class="hljs-number">0</span> then<br>  redis.call(<span class="hljs-string">&quot;SET&quot;</span>, rate_limit_key, new_tat, <span class="hljs-string">&quot;EX&quot;</span>, math.ceil(reset_after))<br>end<br><br>-- 计算剩余可用量并返回成功信息<br>local remaining = (now - (new_tat - burst_offset)) / emission_interval<br><span class="hljs-keyword">return</span> &#123; cost, remaining, tostring(<span class="hljs-number">-1</span>), tostring(reset_after) &#125;<br></code></pre></td></tr></table></figure>
<p>核心思想：“在固定时间窗口内，允许的最大请求数 = 速率（Rate） + 突发容量（Burst）”。</p>
<pre><code class="hljs mermaid">%% 时间轴：绝对秒
timeline
    title QPMLimiter 时间窗口滚动示意（60 s 周期）

    0s  : 首次访问&lt;br&gt;key 创建 TTL=60s
    12s : 第二次访问&lt;br&gt;仍在同一窗口
    30s : 第三次访问&lt;br&gt;仍在同一窗口
    60s : key 过期&lt;br&gt;窗口结束
    65s : 第四次访问&lt;br&gt;新窗口起点 TTL=60s
    125s: key 再次过期</code></pre>
<h5 id="先增加-tat-还是后增加-tat：基于过去状态裁决-vs-基于未来状态裁决">先增加 TAT 还是后增加 TAT：基于过去状态裁决 VS 基于未来状态裁决</h5>
<table>
<thead>
<tr>
<th>维度</th>
<th>基于过去状态裁决（Java-style）</th>
<th>基于未来状态裁决（Redis-style）</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>行动-检查顺序</strong></td>
<td><strong>预行动，再检查 (Act-then-Check)</strong></td>
<td><strong>先检查，后行动 (Check-then-Act)</strong></td>
</tr>
<tr>
<td><strong>核心逻辑</strong></td>
<td>1. 获取旧 TAT。<br>2. 预计算若本次通过后的<strong>未来新 TAT</strong>。<br>3. 用该<strong>未来 TAT</strong>反推最早允许时间点，判断当前请求是否合规。<br>4. 合规才将预计算的 TAT 持久化。</td>
<td>1. 获取旧 TAT。<br>2. 用旧 TAT 判断当前请求是否合规。<br>3. 合规则计算并更新为新 TAT。</td>
</tr>
<tr>
<td><strong>判断基准</strong></td>
<td><strong>历史状态</strong>（上一次请求留下的 TAT_旧）</td>
<td><strong>未来状态</strong>（为当前请求计算出的 TAT_新）</td>
</tr>
<tr>
<td><strong>判断公式</strong></td>
<td><code>now &gt;= TAT_旧 - burst_offset</code></td>
<td><code>now &gt;= TAT_新 - burst_offset</code></td>
</tr>
<tr>
<td><strong>突发行为</strong></td>
<td><strong>不精确</strong>：边界上允许 <strong>burst + 1</strong> 个请求通过，存在“差一错误”(Off-by-one)。</td>
<td><strong>精确</strong>：严格遵守 burst 参数，仅允许 <strong>burst</strong> 个请求通过。</td>
</tr>
<tr>
<td><strong>实现复杂度</strong></td>
<td><strong>稍高</strong>：逻辑需“先假设后验证”，初学者不易理解。</td>
<td><strong>较低</strong>：流程直观，符合常规思维“先看规矩再办事”。</td>
</tr>
<tr>
<td><strong>优点</strong></td>
<td>✓ 实现简单：对非极端场景友好<br>✓ 代码直观，易于编写</td>
<td>✓ 行为精确：结果与参数定义完全一致，无意外<br>✓ 健壮性高：严格限流场景下的优选</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>✗ 控制不精确：严格限制突发时不可接受<br>✗ 潜在风险：可能瞬间超限，压垮下游</td>
<td>✗ 理解成本稍高：需仔细思考工作原理</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>对突发量有一定容忍度、追求最简化实现的场景：<br>- 网站防刷<br>- 非核心业务防护</td>
<td>需要精确控制流量的场景：<br>- API 网关商业级限流<br>- 计费系统调用频率控制<br>- 防止缓存击穿</td>
</tr>
<tr>
<td><strong>一句话总结</strong></td>
<td>“用昨天的规则，决定今天的事。”</td>
<td>“用明天的规划，审视今天的行为。”</td>
</tr>
</tbody>
</table>
<h3 id="算法的核心差异：判断基准不同">算法的核心差异：判断基准不同</h3>
<p>问题的核心在于，两个算法在做“准入判断”时，使用的“理论到达时间”(TAT) 是不同的。</p>
<h4 id="1-java-实现：基于-过去-的状态做判断">1. Java 实现：基于“过去”的状态做判断</h4>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 1. 获取旧的 TAT</span><br><span class="hljs-type">long</span> <span class="hljs-variable">currentTat</span> <span class="hljs-operator">=</span> tat.get(); <br><br><span class="hljs-comment">// 2. 用旧的 TAT 来判断当前请求</span><br><span class="hljs-comment">//    判断逻辑可以理解为：now &gt;= currentTat - burstTolerance</span><br><span class="hljs-keyword">if</span> (now &lt; currentTat - burstTolerance) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 拒绝</span><br>&#125;<br><br><span class="hljs-comment">// 3. 如果允许，再计算新的 TAT</span><br><span class="hljs-type">long</span> <span class="hljs-variable">newTat</span> <span class="hljs-operator">=</span> Math.max(currentTat, now) + emissionInterval;<br>tat.set(newTat);<br></code></pre></td></tr></table></figure>
<p>这个逻辑是：<strong>“根据你上次离开时定下的规矩 (<code>currentTat</code>)，我判断你这次来得是否太早了。”</strong> 它是用历史状态 (<code>currentTat</code>) 来对当前请求 (<code>now</code>) 进行裁决。</p>
<h4 id="2-redis-lua-实现：基于-未来-的状态做判断">2. Redis Lua 实现：基于“未来”的状态做判断</h4>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-comment">-- 1. 获取旧的 TAT</span><br><span class="hljs-keyword">local</span> tat = redis.call(<span class="hljs-string">&quot;GET&quot;</span>, rate_limit_key)<br><br><span class="hljs-comment">-- 2. 立刻计算出如果本次请求被允许，未来的 TAT 将会是多少</span><br>tat = <span class="hljs-built_in">math</span>.<span class="hljs-built_in">max</span>(tat, now)<br><span class="hljs-keyword">local</span> new_tat = tat + increment <span class="hljs-comment">-- new_tat 就是 TAT_新</span><br><br><span class="hljs-comment">-- 3. 用这个未来的 TAT_新 来判断当前请求是否合理</span><br><span class="hljs-comment">--    判断逻辑是：now &gt;= new_tat - burst_offset</span><br><span class="hljs-keyword">local</span> allow_at = new_tat - burst_offset<br><span class="hljs-keyword">if</span> now &lt; allow_at <span class="hljs-keyword">then</span><br>  <span class="hljs-keyword">return</span> &#123; <span class="hljs-number">0</span>, ... &#125; <span class="hljs-comment">-- 拒绝</span><br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">-- 4. 如果允许，才将之前计算出的 new_tat 持久化</span><br>redis.call(<span class="hljs-string">&quot;SET&quot;</span>, rate_limit_key, new_tat, ...)<br></code></pre></td></tr></table></figure>
<p>这个逻辑是：<strong>“我先算一下，如果我放你进来，下一个人的理论时间 (<code>new_tat</code>) 会是什么时候。然后我再反过来看，你现在来的这个时间点 (<code>now</code>)，相对于这个新规矩，是不是可以接受的。”</strong></p>
<h3 id="哪种实现更优？">哪种实现更优？</h3>
<p><strong>Redis 的实现更精确，并且避免了一个经典的“差一错误”(Off-by-one Error)。</strong></p>
<p>让我们用一个实际的突发场景来证明这一点。假设速率是 10个/秒，突发是 5。</p>
<ul>
<li><code>emission_interval</code> (T) = 0.1 秒</li>
<li><code>burst</code> = 5</li>
<li><code>burstTolerance</code> / <code>burst_offset</code> (τ) = 5 * 0.1 = 0.5 秒</li>
</ul>
<p>现在，在同一时刻 <code>t=0</code>，连续来了 6 个请求。初始 <code>TAT = 0</code>。</p>
<p>Java 实现的行为：</p>
<ol>
<li><strong>请求 #1</strong>: <code>now=0</code>, <code>TAT=0</code>. 判断 <code>0 &lt; 0 - 0.5</code> 为 false. <strong>允许</strong>. <code>new_tat</code> 变为 <code>max(0,0)+0.1 = 0.1</code>。</li>
<li><strong>请求 #2</strong>: <code>now=0</code>, <code>TAT=0.1</code>. 判断 <code>0 &lt; 0.1 - 0.5</code> 为 false. <strong>允许</strong>. <code>new_tat</code> 变为 <code>max(0.1,0)+0.1 = 0.2</code>。</li>
<li><strong>请求 #3</strong>: <code>now=0</code>, <code>TAT=0.2</code>. 判断 <code>0 &lt; 0.2 - 0.5</code> 为 false. <strong>允许</strong>. <code>new_tat</code> 变为 <code>0.3</code>。</li>
<li><strong>请求 #4</strong>: <code>now=0</code>, <code>TAT=0.3</code>. 判断 <code>0 &lt; 0.3 - 0.5</code> 为 false. <strong>允许</strong>. <code>new_tat</code> 变为 <code>0.4</code>。</li>
<li><strong>请求 #5</strong>: <code>now=0</code>, <code>TAT=0.4</code>. 判断 <code>0 &lt; 0.4 - 0.5</code> 为 false. <strong>允许</strong>. <code>new_tat</code> 变为 <code>0.5</code>。</li>
<li><strong>请求 #6</strong>: <code>now=0</code>, <code>TAT=0.5</code>. 判断 <code>0 &lt; 0.5 - 0.5</code> (即 <code>0 &lt; 0</code>) 为 false. <strong>允许</strong>. <code>new_tat</code> 变为 <code>0.6</code>。</li>
<li><strong>请求 #7</strong>: <code>now=0</code>, <code>TAT=0.6</code>. 判断 <code>0 &lt; 0.6 - 0.5</code> (即 <code>0 &lt; 0.1</code>) 为 true. <strong>拒绝</strong>.</li>
</ol>
<p><strong>结果：Java 实现放行了 6 个请求，比我们定义的 <code>burst=5</code> 多了 1 个。</strong></p>
<p>Redis Lua 实现的行为：</p>
<ol>
<li><strong>请求 #1</strong>: <code>now=0</code>, <code>old_tat=0</code>. 计算 <code>new_tat = max(0,0)+0.1 = 0.1</code>. 判断 <code>0 &lt; 0.1 - 0.5</code> 为 false. <strong>允许</strong>. <code>TAT</code> 更新为 <code>0.1</code>。</li>
<li><strong>请求 #2</strong>: <code>now=0</code>, <code>old_tat=0.1</code>. 计算 <code>new_tat = max(0.1,0)+0.1 = 0.2</code>. 判断 <code>0 &lt; 0.2 - 0.5</code> 为 false. <strong>允许</strong>. <code>TAT</code> 更新为 <code>0.2</code>。</li>
<li><strong>请求 #3</strong>: <code>now=0</code>, <code>old_tat=0.2</code>. 计算 <code>new_tat = 0.3</code>. 判断 <code>0 &lt; 0.3 - 0.5</code> 为 false. <strong>允许</strong>. <code>TAT</code> 更新为 <code>0.3</code>。</li>
<li><strong>请求 #4</strong>: <code>now=0</code>, <code>old_tat=0.3</code>. 计算 <code>new_tat = 0.4</code>. 判断 <code>0 &lt; 0.4 - 0.5</code> 为 false. <strong>允许</strong>. <code>TAT</code> 更新为 <code>0.4</code>。</li>
<li><strong>请求 #5</strong>: <code>now=0</code>, <code>old_tat=0.4</code>. 计算 <code>new_tat = 0.5</code>. 判断 <code>0 &lt; 0.5 - 0.5</code> 为 false. <strong>允许</strong>. <code>TAT</code> 更新为 <code>0.5</code>。</li>
<li><strong>请求 #6</strong>: <code>now=0</code>, <code>old_tat=0.5</code>. 计算 <code>new_tat = max(0.5,0)+0.1 = 0.6</code>. 判断 <code>0 &lt; 0.6 - 0.5</code> (即 <code>0 &lt; 0.1</code>) 为 true. <strong>拒绝</strong>.</li>
</ol>
<p><strong>结果：Redis 实现精确地放行了 5 个请求，与 <code>burst=5</code> 的定义完全相符。</strong></p>
<p><strong>它们都是 GCRA 算法的变种</strong>，都遵循了“检查-执行”的原子性原则。<br>
<strong>Redis Lua 的实现是一种更精确、更健壮的 GCRA</strong>，它通过“预计算”未来的状态并用其进行判断，巧妙地避免了常见的差一错误，使得 <code>burst</code> 参数的行为与直觉完全一致。<br>
<strong>Java 的实现是另一种常见的 GCRA 变种</strong>，虽然逻辑更直接，但在处理边界情况时会导致允许的突发量比设定值多一个。</p>
<h3 id="令牌桶算法">令牌桶算法</h3>
<pre><code class="hljs mermaid">graph TD
    subgraph &quot;令牌桶 (Token Bucket)&quot;
        A[令牌生成器] -- 定期放入令牌 --&gt; B((令牌桶));
        C&#123;请求到达&#125; -- 检查令牌 --&gt; B;
        B -- 有令牌 --&gt; D[取走一个令牌];
        D -- 允许 --&gt; E[处理请求];
        B -- 无令牌 --&gt; F[拒绝或等待];
    end</code></pre>
<p><img src="token-bucket.png" alt="token-bucket"></p>
<p>令牌桶算法是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下：</p>
<ul>
<li>假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌；</li>
<li>桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝；</li>
<li>当n个请求到达时，将从桶中删除n个令牌，接着数据包被发送到网络上；</li>
<li>如果桶中的令牌不足n个，则不会删除令牌，且该请求将被限流（要么丢弃，要么缓冲区等待）。</li>
</ul>
<p>在这里，我们可以看到令牌桶算法表现出的和漏桶算法不一样的特点：</p>
<ul>
<li>令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求；</li>
<li>漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝；</li>
<li>令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌），并允许一定程度突发流量-关键在于令牌桶可以被积累，突发流量可以一次获得令牌桶里全部的令牌，所以令牌桶漏出的突发流量有多大，取决于桶的 capacity；</li>
<li>漏桶限制的是常量流出速率（即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2），从而平滑突发流入速率；</li>
<li>令牌桶允许一定程度的突发，而漏桶主要目的是平滑流入速率；</li>
<li>在流量无法拿到 permit 的时候，其实漏桶和令牌桶都可以使用 queue 进行 buffer，不一定会拒绝请求。</li>
<li>两个算法实现可以一样，但是方向是相反的，对于相同的参数得到的限流效果是一样的。</li>
</ul>
<p>由此看来，令牌桶算法的包容性更强。</p>
<p>如果我们同样用 Java 来实现的话，一个简单的令牌桶算法可以用一个 token 计数器来实现。有一个后台线程定期地为计数器进行加值，而众多 request 处理线程则随时地为这个计数器减值，两者处于竞争状态（因此要考虑 Thread Safety 问题）。后台线程如果加满了计数器，会暂时放弃加值操作，request 处理线程如果将计数器减为负数，可以暂时放弃减值并放弃请求或将请求放回缓冲区。</p>
<p>或者，我们也可以参考以下的代码，来把令牌桶赋予许可的部分单独封装成一个 API：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TokenBucketDemo</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">long</span> <span class="hljs-variable">timeStamp</span> <span class="hljs-operator">=</span> getNowTime();<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> capacity; <span class="hljs-comment">// 桶的容量</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> rate; <span class="hljs-comment">// 令牌放入速度</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> tokens; <span class="hljs-comment">// 当前令牌数量</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">grant</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">now</span> <span class="hljs-operator">=</span> getNowTime();<br>        <span class="hljs-comment">// 先添加令牌。注意看，和漏桶算法算容量不一样的是，要算 min 而不是 max。</span><br>        tokens = min(capacity, tokens + (now - timeStamp) * rate);<br>        timeStamp = now;<br>        <span class="hljs-keyword">if</span> (tokens &lt; <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-comment">// 若不到1个令牌,则拒绝</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 还有令牌，领取令牌</span><br>            tokens -= <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>如果仔细思考漏桶算法和令牌桶算法，他们适用的场景都比计数器算法要广泛，使用起来对流量的调整也更平滑，而且也不会出现临界点性能毛刺（思考下，为什么），所以是更加健壮的业界通行算法。也因为它们是业界通行的算法（实际上中兴和华为都有关于这两种算法的限流专利。互联网公司遇到的流量问题，被通信公司解决了。其实这也是一种思考和学习的启示，我们在新的领域遇到的新的问题，是不是已经被其他人解决了？这种情况 Dijkstra 也遇到过好几次。），所以 Guava 类库提供了相关的实现，不需要我们自己实现。</p>
<h3 id="漏水-vs-积攒令牌">漏水 VS 积攒令牌</h3>
<h4 id="核心资源-状态变量-的含义不同">核心资源（状态变量）的含义不同</h4>
<p>这是最根本的区别。</p>
<ul>
<li>
<p>漏桶 (waterLevel)：代表【负载/欠债】</p>
<ul>
<li>waterLevel 这个变量，衡量的是**“当前系统已经承载了多少请求”**，或者说是“有多少请求正在占用桶的容量”。</li>
<li>它是一个**“负债”或“压力”**指标。水位越高，代表系统压力越大，离拒绝服务越近。<br>
tryAcquire() 的目标是增加负载。</li>
</ul>
</li>
<li>
<p>令牌桶 (tokens)：代表【许可/资产】</p>
<ul>
<li>tokens 这个变量，衡量的是**“系统未来还有多少处理请求的许可”**。</li>
<li>它是一个**“资产”或“信用”**指标。令牌数越多，代表系统越空闲，能处理的突发请求越多。</li>
<li>grant() 的目标是消耗许可。</li>
</ul>
</li>
</ul>
<h4 id="基于时间更新-操作的目的截然相反">“基于时间更新”操作的目的截然相反</h4>
<p>正是因为核心资源含义不同，导致了那个看似相似的“更新”操作，其目的完全相反。</p>
<ul>
<li>
<p>漏桶的 leak()：是在【偿还债务】</p>
<ul>
<li>目的：随着时间流逝，系统处理掉了一些旧的请求，所以要“减轻负载”。</li>
<li>操作：waterLevel 会减少。leak() 的本质是计算出“在这段时间里，我们处理完了多少积压的请求，可以把水位降下来多少”。</li>
<li>决策：偿还债务后，再看**“负载是否已经低到可以接受新请求了”** (waterLevel &lt; capacity)。</li>
</ul>
</li>
<li>
<p>令牌桶的 tokens = …：是在【积累资产】</p>
<ul>
<li>目的：随着时间流逝，系统获得了新的处理能力，所以要“增加许可”。</li>
<li>操作：tokens 会增加。这个操作的本质是计算“在这段时间里，我们又生成了多少新的令牌（处理许可）”。</li>
<li>决策：积累资产后，再看**“资产是否足够支付本次请求”** (tokens &lt; 1)。</li>
</ul>
</li>
</ul>
<h4 id="行为上的根本差异：如何处理突发流量">行为上的根本差异：如何处理突发流量</h4>
<p>这个实现上的核心差异，直接导致了它们在流量控制行为上的不同。</p>
<ul>
<li>
<p>漏桶：强制平滑，不认“过去的空闲”</p>
<ul>
<li>想象一下，系统空闲了很久。leak() 会把 waterLevel 降到 0。</li>
<li>这时，突然来了 100 个请求。</li>
<li>tryAcquire() 会连续成功 capacity 次，waterLevel 迅速从 0 涨到 capacity。</li>
<li>第 capacity + 1 个请求到来时，即使只是几毫秒之后，leak() 能减少的水位也微乎其微，waterLevel 几乎还是 capacity，所以这个请求会被拒绝。</li>
<li>结论：漏桶不关心你过去是否空闲，它的流出速率是恒定的。它强制性地将突发流量“整形”为平滑的流出。</li>
</ul>
</li>
<li>
<p>令牌桶：允许突发，奖励“过去的空闲”</p>
<ul>
<li>想象一下，系统空闲了很久。tokens = … 这个操作会不断累积令牌，直到 tokens 达到 capacity（桶的容量）。</li>
<li>这时，突然来了 100 个请求（假设 capacity &gt;= 100）。</li>
<li>grant() 会连续成功 100 次，tokens 从 100 迅速消耗到 0。</li>
<li>结论：令牌桶允许将过去空闲时期积攒的处理能力（令牌），用于应对未来的突发流量。它允许突发。</li>
</ul>
</li>
</ul>
<h4 id="总结">总结</h4>
<table>
<thead>
<tr>
<th>特征</th>
<th>漏桶实现 (tryAcquire)</th>
<th>令牌桶实现 (grant)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>状态变量</strong></td>
<td>waterLevel（当前负载）</td>
<td>tokens（可用许可）</td>
</tr>
<tr>
<td><strong>变量性质</strong></td>
<td>债务（越少越好）</td>
<td>资产（越多越好）</td>
</tr>
<tr>
<td><strong>时间更新操作</strong></td>
<td><code>leak()</code> → 减少负载</td>
<td><code>tokens += Δ</code> → 增加许可</td>
</tr>
<tr>
<td><strong>操作目的</strong></td>
<td>偿还旧债</td>
<td>积累新资产</td>
</tr>
<tr>
<td><strong>成功获取后</strong></td>
<td><code>waterLevel++</code>（增加负载）</td>
<td><code>tokens--</code>（消耗许可）</td>
</tr>
<tr>
<td><strong>核心逻辑</strong></td>
<td>先“还债”，再看“能不能欠更多债”</td>
<td>先“挣钱”，再看“够不够花钱”</td>
</tr>
<tr>
<td><strong>最终效果</strong></td>
<td>流量整形（强制平滑）</td>
<td>速率限制（允许突发）</td>
</tr>
</tbody>
</table>
<h1>Guava 的 RateLimiter 实现</h1>
<p><a target="_blank" rel="noopener" href="http://grepcode.com/file/repo1.maven.org/maven2/com.google.guava/guava/19.0-rc1/com/google/common/util/concurrent/RateLimiter.java?av=h#RateLimiter">com.google.common.util.concurrent.RateLimiter</a> 是 Guava 并发包中的限流器的抽象类。它有一个子类叫 SmoothRateLimiter。这个 <a target="_blank" rel="noopener" href="http://grepcode.com/file/repo1.maven.org/maven2/com.google.guava/guava/19.0-rc1/com/google/common/util/concurrent/SmoothRateLimiter.java?av=h#SmoothRateLimiter">SmoothRateLimiter</a> 又有两个内部子类 <strong>SmoothBursty</strong> 和 <strong>SmoothWarmingUp</strong>。这两个子类用不同方式实现了近似令牌桶和漏桶的算法。</p>
<h2 id="smoothbursty">SmoothBursty</h2>
<p>SmoothBursty 专门针对大流量设计，允许请求使用未来令牌担保（想象一个允许负数的令牌机制），它不计算当前请求的的等待时间，而是计算下一个请求的等待时间，是一个非常有意思的实现。</p>
<h3 id="伪代码执行流程">伪代码执行流程</h3>
<p>SmoothBursty 的核心思想是：令牌的成本永远是固定的。它允许“透支”未来的令牌，代价是下一个请求需要等待更长的时间。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * SmoothBursty 伪代码实现</span><br><span class="hljs-comment"> * 核心思想：令牌的成本是固定的，允许为突发流量“透支”未来的令牌。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SmoothBursty</span> &#123;<br>    <span class="hljs-comment">// ---- 状态变量 ----</span><br>    <span class="hljs-type">double</span> maxPermits;          <span class="hljs-comment">// 桶容量，通常等于一秒内产生的令牌数</span><br>    <span class="hljs-type">double</span> storedPermits;       <span class="hljs-comment">// 当前存储的令牌数</span><br>    <span class="hljs-type">double</span> stableIntervalMicros; <span class="hljs-comment">// 生成一个令牌的固定时间间隔（例如，QPS=10，则间隔为100,000微秒）</span><br>    <span class="hljs-type">long</span> nextFreeTicketMicros;  <span class="hljs-comment">// 下一个令牌可用的时间点（核心状态！）</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 尝试获取指定数量的令牌</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> permitsToTake 本次请求希望获取的令牌数</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> 需要等待多久才能获取到这些令牌（单位：微秒）</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-type">long</span> <span class="hljs-title function_">acquire</span><span class="hljs-params">(<span class="hljs-type">int</span> permitsToTake)</span> &#123;<br>        <span class="hljs-comment">// 1. 同步令牌：计算从上次请求到现在，应该新增多少令牌</span><br>        resync();<br><br>        <span class="hljs-comment">// 2. 计算需要等待的时间</span><br>        <span class="hljs-type">long</span> <span class="hljs-variable">waitMicros</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br><br>        <span class="hljs-comment">// 检查当前存储的令牌是否足够本次消耗</span><br>        <span class="hljs-type">double</span> <span class="hljs-variable">storedPermitsToSpend</span> <span class="hljs-operator">=</span> Math.min(permitsToTake, <span class="hljs-built_in">this</span>.storedPermits);<br>        <span class="hljs-type">double</span> <span class="hljs-variable">freshPermitsToSpend</span> <span class="hljs-operator">=</span> permitsToTake - storedPermitsToSpend;<br><br>        <span class="hljs-comment">// 对于不足的部分（freshPermitsToSpend），需要等待它们生成。</span><br>        <span class="hljs-comment">// 这就是“透支”的体现：我们预先计算出未来令牌生成所需的时间，并让当前线程等待。</span><br>        waitMicros = (<span class="hljs-type">long</span>)(freshPermitsToSpend * <span class="hljs-built_in">this</span>.stableIntervalMicros);<br><br>        <span class="hljs-comment">// 3. 更新状态：更新下一个可用令牌的时间点，并减去已消耗的令牌</span><br>        <span class="hljs-comment">// 无论是否需要等待，nextFreeTicketMicros 都会向未来移动</span><br>        <span class="hljs-built_in">this</span>.nextFreeTicketMicros = <span class="hljs-built_in">this</span>.nextFreeTicketMicros + waitMicros;<br>        <span class="hljs-built_in">this</span>.storedPermits -= storedPermitsToSpend;<br><br>        <span class="hljs-comment">// 4. 返回等待时间</span><br>        <span class="hljs-comment">// 调用者需要 sleep(waitMicros)</span><br>        <span class="hljs-keyword">return</span> waitMicros;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 核心函数：根据当前时间和上一个可用时间点，补充这段时间内新生成的令牌。</span><br><span class="hljs-comment">     * 这是所有操作的第一步。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">resync</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">nowMicros</span> <span class="hljs-operator">=</span> System.currentTimeMicros();<br>        <span class="hljs-keyword">if</span> (nowMicros &gt; nextFreeTicketMicros) &#123;<br>            <span class="hljs-comment">// 如果当前时间已经晚于“下一个可用时间点”，说明系统空闲了一段时间</span><br>            <span class="hljs-comment">// 计算这段空闲时间 (nowMicros - nextFreeTicketMicros) 内新生成的令牌数</span><br>            <span class="hljs-type">double</span> <span class="hljs-variable">newPermits</span> <span class="hljs-operator">=</span> (nowMicros - nextFreeTicketMicros) / stableIntervalMicros;<br>            <span class="hljs-comment">// 将新令牌加入桶里，但不能超过桶的容量</span><br>            <span class="hljs-built_in">this</span>.storedPermits = Math.min(maxPermits, storedPermits + newPermits);<br>            <span class="hljs-comment">// 将下一个可用时间点重置为当前时间</span><br>            <span class="hljs-built_in">this</span>.nextFreeTicketMicros = nowMicros;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<ol>
<li>resync()：先根据离上次请求过去了多久，把“应得的”新令牌加上，更新 storedPermits。</li>
<li>acquire()：计算要拿走的 permitsToTake。</li>
<li>如果 storedPermits 不够，不足的部分就视为向未来“透支”。</li>
<li>透支的代价就是，nextFreeTicketMicros 会被加上一个更长的时间，导致下一个请求必须等待更久。</li>
<li>整个过程，一个令牌的“价格”（stableIntervalMicros）是恒定不变的。</li>
</ol>
<h3 id="使用实例">使用实例</h3>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> com.google.common.util.concurrent.RateLimiter;<br><span class="hljs-keyword">import</span> java.time.LocalTime;<br><span class="hljs-keyword">import</span> java.time.format.DateTimeFormatter;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SmoothBurstyExample</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-comment">// 创建一个 SmoothBursty 限流器，速率为 2个令牌/秒。</span><br>        <span class="hljs-comment">// RateLimiter.create(2) 默认创建的就是 SmoothBursty。</span><br>        <span class="hljs-type">RateLimiter</span> <span class="hljs-variable">limiter</span> <span class="hljs-operator">=</span> RateLimiter.create(<span class="hljs-number">2</span>);<br><br>        <span class="hljs-type">DateTimeFormatter</span> <span class="hljs-variable">formatter</span> <span class="hljs-operator">=</span> DateTimeFormatter.ofPattern(<span class="hljs-string">&quot;HH:mm:ss.SSS&quot;</span>);<br><br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 启动任务...&quot;</span>);<br><br>        <span class="hljs-comment">// 第一次请求：模拟突发，一次性获取 5 个令牌</span><br>        <span class="hljs-comment">// 思考：速率是 2/s，为什么能一次性拿到 5 个？</span><br>        <span class="hljs-comment">// 因为 RateLimiter 允许“透支”。它会立刻批准这次请求，</span><br>        <span class="hljs-comment">// 但代价是计算出这 5 个令牌（超出速率的部分）需要多长时间才能“还清”，</span><br>        <span class="hljs-comment">// 然后将这个等待时间叠加到下一个请求上。</span><br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 尝试获取 5 个令牌...&quot;</span>);<br>        <span class="hljs-type">double</span> <span class="hljs-variable">waitTime</span> <span class="hljs-operator">=</span> limiter.acquire(<span class="hljs-number">5</span>);<br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 成功获取 5 个令牌，等待时间：&quot;</span> + waitTime + <span class="hljs-string">&quot; 秒&quot;</span>);<br>        System.out.println(<span class="hljs-string">&quot;--------------------------------------------------&quot;</span>);<br><br>        <span class="hljs-comment">// 第二次请求：在“债务”还清前，再次请求</span><br>        <span class="hljs-comment">// 此时，由于上次请求透支了未来的令牌，这次请求必须等待“债务”还清。</span><br>        <span class="hljs-comment">// 预计等待时间约 2 秒左右，因为速率是 2/s，透支了大约 4 个令牌（第一个是免费的）。</span><br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 尝试获取 1 个令牌...&quot;</span>);<br>        waitTime = limiter.acquire(<span class="hljs-number">1</span>);<br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 成功获取 1 个令牌，等待时间：&quot;</span> + waitTime + <span class="hljs-string">&quot; 秒&quot;</span>);<br>        System.out.println(<span class="hljs-string">&quot;--------------------------------------------------&quot;</span>);<br><br>        <span class="hljs-comment">// 第三次请求</span><br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 尝试获取 1 个令牌...&quot;</span>);<br>        waitTime = limiter.acquire(<span class="hljs-number">1</span>);<br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 成功获取 1 个令牌，等待时间：&quot;</span> + waitTime + <span class="hljs-string">&quot; 秒&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h2 id="smoothwarmingup">SmoothWarmingUp</h2>
<p>SmoothWarmingUp 实现了一个类似 TCP 流量拥塞控制“加性增”的算法，基本思路是：系统在未启动和长期不启动后会存在缓存失效等性能下降的问题。在走完预热周期以前不允许达到指定的 QPS。这个实现对突发流量依然有一定的支持，因此并不是一个严格的漏桶算法。</p>
<h3 id="伪代码执行流程">伪代码执行流程</h3>
<p>SmoothWarmingUp 的核心思想是：令牌的成本是动态变化的。当系统存储了大量令牌时（刚启动或长期空闲后），令牌会变得“昂贵”，以此来强制系统缓慢地“预热”，防止突发流量压垮一个冷系统。</p>
<p>SmoothWarmingUp 的预热算法示意图：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">pre</span>&gt;</span><br>         ^ throttling<br>         |<br>   cold  +                  /<br>interval |                 /.<br>         |                / .<br>         |               /  .   ← &quot;warmup period&quot; is the area of the trapezoid between<br>         |              /   .     thresholdPermits and maxPermits<br>         |             /    .<br>         |            /     .<br>         |           /      .<br>  stable +----------/  WARM .<br>interval |          .   UP  .<br>         |          . PERIOD.<br>         |          .       .<br>       0 +----------+-------+--------------→ storedPermits<br>         0 thresholdPermits maxPermits<br><span class="hljs-tag">&lt;/<span class="hljs-name">pre</span>&gt;</span><br></code></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * SmoothWarmingUp 伪代码实现</span><br><span class="hljs-comment"> * 核心思想：令牌的成本是动态的。存储的令牌越多，获取它的成本（时间间隔）就越高。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SmoothWarmingUp</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">SmoothRateLimiter</span> &#123;<br>    <span class="hljs-comment">// ---- 状态变量 (比Bursty更多) ----</span><br>    <span class="hljs-type">double</span> maxPermits;<br>    <span class="hljs-type">double</span> storedPermits;<br>    <span class="hljs-type">long</span> nextFreeTicketMicros;<br>    <span class="hljs-comment">// double stableIntervalMicros; // 不再是固定的，而是动态计算</span><br><br>    <span class="hljs-comment">// ---- 预热区特有变量 ----</span><br>    <span class="hljs-type">long</span> warmupPeriodMicros;    <span class="hljs-comment">// 预热总时长 (例如 10 秒)</span><br>    <span class="hljs-type">double</span> slope;               <span class="hljs-comment">// 预热区那条斜线的“斜率”，决定了价格上涨的速度</span><br>    <span class="hljs-type">double</span> thresholdPermits;    <span class="hljs-comment">// “稳定区”和“预热区”的令牌数量分界线</span><br>    <span class="hljs-type">double</span> coldIntervalMicros;  <span class="hljs-comment">// “最冷”的时候（令牌最多时）获取一个令牌的时间，通常是稳定期的3倍</span><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 消耗存储的令牌，并返回因此需要等待的时间</span><br><span class="hljs-comment">     * 这是与 SmoothBursty 最大的不同之处</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-type">long</span> <span class="hljs-title function_">spendStoredPermits</span><span class="hljs-params">(<span class="hljs-type">int</span> permitsToTake)</span> &#123;<br>        <span class="hljs-comment">// 1. 计算当前存储的令牌能覆盖多少本次请求</span><br>        <span class="hljs-type">double</span> <span class="hljs-variable">availablePermits</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.storedPermits;<br>        <span class="hljs-type">long</span> <span class="hljs-variable">waitMicros</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br><br>        <span class="hljs-comment">// 2. 核心逻辑：分区域计算令牌的“价格”</span><br>        <span class="hljs-comment">// 如果存储的令牌数量 &gt; 阈值，说明处于“预热区”</span><br>        <span class="hljs-keyword">if</span> (availablePermits &gt; thresholdPermits) &#123;<br>            <span class="hljs-comment">// 计算在“预热区”能消耗的令牌数</span><br>            <span class="hljs-type">double</span> <span class="hljs-variable">warmupPermitsToSpend</span> <span class="hljs-operator">=</span> Math.min(permitsToTake, availablePermits - thresholdPermits);<br><br>            <span class="hljs-comment">// 计算这部分“昂贵”令牌的价格。价格是梯形成本，这里简化理解：</span><br>            <span class="hljs-comment">// 越靠近桶满（maxPermits），令牌越贵。</span><br>            waitMicros += calculateWarmupCost(warmupPermitsToSpend);<br>            permitsToTake -= warmupPermitsToSpend;<br>        &#125;<br><br>        <span class="hljs-comment">// 如果令牌还在预热区消耗完了，或者一开始就在“稳定区”</span><br>        <span class="hljs-keyword">if</span> (permitsToTake &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-comment">// 计算在“稳定区”能消耗的令牌数</span><br>            <span class="hljs-type">double</span> <span class="hljs-variable">stablePermitsToSpend</span> <span class="hljs-operator">=</span> Math.min(permitsToTake, availablePermits);<br>            <span class="hljs-comment">// 计算这部分“便宜”令牌的价格</span><br>            waitMicros += stablePermitsToSpend * stableIntervalMicros; <span class="hljs-comment">// 稳定价格</span><br>            permitsToTake -= stablePermitsToSpend;<br>        &#125;<br>        <br>        <span class="hljs-comment">// 3. 更新状态并返回总等待时间</span><br>        <span class="hljs-built_in">this</span>.storedPermits -= (availablePermits - <span class="hljs-built_in">this</span>.storedPermits); <span class="hljs-comment">// 减去总消耗</span><br>        <span class="hljs-keyword">return</span> waitMicros;<br>    &#125;<br><br>    <span class="hljs-comment">// acquire() 和 resync() 的整体结构与 SmoothBursty 类似，</span><br>    <span class="hljs-comment">// 但在计算等待时间时，会调用上面这个复杂的 spendStoredPermits() 方法，</span><br>    <span class="hljs-comment">// 而不是简单地用固定间隔去乘。</span><br>&#125;<br></code></pre></td></tr></table></figure>
<ol>
<li>resync()：同样，先补充空闲时间产生的令牌。这可能导致 storedPermits 进入“预热区”。</li>
<li>acquire()：当要获取令牌时，检查 storedPermits 处于哪个区间。</li>
<li>在“稳定区” (storedPermits &lt; thresholdPermits)：行为和 SmoothBursty 类似，令牌价格固定且便宜。</li>
<li>在“预热区” (storedPermits &gt; thresholdPermits)：令牌价格变贵了！获取一个令牌需要更长的时间间隔。系统通过这种方式，强迫流量处理速度降下来，实现“预热”的效果。</li>
<li>它依然是令牌桶，因为它还是在管理“许可”的生成和消耗，只是“许可”的价格会变动。</li>
</ol>
<h3 id="使用实例">使用实例</h3>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> com.google.common.util.concurrent.RateLimiter;<br><span class="hljs-keyword">import</span> java.time.LocalTime;<br><span class="hljs-keyword">import</span> java.time.format.DateTimeFormatter;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SmoothWarmingUpExample</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-comment">// 创建一个 SmoothWarmingUp 限流器</span><br>        <span class="hljs-comment">// 速率为 2个令牌/秒</span><br>        <span class="hljs-comment">// 预热期为 3 秒</span><br>        <span class="hljs-type">RateLimiter</span> <span class="hljs-variable">limiter</span> <span class="hljs-operator">=</span> RateLimiter.create(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, TimeUnit.SECONDS);<br><br>        <span class="hljs-type">DateTimeFormatter</span> <span class="hljs-variable">formatter</span> <span class="hljs-operator">=</span> DateTimeFormatter.ofPattern(<span class="hljs-string">&quot;HH:mm:ss.SSS&quot;</span>);<br><br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 启动任务，限流器处于“最冷”状态...&quot;</span>);<br>        System.out.println(<span class="hljs-string">&quot;--------------------------------------------------&quot;</span>);<br><br>        <span class="hljs-comment">// 循环获取令牌，观察速率变化</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">6</span>; i++) &#123;<br>            System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 尝试获取 1 个令牌 (第 &quot;</span> + i + <span class="hljs-string">&quot; 次)...&quot;</span>);<br>            <span class="hljs-type">double</span> <span class="hljs-variable">waitTime</span> <span class="hljs-operator">=</span> limiter.acquire(<span class="hljs-number">1</span>);<br>            System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 成功获取，等待时间：&quot;</span> + waitTime + <span class="hljs-string">&quot; 秒&quot;</span>);<br>        &#125;<br>        <br>        System.out.println(<span class="hljs-string">&quot;--------------------------------------------------&quot;</span>);<br>        System.out.println(LocalTime.now().format(formatter) + <span class="hljs-string">&quot;: 预热期结束，速率应稳定在 0.5 秒/令牌&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h1>我们应该如何在一台机器上限流</h1>
<p>聊了这么多底层的代码和原理，应该想想怎么应用了。</p>
<p>上面已经提到，我们可以使用模糊的并发性限流算法，也可以使用精确而主动的速率限流算法。让我们思路广泛点，想想可以在什么层面上做各种限流。</p>
<p>从操作系统层面，我们可以一开始就限制一个操作系统能够使用的硬件资源，包括但不限于 CPU、内存、硬盘和网卡。现代应用可以借助虚拟机或者容器对资源进行虚拟切割，制造一个有物理极限的操作系统配额限制。</p>
<p>在应用层面，我们可以限制一个进程可以使用的内存和可用的文件描述符数量。</p>
<p>在涉及到 JVM 的应用程序时，我们还可以对内存限制进行细化调优配置。</p>
<p>在涉及到 TCP 协议时，也有很多内核参数可以调节，比如缓冲区队列的大小，irqbalance， MTU 等等。</p>
<p>在上层的应用软件，通常存在一种连接资源池化复用的机制。在 Tomcat/MySQL/Redis 里，通常都有连接数、工作线程数和请求/backlog缓冲区等不同的配置选项（和 TCP 的协议栈实现大同小异）。</p>
<p>在经过这些模糊的限流配置以后，我们可以在应用内部使用上面提到的算法自己实现精确的限流。也可以使用上面提到 RateLimiter 限流，甚至可以使用近几年新出的 Hystrix 做限流（Hystrix 自带一个池化复用的解决方案，感兴趣的读者可以研究下）。</p>
<h1>我们应该如何在分布式环境下限流</h1>
<h2 id="在接入层-proxy-单点限流-vs-在单机上各自限流">在接入层 proxy 单点限流 VS 在单机上各自限流</h2>
<p>现代的服务化/组件化应用，在一个虚拟的应用调用背后，往往有若干个真正的服务实例在承载 QPS。这也就意味着，我们对一个服务进行限流，要考虑分布式环境下多个实例的协同问题。</p>
<p>在分布式环境下限流的思路，主要有两种：</p>
<ol>
<li>在一台机器上把所有流量控制住，然后分发给其他所有机器。我们姑且把这种限流思路称为反向代理式限流或者接入层限流。</li>
<li>在每台机器上单独做整体限流，然后寻找一个全局协调工具来协调全局的整体流量。我们姑且把这种思路称为协调器限流。</li>
</ol>
<h3 id="接入层同步限流">接入层同步限流</h3>
<p>接入层同步限流的方案已经很成熟。</p>
<p>我们常见的反向代理 nginx 里有<code>ngx_http_limit_req_module</code>和<code>ngx_http_limit_conn_module</code> 模块可以提供基于连接/请求测度的限流。在更加复杂的 OpenResty/Kong 上还可以实现各种粒度/维度的限流。</p>
<h3 id="限流的颗粒度与维度">限流的颗粒度与维度</h3>
<p>我们应该仔细考虑接入层限流的配置粒度。往接入层的上游来看，是针对自己后置的所有服务共用同一套限流配置，还是针对每一个资源单独一套限流配置？在做这样的配置的时候，要充分考虑后台不同资源的负载能力，使用大一统的配置不适合复杂的流量入口。</p>
<p>在这种分布式场景下限流还要考虑限流维度的问题。</p>
<p>从请求的链路两端来看，是以被调用方资源为维度来限流，还是以调用方请求来源为维度来限流？</p>
<h4 id="被调用方的隔离维度">被调用方的隔离维度</h4>
<p>以被调用方资源为维度来限流，是一种相当保守的策略，相当于一个资源的总体限流被所有调用方共享了，使一个资源变成了大锅饭。所有的调用方共享一个资源，贪婪的调用方会蚕食其他调用方的 QPS 配额。如果一个调用方的调用频率很高，在资源紧张的场景下，其他调用方会发生饥饿。如果资源的紧张，进一步导致限流策略更趋保守，那真是城门失火殃及池鱼了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs conf"># 定义一个限流区域，名为 &quot;per_ip_limit&quot;<br># 使用二进制远程地址 $binary_remote_addr 作为 key，保证存储效率<br># zone=per_ip_limit:10m 表示开辟 10MB 内存来存储 key 和访问频率<br># rate=1r/s 表示允许的平均速率为每秒 1 个请求<br>http &#123;<br>    limit_req_zone $binary_remote_addr zone=per_ip_limit:10m rate=1r/s;<br><br>    server &#123;<br>        location /api/v1/products/ &#123;<br>            # 在此 location 启用名为 &quot;per_ip_limit&quot; 的限流策略<br>            # burst=5 表示允许的突发请求数。超过 1r/s 但在 5 个以内的请求会被放入队列延迟处理。<br>            # nodelay 表示对于突发请求，不延迟处理而是直接通过，但后续请求会严格卡控。<br>            limit_req zone=per_ip_limit burst=5 nodelay;<br><br>            proxy_pass http://my_backend_service;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h4 id="调用方的隔离维度">调用方的隔离维度</h4>
<p>而如果以调用方为维度来限流，则需要引入类似分级的服务区分制度，对不同级别的服务调用授予不同级别的流量许可。这就要求服务在发起调用的时候能够表达自己的身份，而服务接入层可以理解这种身份，而我们可以针对不同的身份做不同的配置。实际上上面提到的几个反向代理，都支持区分调用方的 ip 地址甚至主机名的鉴别方案。但基于 ip 的流量限制还是略显粗疏，除非我们明确地知道请求 ip 地址背后的服务到底是什么（这可以引入一张配置表，可以是一张 excel 表，也可以是一个数据库的 table），否则还是使用某些服务鉴别报头为好。例如，我们可以要求所有的服务调用方都在发起请求时携带一个 requester-header 一样的 http 请求头，对调用链路上下游进行全面改造，然后在请求通过接入层时做专门鉴别。这种设计的思想类似于操作系统的优先级调度，比被调用方维度更为灵活，也需要做更细致的配置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs conf">http &#123;<br>    # 使用 map 指令，根据传入的 X-Api-Key 设置不同的限流 key<br>    # 如果是 VIP 客户，我们给一个固定的 key &quot;vip_user_key&quot;<br>    # 如果是普通用户，我们用他们的 IP 作为 key<br>    # 默认情况下，也用 IP 作为 key<br>    map $http_x_api_key $limit_key &#123;<br>        &quot;vip-secret-key&quot;   &quot;vip_user_key&quot;;<br>        default            $binary_remote_addr;<br>    &#125;<br><br>    # 定义两个限流区域<br>    limit_req_zone $limit_key zone=api_limit:10m rate=10r/s; # 普通用户 10 QPS<br>    limit_req_zone $limit_key zone=vip_api_limit:10m rate=100r/s; # VIP 用户 100 QPS<br><br>    server &#123;<br>        location /api/v1/data/ &#123;<br>            # 根据 key 的不同，应用不同的限流策略<br>            if ($limit_key = &quot;vip_user_key&quot;) &#123;<br>                limit_req zone=vip_api_limit;<br>            &#125;<br>            if ($limit_key != &quot;vip_user_key&quot;) &#123;<br>                limit_req zone=api_limit;<br>            &#125;<br><br>            proxy_pass http://my_data_service;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>我们都知道接入层限流依赖于反向代理式的系统架构风格，而这种风格要求我们必须使用把限流放在调用方和被调用方的中间，好像一个仲裁者，有没有其他风格的体系结构呢？这就是我们接下来要谈到的协调器限流。</p>
<h3 id="协调者限流">协调者限流</h3>
<p>协调者限流的思想，是通过进程间通信的方法，在多个服务实例之间寻找到一个高性能支持原子化读写（也就意味着并发/并行安全）的存储，维护一个全局的限流计数器，然后多个服务实例通过动态地更新这一个限流计数器，来实现全局的限流配额动态扩散到各个服务节点的效果。通常的情况下，我们可以使用 Redis 的 incr 操作，配合编程语言（Lua/Java）等等来实现这一效果。 Redis 的官网上专门有<a target="_blank" rel="noopener" href="https://redis.io/commands/incr">一个例子</a>，讨论这一问题。在我们得到了每台机器的限流配额以后，我们可以采用之前讨论过的单机限流方法进行限流了。当然，在这个思路上还有其他的延伸，如果不嫌 Zookeeper 的写性能低，也可以考虑使用 Zookeeper。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-comment">--[[</span><br><span class="hljs-comment">  令牌桶限流算法 Lua 脚本</span><br><span class="hljs-comment">  </span><br><span class="hljs-comment">  KEYS[1]: 限流器的 key，例如 &quot;ratelimit:user:123&quot;</span><br><span class="hljs-comment">  ARGV[1]: 桶的容量 (capacity)</span><br><span class="hljs-comment">  ARGV[2]: 令牌生成速率 (rate, 每秒生成几个)</span><br><span class="hljs-comment">  ARGV[3]: 当前时间戳 (timestamp, 秒)</span><br><span class="hljs-comment">  ARGV[4]: 本次请求需要消耗的令牌数 (permits, 通常是 1)</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  返回值:</span><br><span class="hljs-comment">    0: 不允许 (令牌不足)</span><br><span class="hljs-comment">    1: 允许</span><br><span class="hljs-comment">--]]</span><br><br><span class="hljs-keyword">local</span> key = KEYS[<span class="hljs-number">1</span>]<br><span class="hljs-keyword">local</span> capacity = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">1</span>])<br><span class="hljs-keyword">local</span> rate = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">2</span>])<br><span class="hljs-keyword">local</span> now = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">3</span>])<br><span class="hljs-keyword">local</span> requested = <span class="hljs-built_in">tonumber</span>(ARGV[<span class="hljs-number">4</span>])<br><br><span class="hljs-comment">-- hgetall 获取桶的当前状态，如果不存在则初始化</span><br><span class="hljs-keyword">local</span> bucket_info = redis.call(<span class="hljs-string">&#x27;hgetall&#x27;</span>, key)<br><span class="hljs-keyword">local</span> last_tokens<br><span class="hljs-keyword">local</span> last_refreshed_at<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">table</span>.<span class="hljs-built_in">getn</span>(bucket_info) == <span class="hljs-number">0</span> <span class="hljs-keyword">then</span><br>  <span class="hljs-comment">-- 首次访问，桶是满的</span><br>  last_tokens = capacity<br>  last_refreshed_at = now<br><span class="hljs-keyword">else</span><br>  <span class="hljs-comment">-- 从哈希中解析上次的令牌数和刷新时间</span><br>  last_tokens = <span class="hljs-built_in">tonumber</span>(bucket_info[<span class="hljs-number">2</span>])<br>  last_refreshed_at = <span class="hljs-built_in">tonumber</span>(bucket_info[<span class="hljs-number">4</span>])<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">-- 计算从上次到现在，新生成的令牌数</span><br><span class="hljs-keyword">local</span> delta = <span class="hljs-built_in">math</span>.<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, now - last_refreshed_at)<br><span class="hljs-keyword">local</span> new_tokens = delta * rate<br><br><span class="hljs-comment">-- 当前可用令牌 = 上次剩余的 + 新生成的，且不能超过桶的容量</span><br><span class="hljs-keyword">local</span> current_tokens = <span class="hljs-built_in">math</span>.<span class="hljs-built_in">min</span>(capacity, last_tokens + new_tokens)<br><br><span class="hljs-comment">-- 判断令牌是否足够</span><br><span class="hljs-keyword">if</span> current_tokens &lt; requested <span class="hljs-keyword">then</span><br>  <span class="hljs-comment">-- 令牌不足，直接返回 0</span><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><span class="hljs-keyword">else</span><br>  <span class="hljs-comment">-- 令牌充足，扣减令牌并更新状态</span><br>  current_tokens = current_tokens - requested<br>  redis.call(<span class="hljs-string">&#x27;hmset&#x27;</span>, key, <span class="hljs-string">&#x27;tokens&#x27;</span>, current_tokens, <span class="hljs-string">&#x27;refreshed_at&#x27;</span>, now)<br>  <span class="hljs-comment">-- 设置一个过期时间，防止冷数据永久占用内存</span><br>  redis.call(<span class="hljs-string">&#x27;expire&#x27;</span>, key, <span class="hljs-built_in">math</span>.<span class="hljs-built_in">ceil</span>(capacity / rate) * <span class="hljs-number">2</span>)<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Jedis 客户端示例</span><br><span class="hljs-comment">// 1. 将上面的 Lua 脚本加载到 Redis，得到一个 SHA1 摘要</span><br><span class="hljs-type">String</span> <span class="hljs-variable">scriptSha</span> <span class="hljs-operator">=</span> jedis.scriptLoad(luaScript);<br><br><span class="hljs-comment">// 2. 每次处理请求前，调用脚本</span><br><span class="hljs-type">Object</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> jedis.evalsha(<br>    scriptSha, <br>    <span class="hljs-number">1</span>, <span class="hljs-comment">// key 的数量</span><br>    <span class="hljs-string">&quot;ratelimit:api:/v1/user:123&quot;</span>, <span class="hljs-comment">// KEYS[1]</span><br>    <span class="hljs-string">&quot;100&quot;</span>,   <span class="hljs-comment">// ARGV[1]: 桶容量 100</span><br>    <span class="hljs-string">&quot;10&quot;</span>,    <span class="hljs-comment">// ARGV[2]: 速率 10/s</span><br>    String.valueOf(System.currentTimeMillis() / <span class="hljs-number">1000</span>), <span class="hljs-comment">// ARGV[3]: 当前时间戳</span><br>    <span class="hljs-string">&quot;1&quot;</span>      <span class="hljs-comment">// ARGV[4]: 消耗 1 个令牌</span><br>);<br><br><span class="hljs-comment">// 3. 根据返回值判断是否限流</span><br><span class="hljs-keyword">if</span> (<span class="hljs-string">&quot;1&quot;</span>.equals(result.toString())) &#123;<br>    <span class="hljs-comment">// 执行业务逻辑</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">// 拒绝请求，返回 HTTP 429 Too Many Requests</span><br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="基于-mq-的限流">基于 mq 的限流</h3>
<p>如果我们的服务之间使用的是异步通信，如使用了 Kafka 或者 AMQP 的队列，可以考虑使用队列限流（阿里的人喜欢说的削峰填谷）。这种限流需要考虑的问题是怎样在 Message Consumer 消息分发时做限流，做设计的时候要考虑多个 Consumer 之间是怎样共享消息队列的-是拉模式还是推模式，是 queue 风格还是 P/S 风格？本 Consumer 的吞吐率能不能影响全局的吞吐率？</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Kafka Consumer 伪代码示例</span><br><span class="hljs-type">Properties</span> <span class="hljs-variable">props</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>props.put(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;kafka-broker:9092&quot;</span>);<br>props.put(<span class="hljs-string">&quot;group.id&quot;</span>, <span class="hljs-string">&quot;invoice-service-group&quot;</span>);<br><span class="hljs-comment">// ... 其他配置</span><br><br><span class="hljs-comment">// 关键配置项 1: 控制单次 poll() 拉取的最大记录数</span><br><span class="hljs-comment">// 将其调小，可以有效降低瞬间处理的数据量。</span><br>props.put(<span class="hljs-string">&quot;max.poll.records&quot;</span>, <span class="hljs-string">&quot;50&quot;</span>); <br><br><span class="hljs-comment">// 关键配置项 2: 控制两次 poll() 之间的最小间隔</span><br><span class="hljs-comment">// 如果处理速度过快，这个参数可以强制 Consumer &quot;休息&quot;一下。</span><br>props.put(<span class="hljs-string">&quot;fetch.min.bytes&quot;</span>, <span class="hljs-string">&quot;1&quot;</span>); <span class="hljs-comment">// 默认值</span><br>props.put(<span class="hljs-string">&quot;fetch.max.wait.ms&quot;</span>, <span class="hljs-string">&quot;500&quot;</span>); <span class="hljs-comment">// 默认值</span><br><br>KafkaConsumer&lt;String, String&gt; consumer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaConsumer</span>&lt;&gt;(props);<br>consumer.subscribe(Arrays.asList(<span class="hljs-string">&quot;order-topic&quot;</span>));<br><br><span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="hljs-number">100</span>));<br>    <span class="hljs-keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;<br>        <span class="hljs-comment">// 处理业务逻辑...</span><br>        processOrder(record.value());<br><br>        <span class="hljs-comment">// 主动限流：在处理完每条消息后，可以主动 sleep</span><br>        <span class="hljs-comment">// 这种方式更粗暴，但非常有效，可以精确控制处理速率。</span><br>        <span class="hljs-comment">// 例如，目标是 10 QPS，则处理完一条后 sleep 100ms。</span><br>        Thread.sleep(<span class="hljs-number">100</span>); <br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>这种方式天然地实现了背压 (Backpressure)。如果下游服务处理得慢，消息就会在 Kafka 中积压，而不会冲垮服务实例。这正是队列限流的精髓。</p>
<p>如果我们的服务之间的通信走的是自定义协议，比如两个服务器之间使用的是类 Thrift 客户端相互通信，那么可以考虑对客户端进行改造。这样不仅可以在请求到达被调用方时进行限流，也可以在流量离开调用方时进行限流。</p>
<h1>最后做个总结</h1>
<p>总体来讲，限流是为了保护核心系统不要超负荷运行。系统超负荷运行，不仅对被调用者是危险，也对调用者是潜在风险。毕竟被调用者垮了，调用者也不能继续运行下去。限流可以从源头防止系统雪崩。但整个复杂的调用链路的使用场景千变万化，一套死板的限流不可能应付所有情况。所以我们应该有办法正确地识别系统的负载状况，采取对症下药的限流策略。这要求限流系统设计得必须有识别、统计能力（这需要监控系统提供数据输出），也要有动态配置能力。如果流量一上来，没有办法确认源头做细致配置，就盲目地把所有的流量都限死，那么只能保护自己，会造成其他本来正常运行的系统发生没有必要的性能抖动（Thrash），是一种头痛医头，脚痛医脚的方案。</p>
<p>本文写了那么长，总算结束了。下面列一下我囫囵吞枣的参考资料：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/google/guava/blob/v18.0/guava/src/com/google/common/util/concurrent/SmoothRateLimiter.java#L124:L130">SmoothRateLimiter.java 的源注释</a></li>
<li><a target="_blank" rel="noopener" href="http://jinnianshilongnian.iteye.com/blog/2305117">聊聊高并发系统之限流特技</a></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://magicliang.github.io">magicliang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/">https://magicliang.github.io/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/">系统架构</a></div><div class="post-share"><div class="social-share" data-image="/2025/07/15/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BC%B9%E6%80%A7/leaky-bucket.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2018/01/30/%E5%87%A0%E7%A7%8D%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/" title="几种共识算法"><img class="cover" src="/img/wall-paper-36.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-30</div><div class="info-item-2">几种共识算法</div></div><div class="info-2"><div class="info-item-1">达成共识的英文原文是 come to consensus。达成共识以后，也未必代表数据是完全一致的（Raft 算法中 leader 发出 append log 的 commit 命令即算达成共识？但如果中途数据丢失，则还是会有子节点数据不一致）。 在分布式环境下，多个系统协同工作的效率，受制于系统交叉点的性能。在需要达成分布式共识的场景下，分布式共识算法在保证系统安全性的同时，限制了全系统横向扩展的性能提升。 根据环境的不同，可以应用不同的共识算法。 在完全互信的环境下-私有链、私有的分布式数据库，节点之间可以使用 Paxos 或者 Raft 这种 leader 相对固定的算法。 在有限互信的环境下-联盟链，可以使用 PBFT。PBFT 算法是依据确定性的投票（可能是漫长的投票，也可能进入死循环）达到确定性一致的算法。 在没有互信的情况下-公有链，可以使用 POW/POS/DPOS/POA。这类算法是基于概率得到正确的最终一致性，性能比 PBFT 要稍微好点。 最好的共识算法应该模块化，例如 Corda 中的 notary，Hyperledger fabric 中的 solo/k...</div></div></div></a><a class="pagination-related" href="/2018/04/02/%E4%B8%80%E4%B8%AA%E6%BB%9A%E5%8A%A8%E9%87%8D%E5%90%AF%E7%9A%84%E7%8A%B6%E6%80%81%E4%BF%9D%E5%AD%98%E9%97%AE%E9%A2%98/" title="一个滚动重启的状态保存问题"><img class="cover" src="/img/wall-paper-167.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-04-02</div><div class="info-item-2">一个滚动重启的状态保存问题</div></div><div class="info-2"><div class="info-item-1">很多时候滚动重启，都会导致状态丢失。比较好的设计方法是把服务本身设计成无状态的，然后在上游的服务上做好 failover，然后增加 standby server，让 sticky 数据 transmit 到 standby 机器上，让 request 失败以后可以自己由上游重传到 standby server。然后就可以滚动重启了。 这大部分场景下还要考虑幂等的问题。 这就看得出热配置热替换的重要性了。在大多数情况下，除了发布新的 feature 升级以外，都应该尽量用热配置来避免重启。 </div></div></div></a><a class="pagination-related" href="/2018/11/28/%E6%AD%A3%E4%BA%A4%E6%80%A7/" title="正交性"><img class="cover" src="/img/wall-paper-111.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-11-28</div><div class="info-item-2">正交性</div></div><div class="info-2"><div class="info-item-1">所谓正交性（orthogonal 意为正交的），就是设计的维度与其他维度完全隔离，一个正交的设计/值域设计，其变化绝不会受其他正交维度影响，也不会影响其他正交维度。 我们可以把 API 设计成正交的。这样 API 有独立变化的空间的。 我们可以把问题域切分清楚。问题域之间完全不相互干涉（注意跨问题域问题）。 我们可以把变量、字段、列设计成正交的。这样不同业务场景下，列之间的赋值不会相互覆盖。 </div></div></div></a><a class="pagination-related" href="/2019/08/30/%E3%80%8A%E9%AB%98%E5%8F%AF%E7%94%A8%E6%81%A2%E5%A4%8D%E6%80%9D%E8%B7%AF%E3%80%8B%E7%AC%94%E8%AE%B0/" title="《高可用恢复思路》笔记"><img class="cover" src="/img/wall-paper-61.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-08-30</div><div class="info-item-2">《高可用恢复思路》笔记</div></div><div class="info-2"><div class="info-item-1">遇到线上问题，经常陷入一个误区：一定要找到问题的根因（root cause）。但实际上对线上应用而言，最重要的是恢复可用性，所以在开发设计环境除了完成功能性需求以外，还需要加入非功能性设计的需求：  限流保护。抵挡来自突发流量冲垮整个集群。 降级保护，对调用的服务接口保持警惕，其各种因素导致不可用，可以对齐降级，从而确保核心功能可用。 削峰填谷（traffic shaping），不因突发数据来袭，造成任务消费陡增，造成调用系统的连串抖动。  这些基本的系统保护，是应对未来的各种突发不确定事件的高可用思考。 以上描述的是问题的应对机制设计，问题的发现机制，也需要结构化地考虑，体系化地建设：  发现机制，是我们的眼睛，也是基础。 监控主指标，需要找对业务的主要指标，常见的主指标一般是：RT（响应时间）、总量、成功量、失败量、成功率。 主指标有异常，还要有细分维度（即结果还可以内部 group by aggregation）。 快速恢复 根据监控快速寻找问题发生的方向和位置。 找对恢复的人、恢复的预案。 倾向于选择成本低的恢复手段。---- 并不是所有的恢复都用大招（熔断、限流），大招...</div></div></div></a><a class="pagination-related" href="/2019/09/05/%E3%80%8A%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%81%93%E3%80%8B%E7%AC%94%E8%AE%B0/" title="《应用架构之道》笔记"><img class="cover" src="/img/wall-paper-84.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-05</div><div class="info-item-2">《应用架构之道》笔记</div></div><div class="info-2"><div class="info-item-1">架构师的职责 化繁为简。架构师是职责就是把复杂的问题简单化，使得其他人能够更好地在架构里工作。 架构师要努力训练自己的思维，用它去理解复杂的系统，通过合理的分解和抽象，做出合理的设计。 软件架构 软件架构是一个系统的草图。软件架构描述的对象是直接构成系统的抽象组件。各个组件的链接则明确和相对细致地描述组件之间的通信。  软件架构为软件系统提供了结构、行为和属性的高级抽象。，由构件的描述、构件的相互作用、指导构件集成的模式以及这些模式的约束组成。软件架构不仅显示了软件需求和软件结构之间的对应关系，而且指定了整个软件系统的组织和拓扑结构，提供了一些设计决策的基本原理。 软件架构的核心价值应该只围绕一个核心命题：控制复杂性。  软件架构分类  业务架构：由业务架构师负责，也可以称为业务领域专家、行业专家。业务架构属于顶层设计，其对业务的定义和划分会影响组织结构和技术架构。 应用架构：由应用架构师负责，他需要根据业务场景的需要，设计应用的层次结构，制定应用规范、定义接口和数据交互协议等。并尽量将应用的复杂度控制在一个可以接受的水平，从而在快速的支撑业务发展的同时，在保证系统的可用性和可维...</div></div></div></a><a class="pagination-related" href="/2019/09/26/%E6%9E%B6%E6%9E%84%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E7%AC%94%E8%AE%B0/" title="架构整洁之道笔记"><img class="cover" src="/img/wall-paper-123.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-26</div><div class="info-item-2">架构整洁之道笔记</div></div><div class="info-2"><div class="info-item-1">最早的《The Clean Architecture》诞生于 2012年，这个问题很早就被讨论清楚了。 思维导图：   注意，所有的接口都是在高层声明的：UseCase Input Port 和 UseCase Output port，所以高层可以实现高层的接口，低层也可以实现高层的接口。 注意，sofa的分层就是在一个横向的模块里声明了业务用例的接口和 core-model 的接口，这样源代码级的依赖都集中在抽象上：   Use Case Interactor 和 Presenter 应该是可测试的，而 Data Access Interface、View、ORM 应该是 humble object。所以一个应用的低层（外层）应该是被排除掉不做测试的。 附件下载： xmind 关于源代码中的依赖关系的一些澄清：  “使用”并不意味着“定义”，而只是引用  dashed outline 代表虚线框，也代表抽象。           </div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">背景介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">如何保护系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9-workload-%E8%BF%9B%E8%A1%8C%E5%88%86%E7%BA%A7"><span class="toc-number">2.1.</span> <span class="toc-text">对 workload 进行分级</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E4%BB%B6%E5%88%A9%E5%99%A8"><span class="toc-number">2.2.</span> <span class="toc-text">三件利器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98"><span class="toc-number">2.2.1.</span> <span class="toc-text">缓存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%8D%E7%BA%A7"><span class="toc-number">2.2.2.</span> <span class="toc-text">降级</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%90%E6%B5%81"><span class="toc-number">2.2.3.</span> <span class="toc-text">限流</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">开始谈谈限流</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%A0%E4%B8%AA%E6%A6%82%E5%BF%B5%E7%9A%84%E5%BB%93%E6%B8%85"><span class="toc-number">3.1.</span> <span class="toc-text">几个概念的廓清</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%90%E6%B5%81-rate-limiting-vs-%E9%99%90%E9%A2%91-frequency-limiting"><span class="toc-number">3.1.1.</span> <span class="toc-text">限流 (Rate Limiting) VS 限频 (Frequency Limiting)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E9%87%8F%E6%95%B4%E5%BD%A2-traffic-shaping-vs-%E6%B5%81%E9%87%8F%E8%8A%82%E6%B5%81-throttling-vs-%E8%83%8C%E5%8E%8B-back-pressure"><span class="toc-number">3.1.2.</span> <span class="toc-text">流量整形 (Traffic Shaping) VS 流量节流 (Throttling) VS 背压 (Back Pressure)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#qps%E9%99%90%E6%B5%81%EF%BC%9A%E5%8F%91%E7%94%9F%E6%95%B0%E9%87%8F-vs-%E5%AE%8C%E6%88%90%E6%95%B0%E9%87%8F"><span class="toc-number">3.1.3.</span> <span class="toc-text">QPS限流：发生数量 VS 完成数量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">常见的限流算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#little-s-law-%E5%88%A9%E7%89%B9%E5%B0%94%E5%AE%9A%E5%BE%8B%E7%9A%84%E6%8E%A8%E8%AE%BA"><span class="toc-number">4.1.</span> <span class="toc-text">Little’s Law 利特尔定律的推论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%99%BA%E5%8A%9B%E6%B8%B8%E6%88%8F%E6%8E%A8%E8%AE%BA"><span class="toc-number">4.1.1.</span> <span class="toc-text">智力游戏推论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%B6%E5%8F%91%E6%80%A7%E6%8E%A8%E8%AE%BA"><span class="toc-number">4.1.2.</span> <span class="toc-text">并发性推论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E6%95%B0%E5%99%A8%E7%AE%97%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">计数器算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%B6%E5%8F%91%E8%AE%A1%E6%95%B0%E5%99%A8-concurrency-limiter"><span class="toc-number">4.2.1.</span> <span class="toc-text">并发计数器 Concurrency Limiter</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E5%8E%9F%E5%9E%8B"><span class="toc-number">4.2.1.1.</span> <span class="toc-text">方法原型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#semaphore-%E7%89%88%E6%9C%AC"><span class="toc-number">4.2.1.2.</span> <span class="toc-text">Semaphore 版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%BB%E5%A1%9E%E4%B8%8E%E8%87%AA%E6%97%8B"><span class="toc-number">4.2.1.3.</span> <span class="toc-text">阻塞与自旋</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.2.1.4.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rate-limiter-algorithm"><span class="toc-number">4.2.2.</span> <span class="toc-text">Rate Limiter Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%BA%E5%AE%9A%E7%AA%97%E5%8F%A3%E8%AE%A1%E6%95%B0%E5%99%A8-fixed-window-counter"><span class="toc-number">4.2.2.1.</span> <span class="toc-text">固定窗口计数器 (Fixed Window Counter)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%99%E7%A7%8D-qps-%E7%AE%97%E6%B3%95%E7%9A%84%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3-%E6%9C%80%E5%A5%BD%E8%AE%BE%E7%BD%AE%E4%B8%BA1%E7%A7%92%E4%B8%BA%E5%8D%95%E4%BD%8D"><span class="toc-number">4.2.2.1.1.</span> <span class="toc-text">这种 QPS 算法的时间窗口，最好设置为1秒为单位</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%97%A5%E5%BF%97-sliding-window-log"><span class="toc-number">4.2.2.2.</span> <span class="toc-text">滑动窗口日志 (Sliding Window Log)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-java-util-linkedlist-%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83"><span class="toc-number">4.2.2.2.1.</span> <span class="toc-text">基于 java.util.LinkedList (单机环境)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-redis-zset-%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83"><span class="toc-number">4.2.2.2.2.</span> <span class="toc-text">基于 Redis ZSET (分布式环境)</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-multi-exec"><span class="toc-number">4.2.2.2.2.1.</span> <span class="toc-text">基于 multi&#x2F;exec</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-zset"><span class="toc-number">4.2.2.2.2.2.</span> <span class="toc-text">基于 zset</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.2.2.2.2.3.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E5%99%A8%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%9Aredis-%E4%BA%8B%E5%8A%A1-vs-lua-%E8%84%9A%E6%9C%AC%E5%AF%B9%E6%AF%94"><span class="toc-number">4.2.3.</span> <span class="toc-text">分布式限流器场景下：Redis 事务 VS Lua 脚本对比</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E8%AE%A1%E6%95%B0%E5%99%A8-sliding-window-counter"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">滑动窗口计数器 (Sliding Window Counter)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%8E%E7%90%86%E8%AE%BA%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="toc-number">4.2.3.1.1.</span> <span class="toc-text">代码与理论的对应关系</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%98%E7%82%B9%E4%B8%8E%E7%BC%BA%E7%82%B9"><span class="toc-number">4.2.3.1.2.</span> <span class="toc-text">优点与缺点</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%B6%E7%AE%97%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">桶算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%B2%E5%AD%A6%E5%B7%AE%E5%BC%82"><span class="toc-number">4.3.1.</span> <span class="toc-text">哲学差异</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%A1%E6%8E%A7%E5%85%A5%E5%8F%A3-ingress-vs-%E7%AE%A1%E6%8E%A7%E5%87%BA%E5%8F%A3-egress"><span class="toc-number">4.3.1.1.</span> <span class="toc-text">管控入口 (Ingress) VS 管控出口 (Egress)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%A1%E6%8E%A7%E9%80%BB%E8%BE%91%E4%B8%8E%E7%8A%B6%E6%80%81%E6%A0%B8%E5%BF%83"><span class="toc-number">4.3.1.2.</span> <span class="toc-text">管控逻辑与状态核心</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A4%E7%89%8C%E6%A1%B6-vs-%E6%BC%8F%E6%A1%B6"><span class="toc-number">4.3.1.3.</span> <span class="toc-text">令牌桶 VS 漏桶</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95"><span class="toc-number">4.3.2.</span> <span class="toc-text">漏桶算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#java-%E7%9A%84%E6%B5%81%E9%87%8F%E6%95%B4%E5%BD%A2%E5%99%A8-traffic-shaper"><span class="toc-number">4.3.2.1.</span> <span class="toc-text">java 的流量整形器 (Traffic Shaper)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#java-%E7%9A%84%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6%E5%99%A8-rate-limiter"><span class="toc-number">4.3.2.2.</span> <span class="toc-text">java 的速率限制器 (Rate Limiter)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gcra-%E9%80%9A%E7%94%A8%E4%BF%A1%E5%85%83%E9%80%9F%E7%8E%87%E7%AE%97%E6%B3%95-generic-cell-rate-algorithm"><span class="toc-number">4.3.2.3.</span> <span class="toc-text">GCRA 通用信元速率算法（generic cell rate algorithm）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8E%E5%AE%9E%E4%BD%93%E6%BC%8F%E6%A1%B6%E5%88%B0-gcra%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E7%9A%84%E8%BD%AC%E5%8F%98"><span class="toc-number">4.3.2.3.1.</span> <span class="toc-text">从实体漏桶到 GCRA：核心思想的转变</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E7%9A%84-5-%E6%9D%A1%E8%AE%BE%E5%AE%9A"><span class="toc-number">4.3.2.3.2.</span> <span class="toc-text">基础的 5 条设定</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95-vs-gcra"><span class="toc-number">4.3.2.3.2.1.</span> <span class="toc-text">漏桶算法 VS GCRA</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%88%B0%E5%BA%95%E4%BB%80%E4%B9%88%E6%98%AF-burst%EF%BC%9F"><span class="toc-number">4.3.2.3.2.2.</span> <span class="toc-text">到底什么是 Burst？</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#max-%E5%87%BD%E6%95%B0%EF%BC%9A%E9%94%9A%E5%AE%9A%E9%99%90%E6%B5%81%E8%AE%A1%E7%AE%97%E7%9A%84%E8%B5%B7%E7%82%B9"><span class="toc-number">4.3.2.3.2.3.</span> <span class="toc-text">max() 函数：锚定限流计算的起点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E6%8E%A8%E5%AF%BC"><span class="toc-number">4.3.2.4.</span> <span class="toc-text">反向推导</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">4.3.3.</span> <span class="toc-text">结论</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%98%8E%E6%98%9F%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="toc-number">4.3.3.0.1.</span> <span class="toc-text">明星的例子</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4-java-%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.3.3.0.2.</span> <span class="toc-text">完整 java 实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%A6%E4%B8%80%E7%A7%8D-go-%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.3.3.0.3.</span> <span class="toc-text">另一种 go 的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E7%9A%84%E8%83%BD%E5%8A%9B%E5%B0%81%E8%A3%85-limiter-go"><span class="toc-number">4.3.3.0.3.1.</span> <span class="toc-text">基础的能力封装 limiter.go</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#qps-limiter-go"><span class="toc-number">4.3.3.0.3.2.</span> <span class="toc-text">qps_limiter.go</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#qpm-limiter-go"><span class="toc-number">4.3.3.0.3.3.</span> <span class="toc-text">qpm_limiter.go</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#qpd-limiter-go"><span class="toc-number">4.3.3.0.3.4.</span> <span class="toc-text">qpd_limiter.go</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%BB%E9%99%90%E6%B5%81%E5%99%A8"><span class="toc-number">4.3.3.0.3.5.</span> <span class="toc-text">主限流器</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.3.3.0.3.6.</span> <span class="toc-text">底层实现</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%88%E5%A2%9E%E5%8A%A0-tat-%E8%BF%98%E6%98%AF%E5%90%8E%E5%A2%9E%E5%8A%A0-tat%EF%BC%9A%E5%9F%BA%E4%BA%8E%E8%BF%87%E5%8E%BB%E7%8A%B6%E6%80%81%E8%A3%81%E5%86%B3-vs-%E5%9F%BA%E4%BA%8E%E6%9C%AA%E6%9D%A5%E7%8A%B6%E6%80%81%E8%A3%81%E5%86%B3"><span class="toc-number">4.3.3.0.4.</span> <span class="toc-text">先增加 TAT 还是后增加 TAT：基于过去状态裁决 VS 基于未来状态裁决</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B7%AE%E5%BC%82%EF%BC%9A%E5%88%A4%E6%96%AD%E5%9F%BA%E5%87%86%E4%B8%8D%E5%90%8C"><span class="toc-number">4.3.4.</span> <span class="toc-text">算法的核心差异：判断基准不同</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-java-%E5%AE%9E%E7%8E%B0%EF%BC%9A%E5%9F%BA%E4%BA%8E-%E8%BF%87%E5%8E%BB-%E7%9A%84%E7%8A%B6%E6%80%81%E5%81%9A%E5%88%A4%E6%96%AD"><span class="toc-number">4.3.4.1.</span> <span class="toc-text">1. Java 实现：基于“过去”的状态做判断</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-redis-lua-%E5%AE%9E%E7%8E%B0%EF%BC%9A%E5%9F%BA%E4%BA%8E-%E6%9C%AA%E6%9D%A5-%E7%9A%84%E7%8A%B6%E6%80%81%E5%81%9A%E5%88%A4%E6%96%AD"><span class="toc-number">4.3.4.2.</span> <span class="toc-text">2. Redis Lua 实现：基于“未来”的状态做判断</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%AA%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%9B%B4%E4%BC%98%EF%BC%9F"><span class="toc-number">4.3.5.</span> <span class="toc-text">哪种实现更优？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95"><span class="toc-number">4.3.6.</span> <span class="toc-text">令牌桶算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BC%8F%E6%B0%B4-vs-%E7%A7%AF%E6%94%92%E4%BB%A4%E7%89%8C"><span class="toc-number">4.3.7.</span> <span class="toc-text">漏水 VS 积攒令牌</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E8%B5%84%E6%BA%90-%E7%8A%B6%E6%80%81%E5%8F%98%E9%87%8F-%E7%9A%84%E5%90%AB%E4%B9%89%E4%B8%8D%E5%90%8C"><span class="toc-number">4.3.7.1.</span> <span class="toc-text">核心资源（状态变量）的含义不同</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E6%9B%B4%E6%96%B0-%E6%93%8D%E4%BD%9C%E7%9A%84%E7%9B%AE%E7%9A%84%E6%88%AA%E7%84%B6%E7%9B%B8%E5%8F%8D"><span class="toc-number">4.3.7.2.</span> <span class="toc-text">“基于时间更新”操作的目的截然相反</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%8C%E4%B8%BA%E4%B8%8A%E7%9A%84%E6%A0%B9%E6%9C%AC%E5%B7%AE%E5%BC%82%EF%BC%9A%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%AA%81%E5%8F%91%E6%B5%81%E9%87%8F"><span class="toc-number">4.3.7.3.</span> <span class="toc-text">行为上的根本差异：如何处理突发流量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.3.7.4.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">Guava 的 RateLimiter 实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#smoothbursty"><span class="toc-number">5.1.</span> <span class="toc-text">SmoothBursty</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%AA%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">5.1.1.</span> <span class="toc-text">伪代码执行流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B"><span class="toc-number">5.1.2.</span> <span class="toc-text">使用实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#smoothwarmingup"><span class="toc-number">5.2.</span> <span class="toc-text">SmoothWarmingUp</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%AA%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">5.2.1.</span> <span class="toc-text">伪代码执行流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B"><span class="toc-number">5.2.2.</span> <span class="toc-text">使用实例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">我们应该如何在一台机器上限流</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">我们应该如何在分布式环境下限流</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E6%8E%A5%E5%85%A5%E5%B1%82-proxy-%E5%8D%95%E7%82%B9%E9%99%90%E6%B5%81-vs-%E5%9C%A8%E5%8D%95%E6%9C%BA%E4%B8%8A%E5%90%84%E8%87%AA%E9%99%90%E6%B5%81"><span class="toc-number">7.1.</span> <span class="toc-text">在接入层 proxy 单点限流 VS 在单机上各自限流</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A5%E5%85%A5%E5%B1%82%E5%90%8C%E6%AD%A5%E9%99%90%E6%B5%81"><span class="toc-number">7.1.1.</span> <span class="toc-text">接入层同步限流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%90%E6%B5%81%E7%9A%84%E9%A2%97%E7%B2%92%E5%BA%A6%E4%B8%8E%E7%BB%B4%E5%BA%A6"><span class="toc-number">7.1.2.</span> <span class="toc-text">限流的颗粒度与维度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A2%AB%E8%B0%83%E7%94%A8%E6%96%B9%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BB%B4%E5%BA%A6"><span class="toc-number">7.1.2.1.</span> <span class="toc-text">被调用方的隔离维度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E7%94%A8%E6%96%B9%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BB%B4%E5%BA%A6"><span class="toc-number">7.1.2.2.</span> <span class="toc-text">调用方的隔离维度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E8%B0%83%E8%80%85%E9%99%90%E6%B5%81"><span class="toc-number">7.1.3.</span> <span class="toc-text">协调者限流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-mq-%E7%9A%84%E9%99%90%E6%B5%81"><span class="toc-number">7.1.4.</span> <span class="toc-text">基于 mq 的限流</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text">最后做个总结</span></a></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2017 - 2025 By magicliang</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">簡</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>