<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>副本复制算法与架构——PacificA、Elasticsearch、Kafka、Pulsar 全面对比 | 守株阁</title><meta name="author" content="magicliang"><meta name="copyright" content="magicliang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文将深入剖析 PacificA、Elasticsearch、Kafka、Pulsar 四大分布式系统的副本复制机制，揭示它们在一致性、可用性和性能之间的精妙权衡。这些系统虽然都通过副本复制来保证数据可靠性和高可用性，但在具体的实现策略上各有特色，反映了不同的设计哲学和适用场景。  引言：为什么需要副本复制 数据可靠性与高可用性 在分布式系统中，硬件故障是常态而非例外。Google 的统计数据显示">
<meta property="og:type" content="article">
<meta property="og:title" content="副本复制算法与架构——PacificA、Elasticsearch、Kafka、Pulsar 全面对比">
<meta property="og:url" content="https://magicliang.github.io/2025/07/29/%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%B6%E6%9E%84/index.html">
<meta property="og:site_name" content="守株阁">
<meta property="og:description" content="本文将深入剖析 PacificA、Elasticsearch、Kafka、Pulsar 四大分布式系统的副本复制机制，揭示它们在一致性、可用性和性能之间的精妙权衡。这些系统虽然都通过副本复制来保证数据可靠性和高可用性，但在具体的实现策略上各有特色，反映了不同的设计哲学和适用场景。  引言：为什么需要副本复制 数据可靠性与高可用性 在分布式系统中，硬件故障是常态而非例外。Google 的统计数据显示">
<meta property="og:locale">
<meta property="og:image" content="https://magicliang.github.io/img/wall-paper-141.png">
<meta property="article:published_time" content="2025-07-29T07:05:34.000Z">
<meta property="article:modified_time" content="2026-02-07T06:10:52.128Z">
<meta property="article:author" content="magicliang">
<meta property="article:tag" content="一致性协议">
<meta property="article:tag" content="分布式系统">
<meta property="article:tag" content="系统设计">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://magicliang.github.io/img/wall-paper-141.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "副本复制算法与架构——PacificA、Elasticsearch、Kafka、Pulsar 全面对比",
  "url": "https://magicliang.github.io/2025/07/29/%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%B6%E6%9E%84/",
  "image": "https://magicliang.github.io/img/wall-paper-141.png",
  "datePublished": "2025-07-29T07:05:34.000Z",
  "dateModified": "2026-02-07T06:10:52.128Z",
  "author": [
    {
      "@type": "Person",
      "name": "magicliang",
      "url": "https://magicliang.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://magicliang.github.io/2025/07/29/%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%B6%E6%9E%84/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: magicliang","link":"Link: ","source":"Source: 守株阁","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '副本复制算法与架构——PacificA、Elasticsearch、Kafka、Pulsar 全面对比',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"><link rel="alternate" href="/atom.xml" title="守株阁" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      if ($loadingBox.classList.contains('loaded')) return
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()

  if (document.readyState === 'complete') {
    preloader.endLoading()
  } else {
    window.addEventListener('load', preloader.endLoading)
    document.addEventListener('DOMContentLoaded', preloader.endLoading)
    // Add timeout protection: force end after 7 seconds
    setTimeout(preloader.endLoading, 7000)
  }

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/wall-paper-141.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">守株阁</span></a><a class="nav-page-title" href="/"><span class="site-name">副本复制算法与架构——PacificA、Elasticsearch、Kafka、Pulsar 全面对比</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">副本复制算法与架构——PacificA、Elasticsearch、Kafka、Pulsar 全面对比</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-07-29T07:05:34.000Z" title="Created 2025-07-29 15:05:34">2025-07-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-07T06:10:52.128Z" title="Updated 2026-02-07 14:10:52">2026-02-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/">系统设计</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">5.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>18mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>本文将深入剖析 PacificA、Elasticsearch、Kafka、Pulsar 四大分布式系统的副本复制机制，揭示它们在一致性、可用性和性能之间的精妙权衡。这些系统虽然都通过副本复制来保证数据可靠性和高可用性，但在具体的实现策略上各有特色，反映了不同的设计哲学和适用场景。</p>
<hr>
<h2 id="引言：为什么需要副本复制">引言：为什么需要副本复制</h2>
<h3 id="数据可靠性与高可用性">数据可靠性与高可用性</h3>
<p>在分布式系统中，硬件故障是常态而非例外。Google 的统计数据显示，一个拥有 10,000 台服务器的数据中心，每天平均会有 2-3 台服务器发生故障。如果数据只存储在一台机器上，那么这台机器的故障就意味着数据的永久丢失。</p>
<p><strong>副本复制（Replication）</strong> 是解决这个问题的核心手段：将数据复制到多台机器上，即使部分机器故障，数据仍然可用。</p>
<h3 id="cap-定理的实际影响">CAP 定理的实际影响</h3>
<p>CAP 定理告诉我们，在网络分区（Partition）发生时，分布式系统只能在**一致性（Consistency）<strong>和</strong>可用性（Availability）**之间二选一：</p>
<table>
<thead>
<tr>
<th>选择</th>
<th>含义</th>
<th>代表系统</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CP</strong></td>
<td>网络分区时拒绝服务，保证一致性</td>
<td>ZooKeeper、etcd、HBase</td>
</tr>
<tr>
<td><strong>AP</strong></td>
<td>网络分区时继续服务，允许不一致</td>
<td>Cassandra、DynamoDB</td>
</tr>
</tbody>
</table>
<p>实际系统通常不是简单的 CP 或 AP，而是在不同操作和配置下提供不同的一致性级别。</p>
<h3 id="副本复制的核心挑战">副本复制的核心挑战</h3>
<p>副本复制需要解决三个核心问题：</p>
<ol>
<li><strong>一致性</strong>：所有副本看到的数据是否相同？</li>
<li><strong>可用性</strong>：部分副本故障时，系统是否仍能提供服务？</li>
<li><strong>性能</strong>：复制操作对写入延迟和吞吐量的影响有多大？</li>
</ol>
<hr>
<h2 id="part-1-副本复制的基础理论">Part 1: 副本复制的基础理论</h2>
<h3 id="同步复制-vs-异步复制">同步复制 vs 异步复制</h3>
<table>
<thead>
<tr>
<th>模式</th>
<th>写入流程</th>
<th>一致性</th>
<th>延迟</th>
<th>可用性</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>同步复制</strong></td>
<td>等待所有副本确认后才返回成功</td>
<td>强一致</td>
<td>高（受最慢副本影响）</td>
<td>低（任一副本故障阻塞写入）</td>
</tr>
<tr>
<td><strong>异步复制</strong></td>
<td>主副本写入成功即返回</td>
<td>最终一致</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td><strong>半同步复制</strong></td>
<td>等待部分副本（Quorum）确认</td>
<td>可调一致性</td>
<td>中等</td>
<td>中等</td>
</tr>
</tbody>
</table>
<h3 id="主从复制的三种模型">主从复制的三种模型</h3>
<p><strong>单主复制（Single-Leader）</strong>：</p>
<ul>
<li>所有写入都经过一个主节点</li>
<li>从节点从主节点复制数据</li>
<li>代表：MySQL 主从、Kafka、Elasticsearch</li>
</ul>
<p><strong>多主复制（Multi-Leader）</strong>：</p>
<ul>
<li>多个节点都可以接受写入</li>
<li>需要解决写入冲突</li>
<li>代表：CockroachDB、TiDB（Raft Group 级别）</li>
</ul>
<p><strong>无主复制（Leaderless）</strong>：</p>
<ul>
<li>任何节点都可以接受读写</li>
<li>使用 Quorum 机制保证一致性</li>
<li>代表：Cassandra、DynamoDB、Riak</li>
</ul>
<h3 id="quorum-机制">Quorum 机制</h3>
<p>Quorum 机制通过 <strong>W + R &gt; N</strong> 来保证读取到最新数据：</p>
<ul>
<li><strong>N</strong>：副本总数</li>
<li><strong>W</strong>：写入时需要确认的副本数</li>
<li><strong>R</strong>：读取时需要查询的副本数</li>
</ul>
<p>例如，N=3, W=2, R=2：写入需要 2 个副本确认，读取需要查询 2 个副本。由于 W + R = 4 &gt; 3 = N，读取的 2 个副本中至少有 1 个包含最新数据。</p>
<h3 id="脑裂问题">脑裂问题</h3>
<p><strong>脑裂（Split-Brain）</strong> 是分布式系统中最危险的故障之一：网络分区导致两个节点都认为自己是主节点，同时接受写入，导致数据不一致。</p>
<p>解决方案：</p>
<ul>
<li><strong>Fencing（隔离）</strong>：通过 STONITH（Shoot The Other Node In The Head）强制关闭旧主节点</li>
<li><strong>Lease（租约）</strong>：主节点持有一个有时效的租约，租约过期前其他节点不能成为主节点</li>
<li><strong>Epoch/Term</strong>：每次选举递增一个编号，旧编号的主节点的写入被拒绝</li>
</ul>
<hr>
<h2 id="part-2-pacifica-协议">Part 2: PacificA 协议</h2>
<h3 id="论文背景">论文背景</h3>
<p>PacificA 是微软研究院在 2008 年发表的论文《PacificA: Replication in Log-Based Distributed Storage Systems》中提出的复制协议。它的设计目标是为日志结构的分布式存储系统提供<strong>强一致性</strong>的复制方案。</p>
<h3 id="核心架构">核心架构</h3>
<pre><code class="hljs mermaid">graph TD
    CM[Configuration Manager&lt;br/&gt;全局元数据管理]
    P[Primary&lt;br/&gt;接受所有读写] --&gt; S1[Secondary 1&lt;br/&gt;被动复制]
    P --&gt; S2[Secondary 2&lt;br/&gt;被动复制]
    P --&gt; S3[Secondary 3&lt;br/&gt;被动复制]
    CM -.-&gt;|管理配置| P
    CM -.-&gt;|管理配置| S1
    CM -.-&gt;|管理配置| S2
    CM -.-&gt;|管理配置| S3</code></pre>
<p>PacificA 的架构由三个角色组成：</p>
<table>
<thead>
<tr>
<th>角色</th>
<th>职责</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Primary</strong></td>
<td>接受所有读写请求</td>
<td>同一时刻只有一个</td>
</tr>
<tr>
<td><strong>Secondary</strong></td>
<td>被动复制 Primary 的数据</td>
<td>可以有多个</td>
</tr>
<tr>
<td><strong>Configuration Manager</strong></td>
<td>管理副本组的配置信息</td>
<td>全局唯一，类似 ZooKeeper</td>
</tr>
</tbody>
</table>
<h3 id="write-all-强一致性语义">Write-All 强一致性语义</h3>
<p>PacificA 的写入流程：</p>
<ol>
<li>客户端将写入请求发送给 Primary</li>
<li>Primary 将操作追加到本地日志</li>
<li>Primary 将操作<strong>并行发送</strong>给所有 Secondary</li>
<li><strong>所有 Secondary 确认</strong>后，Primary 才向客户端返回成功</li>
<li>Primary 推进 Committed Point（提交点）</li>
</ol>
<p>这就是 <strong>Write-All</strong> 语义：所有副本都必须确认，才算写入成功。</p>
<h3 id="故障检测与-primary-切换">故障检测与 Primary 切换</h3>
<p>PacificA 使用 <strong>Lease（租约）</strong> 机制进行故障检测：</p>
<ol>
<li>Primary 定期向所有 Secondary 发送心跳（同时也是 Lease 续约）</li>
<li>如果 Secondary 在 Lease 超时内没有收到心跳，它会向 Configuration Manager 报告 Primary 故障</li>
<li>Configuration Manager 选择一个数据最新的 Secondary 作为新 Primary</li>
<li>新 Primary 开始接受读写请求</li>
</ol>
<p><strong>Lease 防止脑裂</strong>：旧 Primary 在 Lease 过期前不会被替换，而新 Primary 只有在 Configuration Manager 确认后才开始服务。这保证了任何时刻最多只有一个 Primary。</p>
<h3 id="日志复制与追赶机制">日志复制与追赶机制</h3>
<p>当一个 Secondary 落后于 Primary 时（例如刚从故障中恢复），它需要通过**追赶（Catch-up）**来同步数据：</p>
<ol>
<li>Secondary 向 Primary 报告自己的最新日志位置</li>
<li>Primary 将缺失的日志条目发送给 Secondary</li>
<li>Secondary 应用这些日志条目，直到追上 Primary</li>
<li>Secondary 重新加入副本组</li>
</ol>
<h3 id="reconfiguration-协议细节">Reconfiguration 协议细节</h3>
<p>PacificA 的 Reconfiguration 协议处理副本组的动态变更（添加/移除副本）：</p>
<ol>
<li><strong>配置版本控制</strong>：每个副本组配置都有一个递增的版本号（Configuration Version）</li>
<li><strong>两阶段提交</strong>：
<ul>
<li><strong>Prepare 阶段</strong>：Primary 向所有副本（包括新旧）发送 Prepare 请求，携带新配置</li>
<li><strong>Commit 阶段</strong>：所有副本确认后，Primary 广播 Commit，新配置生效</li>
</ul>
</li>
<li><strong>日志截断与恢复</strong>：
<ul>
<li>新加入的副本从 Primary 的最新日志位置开始复制</li>
<li>被移除的副本在完成已接收日志的复制后停止服务</li>
</ul>
</li>
<li><strong>原子性保证</strong>：通过 Configuration Manager 的全局锁确保同一时刻只有一个 Reconfiguration 在进行</li>
</ol>
<p>Reconfiguration 过程中，系统仍能服务写入请求（Write-All 语义基于当前配置），但读取操作可能短暂阻塞以保证一致性。</p>
<h3 id="优点与局限性">优点与局限性</h3>
<table>
<thead>
<tr>
<th>优点</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr>
<td>强一致性，读写都在 Primary</td>
<td>写入延迟受最慢副本影响</td>
</tr>
<tr>
<td>设计简单直观</td>
<td>Configuration Manager 是单点（需要自身高可用）</td>
</tr>
<tr>
<td>故障恢复流程清晰</td>
<td>Write-All 语义在副本数多时延迟高</td>
</tr>
<tr>
<td>Lease 机制有效防止脑裂</td>
<td>不适合跨数据中心部署（延迟太高）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="part-3-elasticsearch">Part 3: Elasticsearch</h2>
<h3 id="分片与副本模型">分片与副本模型</h3>
<p>Elasticsearch 将索引（Index）划分为多个<strong>分片（Shard）</strong>，每个分片可以有零个或多个<strong>副本（Replica）</strong>：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">Index</span>: products<br>├── Shard <span class="hljs-number">0</span> (<span class="hljs-keyword">Primary</span>) → <span class="hljs-keyword">Replica</span> <span class="hljs-number">0</span><span class="hljs-number">-1</span>, <span class="hljs-keyword">Replica</span> <span class="hljs-number">0</span><span class="hljs-number">-2</span><br>├── Shard <span class="hljs-number">1</span> (<span class="hljs-keyword">Primary</span>) → <span class="hljs-keyword">Replica</span> <span class="hljs-number">1</span><span class="hljs-number">-1</span>, <span class="hljs-keyword">Replica</span> <span class="hljs-number">1</span><span class="hljs-number">-2</span><br>└── Shard <span class="hljs-number">2</span> (<span class="hljs-keyword">Primary</span>) → <span class="hljs-keyword">Replica</span> <span class="hljs-number">2</span><span class="hljs-number">-1</span>, <span class="hljs-keyword">Replica</span> <span class="hljs-number">2</span><span class="hljs-number">-2</span><br></code></pre></td></tr></table></figure>
<p>每个分片本质上是一个独立的 Lucene 索引。分片的数量在索引创建时确定，之后不能更改（除非 Reindex）。</p>
<h3 id="master-node-的职责与选举">Master Node 的职责与选举</h3>
<p>ES 集群中有一个 <strong>Master Node</strong>，负责：</p>
<ul>
<li>管理集群状态（Cluster State）：哪些节点在线、分片分配在哪个节点</li>
<li>创建/删除索引</li>
<li>分配和重新分配分片</li>
</ul>
<p>Master 选举在 ES 7.x 后基于<strong>类 Raft 协议</strong>实现，取代了之前的 Zen Discovery。选举过程：</p>
<ol>
<li>节点发现彼此（通过种子节点列表）</li>
<li>具有 <code>master</code> 角色的节点参与选举</li>
<li>获得多数票的节点成为 Master</li>
<li>Master 发布集群状态更新</li>
</ol>
<h3 id="写入流程">写入流程</h3>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">客户端 → 协调节点 → Primary <span class="hljs-keyword">Shard </span>→ Replica <span class="hljs-keyword">Shard </span><span class="hljs-number">1</span><br>                                   → Replica <span class="hljs-keyword">Shard </span><span class="hljs-number">2</span><br>                                   → ...<br>                  ← 返回成功（所有 in-<span class="hljs-keyword">sync </span>副本确认后）<br></code></pre></td></tr></table></figure>
<p>详细步骤：</p>
<ol>
<li>客户端将写入请求发送给任意节点（该节点成为<strong>协调节点</strong>）</li>
<li>协调节点根据文档 ID 的哈希值确定目标 Primary Shard</li>
<li>请求被转发到 Primary Shard 所在的节点</li>
<li>Primary Shard 执行写入操作（写入 Translog + 内存 Buffer）</li>
<li>Primary Shard <strong>并行</strong>将操作转发给所有 In-Sync Replica</li>
<li>所有 In-Sync Replica 确认后，Primary 向协调节点返回成功</li>
<li>协调节点向客户端返回成功</li>
</ol>
<h3 id="translog-的作用">Translog 的作用</h3>
<p>Translog（Transaction Log）是 ES 的 WAL，保证数据持久性：</p>
<ul>
<li>每次写入操作都会先追加到 Translog</li>
<li>Translog 默认每 5 秒 fsync 一次（可配置为每次请求都 fsync）</li>
<li>当 Translog 达到一定大小时，触发 Flush 操作：将内存中的数据写入 Lucene Segment，并清空 Translog</li>
</ul>
<h3 id="segment-合并与-refresh">Segment 合并与 Refresh</h3>
<p>ES 的近实时搜索（NRT）依赖于 <strong>Refresh</strong> 机制：</p>
<ul>
<li><strong>Refresh</strong>（默认每 1 秒）：将内存 Buffer 中的数据写入一个新的 Lucene Segment（但不 fsync），使数据可被搜索</li>
<li><strong>Segment 合并</strong>：后台线程将多个小 Segment 合并为大 Segment，类似 LSM-Tree 的 Compaction</li>
</ul>
<h3 id="sequence-number-和-primary-term-机制">Sequence Number 和 Primary Term 机制</h3>
<p>ES 7.x 引入了 Sequence Number 和 Primary Term 机制来保证数据一致性：</p>
<ul>
<li><strong>Sequence Number</strong>：每个文档操作都有一个严格递增的序列号，用于标识操作的顺序</li>
<li><strong>Primary Term</strong>：每次 Primary 切换时递增，用于区分不同的 Primary 任期</li>
<li><strong>Checkpoints</strong>：每个副本维护本地 Checkpoint（已确认的最大 Sequence Number）</li>
</ul>
<p>当 Primary 切换时：</p>
<ol>
<li>新 Primary 从 Master 获取最新的 Allocation ID 和 Primary Term</li>
<li>新 Primary 接收写入时，会检查 Sequence Number 是否连续</li>
<li>如果发现空洞（缺失的序列号），会拒绝写入并请求副本同步</li>
<li>副本恢复时，基于 Sequence Number 进行增量同步，而非全量复制</li>
</ol>
<p>这个机制解决了之前版本可能出现的&quot;已删除文档复活&quot;问题，确保操作的线性一致性。</p>
<h3 id="es-对-pacifica-的变体实现">ES 对 PacificA 的变体实现</h3>
<p>ES 的复制模型是 PacificA 的变体：</p>
<table>
<thead>
<tr>
<th>PacificA 原始</th>
<th>ES 变体</th>
</tr>
</thead>
<tbody>
<tr>
<td>Configuration Manager</td>
<td>Master Node</td>
</tr>
<tr>
<td>Primary</td>
<td>Primary Shard</td>
</tr>
<tr>
<td>Secondary</td>
<td>Replica Shard</td>
</tr>
<tr>
<td>Write-All（所有副本）</td>
<td>Write to In-Sync Copies（同步副本集）</td>
</tr>
<tr>
<td>单一 Lease</td>
<td>基于 Cluster State 的分片分配</td>
</tr>
</tbody>
</table>
<p>关键区别：ES 使用 <strong>In-Sync Copies</strong> 而非严格的 Write-All。如果某个 Replica 响应太慢或故障，Master 会将其从 In-Sync 集合中移除，写入不再等待它。</p>
<hr>
<h2 id="part-4-kafka">Part 4: Kafka</h2>
<h3 id="partition-与-replica">Partition 与 Replica</h3>
<p>Kafka 的数据组织：</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-symbol">Topic:</span> <span class="hljs-keyword">orders</span><br><span class="hljs-keyword"></span>├── Partition <span class="hljs-number">0</span>: Leader(<span class="hljs-keyword">Broker </span><span class="hljs-number">1</span>) → Follower(<span class="hljs-keyword">Broker </span><span class="hljs-number">2</span>), Follower(<span class="hljs-keyword">Broker </span><span class="hljs-number">3</span>)<br>├── Partition <span class="hljs-number">1</span>: Leader(<span class="hljs-keyword">Broker </span><span class="hljs-number">2</span>) → Follower(<span class="hljs-keyword">Broker </span><span class="hljs-number">3</span>), Follower(<span class="hljs-keyword">Broker </span><span class="hljs-number">1</span>)<br>└── Partition <span class="hljs-number">2</span>: Leader(<span class="hljs-keyword">Broker </span><span class="hljs-number">3</span>) → Follower(<span class="hljs-keyword">Broker </span><span class="hljs-number">1</span>), Follower(<span class="hljs-keyword">Broker </span><span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<p>每个 Partition 是一个有序的、不可变的消息序列（日志）。每个 Partition 有一个 <strong>Leader</strong> 和零个或多个 <strong>Follower</strong>。</p>
<h3 id="isr-机制详解">ISR 机制详解</h3>
<p><strong>ISR（In-Sync Replicas）</strong> 是 Kafka 复制模型的核心概念：</p>
<ul>
<li>ISR 是一个<strong>动态维护</strong>的副本集合，包含与 Leader 保持同步的所有副本</li>
<li>判断标准：Follower 的复制延迟不超过 <code>replica.lag.time.max.ms</code>（默认 30 秒）</li>
<li>如果 Follower 落后太多，会被从 ISR 中移除</li>
<li>当 Follower 追上 Leader 后，会被重新加入 ISR</li>
</ul>
<p>ISR 的动态性使得 Kafka 在一致性和可用性之间取得了灵活的平衡。</p>
<h4 id="replica-lag-time-max-ms-参数调优建议"><a target="_blank" rel="noopener" href="http://replica.lag.time.max.ms">replica.lag.time.max.ms</a> 参数调优建议</h4>
<p><code>replica.lag.time.max.ms</code> 控制 Follower 被踢出 ISR 的超时时间，调优建议：</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>推荐值</th>
<th>理由</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>标准生产环境</strong></td>
<td>30000（默认）</td>
<td>平衡一致性和可用性，容忍短暂的网络抖动</td>
</tr>
<tr>
<td><strong>低延迟网络</strong></td>
<td>10000-15000</td>
<td>更快检测故障副本，减少 ISR 收缩时间</td>
</tr>
<tr>
<td><strong>高延迟或跨数据中心</strong></td>
<td>60000-120000</td>
<td>容忍更高的网络延迟，避免频繁 ISR 抖动</td>
</tr>
<tr>
<td><strong>批处理场景</strong></td>
<td>300000+</td>
<td>允许更长的追赶时间，最大化可用性</td>
</tr>
</tbody>
</table>
<p><strong>注意事项</strong>：</p>
<ul>
<li>设置过小（&lt; 5000ms）会导致网络抖动时频繁 ISR 收缩，影响吞吐</li>
<li>设置过大（&gt; 300000ms）会导致故障检测延迟，延长数据不一致窗口</li>
<li>应配合 <code>min.insync.replicas</code> 使用，确保即使 ISR 收缩仍有足够副本保证持久性</li>
</ul>
<h3 id="acks-参数的三种模式">acks 参数的三种模式</h3>
<p>Producer 的 <code>acks</code> 参数控制写入的持久性保证：</p>
<table>
<thead>
<tr>
<th>acks 值</th>
<th>含义</th>
<th>持久性</th>
<th>延迟</th>
<th>吞吐量</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0</strong></td>
<td>不等待任何确认</td>
<td>最低（可能丢数据）</td>
<td>最低</td>
<td>最高</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>等待 Leader 确认</td>
<td>中等（Leader 故障可能丢数据）</td>
<td>中等</td>
<td>中等</td>
</tr>
<tr>
<td><strong>all (-1)</strong></td>
<td>等待所有 ISR 副本确认</td>
<td>最高</td>
<td>最高</td>
<td>最低</td>
</tr>
</tbody>
</table>
<p><code>acks=all</code> 配合 <code>min.insync.replicas=2</code>（至少 2 个 ISR 副本）是生产环境推荐的配置。</p>
<h3 id="controller-的角色">Controller 的角色</h3>
<p>Kafka 集群中有一个 <strong>Controller</strong>（由某个 Broker 担任），负责：</p>
<ul>
<li>监控 Broker 的上下线</li>
<li>管理 Partition 的 Leader 选举</li>
<li>管理副本的 ISR 变更</li>
<li>处理 Topic 的创建和删除</li>
</ul>
<h3 id="unclean-leader-election">Unclean Leader Election</h3>
<p>当 ISR 中所有副本都故障时，Kafka 面临一个艰难的选择：</p>
<table>
<thead>
<tr>
<th>配置</th>
<th>行为</th>
<th>权衡</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>unclean.leader.election.enable=false</code>（默认）</td>
<td>Partition 不可用，等待 ISR 中的副本恢复</td>
<td>保证一致性，牺牲可用性</td>
</tr>
<tr>
<td><code>unclean.leader.election.enable=true</code></td>
<td>允许非 ISR 副本成为 Leader</td>
<td>保证可用性，可能丢数据</td>
</tr>
</tbody>
</table>
<h3 id="kraft-模式：去-zookeeper-化">KRaft 模式：去 ZooKeeper 化</h3>
<p>Kafka 3.x 引入了 <strong>KRaft（Kafka Raft）</strong> 模式，用内置的 Raft 协议替代 ZooKeeper：</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>ZooKeeper 模式</th>
<th>KRaft 模式</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>元数据管理</strong></td>
<td>外部 ZooKeeper 集群</td>
<td>内置 Raft 协议</td>
</tr>
<tr>
<td><strong>运维复杂度</strong></td>
<td>需要维护两套集群</td>
<td>只需维护 Kafka</td>
</tr>
<tr>
<td><strong>元数据延迟</strong></td>
<td>通过 ZooKeeper 间接通信</td>
<td>直接在 Broker 间同步</td>
</tr>
<tr>
<td><strong>扩展性</strong></td>
<td>受 ZooKeeper 限制</td>
<td>更好的扩展性</td>
</tr>
</tbody>
</table>
<h3 id="高水位与-leader-epoch">高水位与 Leader Epoch</h3>
<p><strong>高水位（High Watermark, HW）</strong> 是 Kafka 保证一致性的关键机制：</p>
<ul>
<li>HW 表示所有 ISR 副本都已复制到的最大偏移量</li>
<li>消费者只能读取 HW 之前的消息</li>
<li>Leader 故障切换时，新 Leader 会将日志截断到 HW</li>
</ul>
<p><strong>Leader Epoch</strong> 解决了 HW 机制的一个边界问题：</p>
<ul>
<li>每次 Leader 切换时，Epoch 递增</li>
<li>Follower 恢复时，先向 Leader 查询自己 Epoch 对应的结束偏移量</li>
<li>避免了基于 HW 截断可能导致的数据不一致</li>
</ul>
<pre><code class="hljs mermaid">graph TD
    Controller[Controller&lt;br/&gt;Partition 管理]
    L[Leader Broker&lt;br/&gt;接受读写] --&gt; F1[Follower 1&lt;br/&gt;ISR 成员]
    L --&gt; F2[Follower 2&lt;br/&gt;ISR 成员]
    Controller -.-&gt;|Leader 选举| L
    Controller -.-&gt;|ISR 管理| F1
    Controller -.-&gt;|ISR 管理| F2</code></pre>
<hr>
<h2 id="part-5-pulsar">Part 5: Pulsar</h2>
<h3 id="存算分离架构">存算分离架构</h3>
<p>Pulsar 的最大特点是<strong>存算分离</strong>：计算层（Broker）和存储层（BookKeeper）完全解耦。</p>
<pre><code class="hljs mermaid">graph TD
    ZK[ZooKeeper&lt;br/&gt;元数据管理]
    B1[Broker 1&lt;br/&gt;无状态] --&gt; BK1[Bookie 1]
    B1 --&gt; BK2[Bookie 2]
    B1 --&gt; BK3[Bookie 3]
    B2[Broker 2&lt;br/&gt;无状态] --&gt; BK1
    B2 --&gt; BK2
    B2 --&gt; BK3
    ZK -.-&gt; B1
    ZK -.-&gt; B2
    ZK -.-&gt; BK1
    ZK -.-&gt; BK2
    ZK -.-&gt; BK3</code></pre>
<table>
<thead>
<tr>
<th>组件</th>
<th>角色</th>
<th>状态</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Broker</strong></td>
<td>接受客户端请求，处理消息路由</td>
<td><strong>无状态</strong>——不存储任何消息数据</td>
</tr>
<tr>
<td><strong>Bookie（BookKeeper）</strong></td>
<td>存储消息数据</td>
<td><strong>有状态</strong>——持久化存储</td>
</tr>
<tr>
<td><strong>ZooKeeper</strong></td>
<td>管理元数据、服务发现</td>
<td>有状态</td>
</tr>
</tbody>
</table>
<h3 id="ledger-与-fragment">Ledger 与 Fragment</h3>
<p>Pulsar 的消息存储使用 BookKeeper 的 <strong>Ledger</strong> 概念：</p>
<ul>
<li><strong>Ledger</strong>：一个有序的、不可变的日志段。一个 Topic 的消息被分成多个 Ledger</li>
<li><strong>Fragment</strong>：一个 Ledger 内部的分段。当 Bookie 故障时，新的 Fragment 会被分配到其他 Bookie</li>
<li><strong>Entry</strong>：Ledger 中的一条记录（对应一条或一批消息）</li>
</ul>
<h3 id="bookie-ensemble-的写入机制">Bookie Ensemble 的写入机制</h3>
<p>BookKeeper 使用 <strong>Ensemble</strong> 机制来分散写入负载：</p>
<ul>
<li><strong>Ensemble Size (E)</strong>：参与存储一个 Ledger 的 Bookie 总数</li>
<li><strong>Write Quorum (WQ)</strong>：每条 Entry 写入的 Bookie 数量</li>
<li><strong>Ack Quorum (AQ)</strong>：需要确认的 Bookie 数量</li>
</ul>
<p>例如，E=5, WQ=3, AQ=2：</p>
<ul>
<li>每条消息写入 5 个 Bookie 中的 3 个（通过 Round-Robin 选择）</li>
<li>其中 2 个确认即返回成功</li>
</ul>
<p>这种设计比 Kafka 的 ISR 更灵活：</p>
<ul>
<li>写入负载分散到更多节点</li>
<li>不需要所有副本都在线</li>
<li>单个 Bookie 故障不影响写入</li>
</ul>
<h3 id="journal-与-ledger-storage-分离设计">Journal 与 Ledger Storage 分离设计</h3>
<p>BookKeeper 采用 Journal 和 Ledger Storage 分离的存储架构，这是 Pulsar 高性能的关键：</p>
<h4 id="journal-预写日志">Journal（预写日志）</h4>
<ul>
<li><strong>作用</strong>：类似数据库的 WAL，提供持久性和崩溃恢复能力</li>
<li><strong>写入路径</strong>：所有 Entry 先顺序写入 Journal（追加写），再异步写入 Ledger Storage</li>
<li><strong>特点</strong>：
<ul>
<li>严格的顺序写入，充分利用磁盘带宽</li>
<li>默认配置为 fsync 每次写入（保证持久性）</li>
<li>Journal 文件大小固定（默认 1GB），写满后滚动</li>
</ul>
</li>
<li><strong>恢复流程</strong>：Bookie 重启时，先从 Journal 恢复未刷盘的 Entry，再应用到 Ledger Storage</li>
</ul>
<h4 id="ledger-storage-数据文件">Ledger Storage（数据文件）</h4>
<ul>
<li><strong>作用</strong>：实际存储 Entry 数据，支持随机读取</li>
<li><strong>类型</strong>：
<ul>
<li><strong>Interleaved Ledger Storage</strong>：所有 Ledger 的 Entry 混存（默认，兼容性好）</li>
<li><strong>Separate Ledger Storage</strong>：每个 Ledger 独立文件（读写隔离更好）</li>
</ul>
</li>
<li><strong>写入策略</strong>：异步批量写入，合并多个 Entry 的 fsync 操作</li>
<li><strong>读取优化</strong>：基于索引文件的快速定位，支持从任意位置读取</li>
</ul>
<h4 id="性能优化">性能优化</h4>
<p>分离设计带来的性能优势：</p>
<ol>
<li><strong>写入优化</strong>：Journal 顺序写 + Ledger Storage 批量写，最大化吞吐</li>
<li><strong>读取优化</strong>：Ledger Storage 支持并发读取，不受 Journal 限制</li>
<li><strong>恢复优化</strong>：仅从 Journal 恢复少量未刷盘数据，启动快速</li>
<li><strong>存储分层</strong>：Journal 可放在 SSD，Ledger Storage 放在 HDD，成本最优</li>
</ol>
<p><strong>配置建议</strong>：</p>
<ul>
<li>Journal：使用 SSD，配置 <code>journalSyncData=true</code>（强一致）</li>
<li>Ledger Storage：使用 HDD，配置 <code>ledgerStorageClass=interleaved</code>（默认）或 <code>separate</code>（多租户场景）</li>
</ul>
<h3 id="broker-故障恢复">Broker 故障恢复</h3>
<p>由于 Broker 是<strong>无状态</strong>的，故障恢复极其简单：</p>
<ol>
<li>Broker 1 故障</li>
<li>其负责的 Topic 被重新分配给 Broker 2</li>
<li>Broker 2 从 BookKeeper 读取元数据，开始服务</li>
<li><strong>无需数据迁移</strong>——数据始终在 BookKeeper 中</li>
</ol>
<p>恢复时间：<strong>秒级</strong>（对比 Kafka 的分钟级甚至小时级）。</p>
<h3 id="bookie-故障恢复">Bookie 故障恢复</h3>
<p>当一个 Bookie 故障时：</p>
<ol>
<li>BookKeeper 检测到 Bookie 不可用</li>
<li>当前 Ledger 的 Fragment 被关闭</li>
<li>新的 Fragment 被分配到其他健康的 Bookie</li>
<li>后台启动 <strong>Auto Re-replication</strong>：将故障 Bookie 上的数据复制到其他 Bookie</li>
</ol>
<h3 id="分层存储">分层存储</h3>
<p>Pulsar 支持<strong>分层存储（Tiered Storage）</strong>：将冷数据自动卸载到廉价存储（如 S3、HDFS）：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs armasm">热数据（最近的 Ledger）→ Bookie（SSD/HDD）<br>冷数据（旧的 Ledger）  → <span class="hljs-built_in">S3</span>/HDFS/GCS<br></code></pre></td></tr></table></figure>
<p>这使得 Pulsar 可以保留无限期的消息历史，而不会耗尽本地存储。</p>
<hr>
<h2 id="part-6-横向对比与选型指南">Part 6: 横向对比与选型指南</h2>
<h3 id="完整对比表">完整对比表</h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>PacificA 原始</th>
<th>Elasticsearch</th>
<th>Kafka</th>
<th>Pulsar</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>计算节点</strong></td>
<td>Primary</td>
<td>Data Node</td>
<td>Broker</td>
<td>Broker</td>
</tr>
<tr>
<td><strong>存储节点</strong></td>
<td>Secondary</td>
<td>Data Node（本地分片）</td>
<td>Broker（本地日志）</td>
<td>Bookie</td>
</tr>
<tr>
<td><strong>元数据节点</strong></td>
<td>Configuration Manager</td>
<td>Master Node</td>
<td>Controller (+ZK/KRaft)</td>
<td>ZooKeeper</td>
</tr>
<tr>
<td><strong>副本粒度</strong></td>
<td>任意对象</td>
<td>Shard</td>
<td>Partition</td>
<td>Ledger Fragment</td>
</tr>
<tr>
<td><strong>一致性协议</strong></td>
<td>强一致（Write-All）</td>
<td>PacificA 变体（In-Sync）</td>
<td>ISR 机制</td>
<td>Quorum + Ensemble</td>
</tr>
<tr>
<td><strong>存算分离</strong></td>
<td>否</td>
<td>否</td>
<td>否（Tiered Storage 部分支持）</td>
<td><strong>是</strong></td>
</tr>
<tr>
<td><strong>故障恢复时间</strong></td>
<td>秒-分钟级</td>
<td>分钟级</td>
<td>分钟-小时级</td>
<td><strong>秒级</strong></td>
</tr>
<tr>
<td><strong>写入延迟</strong></td>
<td>高（Write-All）</td>
<td>中等</td>
<td>可调（acks）</td>
<td>中等</td>
</tr>
<tr>
<td><strong>运维复杂度</strong></td>
<td>低</td>
<td>中等</td>
<td>中等（KRaft 后降低）</td>
<td>高（三套组件）</td>
</tr>
</tbody>
</table>
<h3 id="选型建议">选型建议</h3>
<table>
<thead>
<tr>
<th>场景</th>
<th>推荐系统</th>
<th>理由</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>全文搜索 + 日志分析</strong></td>
<td>Elasticsearch</td>
<td>Lucene 生态，强大的搜索和聚合能力</td>
</tr>
<tr>
<td><strong>高吞吐消息队列</strong></td>
<td>Kafka</td>
<td>成熟稳定，生态丰富，社区庞大</td>
</tr>
<tr>
<td><strong>多租户消息平台</strong></td>
<td>Pulsar</td>
<td>存算分离，天然支持多租户和弹性伸缩</td>
</tr>
<tr>
<td><strong>强一致性存储</strong></td>
<td>PacificA 变体</td>
<td>简单直观，适合自研存储系统</td>
</tr>
<tr>
<td><strong>云原生消息系统</strong></td>
<td>Pulsar</td>
<td>Broker 无状态，天然适合 Kubernetes</td>
</tr>
<tr>
<td><strong>流处理 + 消息队列</strong></td>
<td>Kafka</td>
<td>Kafka Streams / ksqlDB 生态</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="附录：raft-与-paxos-简介">附录：Raft 与 Paxos 简介</h2>
<h3 id="为什么-raft-比-paxos-更流行">为什么 Raft 比 Paxos 更流行</h3>
<p>Paxos 是 Leslie Lamport 在 1989 年提出的分布式共识算法，是理论上最早的共识协议之一。但 Paxos 以<strong>难以理解和实现</strong>著称。</p>
<p>Raft 是 Diego Ongaro 和 John Ousterhout 在 2014 年提出的，其设计目标就是<strong>可理解性</strong>。Raft 将共识问题分解为三个子问题：</p>
<ol>
<li><strong>Leader 选举</strong>：通过随机超时和投票机制选出 Leader</li>
<li><strong>日志复制</strong>：Leader 将日志条目复制到 Follower</li>
<li><strong>安全性</strong>：保证已提交的日志不会被覆盖</li>
</ol>
<h3 id="raft-vs-pacifica">Raft vs PacificA</h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>Raft</th>
<th>PacificA</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Leader 选举</strong></td>
<td>内置（随机超时 + 投票）</td>
<td>外部（Configuration Manager）</td>
</tr>
<tr>
<td><strong>日志复制</strong></td>
<td>Quorum（多数派确认）</td>
<td>Write-All（所有副本确认）</td>
</tr>
<tr>
<td><strong>读取</strong></td>
<td>默认需要经过 Leader</td>
<td>只从 Primary 读取</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>元数据管理、配置存储</td>
<td>数据复制、日志存储</td>
</tr>
<tr>
<td><strong>代表实现</strong></td>
<td>etcd、CockroachDB、TiKV</td>
<td>Elasticsearch、Kafka（ISR 变体）</td>
</tr>
</tbody>
</table>
<p>Raft 更适合<strong>元数据管理</strong>（少量数据、强一致性），而 PacificA 更适合<strong>数据复制</strong>（大量数据、高吞吐）。</p>
<h2 id="参考资料">参考资料</h2>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/publication/pacifica-replication-in-log-based-distributed-storage-systems/">PacificA: Replication in Log-Based Distributed Storage Systems</a></li>
<li><a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html">Elasticsearch 官方文档 - Replication</a></li>
<li><a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/#replication">Kafka 设计文档 - Replication</a></li>
<li><a target="_blank" rel="noopener" href="https://pulsar.apache.org/docs/concepts-architecture-overview/">Apache Pulsar 架构概述</a></li>
<li><a target="_blank" rel="noopener" href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm (Raft)</a></li>
<li><a target="_blank" rel="noopener" href="https://bookkeeper.apache.org/docs/overview/overview/">Apache BookKeeper 官方文档</a></li>
</ul>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://magicliang.github.io">magicliang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://magicliang.github.io/2025/07/29/%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%B6%E6%9E%84/">https://magicliang.github.io/2025/07/29/%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%B6%E6%9E%84/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/">分布式系统</a><a class="post-meta__tags" href="/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/">系统设计</a><a class="post-meta__tags" href="/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/">一致性协议</a></div><div class="post-share"><div class="social-share" data-image="/img/wall-paper-141.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2018/06/06/log-%E7%9A%84%E5%8E%86%E5%8F%B2/" title="log 的历史"><img class="cover" src="/img/wall-paper-120.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-06-06</div><div class="info-item-2">log 的历史</div></div><div class="info-2"><div class="info-item-1">Log：一种被低估的计算机科学基础抽象 在计算机科学中，log（日志）远不止是&quot;打印调试信息&quot;那么简单。从数据库的 WAL 到分布式系统的共识协议，从版本控制系统到区块链，log 作为一种 append-only 的有序记录序列，是贯穿整个计算机科学发展史的核心抽象之一。 LinkedIn 的前首席工程师 Jay Kreps 在其著名文章 “The Log: What every software engineer should know about real-time data’s unifying abstraction” 中指出：log 是一种比消息队列、数据库、文件系统更基础的抽象——后者都可以建立在 log 之上。 本文尝试梳理 log 这一抽象在不同技术领域中的演化脉络。 数据库中的 Log：WAL 与 Binlog WAL（Write-Ahead Logging） WAL 是数据库实现 ACID 特性的基石。其核心思想是：在修改数据页之前，先将修改操作写入日志。 WAL 的工作流程：  事务开始时，将修改操作（redo log entry）追加写...</div></div></div></a><a class="pagination-related" href="/2020/12/16/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8/" title="云原生应用"><img class="cover" src="/img/wall-paper-16.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-16</div><div class="info-item-2">云原生应用</div></div><div class="info-2"><div class="info-item-1">弹性问题  弹性服务最好和监控服务、限流服务配合。 弹性服务的监控最好低于限流服务的阈值，否则不会被触发。 要注意扩容阈值和缩容阈值。如果有必要，设置阶梯阈值，离正常值越远的阶梯越不敏感，离正常值越近的阶梯越敏感。阶梯越远，弹性的量应该越大。 注意弹性有静默期，注意发布和弹性静默期之间是相互矛盾的，要相互关闭。 如果有压测标记，注意让弹性扩容监控包括/排除压测流量。 任务调度或者特殊的有状态的中间件依赖的分布式节点应该尽量避免弹入和弹出。  慢预热服务-扩容机器服务可用性差问题 极少部分依赖缓存预热的业务在接入弹性的过程中，在业务代码配置不合理的情况下，可能出现服务节点启动时服务不可用或性能较差的情况。 出现这种问题可以产生如下情况:  服务节点启动后尚未完全预热，大量流量打入导致服务不可用（TP耗时飙升）。 服务依赖数据源尚未初始化完成，服务节点就已注册至服务治理的命名服务器，开始承担流量，但此时服务处于不可用状态（请求异常）。 机器刚刚扩容出来时cpu.busy指标较高，承接流量后影响服务可用性。  此类问题的根本原因是：服务自身预热工作未完成时，处于服务不可用状态，此时不应...</div></div></div></a><a class="pagination-related" href="/2021/01/29/EBS/" title="EBS 分布式块存储技术解析"><img class="cover" src="/img/wall-paper-45.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-29</div><div class="info-item-2">EBS 分布式块存储技术解析</div></div><div class="info-2"><div class="info-item-1">EBS 的定义 EBS（Elastic Block Storage）是一种高可用、高性能、弹性可扩展的分布式块存储服务。对于业务来说，它就像是一块普通的磁盘——使用方式和访问本地磁盘一样，但数据实际上存储于远端的网络节点上。 EBS 主要应用于以下场景：  有状态容器的状态存储：解决容器重启后数据丢失的问题 海量数据存储：邮件系统、监控平台、数据库、用户录音、集成测试平台、MySQL 备份等  EBS 的文件系统结构 在 EBS 分布式块存储系统中，ChunkServer 是最终存储业务写入数据的核心服务。 核心组件 123456789101112131415161718192021┌─────────────────────────────────────────┐│              Volume (逻辑卷)              ││  ┌─────────┐ ┌─────────┐ ┌─────────┐   ││  │  Chunk  │ │  Chunk  │ │  Chunk  │   ││  │   #1    │ │   #2    │ │   #N...</div></div></div></a><a class="pagination-related" href="/2025/07/13/aws-%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E6%8C%91%E6%88%98/" title="aws 的分布式系统相关挑战"><img class="cover" src="/2025/07/13/aws-%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E6%8C%91%E6%88%98/reply-messaging-across-network.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">aws 的分布式系统相关挑战</div></div><div class="info-2"><div class="info-item-1">原文：《分布式系统相关挑战》 早期的亚马逊系统的相关挑战 当服务器出现到第二台的时候，分布式系统的挑战就出现了：  latencey scalablity 理解网络 API 数据编组和解组 Paxos 算法的复杂性  随着系统的不断快速扩展和分布程度的不断提高，理论上的边缘情况成为了常态。所以小系统不出问题主要是因为分布程度不够高。 开发分布式实用程序计算服务（例如可靠的长途电话网络或 Amazon Web Services (AWS) 服务）比较困难。与其他形式的计算相比，分布式计算也更古怪，而且不够直观，因为它存在两个相互关联的问题。在分布式系统中，造成最大问题的是故障独立性和不确定性。在分布式系统中，除了大多数工程师习以为常的计算故障外，故障还会以许多其他方式出现。更糟糕的是，不可能时刻知晓某事项是否发生了故障。 分布式系统的类型 离线分布式系统  批处理系统 大数据分析集群 电影场景渲染农场 蛋白质折叠集群  这种离线系统没有对 request 和 response 之间的强实时要求。 虽然离线分布式系统实现起来并不容易，但它却几乎囊括了分布式计算的所有优点（可扩展性和容...</div></div></div></a><a class="pagination-related" href="/2026/02/07/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87/" title="一致性哈希与数据分片"><img class="cover" src="/img/wall-paper-147.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-07</div><div class="info-item-2">一致性哈希与数据分片</div></div><div class="info-2"><div class="info-item-1">数据分片的动机 随着互联网应用的快速发展，数据量和访问量呈现爆炸式增长。单机存储系统面临着两个根本性的瓶颈：存储容量和访问性能。 存储容量方面，单台服务器的磁盘空间是有限的。当数据量超过单机容量时，必须寻找横向扩展的解决方案。垂直扩展通过升级硬件配置可以在一定程度上缓解问题，但成本高昂且存在物理上限。更重要的是，单机无法无限扩展，当数据量达到TB甚至PB级别时，垂直扩展已经无法满足需求。 访问性能方面，单机的处理能力同样有限。随着用户数量和请求量的增加，CPU计算能力、内存带宽、磁盘I/O和网络带宽都会成为性能瓶颈。即使单机能够处理当前的负载，也无法保证未来业务的持续增长。 数据分片提供了一种水平扩展的解决方案。通过将数据分散到多台服务器上，每台服务器只存储部分数据并处理部分请求，从而实现存储容量和访问性能的线性扩展。这种架构具有更好的可扩展性，可以根据业务增长灵活地增加服务器节点。 朴素哈希分片 朴素哈希分片是最直观的数据分片方案。其核心思想是：对于给定的数据键key，通过哈希函数计算其哈希值，然后对节点数量N取模，确定该数据应该存储在哪个节点。 1node_index = h...</div></div></div></a><a class="pagination-related" href="/2020/07/12/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95/" title="软件方法"><img class="cover" src="/2020/07/12/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95/%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-12</div><div class="info-item-2">软件方法</div></div><div class="info-2"><div class="info-item-1">建模带来竞争优势。 前言  “唱曲的名家，唱到极快处，吐字依然干净利落”。 不能站在别人的肩膀上看得更远，只是摘抄别人的观点，无意义。要有足够的积累，和深度的思考。 涉众（stakeholder）往往会做而不会定义，把不同类型的涉众放在一起访谈时，只会剩下在场军衔最高那个人的意见。 需求变更的时候，要注意涉众利益角度分析。 项目的流程步骤：  寻找老大 揣摩愿景 业务建模 系统用例 需求规约 分析模型 设计开发   只有一个领域（核心域）的知识是系统能在市场上生存的理由。 拿来主义要摒除门户之见，不关注流派和风格，着力于细节和应用。  建模与 uml 利润 = 需求 - 设计 需求：提升销售 设计：降低开发维护成本 几种弊习：  从需求直接映射设计，会得到大量的重复代码。 从设计出发来定义需求，会得到一堆假的“需求”。  从涉众视角对系统功能分包会得到需求包。 子系统是基于内部视角根据系统部件的耦合和内聚情况进行切割。    需求 设计     卖的视角 做的视角   具体 抽象   产品当项目做 项目当产品做   设计源于需求，高于需求     建模工作流  业务建模：描述组织...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6"><span class="toc-number">1.</span> <span class="toc-text">引言：为什么需要副本复制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="toc-number">1.1.</span> <span class="toc-text">数据可靠性与高可用性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cap-%E5%AE%9A%E7%90%86%E7%9A%84%E5%AE%9E%E9%99%85%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.</span> <span class="toc-text">CAP 定理的实际影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8C%91%E6%88%98"><span class="toc-number">1.3.</span> <span class="toc-text">副本复制的核心挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-1-%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E7%9A%84%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA"><span class="toc-number">2.</span> <span class="toc-text">Part 1: 副本复制的基础理论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6-vs-%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6"><span class="toc-number">2.1.</span> <span class="toc-text">同步复制 vs 异步复制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">主从复制的三种模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#quorum-%E6%9C%BA%E5%88%B6"><span class="toc-number">2.3.</span> <span class="toc-text">Quorum 机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98"><span class="toc-number">2.4.</span> <span class="toc-text">脑裂问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-2-pacifica-%E5%8D%8F%E8%AE%AE"><span class="toc-number">3.</span> <span class="toc-text">Part 2: PacificA 协议</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E8%83%8C%E6%99%AF"><span class="toc-number">3.1.</span> <span class="toc-text">论文背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84"><span class="toc-number">3.2.</span> <span class="toc-text">核心架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#write-all-%E5%BC%BA%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%AD%E4%B9%89"><span class="toc-number">3.3.</span> <span class="toc-text">Write-All 强一致性语义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B%E4%B8%8E-primary-%E5%88%87%E6%8D%A2"><span class="toc-number">3.4.</span> <span class="toc-text">故障检测与 Primary 切换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6%E4%B8%8E%E8%BF%BD%E8%B5%B6%E6%9C%BA%E5%88%B6"><span class="toc-number">3.5.</span> <span class="toc-text">日志复制与追赶机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reconfiguration-%E5%8D%8F%E8%AE%AE%E7%BB%86%E8%8A%82"><span class="toc-number">3.6.</span> <span class="toc-text">Reconfiguration 协议细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9%E4%B8%8E%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">3.7.</span> <span class="toc-text">优点与局限性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-3-elasticsearch"><span class="toc-number">4.</span> <span class="toc-text">Part 3: Elasticsearch</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%89%87%E4%B8%8E%E5%89%AF%E6%9C%AC%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">分片与副本模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#master-node-%E7%9A%84%E8%81%8C%E8%B4%A3%E4%B8%8E%E9%80%89%E4%B8%BE"><span class="toc-number">4.2.</span> <span class="toc-text">Master Node 的职责与选举</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B"><span class="toc-number">4.3.</span> <span class="toc-text">写入流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#translog-%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">4.4.</span> <span class="toc-text">Translog 的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#segment-%E5%90%88%E5%B9%B6%E4%B8%8E-refresh"><span class="toc-number">4.5.</span> <span class="toc-text">Segment 合并与 Refresh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sequence-number-%E5%92%8C-primary-term-%E6%9C%BA%E5%88%B6"><span class="toc-number">4.6.</span> <span class="toc-text">Sequence Number 和 Primary Term 机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#es-%E5%AF%B9-pacifica-%E7%9A%84%E5%8F%98%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.7.</span> <span class="toc-text">ES 对 PacificA 的变体实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-4-kafka"><span class="toc-number">5.</span> <span class="toc-text">Part 4: Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#partition-%E4%B8%8E-replica"><span class="toc-number">5.1.</span> <span class="toc-text">Partition 与 Replica</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#isr-%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3"><span class="toc-number">5.2.</span> <span class="toc-text">ISR 机制详解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#replica-lag-time-max-ms-%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98%E5%BB%BA%E8%AE%AE"><span class="toc-number">5.2.1.</span> <span class="toc-text">replica.lag.time.max.ms 参数调优建议</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#acks-%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">5.3.</span> <span class="toc-text">acks 参数的三种模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#controller-%E7%9A%84%E8%A7%92%E8%89%B2"><span class="toc-number">5.4.</span> <span class="toc-text">Controller 的角色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#unclean-leader-election"><span class="toc-number">5.5.</span> <span class="toc-text">Unclean Leader Election</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kraft-%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8E%BB-zookeeper-%E5%8C%96"><span class="toc-number">5.6.</span> <span class="toc-text">KRaft 模式：去 ZooKeeper 化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%B0%B4%E4%BD%8D%E4%B8%8E-leader-epoch"><span class="toc-number">5.7.</span> <span class="toc-text">高水位与 Leader Epoch</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-5-pulsar"><span class="toc-number">6.</span> <span class="toc-text">Part 5: Pulsar</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%98%E7%AE%97%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84"><span class="toc-number">6.1.</span> <span class="toc-text">存算分离架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ledger-%E4%B8%8E-fragment"><span class="toc-number">6.2.</span> <span class="toc-text">Ledger 与 Fragment</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bookie-ensemble-%E7%9A%84%E5%86%99%E5%85%A5%E6%9C%BA%E5%88%B6"><span class="toc-number">6.3.</span> <span class="toc-text">Bookie Ensemble 的写入机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#journal-%E4%B8%8E-ledger-storage-%E5%88%86%E7%A6%BB%E8%AE%BE%E8%AE%A1"><span class="toc-number">6.4.</span> <span class="toc-text">Journal 与 Ledger Storage 分离设计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#journal-%E9%A2%84%E5%86%99%E6%97%A5%E5%BF%97"><span class="toc-number">6.4.1.</span> <span class="toc-text">Journal（预写日志）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ledger-storage-%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6"><span class="toc-number">6.4.2.</span> <span class="toc-text">Ledger Storage（数据文件）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="toc-number">6.4.3.</span> <span class="toc-text">性能优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#broker-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D"><span class="toc-number">6.5.</span> <span class="toc-text">Broker 故障恢复</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bookie-%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D"><span class="toc-number">6.6.</span> <span class="toc-text">Bookie 故障恢复</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8"><span class="toc-number">6.7.</span> <span class="toc-text">分层存储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-6-%E6%A8%AA%E5%90%91%E5%AF%B9%E6%AF%94%E4%B8%8E%E9%80%89%E5%9E%8B%E6%8C%87%E5%8D%97"><span class="toc-number">7.</span> <span class="toc-text">Part 6: 横向对比与选型指南</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E5%AF%B9%E6%AF%94%E8%A1%A8"><span class="toc-number">7.1.</span> <span class="toc-text">完整对比表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E5%9E%8B%E5%BB%BA%E8%AE%AE"><span class="toc-number">7.2.</span> <span class="toc-text">选型建议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95%EF%BC%9Araft-%E4%B8%8E-paxos-%E7%AE%80%E4%BB%8B"><span class="toc-number">8.</span> <span class="toc-text">附录：Raft 与 Paxos 简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-raft-%E6%AF%94-paxos-%E6%9B%B4%E6%B5%81%E8%A1%8C"><span class="toc-number">8.1.</span> <span class="toc-text">为什么 Raft 比 Paxos 更流行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#raft-vs-pacifica"><span class="toc-number">8.2.</span> <span class="toc-text">Raft vs PacificA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">9.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2017 - 2026 By magicliang</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">簡</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.2"></script><script src="/js/main.js?v=5.5.2"></script><script src="/js/tw_cn.js?v=5.5.2"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="/"></script></div></body></html>