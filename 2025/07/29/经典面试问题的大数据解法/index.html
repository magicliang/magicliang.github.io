<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>经典面试问题的大数据解法——Spark 与 Flink 实战 | 守株阁</title><meta name="author" content="magicliang"><meta name="copyright" content="magicliang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="“100 亿个数中找出最大的 1000 个”、“两个 10GB 的文件找出共同的 URL”——这些经典面试题的本质都是内存放不下。本文将系统性地梳理大数据场景下的 TopK、排序、去重、词频统计等经典问题，给出从单机到分布式（Spark&#x2F;Flink）的完整解法。  引言：大数据问题的共同特征 为什么&quot;内存放不下&quot;    数据规模 内存需求 典型服务器内存 能否放入内存">
<meta property="og:type" content="article">
<meta property="og:title" content="经典面试问题的大数据解法——Spark 与 Flink 实战">
<meta property="og:url" content="https://magicliang.github.io/2025/07/29/%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%B3%95/index.html">
<meta property="og:site_name" content="守株阁">
<meta property="og:description" content="“100 亿个数中找出最大的 1000 个”、“两个 10GB 的文件找出共同的 URL”——这些经典面试题的本质都是内存放不下。本文将系统性地梳理大数据场景下的 TopK、排序、去重、词频统计等经典问题，给出从单机到分布式（Spark&#x2F;Flink）的完整解法。  引言：大数据问题的共同特征 为什么&quot;内存放不下&quot;    数据规模 内存需求 典型服务器内存 能否放入内存">
<meta property="og:locale">
<meta property="og:image" content="https://magicliang.github.io/img/wall-paper-65.jpg">
<meta property="article:published_time" content="2025-07-29T07:05:34.000Z">
<meta property="article:modified_time" content="2026-02-07T06:15:52.308Z">
<meta property="article:author" content="magicliang">
<meta property="article:tag" content="Flink">
<meta property="article:tag" content="Spark">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="面试">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://magicliang.github.io/img/wall-paper-65.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "经典面试问题的大数据解法——Spark 与 Flink 实战",
  "url": "https://magicliang.github.io/2025/07/29/%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%B3%95/",
  "image": "https://magicliang.github.io/img/wall-paper-65.jpg",
  "datePublished": "2025-07-29T07:05:34.000Z",
  "dateModified": "2026-02-07T06:15:52.308Z",
  "author": [
    {
      "@type": "Person",
      "name": "magicliang",
      "url": "https://magicliang.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://magicliang.github.io/2025/07/29/%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%B3%95/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: magicliang","link":"Link: ","source":"Source: 守株阁","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '经典面试问题的大数据解法——Spark 与 Flink 实战',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"><link rel="alternate" href="/atom.xml" title="守株阁" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      if ($loadingBox.classList.contains('loaded')) return
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()

  if (document.readyState === 'complete') {
    preloader.endLoading()
  } else {
    window.addEventListener('load', preloader.endLoading)
    document.addEventListener('DOMContentLoaded', preloader.endLoading)
    // Add timeout protection: force end after 7 seconds
    setTimeout(preloader.endLoading, 7000)
  }

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/wall-paper-65.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">守株阁</span></a><a class="nav-page-title" href="/"><span class="site-name">经典面试问题的大数据解法——Spark 与 Flink 实战</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">经典面试问题的大数据解法——Spark 与 Flink 实战</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-07-29T07:05:34.000Z" title="Created 2025-07-29 15:05:34">2025-07-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-07T06:15:52.308Z" title="Updated 2026-02-07 14:15:52">2026-02-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">4.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>19mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>“100 亿个数中找出最大的 1000 个”、“两个 10GB 的文件找出共同的 URL”——这些经典面试题的本质都是<strong>内存放不下</strong>。本文将系统性地梳理大数据场景下的 TopK、排序、去重、词频统计等经典问题，给出从单机到分布式（Spark/Flink）的完整解法。</p>
<hr>
<h2 id="引言：大数据问题的共同特征">引言：大数据问题的共同特征</h2>
<h3 id="为什么-内存放不下">为什么&quot;内存放不下&quot;</h3>
<table>
<thead>
<tr>
<th>数据规模</th>
<th>内存需求</th>
<th>典型服务器内存</th>
<th>能否放入内存</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 亿个 int</td>
<td>400 MB</td>
<td>16 GB</td>
<td>✅</td>
</tr>
<tr>
<td>10 亿个 int</td>
<td>4 GB</td>
<td>16 GB</td>
<td>✅</td>
</tr>
<tr>
<td>100 亿个 int</td>
<td>40 GB</td>
<td>16 GB</td>
<td>❌</td>
</tr>
<tr>
<td>10 亿个 URL（平均 100 字节）</td>
<td>100 GB</td>
<td>16 GB</td>
<td>❌</td>
</tr>
</tbody>
</table>
<h3 id="通用解题框架">通用解题框架</h3>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">大数据问题<br>    │<br>    ▼<br>能否放入内存？<br>    ├── 能 → 直接用内存数据结构解决<br>    │<br>    ▼<br>    不能 → 分而治之<br>    │<br>    ├── <span class="hljs-number">1.</span> 分区（<span class="hljs-built_in">Partition</span>）：按哈希<span class="hljs-operator">/</span>范围将数据分成小块<br>    ├── <span class="hljs-number">2.</span> 局部处理：每个小块在内存中处理<br>    └── <span class="hljs-number">3.</span> 合并（<span class="hljs-built_in">Merge</span>）：合并各小块的结果<br></code></pre></td></tr></table></figure>
<h3 id="算法的衍生关系">算法的衍生关系</h3>
<pre><code class="hljs mermaid">graph TD
    DivideConquer[分治法] --&gt; ExternalSort[外部排序]
    DivideConquer --&gt; HashPartition[哈希分区]
    DivideConquer --&gt; MapReduce[MapReduce]

    ExternalSort --&gt; MergeSort[归并排序]
    ExternalSort --&gt; TopK_Sort[TopK 排序]

    HashPartition --&gt; Dedup[去重]
    HashPartition --&gt; WordCount[词频统计]
    HashPartition --&gt; CommonURL[共同 URL]

    MapReduce --&gt; Spark[Spark RDD]
    MapReduce --&gt; Flink[Flink DataStream]

    Heap[堆] --&gt; TopK_Heap[TopK 堆解法]
    BloomFilter[布隆过滤器] --&gt; Dedup_Bloom[近似去重]
    CountMinSketch[Count-Min Sketch] --&gt; FreqEstimate[频率估计]</code></pre>
<hr>
<h2 id="part-1-topk-问题">Part 1: TopK 问题</h2>
<h3 id="问题描述">问题描述</h3>
<blockquote>
<p>100 亿个整数，找出最大的 1000 个。</p>
</blockquote>
<h3 id="解法一：最小堆-单机-内存足够时">解法一：最小堆（单机，内存足够时）</h3>
<p>维护一个大小为 K 的<strong>最小堆</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span>[] topK(<span class="hljs-type">int</span>[] data, <span class="hljs-type">int</span> k) &#123;<br>    PriorityQueue&lt;Integer&gt; minHeap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">PriorityQueue</span>&lt;&gt;(k);<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num : data) &#123;<br>        <span class="hljs-keyword">if</span> (minHeap.size() &lt; k) &#123;<br>            minHeap.offer(num);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (num &gt; minHeap.peek()) &#123;<br>            minHeap.poll();<br>            minHeap.offer(num);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> minHeap.stream().mapToInt(Integer::intValue).toArray();<br>&#125;<br></code></pre></td></tr></table></figure>
<ul>
<li><strong>时间复杂度</strong>：O(N × log K)</li>
<li><strong>空间复杂度</strong>：O(K)</li>
<li><strong>优势</strong>：只需要 O(K) 的内存，K=1000 时只需要几 KB</li>
</ul>
<h3 id="解法二：分区-堆-单机-内存不够时">解法二：分区 + 堆（单机，内存不够时）</h3>
<p>当数据在磁盘上时：</p>
<ol>
<li>将 100 亿个数分成 1000 个文件（每个文件 1000 万个数）</li>
<li>对每个文件用最小堆找出 Top 1000</li>
<li>合并 1000 个文件的 Top 1000（共 100 万个数），再用最小堆找出最终 Top 1000</li>
</ol>
<h3 id="解法三：快速选择算法-quickselect">解法三：快速选择算法（QuickSelect）</h3>
<p>基于快速排序的分区思想，平均 O(N) 时间找到第 K 大的元素：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">quickSelect</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right, <span class="hljs-type">int</span> k)</span> &#123;<br>    <span class="hljs-keyword">if</span> (left == right) <span class="hljs-keyword">return</span> arr[left];<br><br>    <span class="hljs-type">int</span> <span class="hljs-variable">pivotIndex</span> <span class="hljs-operator">=</span> partition(arr, left, right);<br>    <span class="hljs-type">int</span> <span class="hljs-variable">rank</span> <span class="hljs-operator">=</span> pivotIndex - left + <span class="hljs-number">1</span>;<br><br>    <span class="hljs-keyword">if</span> (rank == k) &#123;<br>        <span class="hljs-keyword">return</span> arr[pivotIndex];<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (rank &gt; k) &#123;<br>        <span class="hljs-keyword">return</span> quickSelect(arr, left, pivotIndex - <span class="hljs-number">1</span>, k);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">return</span> quickSelect(arr, pivotIndex + <span class="hljs-number">1</span>, right, k - rank);<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">partition</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span> &#123;<br>    <span class="hljs-comment">// 随机选择 pivot，避免最坏情况</span><br>    <span class="hljs-type">int</span> <span class="hljs-variable">randomIndex</span> <span class="hljs-operator">=</span> left + ThreadLocalRandom.current().nextInt(right - left + <span class="hljs-number">1</span>);<br>    swap(arr, randomIndex, right);<br><br>    <span class="hljs-type">int</span> <span class="hljs-variable">pivot</span> <span class="hljs-operator">=</span> arr[right];<br>    <span class="hljs-type">int</span> <span class="hljs-variable">storeIndex</span> <span class="hljs-operator">=</span> left;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> left; i &lt; right; i++) &#123;<br>        <span class="hljs-keyword">if</span> (arr[i] &gt;= pivot) &#123;  <span class="hljs-comment">// 降序排列，找最大的 K 个</span><br>            swap(arr, i, storeIndex);<br>            storeIndex++;<br>        &#125;<br>    &#125;<br>    swap(arr, storeIndex, right);<br>    <span class="hljs-keyword">return</span> storeIndex;<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">swap</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j)</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">temp</span> <span class="hljs-operator">=</span> arr[i];<br>    arr[i] = arr[j];<br>    arr[j] = temp;<br>&#125;<br></code></pre></td></tr></table></figure>
<ul>
<li><strong>平均时间复杂度</strong>：O(N)</li>
<li><strong>最坏时间复杂度</strong>：O(N²)（通过随机化 pivot 避免）</li>
<li><strong>空间复杂度</strong>：O(1)（原地操作）</li>
</ul>
<h3 id="解法四：spark-分布式-topk">解法四：Spark 分布式 TopK</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> topK = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/numbers.txt&quot;</span>)<br>  .map(_.toLong)<br>  .top(<span class="hljs-number">1000</span>)  <span class="hljs-comment">// 内部使用 BoundedPriorityQueue</span><br></code></pre></td></tr></table></figure>
<p>Spark 的 <code>top(K)</code> 内部实现：</p>
<ol>
<li>每个 Partition 维护一个大小为 K 的最小堆</li>
<li>在 Shuffle 阶段合并各 Partition 的堆</li>
<li>最终 Driver 端合并得到全局 Top K</li>
</ol>
<h3 id="解法五：flink-流式-topk">解法五：Flink 流式 TopK</h3>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStream&lt;Long&gt; numbers = env.readTextFile(<span class="hljs-string">&quot;hdfs:///data/numbers.txt&quot;</span>)<br>    .map(Long::parseLong);<br><br>numbers<br>    .windowAll(TumblingProcessingTimeWindows.of(Time.minutes(<span class="hljs-number">1</span>)))<br>    .process(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TopKProcessFunction</span>(<span class="hljs-number">1000</span>))<br>    .print();<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TopKProcessFunction</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">ProcessAllWindowFunction</span>&lt;Long, String, TimeWindow&gt; &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> k;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">TopKProcessFunction</span><span class="hljs-params">(<span class="hljs-type">int</span> k)</span> &#123;<br>        <span class="hljs-built_in">this</span>.k = k;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">process</span><span class="hljs-params">(Context context, Iterable&lt;Long&gt; elements, Collector&lt;String&gt; out)</span> &#123;<br>        PriorityQueue&lt;Long&gt; minHeap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">PriorityQueue</span>&lt;&gt;(k);<br>        <span class="hljs-keyword">for</span> (Long element : elements) &#123;<br>            <span class="hljs-keyword">if</span> (minHeap.size() &lt; k) &#123;<br>                minHeap.offer(element);<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (element &gt; minHeap.peek()) &#123;<br>                minHeap.poll();<br>                minHeap.offer(element);<br>            &#125;<br>        &#125;<br>        out.collect(<span class="hljs-string">&quot;TopK: &quot;</span> + minHeap);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<hr>
<h2 id="part-2-外部排序">Part 2: 外部排序</h2>
<h3 id="问题描述">问题描述</h3>
<blockquote>
<p>对一个 100GB 的文件进行排序，可用内存只有 1GB。</p>
</blockquote>
<h3 id="外部归并排序算法">外部归并排序算法</h3>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">Phase 1: 分割与排序（Sort Phase）<br>┌──────────────────────────────────────────────┐<br>│ 100GB 文件                                    │<br>│ ┌─────┐ ┌─────┐ ┌─────┐     ┌─────┐         │<br>│ │ 1GB │ │ 1GB │ │ 1GB │ <span class="hljs-string">...</span> │ 1GB │  共100块  │<br>│ └──┬──┘ └──┬──┘ └──┬──┘     └──┬──┘         │<br>│    │       │       │           │              │<br>│    ▼       ▼       ▼           ▼              │<br>│ 内存排序 内存排序 内存排序   内存排序           │<br>│    │       │       │           │              │<br>│    ▼       ▼       ▼           ▼              │<br>│ 有序块1 有序块2 有序块3 <span class="hljs-string">...</span> 有序块100          │<br>└──────────────────────────────────────────────┘<br><br>Phase 2: 多路归并（Merge Phase）<br>┌──────────────────────────────────────────────┐<br>│ 100 个有序块                                   │<br>│    │       │       │           │              │<br>│    ▼       ▼       ▼           ▼              │<br>│ ┌─────────────────────────────────┐           │<br>│ │     100 路归并（最小堆）          │           │<br>│ │  每个块读入一个缓冲区（~10MB）    │           │<br>│ └──────────────┬──────────────────┘           │<br>│                │                              │<br>│                ▼                              │<br>│         排序后的 100GB 文件                     │<br>└──────────────────────────────────────────────┘<br></code></pre></td></tr></table></figure>
<h3 id="多路归并的实现">多路归并的实现</h3>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">externalMergeSort</span><span class="hljs-params">(List&lt;File&gt; sortedChunks, File output)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>    <span class="hljs-comment">// 最小堆，按每个块的当前最小值排序</span><br>    PriorityQueue&lt;ChunkReader&gt; minHeap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">PriorityQueue</span>&lt;&gt;(<br>        Comparator.comparingLong(ChunkReader::peek)<br>    );<br><br>    <span class="hljs-comment">// 初始化：每个块读入第一个元素</span><br>    <span class="hljs-keyword">for</span> (File chunk : sortedChunks) &#123;<br>        <span class="hljs-type">ChunkReader</span> <span class="hljs-variable">reader</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ChunkReader</span>(chunk);<br>        <span class="hljs-keyword">if</span> (reader.hasNext()) &#123;<br>            minHeap.offer(reader);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">try</span> (<span class="hljs-type">BufferedWriter</span> <span class="hljs-variable">writer</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BufferedWriter</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FileWriter</span>(output))) &#123;<br>        <span class="hljs-keyword">while</span> (!minHeap.isEmpty()) &#123;<br>            <span class="hljs-type">ChunkReader</span> <span class="hljs-variable">smallest</span> <span class="hljs-operator">=</span> minHeap.poll();<br>            writer.write(String.valueOf(smallest.pop()));<br>            writer.newLine();<br><br>            <span class="hljs-keyword">if</span> (smallest.hasNext()) &#123;<br>                minHeap.offer(smallest);  <span class="hljs-comment">// 重新入堆</span><br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                smallest.close();<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="多路归并时间复杂度分析">多路归并时间复杂度分析</h3>
<p>对于 k 路归并排序，设总数据量为 N，内存容量为 M，则：</p>
<ol>
<li>
<p><strong>分割阶段</strong>：</p>
<ul>
<li>分块数量：k = N / M</li>
<li>每块排序时间：O(M log M)</li>
<li>总排序时间：O(N log M)</li>
</ul>
</li>
<li>
<p><strong>归并阶段</strong>：</p>
<ul>
<li>每次从最小堆中取出最小元素：O(log k)</li>
<li>总共需要取出 N 个元素</li>
<li>归并时间：O(N log k)</li>
<li>由于 k = N / M，故归并时间：O(N log(N/M))</li>
</ul>
</li>
<li>
<p><strong>总时间复杂度</strong>：</p>
<ul>
<li>O(N log M) + O(N log(N/M))</li>
<li>当 M = √N 时达到最优：O(N log √N) = O(N log N)</li>
</ul>
</li>
<li>
<p><strong>I/O 复杂度</strong>：</p>
<ul>
<li>每个数据块被读取 2 次（排序时 1 次，归并时 1 次）</li>
<li>总 I/O 次数：2N</li>
</ul>
</li>
</ol>
<h3 id="优化技巧">优化技巧</h3>
<table>
<thead>
<tr>
<th>优化</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>替换选择排序</strong></td>
<td>初始块的大小可以达到内存的 2 倍</td>
</tr>
<tr>
<td><strong>多阶段归并</strong></td>
<td>当块数太多时，分多轮归并（如每轮 10 路）</td>
</tr>
<tr>
<td><strong>异步 I/O</strong></td>
<td>读取下一个缓冲区时，同时处理当前缓冲区</td>
</tr>
<tr>
<td><strong>压缩</strong></td>
<td>对中间文件进行压缩，减少 I/O</td>
</tr>
</tbody>
</table>
<h3 id="spark-的排序">Spark 的排序</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> sorted = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/large_file.txt&quot;</span>)<br>  .map(_.toLong)<br>  .sortBy(identity)<br>  .saveAsTextFile(<span class="hljs-string">&quot;hdfs:///data/sorted_output&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>Spark 的排序使用 <strong>Range Partitioner</strong>：</p>
<ol>
<li><strong>采样</strong>：从数据中采样，确定分区边界</li>
<li><strong>分区</strong>：按范围将数据分配到不同 Partition</li>
<li><strong>局部排序</strong>：每个 Partition 内部排序</li>
<li><strong>输出</strong>：按 Partition 顺序输出，得到全局有序结果</li>
</ol>
<hr>
<h2 id="part-3-去重问题">Part 3: 去重问题</h2>
<h3 id="问题描述">问题描述</h3>
<blockquote>
<p>10 亿个 URL，去除重复的 URL。</p>
</blockquote>
<h3 id="解法一：哈希分区-hashset">解法一：哈希分区 + HashSet</h3>
<ol>
<li>对每个 URL 计算哈希值：<code>hash(url) % 1000</code></li>
<li>将 URL 写入对应的文件（共 1000 个文件）</li>
<li>对每个文件，用 HashSet 去重</li>
<li>合并所有文件的结果</li>
</ol>
<p><strong>关键</strong>：相同的 URL 一定会被分到同一个文件中，所以每个文件可以独立去重。</p>
<h3 id="解法二：布隆过滤器-近似去重">解法二：布隆过滤器（近似去重）</h3>
<p><strong>布隆过滤器（Bloom Filter）</strong> 是一种空间高效的概率数据结构：</p>
<ul>
<li><strong>插入</strong>：将元素通过 K 个哈希函数映射到位数组的 K 个位置，置为 1</li>
<li><strong>查询</strong>：检查 K 个位置是否都为 1</li>
<li><strong>特点</strong>：可能有假阳性（误判存在），但不会有假阴性（不会漏判）</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BloomFilter</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> BitSet bitSet;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> size;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> hashCount;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">BloomFilter</span><span class="hljs-params">(<span class="hljs-type">int</span> expectedElements, <span class="hljs-type">double</span> falsePositiveRate)</span> &#123;<br>        <span class="hljs-built_in">this</span>.size = optimalSize(expectedElements, falsePositiveRate);<br>        <span class="hljs-built_in">this</span>.hashCount = optimalHashCount(size, expectedElements);<br>        <span class="hljs-built_in">this</span>.bitSet = <span class="hljs-keyword">new</span> <span class="hljs-title class_">BitSet</span>(size);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(String element)</span> &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; hashCount; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">hash</span> <span class="hljs-operator">=</span> hash(element, i);<br>            bitSet.set(Math.abs(hash % size));<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">mightContain</span><span class="hljs-params">(String element)</span> &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; hashCount; i++) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">hash</span> <span class="hljs-operator">=</span> hash(element, i);<br>            <span class="hljs-keyword">if</span> (!bitSet.get(Math.abs(hash % size))) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;  <span class="hljs-comment">// 一定不存在</span><br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;  <span class="hljs-comment">// 可能存在（有假阳性概率）</span><br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">hash</span><span class="hljs-params">(String element, <span class="hljs-type">int</span> seed)</span> &#123;<br>        <span class="hljs-keyword">return</span> MurmurHash3.hash32(element.getBytes(), seed);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">optimalSize</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">double</span> p)</span> &#123;<br>        <span class="hljs-keyword">return</span> (<span class="hljs-type">int</span>) (-n * Math.log(p) / (Math.log(<span class="hljs-number">2</span>) * Math.log(<span class="hljs-number">2</span>)));<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">optimalHashCount</span><span class="hljs-params">(<span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n)</span> &#123;<br>        <span class="hljs-keyword">return</span> Math.max(<span class="hljs-number">1</span>, (<span class="hljs-type">int</span>) Math.round((<span class="hljs-type">double</span>) m / n * Math.log(<span class="hljs-number">2</span>)));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p><strong>布隆过滤器的参数推导</strong>：</p>
<p>设 n 为期望插入的元素数量，m 为位数组长度（比特数），k 为哈希函数数量。</p>
<ol>
<li>
<p><strong>误判率计算</strong>：</p>
<ul>
<li>插入 n 个元素后，任意一位仍为 0 的概率：(1 - 1/m)^(kn) ≈ e^(-kn/m)</li>
<li>任意一位为 1 的概率：1 - e^(-kn/m)</li>
<li>查询一个不存在的元素时，k 个哈希位置都为 1 的概率（误判率）：<br>
p = (1 - e^(-kn/m))^k</li>
</ul>
</li>
<li>
<p><strong>最优哈希函数数量</strong>：<br>
对 p 关于 k 求导并令导数为 0，得到：<br>
k = (m/n) × ln 2</p>
</li>
<li>
<p><strong>最优位数组长度</strong>：<br>
将 k 代入误判率公式，给定目标误判率 p，解得：<br>
m = -n × ln p / (ln 2)^2</p>
</li>
<li>
<p><strong>参数选择示例</strong>：</p>
</li>
</ol>
<table>
<thead>
<tr>
<th>元素数量</th>
<th>误判率</th>
<th>位数组大小</th>
<th>哈希函数数</th>
</tr>
</thead>
<tbody>
<tr>
<td>10 亿</td>
<td>1%</td>
<td>1.2 GB</td>
<td>7</td>
</tr>
<tr>
<td>10 亿</td>
<td>0.1%</td>
<td>1.8 GB</td>
<td>10</td>
</tr>
<tr>
<td>10 亿</td>
<td>0.01%</td>
<td>2.4 GB</td>
<td>13</td>
</tr>
</tbody>
</table>
<h3 id="解法三：hyperloglog-近似去重">解法三：HyperLogLog 近似去重</h3>
<p>对于超大规模的去重场景（如亿级 UV 统计），可以使用 <strong>HyperLogLog</strong>：</p>
<p><strong>HyperLogLog 原理</strong>：</p>
<p>HyperLogLog 基于 LogLog 算法，通过观察哈希值的二进制表示中前导零的个数来估计基数。</p>
<ol>
<li>
<p><strong>基本思想</strong>：</p>
<ul>
<li>将每个元素通过哈希函数映射为均匀分布的 32 位或 64 位整数</li>
<li>计算哈希值的二进制表示中前导零的个数 ρ(h(x))</li>
<li>前导零越多，说明哈希值越小，对应的基数越大</li>
<li>使用 2^max(ρ) 作为基数的估计</li>
</ul>
</li>
<li>
<p><strong>调和平均数修正</strong>：</p>
<ul>
<li>LogLog 使用算术平均数，对极端值敏感</li>
<li>HyperLogLog 使用调和平均数，具有更好的鲁棒性</li>
<li>设 m 为桶数量，每个桶记录该桶内元素的最大前导零个数 M[j]</li>
<li>基数估计：<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">E</span> = α_m × m² / (Σ[<span class="hljs-number">1</span>/(<span class="hljs-number">2</span>^M[j])])<br></code></pre></td></tr></table></figure>
其中 α_m 为修正系数：
<ul>
<li>α_m ≈ 0.7213/(1 + 1.079/m)（当 m ≥ 128 时）</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>为什么使用调和平均数</strong>：</p>
<ul>
<li>调和平均数对小值更敏感，能更好地处理哈希冲突</li>
<li>当某个桶的 M[j] 异常大时，调和平均数不会被过度影响</li>
<li>数学上，调和平均数 ≤ 几何平均数 ≤ 算术平均数</li>
<li>对于基数估计，调和平均数提供了更保守且准确的估计</li>
</ul>
</li>
<li>
<p><strong>空间复杂度</strong>：</p>
<ul>
<li>只需 m 个寄存器，每个寄存器 5-6 位</li>
<li>m = 2^16 时，仅需 12KB 内存</li>
<li>可以估计 2^27 个不同元素，误差率约 1.04%</li>
</ul>
</li>
<li>
<p><strong>修正规则</strong>：</p>
<ul>
<li><strong>小范围修正</strong>：当 E &lt; 5m/2 时
<ul>
<li>使用线性计数修正：E’ = m × ln(m/V0)</li>
<li>其中 V0 为 M[j] = 0 的桶数量</li>
</ul>
</li>
<li><strong>大范围修正</strong>：当 E &gt; 2^32/30 时
<ul>
<li>修正上限：E’ = -2^32 × ln(1 - E/2^32)</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="解法四：spark-去重">解法四：Spark 去重</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> uniqueUrls = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/urls.txt&quot;</span>)<br>  .distinct()  <span class="hljs-comment">// 内部使用 reduceByKey</span><br>  .saveAsTextFile(<span class="hljs-string">&quot;hdfs:///data/unique_urls&quot;</span>)<br></code></pre></td></tr></table></figure>
<p><code>distinct()</code> 的内部实现：</p>
<ol>
<li><code>map(x =&gt; (x, null))</code>：将每个元素转为 KV 对</li>
<li><code>reduceByKey((a, b) =&gt; a)</code>：按 Key 去重</li>
<li><code>map(_._1)</code>：提取 Key</li>
</ol>
<hr>
<h2 id="part-4-词频统计">Part 4: 词频统计</h2>
<h3 id="问题描述">问题描述</h3>
<blockquote>
<p>统计 10GB 文本文件中每个单词出现的次数，找出出现次数最多的 100 个单词。</p>
</blockquote>
<h3 id="解法一：哈希分区-hashmap">解法一：哈希分区 + HashMap</h3>
<ol>
<li>逐行读取文件，对每个单词计算 <code>hash(word) % 1000</code></li>
<li>将单词写入对应的文件</li>
<li>对每个文件，用 HashMap 统计词频</li>
<li>对每个文件的结果，用最小堆找出 Top 100</li>
<li>合并 1000 个文件的 Top 100，找出全局 Top 100</li>
</ol>
<h3 id="解法二：mapreduce-经典实现">解法二：MapReduce 经典实现</h3>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs scss">Map 阶段：<br>输入：(&quot;Hello World Hello&quot;) → 输出：(Hello, <span class="hljs-number">1</span>), (World, <span class="hljs-number">1</span>), (Hello, <span class="hljs-number">1</span>)<br><br>Shuffle 阶段：<br>按 Key 分组：(Hello, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]), (World, [<span class="hljs-number">1</span>])<br><br>Reduce 阶段：<br>(Hello, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]) → (Hello, <span class="hljs-number">2</span>)<br>(World, [<span class="hljs-number">1</span>]) → (World, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<h3 id="解法三：spark-wordcount">解法三：Spark WordCount</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> wordCounts = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/text.txt&quot;</span>)<br>  .flatMap(_.split(<span class="hljs-string">&quot;\\s+&quot;</span>))<br>  .map(word =&gt; (word.toLowerCase, <span class="hljs-number">1</span>))<br>  .reduceByKey(_ + _)<br><br><span class="hljs-comment">// 找出 Top 100</span><br><span class="hljs-keyword">val</span> top100 = wordCounts<br>  .top(<span class="hljs-number">100</span>)(<span class="hljs-type">Ordering</span>.by(_._2))<br></code></pre></td></tr></table></figure>
<h3 id="解法四：flink-流式词频统计">解法四：Flink 流式词频统计</h3>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStream&lt;String&gt; text = env.readTextFile(<span class="hljs-string">&quot;hdfs:///data/text.txt&quot;</span>);<br><br>DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCounts = text<br>    .flatMap(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Tokenizer</span>())<br>    .keyBy(value -&gt; value.f0)<br>    .sum(<span class="hljs-number">1</span>);<br><br><span class="hljs-comment">// 窗口 TopK</span><br>wordCounts<br>    .windowAll(TumblingProcessingTimeWindows.of(Time.minutes(<span class="hljs-number">5</span>)))<br>    .process(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TopKWordFunction</span>(<span class="hljs-number">100</span>))<br>    .print();<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Tokenizer</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">FlatMapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt; &#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">flatMap</span><span class="hljs-params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> &#123;<br>        <span class="hljs-keyword">for</span> (String word : value.toLowerCase().split(<span class="hljs-string">&quot;\\s+&quot;</span>)) &#123;<br>            <span class="hljs-keyword">if</span> (!word.isEmpty()) &#123;<br>                out.collect(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple2</span>&lt;&gt;(word, <span class="hljs-number">1</span>));<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="count-min-sketch：近似词频统计">Count-Min Sketch：近似词频统计</h3>
<p>当精确统计内存不够时，可以使用 <strong>Count-Min Sketch</strong>：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs stylus">Count-Min Sketch 结构：<br>┌─────────────────────────────────────┐<br>│ d 个哈希函数 × w 个计数器              │<br>│                                     │<br>│ <span class="hljs-selector-tag">h1</span>: <span class="hljs-selector-attr">[3]</span> <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[5]</span> <span class="hljs-selector-attr">[1]</span> <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[2]</span> <span class="hljs-selector-attr">[0]</span>   │<br>│ <span class="hljs-selector-tag">h2</span>: <span class="hljs-selector-attr">[1]</span> <span class="hljs-selector-attr">[4]</span> <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[3]</span> <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[1]</span>   │<br>│ <span class="hljs-selector-tag">h3</span>: <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[2]</span> <span class="hljs-selector-attr">[1]</span> <span class="hljs-selector-attr">[3]</span> <span class="hljs-selector-attr">[0]</span> <span class="hljs-selector-attr">[4]</span> <span class="hljs-selector-attr">[0]</span>   │<br>│                                     │<br>│ 查询 <span class="hljs-string">&quot;hello&quot;</span> 的频率：                 │<br>│ <span class="hljs-built_in">min</span>(<span class="hljs-selector-tag">h1</span><span class="hljs-selector-attr">[hash1(<span class="hljs-string">&quot;hello&quot;</span>)]</span>,             │<br>│     <span class="hljs-selector-tag">h2</span><span class="hljs-selector-attr">[hash2(<span class="hljs-string">&quot;hello&quot;</span>)]</span>,             │<br>│     <span class="hljs-selector-tag">h3</span><span class="hljs-selector-attr">[hash3(<span class="hljs-string">&quot;hello&quot;</span>)]</span>)             │<br>└─────────────────────────────────────┘<br></code></pre></td></tr></table></figure>
<p><strong>Count-Min Sketch 误差界分析</strong>：</p>
<p>设 d 为哈希函数数量，w 为每行的计数器数量，ε 为误差率，δ 为失败概率。</p>
<ol>
<li>
<p><strong>误差上界推导</strong>：</p>
<ul>
<li>设元素 x 的真实频率为 f，估计频率为 f̂</li>
<li>对于任意哈希函数 hi，计数器 C[hi(x)] 的期望为 f</li>
<li>由于哈希冲突，C[hi(x)] = f + noise，其中 noise ≥ 0</li>
<li>取最小值：f̂ = min(C[h1(x)], …, C[hd(x)])</li>
</ul>
</li>
<li>
<p><strong>参数选择</strong>：</p>
<ul>
<li>宽度 w：控制单次哈希冲突的概率
<ul>
<li>w = ⌈e/ε⌉，其中 e ≈ 2.718</li>
</ul>
</li>
<li>深度 d：控制多次哈希同时冲突的概率
<ul>
<li>d = ⌈ln(1/δ)⌉</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>误差保证</strong>：</p>
<ul>
<li>以至少 1-δ 的概率，对于所有元素 x：<br>
f̂ ≤ f + εN<br>
其中 N 为所有元素的频率总和</li>
</ul>
</li>
<li>
<p><strong>空间复杂度</strong>：</p>
<ul>
<li>总空间：O(d × w) = O((1/ε) × ln(1/δ))</li>
<li>对于 ε = 0.01, δ = 0.01：约 4600 个计数器</li>
</ul>
</li>
<li>
<p><strong>特性</strong>：</p>
<ul>
<li>单调性：频率估计值 ≥ 真实值（只会高估，不会低估）</li>
<li>加性：支持增量更新，适合流式数据</li>
<li>并行性：多个 sketch 可以合并（对应位置相加）</li>
</ul>
</li>
</ol>
<hr>
<h2 id="part-5-共同元素问题">Part 5: 共同元素问题</h2>
<h3 id="问题描述">问题描述</h3>
<blockquote>
<p>两个各有 10 亿个 URL 的文件，找出共同的 URL。</p>
</blockquote>
<h3 id="解法一：哈希分区">解法一：哈希分区</h3>
<ol>
<li>对文件 A 的每个 URL，计算 <code>hash(url) % 1000</code>，写入 A_0, A_1, …, A_999</li>
<li>对文件 B 的每个 URL，计算 <code>hash(url) % 1000</code>，写入 B_0, B_1, …, B_999</li>
<li>对每对 (A_i, B_i)，将 A_i 加载到 HashSet，遍历 B_i 查找交集</li>
<li>合并所有交集</li>
</ol>
<p><strong>关键</strong>：使用相同的哈希函数，相同的 URL 一定在相同编号的文件中。</p>
<h3 id="解法二：排序-归并">解法二：排序 + 归并</h3>
<ol>
<li>对文件 A 和文件 B 分别进行外部排序</li>
<li>使用双指针归并，找出相同的 URL</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> List&lt;String&gt; <span class="hljs-title function_">findCommon</span><span class="hljs-params">(BufferedReader readerA, BufferedReader readerB)</span><br>        <span class="hljs-keyword">throws</span> IOException &#123;<br>    List&lt;String&gt; common = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>    <span class="hljs-type">String</span> <span class="hljs-variable">lineA</span> <span class="hljs-operator">=</span> readerA.readLine();<br>    <span class="hljs-type">String</span> <span class="hljs-variable">lineB</span> <span class="hljs-operator">=</span> readerB.readLine();<br><br>    <span class="hljs-keyword">while</span> (lineA != <span class="hljs-literal">null</span> &amp;&amp; lineB != <span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">cmp</span> <span class="hljs-operator">=</span> lineA.compareTo(lineB);<br>        <span class="hljs-keyword">if</span> (cmp == <span class="hljs-number">0</span>) &#123;<br>            common.add(lineA);<br>            lineA = readerA.readLine();<br>            lineB = readerB.readLine();<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cmp &lt; <span class="hljs-number">0</span>) &#123;<br>            lineA = readerA.readLine();<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            lineB = readerB.readLine();<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> common;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="解法三：spark-交集">解法三：Spark 交集</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> urlsA = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/urls_a.txt&quot;</span>)<br><span class="hljs-keyword">val</span> urlsB = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/urls_b.txt&quot;</span>)<br><br><span class="hljs-keyword">val</span> commonUrls = urlsA.intersection(urlsB)<br>commonUrls.saveAsTextFile(<span class="hljs-string">&quot;hdfs:///data/common_urls&quot;</span>)<br></code></pre></td></tr></table></figure>
<p><code>intersection()</code> 的内部实现：</p>
<ol>
<li>将两个 RDD 都转为 <code>(url, null)</code> 的 KV 对</li>
<li>使用 <code>cogroup</code> 将相同 Key 的数据聚合</li>
<li>过滤出在两个 RDD 中都存在的 Key</li>
</ol>
<hr>
<h2 id="part-6-中位数问题">Part 6: 中位数问题</h2>
<h3 id="问题描述">问题描述</h3>
<blockquote>
<p>100 亿个整数，找出中位数。</p>
</blockquote>
<h3 id="解法一：二分搜索">解法一：二分搜索</h3>
<p>如果数据范围已知（如 32 位整数，范围 0 ~ 2^32-1）：</p>
<ol>
<li>猜测中位数为 mid</li>
<li>扫描所有数据，统计 ≤ mid 的个数 count</li>
<li>如果 count &lt; N/2，说明中位数 &gt; mid，搜索右半部分</li>
<li>如果 count ≥ N/2，说明中位数 ≤ mid，搜索左半部分</li>
<li>重复直到范围缩小到 1</li>
</ol>
<p><strong>时间复杂度</strong>：O(N × log(MAX_VALUE))，对于 32 位整数是 O(32N)。<br>
<strong>空间复杂度</strong>：O(1)。</p>
<h3 id="解法二：分桶计数">解法二：分桶计数</h3>
<ol>
<li>将数据范围分成 65536 个桶（每个桶覆盖 65536 个值）</li>
<li>第一遍扫描：统计每个桶中的元素个数</li>
<li>根据桶的计数，确定中位数在哪个桶中</li>
<li>第二遍扫描：只关注目标桶中的元素，精确找到中位数</li>
</ol>
<p><strong>空间复杂度</strong>：O(桶数量) = O(65536) ≈ 256 KB。</p>
<h3 id="解法三：spark-近似中位数">解法三：Spark 近似中位数</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> numbers = sc.textFile(<span class="hljs-string">&quot;hdfs:///data/numbers.txt&quot;</span>).map(_.toLong)<br><br><span class="hljs-comment">// 精确中位数（需要全局排序，代价高）</span><br><span class="hljs-keyword">val</span> count = numbers.count()<br><span class="hljs-keyword">val</span> median = numbers.sortBy(identity)<br>  .zipWithIndex()<br>  .filter &#123; <span class="hljs-keyword">case</span> (_, index) =&gt; index == count / <span class="hljs-number">2</span> &#125;<br>  .map(_._1)<br>  .first()<br><br><span class="hljs-comment">// 近似中位数（使用采样，更高效）</span><br><span class="hljs-keyword">val</span> approxMedian = numbers.sample(<span class="hljs-literal">false</span>, <span class="hljs-number">0.01</span>).collect().sorted<br><span class="hljs-keyword">val</span> medianApprox = approxMedian(approxMedian.length / <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<hr>
<h2 id="part-7-spark-vs-flink-对比">Part 7: Spark vs Flink 对比</h2>
<h3 id="架构对比">架构对比</h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>Spark</th>
<th>Flink</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>计算模型</strong></td>
<td>微批处理（Micro-Batch）</td>
<td>真正的流处理（Event-by-Event）</td>
</tr>
<tr>
<td><strong>延迟</strong></td>
<td>秒级（批间隔）</td>
<td>毫秒级</td>
</tr>
<tr>
<td><strong>状态管理</strong></td>
<td>有限（需要外部存储）</td>
<td>内置强大的状态管理</td>
</tr>
<tr>
<td><strong>容错</strong></td>
<td>RDD Lineage（重算）</td>
<td>Checkpoint + Savepoint</td>
</tr>
<tr>
<td><strong>窗口</strong></td>
<td>基于批次</td>
<td>灵活的事件时间窗口</td>
</tr>
<tr>
<td><strong>API</strong></td>
<td>RDD / DataFrame / Dataset</td>
<td>DataStream / Table API</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>批处理、ETL、机器学习</td>
<td>实时流处理、CEP</td>
</tr>
</tbody>
</table>
<h3 id="何时选择-spark">何时选择 Spark</h3>
<ul>
<li><strong>批处理 ETL</strong>：大规模数据清洗和转换</li>
<li><strong>机器学习</strong>：MLlib 生态成熟</li>
<li><strong>交互式查询</strong>：Spark SQL 性能优秀</li>
<li><strong>团队熟悉度</strong>：Spark 社区更大，学习资源更多</li>
</ul>
<h3 id="何时选择-flink">何时选择 Flink</h3>
<ul>
<li><strong>实时流处理</strong>：毫秒级延迟要求</li>
<li><strong>复杂事件处理（CEP）</strong>：模式匹配、异常检测</li>
<li><strong>有状态计算</strong>：需要精确的状态管理</li>
<li><strong>事件时间处理</strong>：需要处理乱序事件</li>
</ul>
<h3 id="容错机制对比">容错机制对比</h3>
<p><strong>Spark RDD Lineage</strong>：</p>
<ul>
<li>记录 RDD 的转换链（DAG）</li>
<li>某个 Partition 丢失时，根据 Lineage 重新计算</li>
<li>对于窄依赖，只需重算丢失的 Partition</li>
<li>对于宽依赖（Shuffle），可能需要重算多个 Partition</li>
</ul>
<p><strong>Flink Checkpoint</strong>：</p>
<ul>
<li>基于 Chandy-Lamport 算法的分布式快照</li>
<li>定期将所有算子的状态保存到持久化存储</li>
<li>故障恢复时，从最近的 Checkpoint 恢复</li>
<li>支持 Exactly-Once 语义</li>
</ul>
<hr>
<h2 id="part-8-实际生产中的注意事项">Part 8: 实际生产中的注意事项</h2>
<h3 id="数据倾斜处理">数据倾斜处理</h3>
<p><strong>问题</strong>：某些 Key 的数据量远大于其他 Key，导致个别 Task 处理时间过长。</p>
<p><strong>解决方案</strong>：</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>适用场景</th>
<th>实现方式</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>加盐打散</strong></td>
<td>聚合操作</td>
<td>Key 加随机前缀，两阶段聚合</td>
</tr>
<tr>
<td><strong>广播小表</strong></td>
<td>Join 操作（一大一小）</td>
<td>将小表广播到所有节点</td>
</tr>
<tr>
<td><strong>采样倾斜 Key</strong></td>
<td>Join 操作（都大）</td>
<td>对倾斜 Key 单独处理</td>
</tr>
<tr>
<td><strong>自定义分区器</strong></td>
<td>通用</td>
<td>根据数据分布自定义分区逻辑</td>
</tr>
</tbody>
</table>
<p><strong>Spark 加盐打散示例</strong>：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 原始：直接 reduceByKey 会导致数据倾斜</span><br><span class="hljs-keyword">val</span> result = data.reduceByKey(_ + _)<br><br><span class="hljs-comment">// 优化：两阶段聚合</span><br><span class="hljs-keyword">val</span> salted = data.map &#123; <span class="hljs-keyword">case</span> (key, value) =&gt;<br>  <span class="hljs-keyword">val</span> salt = <span class="hljs-type">ThreadLocalRandom</span>.current().nextInt(<span class="hljs-number">10</span>)<br>  (<span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;salt&#125;</span>_<span class="hljs-subst">$&#123;key&#125;</span>&quot;</span>, value)<br>&#125;<br><br><span class="hljs-keyword">val</span> partialResult = salted.reduceByKey(_ + _)<br><br><span class="hljs-keyword">val</span> finalResult = partialResult.map &#123; <span class="hljs-keyword">case</span> (saltedKey, value) =&gt;<br>  <span class="hljs-keyword">val</span> originalKey = saltedKey.split(<span class="hljs-string">&quot;_&quot;</span>, <span class="hljs-number">2</span>)(<span class="hljs-number">1</span>)<br>  (originalKey, value)<br>&#125;.reduceByKey(_ + _)<br></code></pre></td></tr></table></figure>
<h3 id="资源调优">资源调优</h3>
<table>
<thead>
<tr>
<th>参数</th>
<th>Spark</th>
<th>Flink</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>并行度</strong></td>
<td><code>spark.default.parallelism</code></td>
<td><code>parallelism.default</code></td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td><code>spark.executor.memory</code></td>
<td><code>taskmanager.memory.process.size</code></td>
</tr>
<tr>
<td><strong>Shuffle</strong></td>
<td><code>spark.shuffle.file.buffer</code></td>
<td><code>taskmanager.network.memory.fraction</code></td>
</tr>
</tbody>
</table>
<hr>
<h2 id="总结">总结</h2>
<table>
<thead>
<tr>
<th>问题类型</th>
<th>单机解法</th>
<th>分布式解法</th>
<th>近似解法</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TopK</strong></td>
<td>最小堆 O(N log K)</td>
<td>Spark top(K)</td>
<td>—</td>
</tr>
<tr>
<td><strong>排序</strong></td>
<td>外部归并排序</td>
<td>Spark sortBy</td>
<td>—</td>
</tr>
<tr>
<td><strong>去重</strong></td>
<td>哈希分区 + HashSet</td>
<td>Spark distinct</td>
<td>布隆过滤器</td>
</tr>
<tr>
<td><strong>词频统计</strong></td>
<td>哈希分区 + HashMap</td>
<td>Spark reduceByKey</td>
<td>Count-Min Sketch</td>
</tr>
<tr>
<td><strong>共同元素</strong></td>
<td>哈希分区 + HashSet</td>
<td>Spark intersection</td>
<td>布隆过滤器</td>
</tr>
<tr>
<td><strong>中位数</strong></td>
<td>二分搜索 / 分桶</td>
<td>Spark sortBy + zipWithIndex</td>
<td>采样</td>
</tr>
</tbody>
</table>
<p><strong>核心思想</strong>：<strong>分而治之</strong>——将大问题分解为内存可处理的小问题，然后合并结果。</p>
<h2 id="参考资料">参考资料</h2>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/">Spark 官方文档</a></li>
<li><a target="_blank" rel="noopener" href="https://flink.apache.org/docs/stable/">Flink 官方文档</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filter - Wikipedia</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch">Count-Min Sketch - Wikipedia</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/External_sorting">External Sorting - Wikipedia</a></li>
</ul>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://magicliang.github.io">magicliang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://magicliang.github.io/2025/07/29/%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%B3%95/">https://magicliang.github.io/2025/07/29/%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%B3%95/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/Spark/">Spark</a><a class="post-meta__tags" href="/tags/Flink/">Flink</a><a class="post-meta__tags" href="/tags/%E9%9D%A2%E8%AF%95/">面试</a></div><div class="post-share"><div class="social-share" data-image="/img/wall-paper-65.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2018/01/28/DAG-%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6%E4%BC%98%E4%BA%8E-MapReduce-%E7%9A%84%E5%9C%B0%E6%96%B9%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F/" title="DAG 执行框架优于 MapReduce 的地方在哪里？"><img class="cover" src="/img/wall-paper-149.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-28</div><div class="info-item-2">DAG 执行框架优于 MapReduce 的地方在哪里？</div></div><div class="info-2"><div class="info-item-1">有个同学问我什么是 DAG 框架。我感觉隐隐约约听过，但又讲不清楚它的概念。 上网搜了一下，我们常见的新大数据执行框架如 Spark、Storm，还有一个我没听过的 Tez，都算 DAG 任务执行框架。他们的主要优点是，可以用 DAG 事先通晓整个任务的全部步骤，然后进行转换优化。如 Tez 就可以把多个任务转换为一个大任务，而 Spark 则可以把相关联的 Map 直接串联起来， 免得多次写回 hdfs（看来 hdfs 也很慢）。传统的 MapReduce 框架为什么不能理解这种优化空间的存在，在任务运行的时候好像一个盲人一样，是个很有意思的话题。 Quora 上的一个相关的问答。 </div></div></div></a><a class="pagination-related" href="/2017/12/07/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%87%AA%E5%BB%BA%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0/" title="为什么要自建实时计算平台"><img class="cover" src="/img/wall-paper-125.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2017-12-07</div><div class="info-item-2">为什么要自建实时计算平台</div></div><div class="info-2"><div class="info-item-1">#为什么要自建一个离线平台#  可以优化资源利用率。 业务平台应该把精力放在业务上。  #什么是实时计算#  强调响应时间短（相对于离线计算）：毫秒级、亚秒级、秒级。T+1 的报表都是离线计算。 数据的价值随着时间的流逝而迅速降低。 常见技术方案： 流计算 + 实时存储 or 消息队列 流计算 + 实现 OLAP  #什么是流式计算#  实时且无界。 数据驱动计算，事件触发。 有状态及持续集成。 流计算引擎：Spark Streaming、Flink Streaming、Storm/JStorm、Samza 等。  #Spark Streaming 模型#  Micro-Batch 模式。看起来是流式处理的，实际上还是一小批一小批处理的。从批处理走到流处理。 最小延时：batch 的处理时间 最大延时：batch interval（通常2s-10s） + batch 处理时间。 使用场景：数据清洗（实时数据通道）、数据 ETL 等。 对于熟悉 Spark 批处理的 RD 非常容易上手。  #Flink Streaming#  Native Streaming。 低延时，通常在毫秒...</div></div></div></a><a class="pagination-related" href="/2024/01/22/datawarehouse%E7%9B%B8%E5%85%B3/" title="datawarehouse相关"><img class="cover" src="/img/wall-paper-1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-22</div><div class="info-item-2">datawarehouse相关</div></div><div class="info-2"><div class="info-item-1">    </div></div></div></a><a class="pagination-related" href="/2024/04/28/%E4%B8%8D%E5%B8%B8%E8%A7%81%E7%9A%84-SQL/" title="不常见的 SQL"><img class="cover" src="/img/wall-paper-97.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-28</div><div class="info-item-2">不常见的 SQL</div></div><div class="info-2"><div class="info-item-1">窗口函数 OVER OVER用于为行定义一个窗口，它对一组值进行操作，不需要使用GROUP BY 子句对数据进行分组，能够在同一行中同时返回基础行的原始列和聚合列。 在这里要引入窗口函数/开窗函数（Window Function）的概念： 12345678910111213141516171819202122232425CREATE TABLE Employee(ID INT  PRIMARY KEY,Name VARCHAR(20),GroupName VARCHAR(20),Salary INT)INSERT INTO  EmployeeVALUES(1,&#x27;小明&#x27;,&#x27;开发部&#x27;,8000),      (4,&#x27;小张&#x27;,&#x27;开发部&#x27;,7600),      (5,&#x27;小白&#x27;,&#x27;开发部&#x27;,7000),      (8,&#x27;小王&#x27;,&#x27;财务部&#x27;,5000),      (9, null,&#x27;财务部&#x27;,NULL),  ...</div></div></div></a><a class="pagination-related" href="/2018/01/29/Spark-Standalone-%E6%A8%A1%E5%BC%8F%E5%90%AF%E5%8A%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/" title="Spark Standalone 模式启动的全过程"><img class="cover" src="/img/wall-paper-126.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-29</div><div class="info-item-2">Spark Standalone 模式启动的全过程</div></div><div class="info-2"><div class="info-item-1">把这个事情做成一个小 routine，免得以后每次都要看英文文档来搭 dev 环境 准备工作 下载安装包，解压并进入根目录。 ./sbin/start-master.sh。看 jps 果然已经有了一个 Master 进，文档里面说会打印出 spark 的 master url，但没打印出来。就去默认的http://localhost:8080上看即可： 12URL: spark://magicliang:7077REST URL: spark://magicliang:6066 (cluster mode) 这个6066在本地 telnet 不通，也是很神奇。 把这个 URL 拼接成 worker  的启动命令./start-slave.sh spark://magicliang:7077，然后可以看到以下这张图：  文档里的给出的定义 worker 节点的方法：在 Spark 根目录下定义一个 conf/slaves 的文件，每一行写一个主机名。如果这个文件不存在（就是我们现在这个状况），则 worker 就会全部启动在 localhost 上。而 master 是通过 ssh...</div></div></div></a><a class="pagination-related" href="/2020/04/16/Spark-SQL-%E5%8E%9F%E7%90%86/" title="Spark SQL 原理"><img class="cover" src="/img/wall-paper-93.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-16</div><div class="info-item-2">Spark SQL 原理</div></div><div class="info-2"><div class="info-item-1">Spark SQL的发展历程 为了给熟悉的 RDBMS 但又不理解 MapReduce 的技术人员提供快速上手的工具，Hive 应运而生，他是当时唯一运行在 Hadoop 上的SQL-On-Hadoop 工具。 但是 MapReduce 计算过程中大量的中间磁盘落地过程消耗了大量的 I/O，降低的运行效率，为了提高 SQL 的执行效率，大量的 SQL-On-Hadoop工具开始产生，而 Shark 是其中一个表现较为突出的项目。 Shark是伯克利实验室 Spark 生态环境的组件之一，它主要修改了内存管理，物理计划和执行三个模块，值得它能运行在 Spark 的引擎上，从而提高 SQL 查询的效率。 但是随着 Spark 的发展，Shark 对 Hive 过多的依赖制约了 Spark 的设计理念和各个组件之间的相互继承，所以 Spark 团队停止了对 Shark 的开发，提出了 SparkSQL 项目。 因为摆脱了Hive 的过度依赖，Spark SQL在数据兼容性，性能优化和组件扩展等各个方面都得到了极大的方便和发展。 提出了 SparkSQL 项目之后，SQL On Spar...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98%E7%9A%84%E5%85%B1%E5%90%8C%E7%89%B9%E5%BE%81"><span class="toc-number">1.</span> <span class="toc-text">引言：大数据问题的共同特征</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-%E5%86%85%E5%AD%98%E6%94%BE%E4%B8%8D%E4%B8%8B"><span class="toc-number">1.1.</span> <span class="toc-text">为什么&quot;内存放不下&quot;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E8%A7%A3%E9%A2%98%E6%A1%86%E6%9E%B6"><span class="toc-number">1.2.</span> <span class="toc-text">通用解题框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E7%9A%84%E8%A1%8D%E7%94%9F%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.</span> <span class="toc-text">算法的衍生关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-1-topk-%E9%97%AE%E9%A2%98"><span class="toc-number">2.</span> <span class="toc-text">Part 1: TopK 问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%80%EF%BC%9A%E6%9C%80%E5%B0%8F%E5%A0%86-%E5%8D%95%E6%9C%BA-%E5%86%85%E5%AD%98%E8%B6%B3%E5%A4%9F%E6%97%B6"><span class="toc-number">2.2.</span> <span class="toc-text">解法一：最小堆（单机，内存足够时）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%BA%8C%EF%BC%9A%E5%88%86%E5%8C%BA-%E5%A0%86-%E5%8D%95%E6%9C%BA-%E5%86%85%E5%AD%98%E4%B8%8D%E5%A4%9F%E6%97%B6"><span class="toc-number">2.3.</span> <span class="toc-text">解法二：分区 + 堆（单机，内存不够时）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%89%EF%BC%9A%E5%BF%AB%E9%80%9F%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95-quickselect"><span class="toc-number">2.4.</span> <span class="toc-text">解法三：快速选择算法（QuickSelect）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E5%9B%9B%EF%BC%9Aspark-%E5%88%86%E5%B8%83%E5%BC%8F-topk"><span class="toc-number">2.5.</span> <span class="toc-text">解法四：Spark 分布式 TopK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%BA%94%EF%BC%9Aflink-%E6%B5%81%E5%BC%8F-topk"><span class="toc-number">2.6.</span> <span class="toc-text">解法五：Flink 流式 TopK</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-2-%E5%A4%96%E9%83%A8%E6%8E%92%E5%BA%8F"><span class="toc-number">3.</span> <span class="toc-text">Part 2: 外部排序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">3.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%96%E9%83%A8%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">外部归并排序算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%B7%AF%E5%BD%92%E5%B9%B6%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">多路归并的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%B7%AF%E5%BD%92%E5%B9%B6%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">3.4.</span> <span class="toc-text">多路归并时间复杂度分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7"><span class="toc-number">3.5.</span> <span class="toc-text">优化技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-%E7%9A%84%E6%8E%92%E5%BA%8F"><span class="toc-number">3.6.</span> <span class="toc-text">Spark 的排序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-3-%E5%8E%BB%E9%87%8D%E9%97%AE%E9%A2%98"><span class="toc-number">4.</span> <span class="toc-text">Part 3: 去重问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">4.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%80%EF%BC%9A%E5%93%88%E5%B8%8C%E5%88%86%E5%8C%BA-hashset"><span class="toc-number">4.2.</span> <span class="toc-text">解法一：哈希分区 + HashSet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%BA%8C%EF%BC%9A%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-%E8%BF%91%E4%BC%BC%E5%8E%BB%E9%87%8D"><span class="toc-number">4.3.</span> <span class="toc-text">解法二：布隆过滤器（近似去重）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%89%EF%BC%9Ahyperloglog-%E8%BF%91%E4%BC%BC%E5%8E%BB%E9%87%8D"><span class="toc-number">4.4.</span> <span class="toc-text">解法三：HyperLogLog 近似去重</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E5%9B%9B%EF%BC%9Aspark-%E5%8E%BB%E9%87%8D"><span class="toc-number">4.5.</span> <span class="toc-text">解法四：Spark 去重</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-4-%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1"><span class="toc-number">5.</span> <span class="toc-text">Part 4: 词频统计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">5.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%80%EF%BC%9A%E5%93%88%E5%B8%8C%E5%88%86%E5%8C%BA-hashmap"><span class="toc-number">5.2.</span> <span class="toc-text">解法一：哈希分区 + HashMap</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%BA%8C%EF%BC%9Amapreduce-%E7%BB%8F%E5%85%B8%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.3.</span> <span class="toc-text">解法二：MapReduce 经典实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%89%EF%BC%9Aspark-wordcount"><span class="toc-number">5.4.</span> <span class="toc-text">解法三：Spark WordCount</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E5%9B%9B%EF%BC%9Aflink-%E6%B5%81%E5%BC%8F%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1"><span class="toc-number">5.5.</span> <span class="toc-text">解法四：Flink 流式词频统计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#count-min-sketch%EF%BC%9A%E8%BF%91%E4%BC%BC%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1"><span class="toc-number">5.6.</span> <span class="toc-text">Count-Min Sketch：近似词频统计</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-5-%E5%85%B1%E5%90%8C%E5%85%83%E7%B4%A0%E9%97%AE%E9%A2%98"><span class="toc-number">6.</span> <span class="toc-text">Part 5: 共同元素问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">6.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%80%EF%BC%9A%E5%93%88%E5%B8%8C%E5%88%86%E5%8C%BA"><span class="toc-number">6.2.</span> <span class="toc-text">解法一：哈希分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%BA%8C%EF%BC%9A%E6%8E%92%E5%BA%8F-%E5%BD%92%E5%B9%B6"><span class="toc-number">6.3.</span> <span class="toc-text">解法二：排序 + 归并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%89%EF%BC%9Aspark-%E4%BA%A4%E9%9B%86"><span class="toc-number">6.4.</span> <span class="toc-text">解法三：Spark 交集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-6-%E4%B8%AD%E4%BD%8D%E6%95%B0%E9%97%AE%E9%A2%98"><span class="toc-number">7.</span> <span class="toc-text">Part 6: 中位数问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">7.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%80%EF%BC%9A%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2"><span class="toc-number">7.2.</span> <span class="toc-text">解法一：二分搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%BA%8C%EF%BC%9A%E5%88%86%E6%A1%B6%E8%AE%A1%E6%95%B0"><span class="toc-number">7.3.</span> <span class="toc-text">解法二：分桶计数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E4%B8%89%EF%BC%9Aspark-%E8%BF%91%E4%BC%BC%E4%B8%AD%E4%BD%8D%E6%95%B0"><span class="toc-number">7.4.</span> <span class="toc-text">解法三：Spark 近似中位数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-7-spark-vs-flink-%E5%AF%B9%E6%AF%94"><span class="toc-number">8.</span> <span class="toc-text">Part 7: Spark vs Flink 对比</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94"><span class="toc-number">8.1.</span> <span class="toc-text">架构对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%95%E6%97%B6%E9%80%89%E6%8B%A9-spark"><span class="toc-number">8.2.</span> <span class="toc-text">何时选择 Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%95%E6%97%B6%E9%80%89%E6%8B%A9-flink"><span class="toc-number">8.3.</span> <span class="toc-text">何时选择 Flink</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%E5%AF%B9%E6%AF%94"><span class="toc-number">8.4.</span> <span class="toc-text">容错机制对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#part-8-%E5%AE%9E%E9%99%85%E7%94%9F%E4%BA%A7%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">9.</span> <span class="toc-text">Part 8: 实际生产中的注意事项</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%A4%84%E7%90%86"><span class="toc-number">9.1.</span> <span class="toc-text">数据倾斜处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B5%84%E6%BA%90%E8%B0%83%E4%BC%98"><span class="toc-number">9.2.</span> <span class="toc-text">资源调优</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">10.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">11.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2017 - 2026 By magicliang</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">簡</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.2"></script><script src="/js/main.js?v=5.5.2"></script><script src="/js/tw_cn.js?v=5.5.2"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="/"></script></div></body></html>